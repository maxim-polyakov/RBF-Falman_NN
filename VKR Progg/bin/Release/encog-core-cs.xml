<?xml version="1.0"?>
<doc>
    <assembly>
        <name>encog-core-cs</name>
    </assembly>
    <members>
        <member name="T:Encog.Bot.BotError">
            <summary>
            Indicates an error has occurred in the bot classes.
            </summary>
        </member>
        <member name="M:Encog.Bot.BotError.#ctor(System.String)">
            <summary>
            Construct a message exception.
            </summary>
            <param name="str">The message.</param>
        </member>
        <member name="M:Encog.Bot.BotError.#ctor(System.Exception)">
            <summary>
            Pass on an exception.
            </summary>
            <param name="e">The other exception.</param>
        </member>
        <member name="T:Encog.Bot.BotUtil">
            <summary>
            Utility class for bots.
            </summary>
        </member>
        <member name="F:Encog.Bot.BotUtil.BufferSize">
            <summary>
            How much data to read at once.
            </summary>
        </member>
        <member name="M:Encog.Bot.BotUtil.ExtractFromIndex(System.String,System.String,System.String,System.Int32,System.Int32)">
            <summary>
            This method is very useful for grabbing information from a HTML page.
            </summary>
            <param name="str">The string to search.</param>
            <param name="token1">The text, or tag, that comes before the desired text</param>
            <param name="token2">The text, or tag, that comes after the desired text</param>
            <param name="index">Index in the string to start searching from.</param>
            <param name="occurence">What occurence.</param>
            <returns>The contents of the URL that was downloaded.</returns>
        </member>
        <member name="M:Encog.Bot.BotUtil.Extract(System.String,System.String,System.String,System.Int32)">
            <summary>
            This method is very useful for grabbing information from a HTML page.
            </summary>
            <param name="str">The string to search.</param>
            <param name="token1">The text, or tag, that comes before the desired text.</param>
            <param name="token2">The text, or tag, that comes after the desired text.</param>
            <param name="index">Which occurrence of token1 to use, 1 for the first.</param>
            <returns>The contents of the URL that was downloaded.</returns>
        </member>
        <member name="M:Encog.Bot.BotUtil.POSTPage(System.Uri,System.Collections.Generic.IDictionary{System.String,System.String})">
            <summary>
            Post to a page.
            </summary>
            <param name="uri">The URI to post to.</param>
            <param name="param">The post params.</param>
            <returns>The HTTP response.</returns>
        </member>
        <member name="M:Encog.Bot.BotUtil.POSTPage(System.Uri,System.Byte[],System.Int32)">
            <summary>
            Post bytes to a page.
            </summary>
            <param name="uri">The URI to post to.</param>
            <param name="bytes">The bytes to post.</param>
            <param name="length">The length of the posted data.</param>
            <returns>The HTTP response.</returns>
        </member>
        <member name="M:Encog.Bot.BotUtil.LoadPage(System.Uri)">
            <summary>
            Load the specified web page into a string.
            </summary>
            <param name="url">The url to load.</param>
            <returns>The web page as a string.</returns>
        </member>
        <member name="M:Encog.Bot.BotUtil.#ctor">
            <summary>
            Private constructor.
            </summary>
        </member>
        <member name="M:Encog.Bot.BotUtil.POSTPage(System.Uri,System.IO.Stream)">
            <summary>
            Post to a page.
            </summary>
            <param name="uri">The URI to post to.</param>
            <param name="stream">The stream.</param>
            <returns>The page returned.</returns>
        </member>
        <member name="T:Encog.Bot.Browse.Address">
            <summary>
            A URL address. Holds both the URL object, as well as original text.
            </summary>
        </member>
        <member name="F:Encog.Bot.Browse.Address._original">
            <summary>
            The original text from the address.
            </summary>
        </member>
        <member name="F:Encog.Bot.Browse.Address._url">
            <summary>
            The address as a URL.
            </summary>
        </member>
        <member name="M:Encog.Bot.Browse.Address.#ctor(System.Uri)">
            <summary>
            Construct the address from a URL.
            </summary>
            <param name="u">The URL to use.</param>
        </member>
        <member name="M:Encog.Bot.Browse.Address.#ctor(System.Uri,System.String)">
            <summary>
            Construct a URL using a perhaps relative URL and a base URL.
            </summary>
            <param name="b">The base URL.</param>
            <param name="original">A full URL or a URL relative to the base.</param>
        </member>
        <member name="P:Encog.Bot.Browse.Address.Original">
            <summary>
            The original text from this URL.
            </summary>
        </member>
        <member name="P:Encog.Bot.Browse.Address.Url">
            <summary>
            The URL.
            </summary>
        </member>
        <member name="M:Encog.Bot.Browse.Address.ToString">
            <summary>
            The object as a string.
            </summary>
            <returns></returns>
        </member>
        <member name="T:Encog.Bot.Browse.BrowseError">
            <summary>
            Indicates an error has occurred in the browse classes.
            </summary>
        </member>
        <member name="M:Encog.Bot.Browse.BrowseError.#ctor(System.String)">
            <summary>
            Construct a message exception.
            </summary>
            <param name="str">The message.</param>
        </member>
        <member name="M:Encog.Bot.Browse.BrowseError.#ctor(System.Exception)">
            <summary>
            Pass on an exception.
            </summary>
            <param name="e">The other exception.</param>
        </member>
        <member name="T:Encog.Bot.Browse.Browser">
            <summary>
            The main class for web browsing. This class allows you to navigate to a
            specific URL. Once you navigate to one URL, you can naviage to any URL
            contained on the page.
            </summary>
        </member>
        <member name="F:Encog.Bot.Browse.Browser._currentPage">
            <summary>
            The page that is currently being browsed.
            </summary>
        </member>
        <member name="P:Encog.Bot.Browse.Browser.CurrentPage">
            <summary>
            The page currently being browsed.
            </summary>
        </member>
        <member name="M:Encog.Bot.Browse.Browser.Navigate(Encog.Bot.Browse.Range.Form)">
            <summary>
            Navigate to the specified form by performing a submit of that form.
            </summary>
            <param name="form">The form to be submitted.</param>
        </member>
        <member name="M:Encog.Bot.Browse.Browser.Navigate(Encog.Bot.Browse.Range.Form,Encog.Bot.Browse.Range.Input)">
            <summary>
            Navigate based on a form. Complete and post the form.
            </summary>
            <param name="form">The form to be posted.</param>
            <param name="submit">The submit button on the form to simulate clicking.</param>
        </member>
        <member name="M:Encog.Bot.Browse.Browser.Navigate(Encog.Bot.Browse.Range.Link)">
            <summary>
            Navigate to a new page based on a link.
            </summary>
            <param name="link">The link to navigate to.</param>
        </member>
        <member name="M:Encog.Bot.Browse.Browser.Navigate(System.String)">
            <summary>
            Navigate based on a string URL.
            </summary>
            <param name="url">The URL to navigate to.</param>
        </member>
        <member name="M:Encog.Bot.Browse.Browser.Navigate(System.Uri)">
            <summary>
            Navigate to a page based on a URL object. This will be an HTTP GET
            operation.
            </summary>
            <param name="url">The URL to navigate to.</param>
        </member>
        <member name="M:Encog.Bot.Browse.Browser.Navigate(System.Uri,System.IO.Stream)">
            <summary>
            Navigate to a page and post the specified data.
            </summary>
            <param name="url">The URL to post the data to.</param>
            <param name="istream">The data to post to the page.</param>
        </member>
        <member name="T:Encog.Bot.Browse.Extract.BasicExtract">
            <summary>
            Implements the basic functionality that most extractors will need to
            implement. Mostly this involves maintaining a collection of the extraction
            listeners that will receive events as the extraction occurs.
            </summary>
        </member>
        <member name="F:Encog.Bot.Browse.Extract.BasicExtract._listeners">
            <summary>
            The classes registered as listeners for the extraction.
            </summary>
        </member>
        <member name="M:Encog.Bot.Browse.Extract.BasicExtract.AddListener(Encog.Bot.Browse.Extract.IExtractListener)">
            <summary>
            Add a listener for the extraction.
            </summary>
            <param name="listener">The listener to add.</param>
        </member>
        <member name="M:Encog.Bot.Browse.Extract.BasicExtract.ExtractList(Encog.Bot.Browse.WebPage)">
            <summary>
            Extract from the web page and return the results as a list.
            </summary>
            <param name="page">The web page to extract from.</param>
            <returns>The results of the extraction as a List.</returns>
        </member>
        <member name="P:Encog.Bot.Browse.Extract.BasicExtract.Listeners">
            <summary>
            A list of listeners registered with this object.
            </summary>
        </member>
        <member name="M:Encog.Bot.Browse.Extract.BasicExtract.RemoveListener(Encog.Bot.Browse.Extract.IExtractListener)">
            <summary>
            Remove the specified listener.
            </summary>
            <param name="listener">The listener to rmove.</param>
        </member>
        <member name="M:Encog.Bot.Browse.Extract.BasicExtract.Extract(Encog.Bot.Browse.WebPage)">
            <summary>
            Extract data from the web page.
            </summary>
            <param name="page">The page to extract from.</param>
        </member>
        <member name="M:Encog.Bot.Browse.Extract.BasicExtract.Distribute(System.Object)">
            <summary>
            Distribute an object to the listeners.
            </summary>
            <param name="obj">The object to be distributed.</param>
        </member>
        <member name="T:Encog.Bot.Browse.Extract.IExtractListener">
            <summary>
            The ExtractListener interface defines a class that can receive extraction
            events as an extraction process occurs.
            </summary>
        </member>
        <member name="M:Encog.Bot.Browse.Extract.IExtractListener.FoundData(System.Object)">
            <summary>
            Notify that some data has been extracted.
            </summary>
            <param name="obj">The data that was extracted.</param>
        </member>
        <member name="T:Encog.Bot.Browse.Extract.IExtract">
            <summary>
            Provides the basic interface that any extractor must support. An extractor is
            a class that is capable of extracting certain types of data from web data.
            For example, the ExtractWords extractor is used to extract all of the words
            from a web page.
            </summary>
        </member>
        <member name="P:Encog.Bot.Browse.Extract.IExtract.Listeners">
            <summary>
            A list of listeners registered with this object.
            </summary>
        </member>
        <member name="M:Encog.Bot.Browse.Extract.IExtract.AddListener(Encog.Bot.Browse.Extract.IExtractListener)">
            <summary>
            Add a listener for the extraction.
            </summary>
            <param name="listener">The listener to add.</param>
        </member>
        <member name="M:Encog.Bot.Browse.Extract.IExtract.Extract(Encog.Bot.Browse.WebPage)">
            <summary>
            Extract data from the web page.
            </summary>
            <param name="page">The page to extract from.</param>
        </member>
        <member name="M:Encog.Bot.Browse.Extract.IExtract.ExtractList(Encog.Bot.Browse.WebPage)">
            <summary>
            Extract from the web page and return the results as a list.
            </summary>
            <param name="page">The web page to extract from.</param>
            <returns>The results of the extraction as a List.</returns>
        </member>
        <member name="M:Encog.Bot.Browse.Extract.IExtract.RemoveListener(Encog.Bot.Browse.Extract.IExtractListener)">
            <summary>
            Remove the specified listener.
            </summary>
            <param name="listener">The listener to rmove.</param>
        </member>
        <member name="T:Encog.Bot.Browse.Extract.ListExtractListener">
            <summary>
            A simple implementation of the ExtractListener interface that will listen for
            words and add them to a list. This allows you to quickly build a list of all
            of the words on a web page.
            </summary>
        </member>
        <member name="F:Encog.Bot.Browse.Extract.ListExtractListener._list">
            <summary>
            The list to extract into.
            </summary>
        </member>
        <member name="P:Encog.Bot.Browse.Extract.ListExtractListener.List">
            <summary>
            The list of words extracted.
            </summary>
        </member>
        <member name="M:Encog.Bot.Browse.Extract.ListExtractListener.FoundData(System.Object)">
            <summary>
            Called when a word is found, add it to the list.
            </summary>
            <param name="obj">The word found.</param>
        </member>
        <member name="T:Encog.Bot.Browse.LoadWebPage">
            <summary>
            Called to actually load a web page. This will read the HTML on a web page and
            generate the DocumentRange classes.
            </summary>
        </member>
        <member name="F:Encog.Bot.Browse.LoadWebPage._page">
            <summary>
            The loaded webpage.
            </summary>
        </member>
        <member name="F:Encog.Bot.Browse.LoadWebPage._baseURL">
            <summary>
            The base URL for the page being loaded.
            </summary>
        </member>
        <member name="F:Encog.Bot.Browse.LoadWebPage._lastForm">
            <summary>
            The last form that was processed.
            </summary>
        </member>
        <member name="F:Encog.Bot.Browse.LoadWebPage._lastHierarchyElement">
            <summary>
            The last hierarchy element that was processed.
            </summary>
        </member>
        <member name="M:Encog.Bot.Browse.LoadWebPage.#ctor(System.Uri)">
            <summary>
            Construct a web page loader with the specified base URL.
            </summary>
            <param name="baseURL">The base URL to use when loading.</param>
        </member>
        <member name="M:Encog.Bot.Browse.LoadWebPage.AddHierarchyElement(Encog.Bot.Browse.Range.DocumentRange)">
            <summary>
            Add the specified hierarchy element.
            </summary>
            <param name="element">The hierarchy element to add.</param>
        </member>
        <member name="M:Encog.Bot.Browse.LoadWebPage.CreateCodeDataUnit(System.String)">
            <summary>
            Create a dataunit to hode the code HTML tag.
            </summary>
            <param name="str">The code to create the data unit with.</param>
        </member>
        <member name="M:Encog.Bot.Browse.LoadWebPage.CreateTagDataUnit(Encog.Parse.Tags.Tag)">
            <summary>
            Create a tag data unit.
            </summary>
            <param name="tag">The tag name to create the data unit for.</param>
        </member>
        <member name="M:Encog.Bot.Browse.LoadWebPage.CreateTextDataUnit(System.String)">
            <summary>
            Create a text data unit.
            </summary>
            <param name="str">The text.</param>
        </member>
        <member name="M:Encog.Bot.Browse.LoadWebPage.FindEndTag(System.Int32,Encog.Parse.Tags.Tag)">
            <summary>
             Find the end tag that lines up to the beginning tag.
            </summary>
            <param name="index">The index to start the search on. This specifies
            the starting data unit.</param>
            <param name="tag">The beginning tag that we are seeking the end tag 
            for.</param>
            <returns>The index that the ending tag was found at. Returns -1
            if not found.</returns>
        </member>
        <member name="M:Encog.Bot.Browse.LoadWebPage.Load(System.IO.Stream)">
            <summary>
            Load a web page from the specified stream.
            </summary>
            <param name="istream">The input stream to load from.</param>
            <returns>The loaded web page.</returns>
        </member>
        <member name="M:Encog.Bot.Browse.LoadWebPage.Load(System.String)">
            <summary>
            Load the web page from a string that contains HTML.
            </summary>
            <param name="str">A string containing HTML.</param>
            <returns>The loaded WebPage.</returns>
        </member>
        <member name="M:Encog.Bot.Browse.LoadWebPage.LoadContents">
            <summary>
            Using the data units, which should have already been loaded by this 
            time, load the contents of the web page.  This includes the title,
            any links and forms.  Div tags and spans are also processed.
            </summary>
        </member>
        <member name="M:Encog.Bot.Browse.LoadWebPage.LoadDataUnits(System.IO.Stream)">
            <summary>
            Load the data units.  Once the lower level data units have been 
            loaded, the contents can be loaded.
            </summary>
            <param name="istream">The input stream that the data units are loaded from.</param>
        </member>
        <member name="M:Encog.Bot.Browse.LoadWebPage.LoadDiv(System.Int32,Encog.Parse.Tags.Tag)">
            <summary>
            Called by loadContents to load a div tag.
            </summary>
            <param name="index">The index to begin at.</param>
            <param name="tag">The beginning div tag.</param>
        </member>
        <member name="M:Encog.Bot.Browse.LoadWebPage.LoadForm(System.Int32,Encog.Parse.Tags.Tag)">
            <summary>
            Called by loadContents to load a form on the page.
            </summary>
            <param name="index">The index to begin loading at.</param>
            <param name="tag">The beginning tag.</param>
        </member>
        <member name="M:Encog.Bot.Browse.LoadWebPage.LoadInput(System.Int32,Encog.Parse.Tags.Tag)">
            <summary>
            Called by loadContents to load an input tag on the form.
            </summary>
            <param name="index">The index to begin loading at.</param>
            <param name="tag">The beginning tag.</param>
        </member>
        <member name="M:Encog.Bot.Browse.LoadWebPage.LoadLink(System.Int32,Encog.Parse.Tags.Tag)">
            <summary>
            Called by loadContents to load a link on the page.
            </summary>
            <param name="index">The index to begin loading at.</param>
            <param name="tag">The beginning tag.</param>
        </member>
        <member name="M:Encog.Bot.Browse.LoadWebPage.LoadSpan(System.Int32,Encog.Parse.Tags.Tag)">
            <summary>
            Called by loadContents to load a span.
            </summary>
            <param name="index">The index to begin loading at.</param>
            <param name="tag">The beginning tag.</param>
        </member>
        <member name="M:Encog.Bot.Browse.LoadWebPage.LoadTitle(System.Int32,Encog.Parse.Tags.Tag)">
            <summary>
            Called by loadContents to load the title of the page.
            </summary>
            <param name="index">The index to begin loading at.</param>
            <param name="tag">The beginning tag.</param>
        </member>
        <member name="T:Encog.Bot.Browse.Range.Div">
            <summary>
            A document range that represents the beginning and ending DIV tag, as well as
            any tages embedded between them.
            </summary>
        </member>
        <member name="M:Encog.Bot.Browse.Range.Div.#ctor(Encog.Bot.Browse.WebPage)">
            <summary>
            Construct a range to hold the DIV tag.
            </summary>
            <param name="source">The web page this range was found on.</param>
        </member>
        <member name="M:Encog.Bot.Browse.Range.Div.ToString">
            <summary>
            This object as a string.
            </summary>
            <returns>This object as a string.</returns>
        </member>
        <member name="T:Encog.Bot.Browse.Range.DocumentRange">
            <summary>
            Base class that represents a document range. A document range is a collection
            of tags that all apply to one "concept". For example, a Form, or a Link. This
            allows the form to collect the elements inside the form, or a link to collect
            the text along with the link tag.
            </summary>
        </member>
        <member name="F:Encog.Bot.Browse.Range.DocumentRange._elements">
            <summary>
            Sub elements of this range.
            </summary>
        </member>
        <member name="F:Encog.Bot.Browse.Range.DocumentRange._source">
            <summary>
            The source page for this range.
            </summary>
        </member>
        <member name="M:Encog.Bot.Browse.Range.DocumentRange.#ctor(Encog.Bot.Browse.WebPage)">
            <summary>
            Construct a document range from the specified WebPage.
            </summary>
            <param name="source">The web page that this range belongs to.</param>
        </member>
        <member name="P:Encog.Bot.Browse.Range.DocumentRange.Begin">
            <summary>
            The beginning of this attribute.
            </summary>
        </member>
        <member name="P:Encog.Bot.Browse.Range.DocumentRange.ClassAttribute">
            <summary>
            The HTML class attribiute for this element.
            </summary>
        </member>
        <member name="P:Encog.Bot.Browse.Range.DocumentRange.Elements">
            <summary>
            The elements of this document range. 
            </summary>
        </member>
        <member name="P:Encog.Bot.Browse.Range.DocumentRange.End">
            <summary>
            The ending index.
            </summary>
        </member>
        <member name="P:Encog.Bot.Browse.Range.DocumentRange.IdAttribute">
            <summary>
            The HTML id for this element.
            </summary>
        </member>
        <member name="P:Encog.Bot.Browse.Range.DocumentRange.Parent">
            <summary>
            The web page that owns this class.
            </summary>
        </member>
        <member name="P:Encog.Bot.Browse.Range.DocumentRange.Source">
            <summary>
            The web page that this range is owned by.
            </summary>
        </member>
        <member name="M:Encog.Bot.Browse.Range.DocumentRange.AddElement(Encog.Bot.Browse.Range.DocumentRange)">
            <summary>
            Add an element.
            </summary>
            <param name="element">The element to add.</param>
        </member>
        <member name="M:Encog.Bot.Browse.Range.DocumentRange.GetTextOnly">
            <summary>
            Get the text from this range.
            </summary>
            <returns>The text from this range.</returns>
        </member>
        <member name="M:Encog.Bot.Browse.Range.DocumentRange.ToString">
            <summary>
            This object as a string.
            </summary>
            <returns>This object as a string.</returns>
        </member>
        <member name="T:Encog.Bot.Browse.Range.Form">
            <summary>
            A document range that represents a form, and all embedded tags.
            </summary>
        </member>
        <member name="T:Encog.Bot.Browse.Range.Form.FormMethod">
            <summary>
            The method for this form.
            </summary>
        </member>
        <member name="F:Encog.Bot.Browse.Range.Form.FormMethod.Post">
            <summary>
            This form is to be POSTed.
            </summary>
        </member>
        <member name="F:Encog.Bot.Browse.Range.Form.FormMethod.Get">
            <summary>
            This form is to sent using a GET.
            </summary>
        </member>
        <member name="M:Encog.Bot.Browse.Range.Form.#ctor(Encog.Bot.Browse.WebPage)">
            <summary>
            Construct a form on the specified web page.
            </summary>
            <param name="source">The web page that contains this form.</param>
        </member>
        <member name="P:Encog.Bot.Browse.Range.Form.Action">
            <summary>
            The URL to send the form to.
            </summary>
        </member>
        <member name="P:Encog.Bot.Browse.Range.Form.Method">
            <summary>
            The method, GET or POST.
            </summary>
        </member>
        <member name="M:Encog.Bot.Browse.Range.Form.FindType(System.String,System.Int32)">
            <summary>
            Find the form input by type.
            </summary>
            <param name="type">The type of input we want.</param>
            <param name="index">The index to begin searching at.</param>
            <returns>The Input object that was found.</returns>
        </member>
        <member name="M:Encog.Bot.Browse.Range.Form.ToString">
            <summary>
            The object as a string.
            </summary>
            <returns>The object as a string.</returns>
        </member>
        <member name="T:Encog.Bot.Browse.Range.FormElement">
            <summary>
            A document range that represents one individual component to a form.
            </summary>
        </member>
        <member name="F:Encog.Bot.Browse.Range.FormElement._name">
            <summary>
            The name of the element.
            </summary>
        </member>
        <member name="F:Encog.Bot.Browse.Range.FormElement._owner">
            <summary>
            The owner.
            </summary>
        </member>
        <member name="F:Encog.Bot.Browse.Range.FormElement._value">
            <summary>
            The value.
            </summary>
        </member>
        <member name="M:Encog.Bot.Browse.Range.FormElement.#ctor(Encog.Bot.Browse.WebPage)">
            <summary>
            Construct a form element from the specified web page. 
            </summary>
            <param name="source">The page that holds this form element.</param>
        </member>
        <member name="P:Encog.Bot.Browse.Range.FormElement.Name">
            <summary>
            The name of this form.
            </summary>
        </member>
        <member name="P:Encog.Bot.Browse.Range.FormElement.Owner">
            <summary>
            The owner of this form element.
            </summary>
        </member>
        <member name="P:Encog.Bot.Browse.Range.FormElement.Value">
            <summary>
            The value of this form element.
            </summary>
        </member>
        <member name="P:Encog.Bot.Browse.Range.FormElement.AutoSend">
            <summary>
            True if this is autosend, which means that the type is 
            NOT submit.  This prevents a form that has multiple submit buttons
            from sending ALL of them in a single post.
            </summary>
        </member>
        <member name="T:Encog.Bot.Browse.Range.Input">
            <summary>
            A form element that represents for input for text.  These are of the
            form name=value.
            </summary>
        </member>
        <member name="F:Encog.Bot.Browse.Range.Input._type">
            <summary>
            The type of input element that this is.
            </summary>
        </member>
        <member name="M:Encog.Bot.Browse.Range.Input.#ctor(Encog.Bot.Browse.WebPage)">
            <summary>
            Construct this Input element.
            </summary>
            <param name="source">The source for this input ent.</param>
        </member>
        <member name="P:Encog.Bot.Browse.Range.Input.Type">
            <summary>
            The type of this input.
            </summary>
        </member>
        <member name="P:Encog.Bot.Browse.Range.Input.AutoSend">
            <summary>
            True if this is autosend, which means that the type is NOT
            submit. This prevents a form that has multiple submit buttons
            from sending ALL of them in a single post.
            </summary>
        </member>
        <member name="M:Encog.Bot.Browse.Range.Input.ToString">
            <summary>
            This object as a string.
            </summary>
            <returns>This object as a string.</returns>
        </member>
        <member name="T:Encog.Bot.Browse.Range.Link">
            <summary>
            A document range that represents a hyperlink, and any embedded tags and text.
            </summary>
        </member>
        <member name="F:Encog.Bot.Browse.Range.Link._target">
            <summary>
            The target address for this link.
            </summary>
        </member>
        <member name="M:Encog.Bot.Browse.Range.Link.#ctor(Encog.Bot.Browse.WebPage)">
            <summary>
            Construct a link from the specified web page.
            </summary>
            <param name="source">The web page this link is from.</param>
        </member>
        <member name="P:Encog.Bot.Browse.Range.Link.Target">
            <summary>
            The target of this link.
            </summary>
        </member>
        <member name="M:Encog.Bot.Browse.Range.Link.ToString">
            <summary>
            This object as a string.
            </summary>
            <returns>This object as a string.</returns>
        </member>
        <member name="T:Encog.Bot.Browse.Range.Span">
            <summary>
            A document range that specifies a span tag, and any embedded tags.
            </summary>
        </member>
        <member name="M:Encog.Bot.Browse.Range.Span.#ctor(Encog.Bot.Browse.WebPage)">
            <summary>
            Construct a span range from the specified web page.
            </summary>
            <param name="source">The source web page.</param>
        </member>
        <member name="M:Encog.Bot.Browse.Range.Span.ToString">
            <summary>
            This object as a string. 
            </summary>
            <returns>This object as a string. </returns>
        </member>
        <member name="T:Encog.Bot.Browse.WebPage">
            <summary>
            Holds a web page that was loaded by the Browse class. Web pages are made
            up of DataUnits and contents, which are ranges of data units.  The data
            units are basically tags and blocks of text.  The contents collection uses
            DocumentRange objects to assign meatning to the lower level DataObjects.
            </summary>
        </member>
        <member name="F:Encog.Bot.Browse.WebPage._contents">
            <summary>
            The contents of this page, builds upon the list of DataUnits.
            </summary>
        </member>
        <member name="F:Encog.Bot.Browse.WebPage._data">
            <summary>
            The data units that make up this page.
            </summary>
        </member>
        <member name="F:Encog.Bot.Browse.WebPage._title">
            <summary>
            The title of this HTML page.
            </summary>
        </member>
        <member name="P:Encog.Bot.Browse.WebPage.Contents">
            <summary>
            The contents in a list collection.
            </summary>
        </member>
        <member name="P:Encog.Bot.Browse.WebPage.Data">
            <summary>
            The data units in a list collection.
            </summary>
        </member>
        <member name="P:Encog.Bot.Browse.WebPage.Title">
            <summary>
            The title of this document.
            </summary>
        </member>
        <member name="M:Encog.Bot.Browse.WebPage.AddContent(Encog.Bot.Browse.Range.DocumentRange)">
            <summary>
            Add to the content collection.
            </summary>
            <param name="span">The range to add to the collection.</param>
        </member>
        <member name="M:Encog.Bot.Browse.WebPage.AddDataUnit(Encog.Bot.DataUnits.DataUnit)">
            <summary>
            Add a data unit to the collection.
            </summary>
            <param name="unit">The data unit to load.</param>
        </member>
        <member name="M:Encog.Bot.Browse.WebPage.Find(System.Type,System.Int32)">
            <summary>
            Find the specified DocumentRange subclass in the contents list.
            </summary>
            <param name="c">The class type to search for.</param>
            <param name="index">The index to search from.</param>
            <returns>The document range that was found.</returns>
        </member>
        <member name="M:Encog.Bot.Browse.WebPage.FindLink(System.String)">
            <summary>
            Find the link that contains the specified string.
            </summary>
            <param name="str">The string to search for.</param>
            <returns>The link found.</returns>
        </member>
        <member name="M:Encog.Bot.Browse.WebPage.getDataSize">
            <summary>
            Get the number of data items in this collection.
            </summary>
            <returns>The size of the data unit.</returns>
        </member>
        <member name="M:Encog.Bot.Browse.WebPage.GetDataUnit(System.Int32)">
            <summary>
            Get the DataUnit unit at the specified index.
            </summary>
            <param name="i">The index to use.</param>
            <returns>The DataUnit found at the specified index.</returns>
        </member>
        <member name="M:Encog.Bot.Browse.WebPage.ToString">
            <summary>
            The object as a string.
            </summary>
            <returns>The object as a string.</returns>
        </member>
        <member name="T:Encog.Bot.DataUnits.CodeDataUnit">
            <summary>
            A data unit that holds code.
            </summary>
        </member>
        <member name="F:Encog.Bot.DataUnits.CodeDataUnit._code">
            <summary>
            The code for this data unit.
            </summary>
        </member>
        <member name="P:Encog.Bot.DataUnits.CodeDataUnit.Code">
            <summary>
            The code for this data unit.
            </summary>
        </member>
        <member name="M:Encog.Bot.DataUnits.CodeDataUnit.ToString">
            <summary>
            This object as a string.
            </summary>
            <returns>This object as a string.</returns>
        </member>
        <member name="T:Encog.Bot.DataUnits.DataUnit">
            <summary>
            Data units are very abstract pieces of data that the browser processes.
            </summary>
        </member>
        <member name="T:Encog.Bot.DataUnits.TagDataUnit">
            <summary>
            A data unit that holds a tag.
            </summary>
        </member>
        <member name="P:Encog.Bot.DataUnits.TagDataUnit.Tag">
            <summary>
            The tag that this data unit is based on.
            </summary>
        </member>
        <member name="T:Encog.Bot.DataUnits.TextDataUnit">
            <summary>
            A data unit that holds text.
            </summary>
        </member>
        <member name="F:Encog.Bot.DataUnits.TextDataUnit._text">
            <summary>
            The text for this data unit.
            </summary>
        </member>
        <member name="P:Encog.Bot.DataUnits.TextDataUnit.Text">
            <summary>
            The text for this data unit.
            </summary>
        </member>
        <member name="M:Encog.Bot.DataUnits.TextDataUnit.ToString">
            <summary>
            This object as a string.
            </summary>
            <returns>This object as a string.</returns>
        </member>
        <member name="T:Encog.Bot.RSS.RSS">
            <summary>
            RSS: This is the class that actually parses the 
            RSS and builds a collection of RSSItems.  To make use
            of this class call the load method with a URL that
            points to RSS.
            </summary>
        </member>
        <member name="F:Encog.Bot.RSS.RSS._attributes">
            <summary>
            All of the attributes for this RSS document.
            </summary>
        </member>
        <member name="F:Encog.Bot.RSS.RSS._items">
            <summary>
            All RSS items, or stories, found.
            </summary>
        </member>
        <member name="P:Encog.Bot.RSS.RSS.Attributes">
            <summary>
            All of the attributes for this RSS document.
            </summary>
        </member>
        <member name="P:Encog.Bot.RSS.RSS.Items">
            <summary>
            All RSS items, or stories, found.
            </summary>
        </member>
        <member name="M:Encog.Bot.RSS.RSS.ParseDate(System.String)">
            <summary>
            Simple utility function that converts a RSS formatted date
            into a C# date.
            </summary>
            <param name="datestr">A date</param>
            <returns>A C# DateTime object.</returns>
        </member>
        <member name="M:Encog.Bot.RSS.RSS.LoadItem(System.Xml.XmlNode)">
            <summary>
            Load the specified RSS item, or story.
            </summary>
            <param name="item">A XML node that contains a RSS item.</param>
        </member>
        <member name="M:Encog.Bot.RSS.RSS.LoadChannel(System.Xml.XmlNode)">
            <summary>
            Load the channle node.
            </summary>
            <param name="channel">A node that contains a channel.</param>
        </member>
        <member name="M:Encog.Bot.RSS.RSS.Load(System.Uri)">
            <summary>
            Load all RSS data from the specified URL.
            </summary>
            <param name="url">URL that contains XML data.</param>
        </member>
        <member name="M:Encog.Bot.RSS.RSS.ToString">
            <summary>
            Convert the object to a String.
            </summary>
            <returns>The object as a String.</returns>
        </member>
        <member name="T:Encog.Bot.RSS.RSSItem">
            <summary>
            RSSItem: This is the class that holds individual RSS items,
            or stories, for the RSS class.
            </summary>
        </member>
        <member name="F:Encog.Bot.RSS.RSSItem._date">
            <summary>
            The date this item was published.
            </summary>
        </member>
        <member name="F:Encog.Bot.RSS.RSSItem._description">
            <summary>
            The description of this item.
            </summary>
        </member>
        <member name="F:Encog.Bot.RSS.RSSItem._link">
            <summary>
            The hyperlink to this item.
            </summary>
        </member>
        <member name="F:Encog.Bot.RSS.RSSItem._title">
            <summary>
            The title of this item.
            </summary>
        </member>
        <member name="P:Encog.Bot.RSS.RSSItem.Title">
            <summary>
            The title of this item.
            </summary>
        </member>
        <member name="P:Encog.Bot.RSS.RSSItem.Link">
            <summary>
            The hyperlink to this item.
            </summary>
        </member>
        <member name="P:Encog.Bot.RSS.RSSItem.Description">
            <summary>
            The description of this item.
            </summary>
        </member>
        <member name="P:Encog.Bot.RSS.RSSItem.Date">
            <summary>
            The date this item was published.
            </summary>
        </member>
        <member name="M:Encog.Bot.RSS.RSSItem.Load(System.Xml.XmlNode)">
            <summary>
            Load an item from the specified node.
            </summary>
            <param name="node">The Node to load the item from.</param>
        </member>
        <member name="M:Encog.Bot.RSS.RSSItem.ToString">
            <summary>
            Convert the object to a String.
            </summary>
            <returns>The object as a String.</returns>
        </member>
        <member name="T:Encog.ConsoleStatusReportable">
            <summary>
            A simple status report that goes to the console.
            </summary>
        </member>
        <member name="M:Encog.ConsoleStatusReportable.Report(System.Int32,System.Int32,System.String)">
            <summary>
            Simply display any status reports.
            </summary>
            <param name="total">Total amount.</param>
            <param name="current">Current item.</param>
            <param name="message">Current message.</param>
        </member>
        <member name="T:Encog.EncogFramework">
            <summary>
            Main Encog class, does little more than provide version information.
            Also used to hold the ORM session that Encog uses to work with
            Hibernate.
            </summary>
        </member>
        <member name="F:Encog.EncogFramework.Version">
            <summary>
            The current engog version, this should be read from the properties.
            </summary>
        </member>
        <member name="F:Encog.EncogFramework.PLATFORM">
            <summary>
            The platform.
            </summary>
        </member>
        <member name="F:Encog.EncogFramework.FileVersion">
            <summary>
            The current engog file version, this should be read from the properties.
            </summary>
        </member>
        <member name="F:Encog.EncogFramework.DefaultPrecision">
            <summary>
            The default precision to use for compares.
            </summary>
        </member>
        <member name="F:Encog.EncogFramework.DefaultDoubleEqual">
            <summary>
            Default point at which two doubles are equal.
            </summary>
        </member>
        <member name="F:Encog.EncogFramework.EncogVersion">
            <summary>
            The version of the Encog JAR we are working with. Given in the form
            x.x.x.
            </summary>
        </member>
        <member name="F:Encog.EncogFramework.EncogFileVersion">
            <summary>
            The encog file version. This determines of an encog file can be read.
            This is simply an integer, that started with zero and is incramented each
            time the format of the encog data file changes.
            </summary>
        </member>
        <member name="F:Encog.EncogFramework._instance">
            <summary>
            The instance.
            </summary>
        </member>
        <member name="F:Encog.EncogFramework._loggingPlugin">
             <summary>
             The current logging plugin.
             </summary>
            
        </member>
        <member name="F:Encog.EncogFramework._plugins">
             <summary>
             The plugins.
             </summary>
            
        </member>
        <member name="P:Encog.EncogFramework.Instance">
            <summary>
            Get the instance to the singleton.
            </summary>
        </member>
        <member name="F:Encog.EncogFramework._properties">
            <summary>
            Get the properties as a Map.
            </summary>
        </member>
        <member name="M:Encog.EncogFramework.#ctor">
            <summary>
            Private constructor.
            </summary>
        </member>
        <member name="P:Encog.EncogFramework.Properties">
            <summary>
            The Encog properties.  Contains version information.
            </summary>
        </member>
        <member name="M:Encog.EncogFramework.Shutdown">
            <summary>
            Shutdown Encog.
            </summary>
        </member>
        <member name="P:Encog.EncogFramework.LoggingPlugin">
            <value>the loggingPlugin</value>
        </member>
        <member name="M:Encog.EncogFramework.RegisterPlugin(Encog.Plugin.EncogPluginBase)">
             <summary>
             Register a plugin. If this plugin provides a core service, such as
             calculation or logging, this will remove the old plugin.
             </summary>
            
             <param name="plugin">The plugin to register.</param>
        </member>
        <member name="M:Encog.EncogFramework.UnregisterPlugin(Encog.Plugin.EncogPluginBase)">
            <summary>
            Unregister a plugin. If you unregister the current logging or calc
            plugin, a new system one will be created. Encog will crash without a
            logging or system plugin.
            </summary>
        </member>
        <member name="P:Encog.EncogFramework.Plugins">
            <summary>
            The plugins.
            </summary>
        </member>
        <member name="T:Encog.EncogError">
            <summary>
            The base Encog error from which all other errors are build.
            </summary>
        </member>
        <member name="M:Encog.EncogError.#ctor(System.String)">
            <summary>
            Construct a message exception.
            </summary>
            <param name="str">The message.</param>
        </member>
        <member name="M:Encog.EncogError.#ctor(System.Exception)">
            <summary>
            Pass on an exception.
            </summary>
            <param name="e">The other exception.</param>
        </member>
        <member name="M:Encog.EncogError.#ctor(System.String,System.Exception)">
            <summary>
            Pass on an exception.
            </summary>
            <param name="msg">The message.</param>
            <param name="e">The exception.</param>
        </member>
        <member name="T:Encog.Engine.Network.Activation.ActivationBiPolar">
            <summary>
            BiPolar activation function. This will scale the neural data into the bipolar
            range. Greater than zero becomes 1, less than or equal to zero becomes -1.
            </summary>
        </member>
        <member name="F:Encog.Engine.Network.Activation.ActivationBiPolar._paras">
             <summary>
             The parameters.
             </summary>
            
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationBiPolar.#ctor">
             <summary>
             Construct the bipolar activation function.
             </summary>
            
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationBiPolar.DerivativeFunction(System.Double,System.Double)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationBiPolar.HasDerivative">
            <returns>Return true, bipolar has a 1 for derivative.</returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationBiPolar.ActivationFunction(System.Double[],System.Int32,System.Int32)">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationBiPolar.ParamNames">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationBiPolar.Params">
            <inheritdoc />
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationBiPolar.Clone">
            <summary>
            Clone the object.
            </summary>
            <returns>The cloned object.</returns>
        </member>
        <member name="T:Encog.Engine.Network.Activation.ActivationCompetitive">
            <summary>
            An activation function that only allows a specified number, usually one, of
            the out-bound connection to win. These connections will share in the sum of
            the output, whereas the other neurons will receive zero.
            This activation function can be useful for "winner take all" layers.
            </summary>
        </member>
        <member name="F:Encog.Engine.Network.Activation.ActivationCompetitive.ParamCompetitiveMaxWinners">
             <summary>
             The offset to the parameter that holds the max winners.
             </summary>
            
        </member>
        <member name="F:Encog.Engine.Network.Activation.ActivationCompetitive._paras">
             <summary>
             The parameters.
             </summary>
            
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationCompetitive.#ctor">
             <summary>
             Create a competitive activation function with one winner allowed.
             </summary>
            
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationCompetitive.#ctor(System.Int32)">
             <summary>
             Create a competitive activation function with the specified maximum
             number of winners.
             </summary>
            
             <param name="winners">The maximum number of winners that this function supports.</param>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationCompetitive.ActivationFunction(System.Double[],System.Int32,System.Int32)">
            <inheritdoc />
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationCompetitive.System#ICloneable#Clone">
            <summary>
            Clone the object.
            </summary>
            <returns>The cloned object.</returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationCompetitive.DerivativeFunction(System.Double,System.Double)">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationCompetitive.MaxWinners">
            <summary>
            The maximum number of winners this function supports.
            </summary>
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationCompetitive.ParamNames">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationCompetitive.Params">
            <inheritdoc />
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationCompetitive.HasDerivative">
            <returns>False, indication that no derivative is available for thisfunction.</returns>
        </member>
        <!-- Проигнорирован некорректный комментарий XML для члена "T:Encog.Engine.Network.Activation.ActivationElliott" -->
        <member name="F:Encog.Engine.Network.Activation.ActivationElliott._p">
            <summary>
            The params.
            </summary>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationElliott.#ctor">
            <summary>
            Construct a basic Elliott activation function, with a slope of 1.
            </summary>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationElliott.ActivationFunction(System.Double[],System.Int32,System.Int32)">
            <inheritdoc />
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationElliott.Clone">
            <summary>
            Clone the object.
            </summary>
            <returns>The object to be cloned.</returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationElliott.DerivativeFunction(System.Double,System.Double)">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationElliott.ParamNames">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationElliott.Params">
            <inheritdoc />
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationElliott.HasDerivative">
            <summary>
            Return true, Elliott activation has a derivative.
            </summary>
            <returns>Return true, Elliott activation has a derivative.</returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationElliott.SetParam(System.Int32,System.Double)">
            <inheritdoc />
        </member>
        <!-- Проигнорирован некорректный комментарий XML для члена "T:Encog.Engine.Network.Activation.ActivationElliottSymmetric" -->
        <member name="F:Encog.Engine.Network.Activation.ActivationElliottSymmetric._p">
            <summary>
            The params.
            </summary>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationElliottSymmetric.#ctor">
            <summary>
            Construct a basic Elliott activation function, with a slope of 1.
            </summary>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationElliottSymmetric.ActivationFunction(System.Double[],System.Int32,System.Int32)">
            <inheritdoc />
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationElliottSymmetric.Clone">
            <summary>
            Clone the object.
            </summary>
            <returns>The object to be cloned.</returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationElliottSymmetric.DerivativeFunction(System.Double,System.Double)">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationElliottSymmetric.ParamNames">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationElliottSymmetric.Params">
            <inheritdoc />
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationElliottSymmetric.HasDerivative">
            <summary>
            Return true, Elliott activation has a derivative.
            </summary>
            <returns>Return true, Elliott activation has a derivative.</returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationElliottSymmetric.SetParam(System.Int32,System.Double)">
            <inheritdoc />
        </member>
        <member name="T:Encog.Engine.Network.Activation.ActivationGaussian">
            <summary>
            An activation function based on the gaussian function.
            </summary>
        </member>
        <member name="F:Encog.Engine.Network.Activation.ActivationGaussian.ParamGaussianCenter">
             <summary>
             The offset to the parameter that holds the width.
             </summary>
            
        </member>
        <member name="F:Encog.Engine.Network.Activation.ActivationGaussian.ParamGaussianPeak">
             <summary>
             The offset to the parameter that holds the peak.
             </summary>
            
        </member>
        <member name="F:Encog.Engine.Network.Activation.ActivationGaussian.ParamGaussianWidth">
             <summary>
             The offset to the parameter that holds the width.
             </summary>
            
        </member>
        <member name="F:Encog.Engine.Network.Activation.ActivationGaussian._paras">
             <summary>
             The parameters.
             </summary>
            
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationGaussian.#ctor">
            <summary>
            Create an empty activation gaussian.
            </summary>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationGaussian.#ctor(System.Double,System.Double,System.Double)">
             <summary>
             Create a gaussian activation function.
             </summary>
            
             <param name="center">The center of the curve.</param>
             <param name="peak">The peak of the curve.</param>
             <param name="width">The width of the curve.</param>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationGaussian.Clone">
            <summary>
            Clone the object.
            </summary>
            <returns>The cloned object.</returns>
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationGaussian.Width">
            <summary>
            The width of the function.
            </summary>
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationGaussian.Center">
            <summary>
            The center of the function.
            </summary>
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationGaussian.Peak">
            <summary>
            The peak of the function.
            </summary>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationGaussian.HasDerivative">
            <summary>
            Return true, gaussian has a derivative.
            </summary>
            <returns>Return true, gaussian has a derivative.</returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationGaussian.ActivationFunction(System.Double[],System.Int32,System.Int32)">
            <inheritdoc />
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationGaussian.DerivativeFunction(System.Double,System.Double)">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationGaussian.ParamNames">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationGaussian.Params">
             <summary>
             {@inheritDoc}
             </summary>
            
        </member>
        <member name="T:Encog.Engine.Network.Activation.ActivationLinear">
            <summary>
            The Linear layer is really not an activation function at all. The input is
            simply passed on, unmodified, to the output. This activation function is
            primarily theoretical and of little actual use. Usually an activation
            function that scales between 0 and 1 or -1 and 1 should be used.
            </summary>
        </member>
        <member name="F:Encog.Engine.Network.Activation.ActivationLinear._paras">
             <summary>
             The parameters.
             </summary>
            
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationLinear.#ctor">
             <summary>
             Construct a linear activation function, with a slope of 1.
             </summary>
            
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationLinear.Clone">
            <summary>
            Clone the object.
            </summary>
            <returns>The cloned object.</returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationLinear.HasDerivative">
            <returns>Return true, linear has a 1 derivative.</returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationLinear.ActivationFunction(System.Double[],System.Int32,System.Int32)">
            <inheritdoc />
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationLinear.DerivativeFunction(System.Double,System.Double)">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationLinear.ParamNames">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationLinear.Params">
            <inheritdoc />
        </member>
        <member name="T:Encog.Engine.Network.Activation.ActivationLOG">
            <summary>
            An activation function based on the logarithm function.
            This type of activation function can be useful to prevent saturation. A
            hidden node of a neural network is said to be saturated on a given set of
            inputs when its output is approximately 1 or -1 "most of the time". If this
            phenomena occurs during training then the learning of the network can be
            slowed significantly since the error surface is very at in this instance.
            </summary>
        </member>
        <member name="F:Encog.Engine.Network.Activation.ActivationLOG._paras">
             <summary>
             The parameters.
             </summary>
            
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationLOG.#ctor">
             <summary>
             Construct the activation function.
             </summary>
            
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationLOG.Clone">
            <summary>
            Clone the object.
            </summary>
            <returns>The cloned object.</returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationLOG.HasDerivative">
            <returns>Return true, log has a derivative.</returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationLOG.ActivationFunction(System.Double[],System.Int32,System.Int32)">
            <inheritdoc />
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationLOG.DerivativeFunction(System.Double,System.Double)">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationLOG.ParamNames">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationLOG.Params">
            <inheritdoc />
        </member>
        <member name="T:Encog.Engine.Network.Activation.ActivationRamp">
            <summary>
            A ramp activation function. This function has a high and low threshold. If
            the high threshold is exceeded a fixed value is returned. Likewise, if the
            low value is exceeded another fixed value is returned.
            </summary>
        </member>
        <member name="F:Encog.Engine.Network.Activation.ActivationRamp.ParamRampHighThreshold">
             <summary>
             The ramp high threshold parameter.
             </summary>
            
        </member>
        <member name="F:Encog.Engine.Network.Activation.ActivationRamp.ParamRampLowThreshold">
             <summary>
             The ramp low threshold parameter.
             </summary>
            
        </member>
        <member name="F:Encog.Engine.Network.Activation.ActivationRamp.ParamRampHigh">
             <summary>
             The ramp high parameter.
             </summary>
            
        </member>
        <member name="F:Encog.Engine.Network.Activation.ActivationRamp.ParamRampLow">
             <summary>
             The ramp low parameter.
             </summary>
            
        </member>
        <member name="F:Encog.Engine.Network.Activation.ActivationRamp._paras">
             <summary>
             The parameters.
             </summary>
            
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationRamp.#ctor(System.Double,System.Double,System.Double,System.Double)">
             <summary>
             Construct a ramp activation function.
             </summary>
            
             <param name="thresholdHigh">The high threshold value.</param>
             <param name="thresholdLow">The low threshold value.</param>
             <param name="high">The high value, replaced if the high threshold is exceeded.</param>
             <param name="low">The low value, replaced if the low threshold is exceeded.</param>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationRamp.#ctor">
             <summary>
             Default constructor.
             </summary>
            
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationRamp.Clone">
            <summary>
            Clone the object.
            </summary>
            <returns>The cloned object.</returns>
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationRamp.High">
            <summary>
            The high value.
            </summary>
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationRamp.Low">
            <summary>
            The low value.
            </summary>
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationRamp.ThresholdHigh">
            <summary>
            Set the threshold high.
            </summary>
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationRamp.ThresholdLow">
            <summary>
            The threshold low.
            </summary>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationRamp.HasDerivative">
            <summary>
            True, as this function does have a derivative.
            </summary>
            <returns>True, as this function does have a derivative.</returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationRamp.ActivationFunction(System.Double[],System.Int32,System.Int32)">
            <inheritdoc />
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationRamp.DerivativeFunction(System.Double,System.Double)">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationRamp.ParamNames">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationRamp.Params">
            <inheritdoc />
        </member>
        <member name="T:Encog.Engine.Network.Activation.ActivationSigmoid">
            <summary>
            The sigmoid activation function takes on a sigmoidal shape. Only positive
            numbers are generated. Do not use this activation function if negative number
            output is desired.
            </summary>
        </member>
        <member name="F:Encog.Engine.Network.Activation.ActivationSigmoid._paras">
             <summary>
             The parameters.
             </summary>
            
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationSigmoid.#ctor">
             <summary>
             Construct a basic sigmoid function, with a slope of 1.
             </summary>
            
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationSigmoid.Clone">
            <summary>
            Clone the object.
            </summary>
            <returns>The cloned object.</returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationSigmoid.HasDerivative">
            <returns>True, sigmoid has a derivative.</returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationSigmoid.ActivationFunction(System.Double[],System.Int32,System.Int32)">
            <inheritdoc />
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationSigmoid.DerivativeFunction(System.Double,System.Double)">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationSigmoid.ParamNames">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationSigmoid.Params">
            <inheritdoc />
        </member>
        <member name="T:Encog.Engine.Network.Activation.ActivationSIN">
            <summary>
            An activation function based on the sin function.
            </summary>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationSIN.#ctor">
             <summary>
             Construct the sin activation function.
             </summary>
            
        </member>
        <member name="F:Encog.Engine.Network.Activation.ActivationSIN._paras">
             <summary>
             The parameters.
             </summary>
            
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationSIN.Clone">
            <summary>
            Clone the object.
            </summary>
            <returns>The cloned object.</returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationSIN.HasDerivative">
            <returns>Return true, sin has a derivative.</returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationSIN.ActivationFunction(System.Double[],System.Int32,System.Int32)">
            <inheritdoc />
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationSIN.DerivativeFunction(System.Double,System.Double)">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationSIN.ParamNames">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationSIN.Params">
            <inheritdoc />
        </member>
        <member name="T:Encog.Engine.Network.Activation.ActivationSoftMax">
            <summary>
            The softmax activation function.
            </summary>
        </member>
        <member name="F:Encog.Engine.Network.Activation.ActivationSoftMax._paras">
             <summary>
             The parameters.
             </summary>
            
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationSoftMax.#ctor">
             <summary>
             Construct the soft-max activation function.
             </summary>
            
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationSoftMax.Clone">
            <summary>
            Clone the object.
            </summary>
            <returns>The cloned object.</returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationSoftMax.HasDerivative">
            <returns>Return false, softmax has no derivative.</returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationSoftMax.ActivationFunction(System.Double[],System.Int32,System.Int32)">
            <inheritdoc />
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationSoftMax.DerivativeFunction(System.Double,System.Double)">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationSoftMax.ParamNames">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationSoftMax.Params">
            <inheritdoc />
        </member>
        <member name="T:Encog.Engine.Network.Activation.ActivationStep">
            <summary>
            The step activation function is a very simple activation function. It is the
            activation function that was used by the original perceptron. Using the
            default parameters it will return 1 if the input is 0 or greater. Otherwise
            it will return 1.
            The center, low and high properties allow you to define how this activation
            function works. If the input is equal to center or higher the high property
            value will be returned, otherwise the low property will be returned. This
            activation function does not have a derivative, and can not be used with
            propagation training, or any other training that requires a derivative.
            </summary>
        </member>
        <member name="F:Encog.Engine.Network.Activation.ActivationStep.ParamStepCenter">
             <summary>
             The step center parameter.
             </summary>
            
        </member>
        <member name="F:Encog.Engine.Network.Activation.ActivationStep.ParamStepLow">
             <summary>
             The step low parameter.
             </summary>
            
        </member>
        <member name="F:Encog.Engine.Network.Activation.ActivationStep.ParamStepHigh">
             <summary>
             The step high parameter.
             </summary>
            
        </member>
        <member name="F:Encog.Engine.Network.Activation.ActivationStep._paras">
             <summary>
             The parameters.
             </summary>
            
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationStep.#ctor(System.Double,System.Double,System.Double)">
             <summary>
             Construct a step activation function.
             </summary>
            
             <param name="low">The low of the function.</param>
             <param name="center">The center of the function.</param>
             <param name="high">The high of the function.</param>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationStep.#ctor">
             <summary>
             Create a basic step activation with low=0, center=0, high=1.
             </summary>
            
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationStep.Center">
            <summary>
            Set the center of this function.
            </summary>
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationStep.Low">
            <summary>
            Set the low of this function.
            </summary>
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationStep.High">
            <summary>
            Set the high of this function.
            </summary>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationStep.Clone">
            <summary>
            Clone the object.
            </summary>
            <returns>The cloned object.</returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationStep.HasDerivative">
            <returns>Returns true, this activation function has a derivative.</returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationStep.ActivationFunction(System.Double[],System.Int32,System.Int32)">
            <inheritdoc />
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationStep.DerivativeFunction(System.Double,System.Double)">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationStep.ParamNames">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationStep.Params">
            <inheritdoc />
        </member>
        <member name="T:Encog.Engine.Network.Activation.ActivationTANH">
            <summary>
            The hyperbolic tangent activation function takes the curved shape of the
            hyperbolic tangent. This activation function produces both positive and
            negative output. Use this activation function if both negative and positive
            output is desired.
            </summary>
        </member>
        <member name="F:Encog.Engine.Network.Activation.ActivationTANH._paras">
             <summary>
             The parameters.
             </summary>
            
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationTANH.#ctor">
             <summary>
             Construct a basic HTAN activation function, with a slope of 1.
             </summary>
            
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationTANH.Clone">
            <summary>
            Clone the object.
            </summary>
            <returns>The cloned object.</returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationTANH.HasDerivative">
            <returns>Return true, TANH has a derivative.</returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationTANH.ActivationFunction(System.Double[],System.Int32,System.Int32)">
            <inheritdoc />
        </member>
        <member name="M:Encog.Engine.Network.Activation.ActivationTANH.DerivativeFunction(System.Double,System.Double)">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationTANH.ParamNames">
            <inheritdoc />
        </member>
        <member name="P:Encog.Engine.Network.Activation.ActivationTANH.Params">
            <inheritdoc />
        </member>
        <member name="T:Encog.Engine.Network.Activation.IActivationFunction">
             <summary>
             This interface allows various activation functions to be used with the neural
             network. Activation functions are applied to the output from each layer of a
             neural network. Activation functions scale the output into the desired range.
             Methods are provided both to process the activation function, as well as the
             derivative of the function. Some training algorithms, particularly back
             propagation, require that it be possible to take the derivative of the
             activation function.
             Not all activation functions support derivatives. If you implement an
             activation function that is not derivable then an exception should be thrown
             inside of the derivativeFunction method implementation.
             Non-derivable activation functions are perfectly valid, they simply cannot be
             used with every training algorithm.
             </summary>
            
        </member>
        <member name="P:Encog.Engine.Network.Activation.IActivationFunction.Params">
            <returns>The params for this activation function.</returns>
        </member>
        <member name="P:Encog.Engine.Network.Activation.IActivationFunction.ParamNames">
            <returns>The names of the parameters.</returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.IActivationFunction.ActivationFunction(System.Double[],System.Int32,System.Int32)">
             <summary>
             Implements the activation function. The array is modified according to
             the activation function being used. See the class description for more
             specific information on this type of activation function.
             </summary>
            
             <param name="d">The input array to the activation function.</param>
             <param name="start">The starting index.</param>
             <param name="size">The number of values to calculate.</param>
        </member>
        <member name="M:Encog.Engine.Network.Activation.IActivationFunction.DerivativeFunction(System.Double,System.Double)">
            <summary>
            Calculate the derivative.  For performance reasons two numbers are provided.
            First, the value "b" is simply the number that we would like to calculate
            the derivative of.
            
            Second, the value "a", which is the value returned by the activation function,
            when presented with "b".  
            
            We use two values because some of the most common activation functions make 
            use of the result of the activation function.  It is bad for performance to
            calculate this value twice.  Yet, not all derivatives are calculated this way.
            By providing both the value before the activation function is applied ("b"), 
            and after the activation function is applied("a"), the class can be constructed
            to use whichever value will be the most efficient.
            </summary>
            <param name="b">The number to calculate the derivative of, the number "before" the
            activation function was applied.</param>
            <param name="a">The number "after" an activation function has been applied.
            @return The derivative.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Engine.Network.Activation.IActivationFunction.HasDerivative">
            <returns>Return true if this function has a derivative.</returns>
        </member>
        <member name="T:Encog.IStatusReportable">
             <summary>
             This class allows for Encog jobs to report their current status, as they run.
             </summary>
            
        </member>
        <member name="M:Encog.IStatusReportable.Report(System.Int32,System.Int32,System.String)">
             <summary>
             Report on current status.
             </summary>
            
             <param name="total">The total amount of units to process.</param>
             <param name="current">The current unit being processed.</param>
             <param name="message">The message to currently display.</param>
        </member>
        <member name="T:Encog.MathUtil.BoundMath">
            <summary>
            C# will sometimes return Math.NaN or Math.Infinity when numbers get to
            large or too small. This can have undesirable effects. This class provides
            some basic math functions that may be in danger of returning such a value.
            This class imposes a very large and small ceiling and floor to keep the
            numbers within range.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.BoundMath.Cos(System.Double)">
            <summary>
            Calculate the cos.
            </summary>
            <param name="a">The value passed to the function.</param>
            <returns>The result of the function.</returns>
        </member>
        <member name="M:Encog.MathUtil.BoundMath.Exp(System.Double)">
            <summary>
            Calculate the exp.
            </summary>
            <param name="a">The value passed to the function.</param>
            <returns>The result of the function.</returns>
        </member>
        <member name="M:Encog.MathUtil.BoundMath.Log(System.Double)">
            <summary>
            Calculate the log.
            </summary>
            <param name="a">The value passed to the function.</param>
            <returns>The result of the function.</returns>
        </member>
        <member name="M:Encog.MathUtil.BoundMath.Pow(System.Double,System.Double)">
            <summary>
            Calculate the power of a number.
            </summary>
            <param name="a">The base.</param>
            <param name="b">The exponent.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.MathUtil.BoundMath.Sin(System.Double)">
            <summary>
            Calculate the sin.
            </summary>
            <param name="a">The value passed to the function.</param>
            <returns>The result of the function.</returns>
        </member>
        <member name="M:Encog.MathUtil.BoundMath.Sqrt(System.Double)">
            <summary>
            Calculate the square root.
            </summary>
            <param name="a">The value passed to the function.</param>
            <returns>The result of the function.</returns>
        </member>
        <member name="T:Encog.MathUtil.BoundNumbers">
            <summary>
            A simple class that prevents numbers from getting either too
            big or too small.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.BoundNumbers.TooSmall">
            <summary>
            Too small of a number.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.BoundNumbers.TooBig">
            <summary>
            Too big of a number.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.BoundNumbers.Bound(System.Double)">
            <summary>
            Bound the number so that it does not become too big or too small.
            </summary>
            <param name="d">The number to check.</param>
            <returns>The new number. Only changed if it was too big or too small.</returns>
        </member>
        <member name="T:Encog.MathUtil.ComplexNumber">
             <summary>
             A complex number class.  This class is based on source code by
             
             Andrew G. Bennett, Department of Mathematics
             Kansas State University
             
             The original version can be found here:
             
             http://www.math.ksu.edu/~bennett/jomacg/c.html
            
             </summary>
        </member>
        <member name="F:Encog.MathUtil.ComplexNumber._x">
            <summary>
            The real part.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.ComplexNumber._y">
            <summary>
            The imaginary part.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.ComplexNumber.#ctor(System.Double,System.Double)">
            <summary>
            Constructs the complex number z = u + i*v
            </summary>
            <param name="u">Real part</param>
            <param name="v">Imaginary part</param>
        </member>
        <member name="M:Encog.MathUtil.ComplexNumber.#ctor(Encog.MathUtil.ComplexNumber)">
            <summary>
            Create a complex number from another complex number. 
            </summary>
            <param name="other">The other complex number. </param>
        </member>
        <member name="P:Encog.MathUtil.ComplexNumber.Real">
                        
            <summary>
            Real part of this Complex number 
            (the x-coordinate in rectangular coordinates).
            </summary>
        </member>
        <member name="P:Encog.MathUtil.ComplexNumber.Imaginary">
            <summary>
            Imaginary part of this Complex number         
            </summary>
        </member>
        <member name="M:Encog.MathUtil.ComplexNumber.Mod">
                        @return 
            <summary>
            Modulus of this Complex number
            (the distance from the origin in polar coordinates).
            </summary>
            <returns>|z| where z is this Complex number.</returns>
        </member>
        <member name="M:Encog.MathUtil.ComplexNumber.Arg">
            <summary>
            Argument of this Complex number 
            (the angle in radians with the x-axis in polar coordinates).
            </summary>
            <returns>arg(z) where z is this Complex number.</returns>
        </member>
        <member name="M:Encog.MathUtil.ComplexNumber.Conj">
            <summary>
            Complex conjugate of this Complex number
            (the conjugate of x+i*y is x-i*y).
            </summary>
            <returns>z-bar where z is this Complex number.</returns>
        </member>
        <member name="M:Encog.MathUtil.ComplexNumber.op_Addition(Encog.MathUtil.ComplexNumber,Encog.MathUtil.ComplexNumber)">
            <summary>
            Addition of Complex numbers (doesn't change this Complex number).
            (x+i*y) + (s+i*t) = (x+s)+i*(y+t)
            </summary>
            <param name="c1">The first argument.</param>
            <param name="c2">The second argument.</param>
            <returns>The result of the addition.</returns>
        </member>
        <member name="M:Encog.MathUtil.ComplexNumber.op_Subtraction(Encog.MathUtil.ComplexNumber,Encog.MathUtil.ComplexNumber)">
            <summary>
            Subtraction of Complex numbers.
            (x-i*y) + (s-i*t) = (x-s)+i*(y-t)
            </summary>
            <param name="c1">The first argument.</param>
            <param name="c2">The second argument.</param>
            <returns>The result of the addition.</returns>
        </member>
        <member name="M:Encog.MathUtil.ComplexNumber.op_Multiply(Encog.MathUtil.ComplexNumber,Encog.MathUtil.ComplexNumber)">
            <summary>
            Multiplication of Complex numbers.
            </summary>
            <param name="c1">The first argument.</param>
            <param name="c2">The second argument.</param>
            <returns>The result of the addition.</returns>
        </member>
        <member name="M:Encog.MathUtil.ComplexNumber.op_Division(Encog.MathUtil.ComplexNumber,Encog.MathUtil.ComplexNumber)">
            <summary>
            Division of Complex numbers.
            </summary>
            <param name="c1">The first argument.</param>
            <param name="c2">The second argument.</param>
            <returns>The result of the addition.</returns>
        </member>
        <member name="M:Encog.MathUtil.ComplexNumber.Exp">
            <summary>
            Complex exponential (doesn't change this Complex number).
            </summary>
            <returns>exp(z) where z is this Complex number.</returns>
        </member>
        <member name="M:Encog.MathUtil.ComplexNumber.Log">
            <summary>
            Principal branch of the Complex logarithm of this Complex number.
            (doesn't change this Complex number).
            The principal branch is the branch with -pi less arg les-equals pi.
            </summary>
            <returns>log(z) where z is this Complex number.</returns>
        </member>
        <member name="M:Encog.MathUtil.ComplexNumber.Sqrt">
            <summary>
            Complex square root (doesn't change this complex number).
            Computes the principal branch of the square root, which 
            is the value with 0 less equals arg less pi.
            </summary>
            <returns>sqrt(z) where z is this Complex number.</returns>
        </member>
        <member name="M:Encog.MathUtil.ComplexNumber.Cosh(System.Double)">
            <summary>
            Real cosh function (used to compute complex trig functions).
            </summary>
            <param name="theta">The argument.</param>
            <returns>The result.</returns>
        </member>
        <member name="M:Encog.MathUtil.ComplexNumber.Sinh(System.Double)">
            <summary>
            Real sinh function (used to compute complex trig functions).
            </summary>
            <param name="theta">The argument.</param>
            <returns>The result.</returns>
        </member>
        <member name="M:Encog.MathUtil.ComplexNumber.Sin">
            <summary>
            Sine of this Complex number (doesn't change this Complex number).
            sin(z) = (exp(i*z)-exp(-i*z))/(2*i).
            </summary>
            <returns>sin(z) where z is this Complex number.</returns>
        </member>
        <member name="M:Encog.MathUtil.ComplexNumber.Cos">
            <summary>
            Cosine of this Complex number (doesn't change this Complex number).
            cos(z) = (exp(i*z)+exp(-i*z))/ 2.
            </summary>
            <returns>cos(z) where z is this Complex number.</returns>
        </member>
        <member name="M:Encog.MathUtil.ComplexNumber.Sinh">
            <summary>
            Hyperbolic sine of this Complex number 
            (doesn't change this Complex number).
            sinh(z) = (exp(z)-exp(-z))/2.
            </summary>
            <returns>sinh(z) where z is this Complex number.</returns>
        </member>
        <member name="M:Encog.MathUtil.ComplexNumber.Cosh">
            <summary>
             Hyperbolic cosine of this Complex number 
             (doesn't change this Complex number).
            cosh(z) = (exp(z) + exp(-z)) / 2.
            </summary>
            <returns>cosh(z) where z is this Complex number.</returns>
        </member>
        <member name="M:Encog.MathUtil.ComplexNumber.Tan">
            <summary>
            Tangent of this Complex number (doesn't change this Complex number).
            </summary>
            <returns>tan(z) = sin(z)/cos(z).</returns>
        </member>
        <member name="M:Encog.MathUtil.ComplexNumber.op_UnaryNegation(Encog.MathUtil.ComplexNumber)">
            <summary>
            Negative of this complex number (chs stands for change sign). 
            This produces a new Complex number and doesn't change 
            this Complex number.
            -(x+i*y) = -x-i*y.
            </summary>
            <param name="op"></param>
            <returns>-op where op is this Complex number.</returns>
        </member>
        <member name="M:Encog.MathUtil.ComplexNumber.ToString">
            <inheritdoc/>
        </member>
        <member name="T:Encog.MathUtil.EncogMath">
            <summary>
            Math functions used by Encog.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.EncogMath.Hypot(System.Double,System.Double)">
            <summary>
            Calculate sqrt(a^2 + b^2) without under/overflow.
            </summary>
            <param name="a">The a value.</param>
            <param name="b">The b value.</param>
            <returns>The result.</returns>
        </member>
        <member name="M:Encog.MathUtil.EncogMath.Deg2Rad(System.Double)">
            <summary>
            Convert degrees to radians.
            </summary>
            <param name="deg">Degrees</param>
            <returns>Radians</returns>
        </member>
        <member name="M:Encog.MathUtil.EncogMath.Rad2Deg(System.Double)">
            <summary>
            Convert radians to degrees.
            </summary>
            <param name="rad">Radians.</param>
            <returns>Degrees.</returns>
        </member>
        <member name="M:Encog.MathUtil.EncogMath.Factorial(System.Int32)">
            <summary>
            Compute the factorial (n!) for p.
            </summary>
            <param name="p">The number to compute the factorial for.</param>
            <returns>The factorial.</returns>
        </member>
        <member name="T:Encog.MathUtil.Error.ErrorCalculation">
            <summary>
            Calculate the error of a neural network. Encog currently supports three error
            calculation modes. See ErrorCalculationMode for more info.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Error.ErrorCalculation._mode">
            <summary>
            The current error calculation mode.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Error.ErrorCalculation._globalError">
            <summary>
            The overall error.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Error.ErrorCalculation._setSize">
            <summary>
            The size of a set.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.Error.ErrorCalculation.Mode">
            <summary>
            The error calculation mode, this is static and therefore global to
            all Encog training. If a particular training method only supports a
            particular error calculation method, it may override this value. It will
            not change the value set here, rather the training will occur with its
            preferred training method. Currently the only training method that does
            this is Levenberg Marquardt (LMA).
            
            The default error mode for Encog is RMS.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Error.ErrorCalculation.Calculate">
            <summary>
            Returns the root mean square error for a complete training set. 
            </summary>
            <returns>The current error for the neural network.</returns>
        </member>
        <member name="M:Encog.MathUtil.Error.ErrorCalculation.CalculateMSE">
            <summary>
            Calculate the error with MSE. 
            </summary>
            <returns>The current error for the neural network.</returns>
        </member>
        <member name="M:Encog.MathUtil.Error.ErrorCalculation.CalculateRMS">
            <summary>
            Calculate the error with RMS. 
            </summary>
            <returns>The current error for the neural network.</returns>
        </member>
        <member name="M:Encog.MathUtil.Error.ErrorCalculation.Reset">
            <summary>
            Reset the error accumulation to zero.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Error.ErrorCalculation.UpdateError(System.Double[],System.Double[],System.Double)">
            <summary>
            Called to update for each number that should be checked.
            </summary>
            <param name="actual">The actual number.</param>
            <param name="ideal">The ideal number.</param>
            <param name="significance">The significance of this error, 1.0 is the baseline.</param>
        </member>
        <member name="M:Encog.MathUtil.Error.ErrorCalculation.UpdateError(System.Double,System.Double)">
            <summary>
            Update the error with single values.
            </summary>
            <param name="actual">The actual value.</param>
            <param name="ideal">The ideal value.</param>
        </member>
        <member name="M:Encog.MathUtil.Error.ErrorCalculation.CalculateSSE">
            <summary>
            Calculate the error as sum of squares.
            </summary>
            <returns>The error.</returns>
        </member>
        <member name="T:Encog.MathUtil.Error.ErrorCalculationMode">
            <summary>
            Selects the error calculation mode for Encog.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Error.ErrorCalculationMode.RMS">
            <summary>
            Root mean square error.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Error.ErrorCalculationMode.MSE">
            <summary>
            Mean square error.
            </summary>
        </member>
        <member name="T:Encog.MathUtil.IntRange">
            <summary>
            A range of integers.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.IntRange.#ctor(System.Int32,System.Int32)">
            <summary>
            Construct an integer range.
            </summary>
            <param name="high">The high  end of the range.</param>
            <param name="low">The low end of the range.</param>
        </member>
        <member name="P:Encog.MathUtil.IntRange.High">
            <summary>
            The low end of the range.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.IntRange.Low">
            <summary>
            The high end of the range.
            </summary>
        </member>
        <member name="T:Encog.MathUtil.LIBSVM.SupportClass">
            <summary>
            Contains conversion support elements such as classes, interfaces and static methods.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.LIBSVM.SupportClass.Random">
            <summary>
            Provides access to a static System.Random class instance
            </summary>
        </member>
        <member name="T:Encog.MathUtil.LIBSVM.SupportClass.Tokenizer">
            <summary>
            The class performs token processing in strings
            </summary>
        </member>
        <member name="F:Encog.MathUtil.LIBSVM.SupportClass.Tokenizer.chars">
            Char representation of the String to tokenize.
        </member>
        <member name="F:Encog.MathUtil.LIBSVM.SupportClass.Tokenizer.includeDelims">
            Include demiliters in the results.
        </member>
        <member name="F:Encog.MathUtil.LIBSVM.SupportClass.Tokenizer.currentPos">
            Position over the string
        </member>
        <member name="M:Encog.MathUtil.LIBSVM.SupportClass.Tokenizer.#ctor(System.String)">
            <summary>
            Initializes a new class instance with a specified string to process
            </summary>
            <param name="source">String to tokenize</param>
        </member>
        <member name="M:Encog.MathUtil.LIBSVM.SupportClass.Tokenizer.#ctor(System.String,System.String)">
            <summary>
            Initializes a new class instance with a specified string to process
            and the specified token delimiters to use
            </summary>
            <param name="source">String to tokenize</param>
            <param name="delimiters">String containing the delimiters</param>
        </member>
        <member name="M:Encog.MathUtil.LIBSVM.SupportClass.Tokenizer.#ctor(System.String,System.String,System.Boolean)">
            <summary>
            Initializes a new class instance with a specified string to process, the specified token 
            delimiters to use, and whether the delimiters must be included in the results.
            </summary>
            <param name="source">String to tokenize</param>
            <param name="delimiters">String containing the delimiters</param>
            <param name="includeDelims">Determines if delimiters are included in the results.</param>
        </member>
        <member name="P:Encog.MathUtil.LIBSVM.SupportClass.Tokenizer.Count">
            <summary>
            Remaining tokens count
            </summary>
        </member>
        <member name="P:Encog.MathUtil.LIBSVM.SupportClass.Tokenizer.Current">
            <summary>
             Performs the same action as NextToken.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.LIBSVM.SupportClass.Tokenizer.MoveNext">
            <summary>
             Performs the same action as HasMoreTokens.
            </summary>
            <returns>True or false, depending if there are more tokens</returns>
        </member>
        <member name="M:Encog.MathUtil.LIBSVM.SupportClass.Tokenizer.Reset">
            <summary>
            Does nothing.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.LIBSVM.SupportClass.Tokenizer.NextToken">
            <summary>
            Returns the next token from the token list
            </summary>
            <returns>The string value of the token</returns>
        </member>
        <member name="M:Encog.MathUtil.LIBSVM.SupportClass.Tokenizer.NextToken(System.String)">
            <summary>
            Returns the next token from the source string, using the provided
            token delimiters
            </summary>
            <param name="delimiters">String containing the delimiters to use</param>
            <returns>The string value of the token</returns>
        </member>
        <member name="M:Encog.MathUtil.LIBSVM.SupportClass.Tokenizer.HasMoreTokens">
            <summary>
            Determines if there are more tokens to return from the source string
            </summary>
            <returns>True or false, depending if there are more tokens</returns>
        </member>
        <member name="T:Encog.MathUtil.Matrices.BiPolarUtil">
            <summary>
            This class contains a number of utility methods used to work
            with bipolar numbers. A bipolar number is another way to represent binary
            numbers. The value of true is defined to be one, where as false is defined to
            be negative one.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.BiPolarUtil.Bipolar2double(System.Boolean)">
            <summary>
            Convert binary to bipolar, true is 1 and false is -1.
            </summary>
            <param name="b">The binary value.</param>
            <returns>The bipolar value.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.BiPolarUtil.Bipolar2double(System.Boolean[])">
            <summary>
            Convert a boolean array to bipolar, true is 1 and false is -1.
            </summary>
            <param name="b">The binary array to convert.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.BiPolarUtil.Bipolar2double(System.Boolean[][])">
            <summary>
            Convert a 2D boolean array to bipolar, true is 1 and false is -1.
            </summary>
            <param name="b">The 2D array to convert.</param>
            <returns>A bipolar array.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.BiPolarUtil.Double2bipolar(System.Double)">
            <summary>
            Convert biploar to boolean, true is 1 and false is -1.
            </summary>
            <param name="d">A bipolar value.</param>
            <returns>A boolean value.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.BiPolarUtil.Double2bipolar(System.Double[])">
            <summary>
            Convert a bipolar array to a boolean array, true is 1 and false is -1.
            </summary>
            <param name="d">A bipolar array.</param>
            <returns>A boolean array.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.BiPolarUtil.Double2bipolar(System.Double[][])">
            <summary>
            Convert a 2D bipolar array to a boolean array, true is 1 and false is -1.
            </summary>
            <param name="d">A 2D bipolar array.</param>
            <returns>A 2D boolean array.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.BiPolarUtil.NormalizeBinary(System.Double)">
            <summary>
            Normalize a binary number.  Greater than 0 becomes 1, zero and below are false.
            </summary>
            <param name="d">A binary number in a double.</param>
            <returns>A double that will be 0 or 1.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.BiPolarUtil.ToBinary(System.Double)">
            <summary>
            Convert a single number from bipolar to binary.
            </summary>
            <param name="d">a bipolar number.</param>
            <returns>A binary number.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.BiPolarUtil.ToBiPolar(System.Double)">
            <summary>
            Convert a number to bipolar.
            </summary>
            <param name="d">A binary number.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.BiPolarUtil.ToNormalizedBinary(System.Double)">
            <summary>
            Normalize a number and convert to binary.
            </summary>
            <param name="d">A bipolar number.</param>
            <returns>A binary number stored as a double</returns>
        </member>
        <member name="T:Encog.MathUtil.Matrices.Decomposition.CholeskyDecomposition">
            <summary>
            Cholesky Decomposition.
            
            For a symmetric, positive definite matrix A, the Cholesky decomposition is an
            lower triangular matrix L so that A = L*L'.
            
            If the matrix is not symmetric or positive definite, the constructor returns
            a partial decomposition and sets an internal flag that may be queried by the
            isSPD() method.
            
            This file based on a class from the public domain JAMA package.
            http://math.nist.gov/javanumerics/jama/
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.CholeskyDecomposition.isspd">
            <summary>
            Symmetric and positive definite flag.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.CholeskyDecomposition.l">
            <summary>
            Array for internal storage of decomposition.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.CholeskyDecomposition.n">
            <summary>
            Row and column dimension (square matrix).
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Decomposition.CholeskyDecomposition.#ctor(Encog.MathUtil.Matrices.Matrix)">
            <summary>
            Cholesky algorithm for symmetric and positive definite matrix.
            </summary>
            <param name="matrix">Square, symmetric matrix.</param>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Decomposition.CholeskyDecomposition.IsSPD">
            <summary>
            Is the matrix symmetric and positive definite?
            </summary>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Decomposition.CholeskyDecomposition.L">
            <summary>
            Return triangular factor.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Decomposition.CholeskyDecomposition.Solve(Encog.MathUtil.Matrices.Matrix)">
            <summary>
            Solve A*X = B.
            </summary>
            <param name="b">A Matrix with as many rows as A and any number of columns.</param>
            <returns>X so that L*L'*X = b.</returns>
        </member>
        <member name="T:Encog.MathUtil.Matrices.Decomposition.EigenvalueDecomposition">
             <summary>
             Eigenvalues and eigenvectors of a real matrix.
             
             If A is symmetric, then A = V*D*V' where the eigenvalue matrix D is diagonal
             and the eigenvector matrix V is orthogonal. I.e. A =
             V.times(D.times(V.transpose())) and V.times(V.transpose()) equals the
             identity matrix.
            
             If A is not symmetric, then the eigenvalue matrix D is block diagonal with
             the real eigenvalues in 1-by-1 blocks and any complex eigenvalues, lambda +
             i*mu, in 2-by-2 blocks, [lambda, mu; -mu, lambda]. The columns of V represent
             the eigenvectors in the sense that A*V = V*D, i.e. A.times(V) equals
             V.times(D). The matrix V may be badly conditioned, or even singular, so the
             validity of the equation A = V*D*inverse(V) depends upon V.cond().
             
             This file based on a class from the public domain JAMA package.
             http://math.nist.gov/javanumerics/jama/
             </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.EigenvalueDecomposition.d">
            <summary>
            Arrays for internal storage of eigenvalues.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.EigenvalueDecomposition.e">
            <summary>
            Arrays for internal storage of eigenvalues.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.EigenvalueDecomposition.h">
            <summary>
            Array for internal storage of nonsymmetric Hessenberg form.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.EigenvalueDecomposition.issymmetric">
            <summary>
            Symmetry flag.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.EigenvalueDecomposition.n">
            <summary>
            Row and column dimension (square matrix).
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.EigenvalueDecomposition.ort">
            <summary>
            Working storage for nonsymmetric algorithm.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.EigenvalueDecomposition.v">
            <summary>
            Array for internal storage of eigenvectors.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.EigenvalueDecomposition.cdivi">
            <summary>
            Complex scalar division.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.EigenvalueDecomposition.cdivr">
            <summary>
            Complex scalar division.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Decomposition.EigenvalueDecomposition.#ctor(Encog.MathUtil.Matrices.Matrix)">
            <summary>
            Check for symmetry, then construct the eigenvalue decomposition
            </summary>
            <param name="matrix">Square matrix</param>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Decomposition.EigenvalueDecomposition.V">
            <summary>
            Return the eigenvector matrix.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Decomposition.EigenvalueDecomposition.RealEigenvalues">
            <summary>
            Return the real parts of the eigenvalues.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Decomposition.EigenvalueDecomposition.D">
            <summary>
            Return the block diagonal eigenvalue matrix
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Decomposition.EigenvalueDecomposition.Tred2">
            <summary>
            Symmetric Householder reduction to tridiagonal form.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Decomposition.EigenvalueDecomposition.Tql2">
            <summary>
            Symmetric tridiagonal QL algorithm.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Decomposition.EigenvalueDecomposition.Orthes">
            <summary>
            This is derived from the Algol procedures orthes and ortran, by Martin
            and Wilkinson, Handbook for Auto. Comp., Vol.ii-Linear Algebra, and the
            corresponding Fortran subroutines in EISPACK.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Decomposition.EigenvalueDecomposition.Hqr2">
            <summary>
            This is derived from the Algol procedure hqr2, by Martin and Wilkinson,
            Handbook for Auto. Comp., Vol.ii-Linear Algebra, and the corresponding
            Fortran subroutine in EISPACK.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Decomposition.EigenvalueDecomposition.getImagEigenvalues">
            Return the imaginary parts of the eigenvalues.
            
            @return imag(diag(D)).
        </member>
        <member name="T:Encog.MathUtil.Matrices.Decomposition.LUDecomposition">
             <summary>
             LU Decomposition.
            
             For an m-by-n matrix A with m >= n, the LU decomposition is an m-by-n unit
             lower triangular matrix L, an n-by-n upper triangular matrix U, and a
             permutation vector piv of length m so that A(piv,:) = L*U. If m less than n, then L
             is m-by-m and U is m-by-n.
            
             The LU decompostion with pivoting always exists, even if the matrix is
             singular, so the constructor will never fail. The primary use of the LU
             decomposition is in the solution of square systems of simultaneous linear
             equations. This will fail if isNonsingular() returns false.
             
             This file based on a class from the public domain JAMA package.
             http://math.nist.gov/javanumerics/jama/
             </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.LUDecomposition.LU">
            <summary>
            Array for internal storage of decomposition.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.LUDecomposition.m">
            <summary>
            column dimension.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.LUDecomposition.n">
            <summary>
            row dimension.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.LUDecomposition.piv">
            <summary>
            Internal storage of pivot vector.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.LUDecomposition.pivsign">
            <summary>
            pivot sign.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Decomposition.LUDecomposition.#ctor(Encog.MathUtil.Matrices.Matrix)">
            <summary>
            LU Decomposition
            </summary>
            <param name="A">Rectangular matrix</param>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Decomposition.LUDecomposition.IsNonsingular">
            <summary>
            Is the matrix nonsingular?
            </summary>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Decomposition.LUDecomposition.L">
            <summary>
            Return lower triangular factor
            </summary>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Decomposition.LUDecomposition.U">
            Return upper triangular factor
            
            @return U
        </member>
        <member name="P:Encog.MathUtil.Matrices.Decomposition.LUDecomposition.Pivot">
            <summary>
            Return pivot permutation vector
            </summary>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Decomposition.LUDecomposition.DoublePivot">
            <summary>
            Return pivot permutation vector as a one-dimensional double array
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Decomposition.LUDecomposition.Det">
            <summary>
            Determinant
            </summary>
            <returns>det(A)</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Decomposition.LUDecomposition.Solve(Encog.MathUtil.Matrices.Matrix)">
            <summary>
            Solve A*X = B
            </summary>
            <param name="B">A Matrix with as many rows as A and any number of columns.</param>
            <returns>so that L*U*X = B(piv,:)</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Decomposition.LUDecomposition.Solve(System.Double[])">
            <summary>
            Solve the matrix for a 1d array.
            </summary>
            <param name="value_ren">The value to solve for.</param>
            <returns>The solved matrix.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Decomposition.LUDecomposition.Inverse">
            <summary>
            Solves a set of equation systems of type <c>A * X = B</c>.
            </summary>
            <returns>Matrix <c>X</c> so that <c>L * U * X = B</c>.</returns>
        </member>
        <member name="T:Encog.MathUtil.Matrices.Decomposition.QRDecomposition">
             <summary>
             QR Decomposition.
            
             For an m-by-n matrix A with m >= n, the QR decomposition is an m-by-n
             orthogonal matrix Q and an n-by-n upper triangular matrix R so that A = Q*R.
            
             The QR decompostion always exists, even if the matrix does not have full
             rank, so the constructor will never fail. The primary use of the QR
             decomposition is in the least squares solution of nonsquare systems of
             simultaneous linear equations. This will fail if isFullRank() returns false.
             
             This file based on a class from the public domain JAMA package.
             http://math.nist.gov/javanumerics/jama/
             </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.QRDecomposition.QR">
            <summary>
            Array for internal storage of decomposition.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.QRDecomposition.Rdiag">
            <summary>
            Array for internal storage of diagonal of R.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.QRDecomposition.m">
            <summary>
            Row dimension.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.QRDecomposition.n">
            <summary>
            Column dimension.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Decomposition.QRDecomposition.#ctor(Encog.MathUtil.Matrices.Matrix)">
            <summary>
            QR Decomposition, computed by Householder reflections.
            </summary>
            <param name="A">Structure to access R and the Householder vectors and compute Q.</param>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Decomposition.QRDecomposition.H">
            <summary>
            Return the Householder vectors
            </summary>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Decomposition.QRDecomposition.R">
            Return the upper triangular factor
            
            @return R
        </member>
        <member name="P:Encog.MathUtil.Matrices.Decomposition.QRDecomposition.Q">
            <summary>
            Generate and return the (economy-sized) orthogonal factor
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Decomposition.QRDecomposition.IsFullRank">
            <summary>
            Is the matrix full rank? 
            </summary>
            <returns>true if R, and hence A, has full rank.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Decomposition.QRDecomposition.Solve(Encog.MathUtil.Matrices.Matrix)">
            <summary>
            Least squares solution of A*X = B
            </summary>
            <param name="B">A Matrix with as many rows as A and any number of columns.</param>
            <returns>that minimizes the two norm of Q*R*X-B.</returns>
        </member>
        <member name="T:Encog.MathUtil.Matrices.Decomposition.SingularValueDecomposition">
            <summary>
            Singular Value Decomposition.
            
            For an m-by-n matrix A with m &gt;= n, the singular value decomposition is an
            m-by-n orthogonal matrix U, an n-by-n diagonal matrix S, and an n-by-n
            orthogonal matrix V so that A = U*S*V'.
            
            The singular values, sigma[k] = S[k][k], are ordered so that sigma[0] &gt;=
            sigma[1] &gt;= ... &gt;= sigma[n-1].
            
            The singular value decompostion always exists, so the constructor will never
            fail. The matrix condition number and the effective numerical rank can be
            computed from this decomposition.
            
            This file based on a class from the public domain JAMA package.
            http://math.nist.gov/javanumerics/jama/
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.SingularValueDecomposition.m">
            <summary>
            rows
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.SingularValueDecomposition.n">
            <summary>
            cols
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.SingularValueDecomposition.s">
            <summary>
            Array for internal storage of singular values.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.SingularValueDecomposition.umatrix">
            <summary>
            The U matrix.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Decomposition.SingularValueDecomposition.vmatrix">
            <summary>
            The V matrix.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Decomposition.SingularValueDecomposition.#ctor(Encog.MathUtil.Matrices.Matrix)">
            <summary>
            Construct the singular value decomposition
            </summary>
            <param name="Arg">Rectangular matrix</param>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Decomposition.SingularValueDecomposition.U">
            <summary>
            Return the left singular vectors
            </summary>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Decomposition.SingularValueDecomposition.V">
            <summary>
            Return the right singular vectors
            </summary>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Decomposition.SingularValueDecomposition.SingularValues">
            <summary>
            The singular values.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Decomposition.SingularValueDecomposition.S">
            <summary>
            Return the diagonal matrix of singular values
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Decomposition.SingularValueDecomposition.Norm2">
            <summary>
            
            </summary>
            <returns></returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Decomposition.SingularValueDecomposition.Cond">
            <summary>
            Two norm condition number
            </summary>
            <returns>max(S)/min(S)</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Decomposition.SingularValueDecomposition.Rank">
            <summary>
            Effective numerical matrix rank
            </summary>
            <returns>The rank</returns>
        </member>
        <member name="T:Encog.MathUtil.Matrices.Hessian.BasicHessian">
            <summary>
            Some basic code used to calculate Hessian matrixes.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.BasicHessian.derivative">
            <summary>
            The derivatives.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.BasicHessian.flat">
            <summary>
            The flat network.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.BasicHessian.gradients">
            <summary>
            The gradients of the Hessian.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.BasicHessian.hessian">
            <summary>
            The Hessian 2d array.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.BasicHessian.hessianMatrix">
            <summary>
            The Hessian matrix.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.BasicHessian.network">
            <summary>
            The neural network that we would like to train.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.BasicHessian.sse">
            <summary>
            The sum of square error.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.BasicHessian.training">
            <summary>
            The training data that provides the ideal values.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Hessian.BasicHessian.Init(Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet)">
            <inheritdoc/>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Hessian.BasicHessian.Gradients">
            <inheritdoc/>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Hessian.BasicHessian.HessianMatrix">
            <inheritdoc/>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Hessian.BasicHessian.Hessian">
            <inheritdoc/>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Hessian.BasicHessian.Clear">
            <inheritdoc/>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Hessian.BasicHessian.SSE">
            <inheritdoc/>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Hessian.BasicHessian.Compute">
            <inheritdoc/>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Hessian.BasicHessian.UpdateHessian(System.Double[])">
            <summary>
            Update the Hessian, sum's with what is in the Hessian already.  Call clear to clear out old Hessian.
            </summary>
            <param name="d">The first derivatives to update with.</param>
        </member>
        <member name="T:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker">
            <summary>
            A threaded worker that is used to calculate the first derivatives of the
            output of the neural network. These values are ultimatly used to calculate
            the Hessian.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker._actual">
            <summary>
            The actual values from the neural network.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker._derivative">
            <summary>
            The current first derivatives.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker._flat">
            <summary>
            The flat network.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker._gradients">
            <summary>
            The gradients.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker._high">
            <summary>
            The high range.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker._layerCounts">
            <summary>
            The neuron counts, per layer.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker._layerDelta">
            <summary>
            The deltas for each layer.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker._layerFeedCounts">
            <summary>
            The feed counts, per layer.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker._layerIndex">
            <summary>
            The layer indexes.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker._layerOutput">
            <summary>
            The output from each layer.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker._layerSums">
            <summary>
            The sums.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker._low">
            <summary>
            The low range.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker._pair">
            <summary>
            The pair to use for training.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker._totDeriv">
            <summary>
            The total first derivatives.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker._training">
            <summary>
            The training data.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker._weightIndex">
            <summary>
            The index to each layer's weights and thresholds.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker._weights">
            <summary>
            The weights and thresholds.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker._error">
            <summary>
            The error.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker._outputNeuron">
            <summary>
            The output neuron to calculate for.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker.#ctor(Encog.Neural.Flat.FlatNetwork,Encog.ML.Data.IMLDataSet,System.Int32,System.Int32)">
            <summary>
            Construct the chain rule worker. 
            </summary>
            <param name="theNetwork">The network to calculate a Hessian for.</param>
            <param name="theTraining">The training data.</param>
            <param name="theLow">The low range.</param>
            <param name="theHigh">The high range.</param>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker.OutputNeuron">
            <summary>
            The output neuron we are processing.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker.Derivative">
            <summary>
            The first derivatives, used to calculate the Hessian.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker.Gradients">
            <summary>
            The gradients.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker.Error">
            <summary>
            The SSE error.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker.Network">
            <summary>
            The flat network.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker.Run">
            <inheritdoc/>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker.Process(System.Int32,System.Double[],System.Double[])">
            <summary>
            Process one training set element.
            </summary>
            <param name="outputNeuron">The output neuron.</param>
            <param name="input">The network input.</param>
            <param name="ideal">The ideal values.</param>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Hessian.ChainRuleWorker.ProcessLevel(System.Int32)">
            <summary>
            Process one level. 
            </summary>
            <param name="currentLevel">The level.</param>
        </member>
        <member name="T:Encog.MathUtil.Matrices.Hessian.HessianCR">
            <summary>
            Calculate the Hessian matrix using the chain rule method. 
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.HessianCR._numThreads">
            <summary>
            The number of threads to use.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.HessianCR._workers">
            <summary>
            The workers.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Hessian.HessianCR.ThreadCount">
            <summary>
            Set the number of threads. Specify zero to tell Encog to automatically
            determine the best number of threads for the processor. If OpenCL is used
            as the target device, then this value is not used.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Hessian.HessianCR.Init(Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Hessian.HessianCR.Compute">
            <inheritdoc/>
        </member>
        <member name="T:Encog.MathUtil.Matrices.Hessian.HessianFD">
            <summary>
            Calculate the Hessian matrix using the finite difference method. This is a
            very simple method of calculating the Hessian. The algorithm does not vary
            greatly by number layers. This makes it very useful as a tool to check the
            accuracy of other methods of determining the Hessian.
            
            For more information on the Finite Difference Method see the following article.
            
            http://en.wikipedia.org/wiki/Finite_difference_method
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.HessianFD.InitialStep">
            <summary>
            The initial step size for dStep.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.HessianFD._center">
            <summary>
            The center of the point array.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.HessianFD._dCoeff">
            <summary>
            The derivative coefficient, used for the finite difference method.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.HessianFD._dStep">
            <summary>
            The derivative step size, used for the finite difference method.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.HessianFD._pointCount">
            <summary>
            The number of points actually used, which is (pointsPerSide*2)+1. 
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Hessian.HessianFD._pointsPerSide">
            <summary>
            The number of points requested per side.  This determines the accuracy of the calculation.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Hessian.HessianFD.PointsPerSide">
            <summary>
            The number of points per side.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Hessian.HessianFD.Init(Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Hessian.HessianFD.Compute">
            <inheritdoc/>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Hessian.HessianFD.InternalCompute(System.Int32)">
            <summary>
            Called internally to compute each output neuron.
            </summary>
            <param name="outputNeuron">The output neuron to compute.</param>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Hessian.HessianFD.ComputeDerivative(Encog.ML.Data.IMLData,System.Int32,System.Int32,System.Double[],System.Double,System.Int32)">
            <summary>
            Computes the derivative of the output of the neural network with respect to a weight. 
            </summary>
            <param name="inputData">The input data to the neural network.</param>
            <param name="outputNeuron">The output neuron to calculate for.</param>
            <param name="weight">The weight.</param>
            <param name="stepSize">The step size.</param>
            <param name="networkOutput">The output from the neural network.</param>
            <param name="row">The training row currently being processed.</param>
            <returns>The derivative output.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Hessian.HessianFD.CreateCoefficients">
             <summary>
             Compute finite difference coefficients according to the method provided here:
             
             http://en.wikipedia.org/wiki/Finite_difference_coefficients
            
             </summary>
             <returns>An array of the coefficients for FD.</returns>
        </member>
        <member name="T:Encog.MathUtil.Matrices.Hessian.IComputeHessian">
            <summary>
             Compute (estimate) the Hessian matrix. The Hessian matrix is a matrix of the second
            derivatives of the neural network. This is a square matrix with rows and columns
            equal to the number of weights in the neural network.
            
            A Hessian matrix is useful for several neural network functions.  It is also used
            by the Levenberg Marquardt training method. 
            
            http://en.wikipedia.org/wiki/Hessian_matrix
            </summary>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Hessian.IComputeHessian.Gradients">
            <summary>
            The gradeints. 
            </summary>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Hessian.IComputeHessian.SSE">
            <summary>
            The sum of squares error over all of the training elements.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Hessian.IComputeHessian.HessianMatrix">
            <summary>
            The Hessian matrix.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Hessian.IComputeHessian.Hessian">
            <summary>
            Get the Hessian as a 2d array.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Hessian.IComputeHessian.Init(Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet)">
            <summary>
            Init the class.  
            </summary>
            <param name="theNetwork">The neural network to train.</param>
            <param name="theTraining">The training set to train with.</param>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Hessian.IComputeHessian.Compute">
            <summary>
            Compute the Hessian.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Hessian.IComputeHessian.Clear">
            <summary>
            Clear the Hessian and gradients.
            </summary>
        </member>
        <member name="T:Encog.MathUtil.Matrices.Matrix">
            <summary>
            Matrix: This class implements a mathematical matrix.  Matrix
            math is very important to neural network processing.  Many
            of the classes developed in this book will make use of the
            matrix classes in this package.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Matrix.Item(System.Int32,System.Int32)">
            <summary>
            Allows index access to the elements of the matrix.
            Warning: This can be a somewhat slow way to access the matrix.  
            Do not put this in performance critical loops.  Make sure to use
            the Data property and access the matrix array directly.
            </summary>
            <param name="row">The row to access.</param>
            <param name="col">The column to access.</param>
            <returns>The element at the specified position in the matrix.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.CreateColumnMatrix(System.Double[])">
            <summary>
            Create a matrix that is a single column.
            </summary>
            <param name="input">A 1D array to make the matrix from.</param>
            <returns>A matrix that contains a single column.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.CreateRowMatrix(System.Double[])">
            <summary>
            Create a matrix that is a single row.
            </summary>
            <param name="input">A 1D array to make the matrix from.</param>
            <returns>A matrix that contans a single row.</returns>
        </member>
        <member name="F:Encog.MathUtil.Matrices.Matrix.matrix">
            <summary>
            The matrix data, stored as a 2D array.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.#ctor(System.Boolean[][])">
            <summary>
            Construct a matrix from a 2D boolean array.  Translate true to 1, false to -1.
            </summary>
            <param name="sourceMatrix">A 2D array to construcat the matrix from.</param>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.#ctor(System.Double[][])">
            <summary>
            Construct a matrix from a 2D double array.
            </summary>
            <param name="sourceMatrix">A 2D double array.</param>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.#ctor(System.Int32,System.Int32)">
            <summary>
            Construct a blank matrix with the specified number of rows and columns.
            </summary>
            <param name="rows">How many rows.</param>
            <param name="cols">How many columns.</param>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.Add(System.Int32,System.Int32,System.Double)">
            <summary>
            Add the specified value to the specified row and column of the matrix.
            </summary>
            <param name="row">The row to add to.</param>
            <param name="col">The column to add to.</param>
            <param name="value_ren">The value to add.</param>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.Clear">
            <summary>
            Clear the matrix.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.Clone">
            <summary>
            Clone the matrix.
            </summary>
            <returns>A cloned copy of the matrix.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.Equals(System.Object)">
            <summary>
            Determine if this matrix is equal to another.  Use a precision of 10 decimal places.
            </summary>
            <param name="other">The other matrix to compare.</param>
            <returns>True if the two matrixes are equal.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.GetHashCode">
            <summary>
            Generate a hash code, this is just rows+cols.  Probably a better way to 
            do this, but I really don't see the Matrix class being used as the key to
            a hash table.  
            </summary>
            <returns>A hash code for the matrix.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.equals(Encog.MathUtil.Matrices.Matrix,System.Int32)">
            <summary>
            Compare the matrix to another with the specified level of precision.
            </summary>
            <param name="matrix">The other matrix to compare.</param>
            <param name="precision">The number of decimal places of precision to use.</param>
            <returns>True if the two matrixes are equal.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.FromPackedArray(System.Double[],System.Int32)">
            <summary>
            Take the values of thie matrix from a packed array.
            </summary>
            <param name="array">The packed array to read the matrix from.</param>
            <param name="index">The index to begin reading at in the array.</param>
            <returns>The new index after this matrix has been read.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.GetCol(System.Int32)">
            <summary>
            Get one column from this matrix as a column matrix.
            </summary>
            <param name="col">The desired column.</param>
            <returns>The column matrix.</returns>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Matrix.Cols">
            <summary>
            Get the number of columns in this matrix
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.GetRow(System.Int32)">
            <summary>
            Get the specified row as a row matrix.
            </summary>
            <param name="row">The desired row.</param>
            <returns>A row matrix.</returns>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Matrix.Rows">
            <summary>
            Get the number of rows in this matrix
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.IsVector">
            <summary>
            Determine if this matrix is a vector.  A vector matrix only has a single row or column.
            </summary>
            <returns>True if this matrix is a vector.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.IsZero">
            <summary>
            Determine if all of the values in the matrix are zero.
            </summary>
            <returns>True if all of the values in the matrix are zero.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.Ramdomize(System.Double,System.Double)">
            <summary>
            Fill the matrix with random values in the specified range.
            </summary>
            <param name="min">The minimum value for the random numbers.</param>
            <param name="max">The maximum value for the random numbers.</param>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Matrix.Size">
            <summary>
            Get the size fo the matrix.  This is thr rows times the columns.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.Sum">
            <summary>
            Sum all of the values in the matrix.
            </summary>
            <returns>The sum of all of the values in the matrix.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.ToPackedArray">
            <summary>
            Convert the matrix to a packed array.
            </summary>
            <returns>A packed array.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.Validate(System.Int32,System.Int32)">
            <summary>
            Validate that the specified row and column are inside of the range of the matrix.
            </summary>
            <param name="row">The row to check.</param>
            <param name="col">The column to check.</param>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.Add(Encog.MathUtil.Matrices.Matrix)">
            <summary>
            Add the specified matrix to this matrix.  This will modify the matrix
            to hold the result of the addition.
            </summary>
            <param name="matrix">The matrix to add.</param>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.Set(System.Double)">
            <summary>
            Set every value in the matrix to the specified value.
            </summary>
            <param name="value_ren">The value to set the matrix to.</param>
        </member>
        <member name="P:Encog.MathUtil.Matrices.Matrix.Data">
            <summary>
            Get the matrix array for this matrix.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.Set(Encog.MathUtil.Matrices.Matrix)">
            <summary>
            Set the values from the other matrix into this one.
            </summary>
            <param name="other">The source matrix.</param>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.GetArrayCopy">
            <summary>
            Make a copy of this matrix as an array.
            </summary>
            <returns>An array copy of this matrix.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.GetMatrix(System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            Get a submatrix.
            </summary>
            <param name="i0">Initial row index.</param>
            <param name="i1">Final row index.</param>
            <param name="j0">Initial column index.</param>
            <param name="j1">Final column index.</param>
            <returns>The specified submatrix.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.GetMatrix(System.Int32[],System.Int32[])">
            <summary>
            Get a submatrix.
            </summary>
            <param name="r">Array of row indices.</param>
            <param name="c">Array of column indices.</param>
            <returns>The specified submatrix.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.GetMatrix(System.Int32,System.Int32,System.Int32[])">
            <summary>
            Get a submatrix.
            </summary>
            <param name="i0">Initial row index.</param>
            <param name="i1">Final row index.</param>
            <param name="c">Array of column indices.</param>
            <returns>The specified submatrix.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.GetMatrix(System.Int32[],System.Int32,System.Int32)">
            <summary>
            Get a submatrix.
            </summary>
            <param name="r">Array of row indices.</param>
            <param name="j0">Initial column index</param>
            <param name="j1">Final column index</param>
            <returns>The specified submatrix.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.Multiply(System.Double[],System.Double[])">
            <summary>
            Multiply every row by the specified vector.
            </summary>
            <param name="vector">The vector to multiply by.</param>
            <param name="result">The result to hold the values.</param>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.Inverse">
            <summary>
            The matrix inverted.
            </summary>
            <returns>The inverse of the matrix.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.Solve(Encog.MathUtil.Matrices.Matrix)">
            <summary>
            Solve A*X = B
            </summary>
            <param name="b">right hand side.</param>
            <returns>Solution if A is square, least squares solution otherwise.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.SetMatrix(System.Int32,System.Int32,System.Int32,System.Int32,Encog.MathUtil.Matrices.Matrix)">
            <summary>
            Set a submatrix.
            </summary>
            <param name="i0">Initial row index</param>
            <param name="i1">Final row index</param>
            <param name="j0">Initial column index</param>
            <param name="j1">Final column index</param>
            <param name="x">A(i0:i1,j0:j1)</param>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.SetMatrix(System.Int32[],System.Int32[],Encog.MathUtil.Matrices.Matrix)">
            <summary>
            Set a submatrix.
            </summary>
            <param name="r">Array of row indices.</param>
            <param name="c">Array of column indices.</param>
            <param name="x">The matrix to set.</param>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.SetMatrix(System.Int32[],System.Int32,System.Int32,Encog.MathUtil.Matrices.Matrix)">
            <summary>
            Set a submatrix.
            </summary>
            <param name="r">Array of row indices.</param>
            <param name="j0">Initial column index</param>
            <param name="j1">Final column index</param>
            <param name="x">A(r(:),j0:j1)</param>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.SetMatrix(System.Int32,System.Int32,System.Int32[],Encog.MathUtil.Matrices.Matrix)">
            <summary>
            Set a submatrix. 
            </summary>
            <param name="i0">Initial row index</param>
            <param name="i1">Final row index</param>
            <param name="c">Array of column indices.</param>
            <param name="x">The submatrix.</param>
        </member>
        <member name="M:Encog.MathUtil.Matrices.Matrix.Randomize(System.Double,System.Double)">
             <summary>
             Randomize the matrix.
             </summary>
            
             <param name="min">Minimum random value.</param>
             <param name="max">Maximum random value.</param>
        </member>
        <member name="T:Encog.MathUtil.Matrices.MatrixError">
            <summary>
            Indicates an error has occurred in Matrix classes..
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.MatrixError.#ctor(System.String)">
            <summary>
            Construct a message exception.
            </summary>
            <param name="str">The message.</param>
        </member>
        <member name="M:Encog.MathUtil.Matrices.MatrixError.#ctor(System.Exception)">
            <summary>
            Pass on an exception.
            </summary>
            <param name="e">The other exception.</param>
        </member>
        <member name="T:Encog.MathUtil.Matrices.MatrixMath">
            <summary>
            MatrixMath: This class can perform many different mathematical
            operations on matrixes.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.MatrixMath.#ctor">
            <summary>
            Private constructor.  All methods are static.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Matrices.MatrixMath.Add(Encog.MathUtil.Matrices.Matrix,Encog.MathUtil.Matrices.Matrix)">
            <summary>
            Add two matrixes together, producing a third.
            </summary>
            <param name="a">The first matrix to add.</param>
            <param name="b">The second matrix to add.</param>
            <returns>The two matrixes added together.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.MatrixMath.Copy(Encog.MathUtil.Matrices.Matrix,Encog.MathUtil.Matrices.Matrix)">
            <summary>
            Copy the source matrix to the target matrix.  Both matrixes must have the same dimensions.
            </summary>
            <param name="source">The source matrix.</param>
            <param name="target">The target matrix.</param>
        </member>
        <member name="M:Encog.MathUtil.Matrices.MatrixMath.DeleteCol(Encog.MathUtil.Matrices.Matrix,System.Int32)">
            <summary>
            Delete a single column from a matrix.  A new matrix, with the delete is returned.
            </summary>
            <param name="matrix">The matrix to delete from.</param>
            <param name="deleted">The column to delete.</param>
            <returns>The matrix, with the delete.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.MatrixMath.DeleteRow(Encog.MathUtil.Matrices.Matrix,System.Int32)">
            <summary>
            Delete a row from a matrix.  A new matrix, with the row deleted, is returned.
            </summary>
            <param name="matrix">The matrix to delete from.</param>
            <param name="deleted">The row to delete.</param>
            <returns>The matrix, with the row deleted.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.MatrixMath.Divide(Encog.MathUtil.Matrices.Matrix,System.Double)">
            <summary>
            Divide every cell in the matrix by the specified number.
            </summary>
            <param name="a">The matrix to divide.</param>
            <param name="b">The number to divide by.</param>
            <returns>The divided matrix.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.MatrixMath.DotProduct(Encog.MathUtil.Matrices.Matrix,Encog.MathUtil.Matrices.Matrix)">
            <summary>
            Compute the dot product for two matrixes.  Note: both matrixes must be vectors.
            </summary>
            <param name="a">The first matrix, must be a vector.</param>
            <param name="b">The second matrix, must be a vector.</param>
            <returns>The dot product of the two matrixes.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.MatrixMath.Identity(System.Int32)">
            <summary>
            Create an identiry matrix, of the specified size.  An identity matrix is always square.
            </summary>
            <param name="size"></param>
            <returns></returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.MatrixMath.Multiply(Encog.MathUtil.Matrices.Matrix,System.Double)">
            <summary>
            Multiply every cell in the matrix by the specified value.
            </summary>
            <param name="a">Multiply every cell in a matrix by the specified value.</param>
            <param name="b">The value to multiply by.</param>
            <returns>The new multiplied matrix.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.MatrixMath.Multiply(Encog.MathUtil.Matrices.Matrix,Encog.MathUtil.Matrices.Matrix)">
            <summary>
            Multiply two matrixes.
            </summary>
            <param name="a">The first matrix.</param>
            <param name="b">The second matrix.</param>
            <returns>The resulting matrix.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.MatrixMath.Subtract(Encog.MathUtil.Matrices.Matrix,Encog.MathUtil.Matrices.Matrix)">
            <summary>
            Subtract one matrix from another.  The two matrixes must have the same number of rows and columns.
            </summary>
            <param name="a">The first matrix.</param>
            <param name="b">The second matrix.</param>
            <returns>The subtracted matrix.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.MatrixMath.Transpose(Encog.MathUtil.Matrices.Matrix)">
            <summary>
            Transpose the specified matrix.
            </summary>
            <param name="input">The matrix to transpose.</param>
            <returns>The transposed matrix.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.MatrixMath.VectorLength(Encog.MathUtil.Matrices.Matrix)">
            <summary>
            Calculate the vector length of the matrix.
            </summary>
            <param name="input">The vector to calculate for.</param>
            <returns>The vector length.</returns>
        </member>
        <member name="M:Encog.MathUtil.Matrices.MatrixMath.Multiply(Encog.MathUtil.Matrices.Matrix,System.Double[])">
            <summary>
            Multiply the matrix by a vector.
            </summary>
            <param name="a">The matrix.</param>
            <param name="d">The vector.</param>
            <returns>The resulting vector.</returns>
        </member>
        <member name="T:Encog.MathUtil.NumericRange">
            <summary>
            A numeric range has a high, low, mean, root-mean-square, standard deviation,
            and the count of how many samples it contains.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.NumericRange._high">
            <summary>
            The high number in the range.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.NumericRange._low">
            <summary>
            The low number in the range.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.NumericRange._mean">
            <summary>
            The mean value.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.NumericRange._rms">
            <summary>
            The root mean square of the range.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.NumericRange._samples">
            <summary>
            The number of values in this range.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.NumericRange._standardDeviation">
            <summary>
            The standard deviation of the range.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.NumericRange.#ctor(System.Collections.Generic.IList{System.Double})">
            <summary>
            Create a numeric range from a list of values. 
            </summary>
            <param name="values">The values to calculate for.</param>
        </member>
        <member name="P:Encog.MathUtil.NumericRange.High">
            <summary>
            The high number in the range.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.NumericRange.Low">
            <summary>
            The low number in the range.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.NumericRange.Mean">
            <summary>
            The mean in the range.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.NumericRange.RMS">
            <summary>
            The root mean square of the range.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.NumericRange.StandardDeviation">
            <summary>
            The standard deviation of the range.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.NumericRange.Samples">
            <summary>
            The number of samples in the range.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.NumericRange.ToString">
            <summary>
            The range as a string.
            </summary>
            <returns>The range as a string.</returns>
        </member>
        <member name="T:Encog.MathUtil.Randomize.BasicRandomizer">
            <summary>
            Provides basic functionality that most randomizers will need.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Randomize.BasicRandomizer._random">
             <summary>
             The random number generator.
             </summary>
            
        </member>
        <member name="M:Encog.MathUtil.Randomize.BasicRandomizer.#ctor">
             <summary>
             Construct a random number generator with a random(current time) seed. If
             you want to set your own seed, just call "getRandom().setSeed".
             </summary>
            
        </member>
        <member name="P:Encog.MathUtil.Randomize.BasicRandomizer.Random">
            <value>the random to set</value>
        </member>
        <member name="M:Encog.MathUtil.Randomize.BasicRandomizer.Randomize(System.Double[])">
             <summary>
             Randomize the array based on an array, modify the array. Previous values
             may be used, or they may be discarded, depending on the randomizer.
             </summary>
            
             <param name="d">An array to randomize.</param>
        </member>
        <member name="M:Encog.MathUtil.Randomize.BasicRandomizer.Randomize(System.Double[],System.Int32,System.Int32)">
             <summary>
             Randomize the array based on an array, modify the array. Previous values
             may be used, or they may be discarded, depending on the randomizer.
             </summary>
            
             <param name="d">An array to randomize.</param>
             <param name="begin">The beginning element of the array.</param>
             <param name="size">The size of the array to copy.</param>
        </member>
        <member name="M:Encog.MathUtil.Randomize.BasicRandomizer.Randomize(System.Double[][])">
             <summary>
             Randomize the 2d array based on an array, modify the array. Previous
             values may be used, or they may be discarded, depending on the
             randomizer.
             </summary>
            
             <param name="d">An array to randomize.</param>
        </member>
        <member name="M:Encog.MathUtil.Randomize.BasicRandomizer.Randomize(Encog.MathUtil.Matrices.Matrix)">
             <summary>
             Randomize the matrix based on an array, modify the array. Previous values
             may be used, or they may be discarded, depending on the randomizer.
             </summary>
            
             <param name="m">A matrix to randomize.</param>
        </member>
        <member name="M:Encog.MathUtil.Randomize.BasicRandomizer.Randomize(Encog.ML.IMLMethod)">
             <summary>
             Randomize the synapses and biases in the basic network based on an array,
             modify the array. Previous values may be used, or they may be discarded,
             depending on the randomizer.
             </summary>
            
             <param name="method">A network to randomize.</param>
        </member>
        <member name="M:Encog.MathUtil.Randomize.BasicRandomizer.Randomize(System.Double)">
             <summary>
             from Encog.mathutil.randomize.Randomizer
             </summary>
            
        </member>
        <member name="M:Encog.MathUtil.Randomize.BasicRandomizer.NextDouble">
            <returns>The next double.</returns>
        </member>
        <member name="M:Encog.MathUtil.Randomize.BasicRandomizer.NextDouble(System.Double,System.Double)">
             <summary>
             Generate a random number in the specified range.
             </summary>
            
             <param name="min">The minimum value.</param>
             <param name="max">The maximum value.</param>
             <returns>A random number.</returns>
        </member>
        <member name="M:Encog.MathUtil.Randomize.BasicRandomizer.Randomize(Encog.Neural.Networks.BasicNetwork,System.Int32)">
             <summary>
             Randomize one level of a neural network.
             </summary>
            
             <param name="network">The network to randomize</param>
             <param name="fromLayer">The from level to randomize.</param>
        </member>
        <member name="T:Encog.MathUtil.Randomize.ConsistentRandomizer">
             <summary>
             A randomizer that takes a seed and will always produce consistent results.
             </summary>
            
        </member>
        <member name="F:Encog.MathUtil.Randomize.ConsistentRandomizer._max">
             <summary>
             The maximum value for the random range.
             </summary>
            
        </member>
        <member name="F:Encog.MathUtil.Randomize.ConsistentRandomizer._min">
             <summary>
             The minimum value for the random range.
             </summary>
            
        </member>
        <member name="F:Encog.MathUtil.Randomize.ConsistentRandomizer._rand">
             <summary>
             The generator.
             </summary>
            
        </member>
        <member name="F:Encog.MathUtil.Randomize.ConsistentRandomizer._seed">
             <summary>
             The seed.
             </summary>
            
        </member>
        <member name="M:Encog.MathUtil.Randomize.ConsistentRandomizer.#ctor(System.Double,System.Double)">
             <summary>
             Construct a range randomizer.
             </summary>
            
             <param name="min">The minimum random value.</param>
             <param name="max">The maximum random value.</param>
        </member>
        <member name="M:Encog.MathUtil.Randomize.ConsistentRandomizer.#ctor(System.Double,System.Double,System.Int32)">
             <summary>
             Construct a range randomizer.
             </summary>
            
             <param name="min">The minimum random value.</param>
             <param name="max">The maximum random value.</param>
             <param name="seed">The seed value.</param>
        </member>
        <member name="M:Encog.MathUtil.Randomize.ConsistentRandomizer.Randomize(System.Double)">
             <summary>
             Generate a random number based on the range specified in the constructor.
             </summary>
            
             <param name="d">The range randomizer ignores this value.</param>
             <returns>The random number.</returns>
        </member>
        <member name="M:Encog.MathUtil.Randomize.ConsistentRandomizer.Randomize(Encog.Neural.Networks.BasicNetwork)">
             <summary>
             Randomize the network.
             </summary>
            
             <param name="network">The network to randomize.</param>
        </member>
        <member name="T:Encog.MathUtil.Randomize.ConstRandomizer">
             <summary>
             A randomizer that will create always set the random number to a const value,
             used mainly for testing.
             </summary>
            
        </member>
        <member name="F:Encog.MathUtil.Randomize.ConstRandomizer.value">
             <summary>
             The constant value.
             </summary>
            
        </member>
        <member name="M:Encog.MathUtil.Randomize.ConstRandomizer.#ctor(System.Double)">
             <summary>
             Construct a range randomizer.
             </summary>
            
             <param name="v">The constant value.</param>
        </member>
        <member name="M:Encog.MathUtil.Randomize.ConstRandomizer.Randomize(System.Double)">
             <summary>
             Generate a random number based on the range specified in the constructor.
             </summary>
            
             <param name="d">The range randomizer ignores this value.</param>
             <returns>The random number.</returns>
        </member>
        <member name="T:Encog.MathUtil.Randomize.Distort">
             <summary>
             A randomizer that distorts what is already present in the neural network.
             </summary>
            
        </member>
        <member name="F:Encog.MathUtil.Randomize.Distort._factor">
             <summary>
             The factor to use to distort the numbers.
             </summary>
            
        </member>
        <member name="M:Encog.MathUtil.Randomize.Distort.#ctor(System.Double)">
             <summary>
             Construct a distort randomizer for the specified factor.
             </summary>
            
             <param name="f">The randomizer factor.</param>
        </member>
        <member name="M:Encog.MathUtil.Randomize.Distort.Randomize(System.Double)">
             <summary>
             Distort the random number by the factor that was specified in the
             constructor.
             </summary>
            
             <param name="d">The number to distort.</param>
             <returns>The result.</returns>
        </member>
        <member name="T:Encog.MathUtil.Randomize.GaussianRandomizer">
            <summary>
            Generally, you will not want to use this randomizer as a pure neural network
            randomizer. More on this later in the description.
            Generate random numbers that fall within a Gaussian curve. The mean
            represents the center of the curve, and the standard deviation helps
            determine the length of the curve on each side.
            This randomizer is used mainly for special cases where I want to generate
            random numbers in a Gaussian range. For a pure neural network initializer, it
            leaves much to be desired. However, it can make for a decent randomizer.
            Usually, the Nguyen Widrow randomizer performs better.
            Uses the "Box Muller" method.
            http://en.wikipedia.org/wiki/Box%E2%80%93Muller_transform
            Ported from C++ version provided by Everett F. Carter Jr., 1994
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Randomize.GaussianRandomizer._mean">
             <summary>
             The mean.
             </summary>
            
        </member>
        <member name="F:Encog.MathUtil.Randomize.GaussianRandomizer._standardDeviation">
             <summary>
             The standard deviation.
             </summary>
            
        </member>
        <member name="F:Encog.MathUtil.Randomize.GaussianRandomizer._useLast">
             <summary>
             Should we use the last value.
             </summary>
            
        </member>
        <member name="F:Encog.MathUtil.Randomize.GaussianRandomizer._y2">
             <summary>
             The y2 value.
             </summary>
            
        </member>
        <member name="M:Encog.MathUtil.Randomize.GaussianRandomizer.#ctor(System.Double,System.Double)">
             <summary>
             Construct a Gaussian randomizer. The mean, the standard deviation.
             </summary>
            
             <param name="mean">The mean.</param>
             <param name="standardDeviation">The standard deviation.</param>
        </member>
        <member name="M:Encog.MathUtil.Randomize.GaussianRandomizer.BoxMuller(System.Double,System.Double)">
             <summary>
             Compute a Gaussian random number.
             </summary>
            
             <param name="m">The mean.</param>
             <param name="s">The standard deviation.</param>
             <returns>The random number.</returns>
        </member>
        <member name="M:Encog.MathUtil.Randomize.GaussianRandomizer.Randomize(System.Double)">
             <summary>
             Generate a random number.
             </summary>
            
             <param name="d">The input value, not used.</param>
             <returns>The random number.</returns>
        </member>
        <member name="T:Encog.MathUtil.Randomize.NguyenWidrowRandomizer">
             <summary>
             Implementation of <i>Nguyen-Widrow</i> weight initialization. This is the
             default weight initialization used by Encog, as it generally provides the
             most trainable neural network.
             </summary>
            
        </member>
        <member name="F:Encog.MathUtil.Randomize.NguyenWidrowRandomizer.MSG">
            <summary>
            Message to indicate which operations are not allowed.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Randomize.NguyenWidrowRandomizer.Randomize(Encog.ML.IMLMethod)">
            <summary>
            Randomize the specified BasicNetwork.
            </summary>
            <param name="method">The network to randomize.</param>
        </member>
        <member name="M:Encog.MathUtil.Randomize.NguyenWidrowRandomizer.CalculateRange(Encog.Engine.Network.Activation.IActivationFunction,System.Double)">
            <summary>
            Calculate the range of an activation function.
            </summary>
            <param name="af">The actionvation function to calculate for.</param>
            <param name="r">The value to collect the range at.</param>
            <returns>The range.</returns>
        </member>
        <member name="M:Encog.MathUtil.Randomize.NguyenWidrowRandomizer.RandomizeSynapse(Encog.Neural.Networks.BasicNetwork,System.Int32)">
            <summary>
            Randomize the connections between two layers.
            </summary>
            <param name="network">The network to randomize.</param>
            <param name="fromLayer">The starting layer.</param>
        </member>
        <member name="M:Encog.MathUtil.Randomize.NguyenWidrowRandomizer.Randomize(System.Double)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.MathUtil.Randomize.NguyenWidrowRandomizer.Randomize(System.Double[])">
            <inheritdoc/>
        </member>
        <member name="M:Encog.MathUtil.Randomize.NguyenWidrowRandomizer.Randomize(System.Double[][])">
            <inheritdoc/>
        </member>
        <member name="M:Encog.MathUtil.Randomize.NguyenWidrowRandomizer.Randomize(Encog.MathUtil.Matrices.Matrix)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.MathUtil.Randomize.NguyenWidrowRandomizer.Randomize(System.Double[],System.Int32,System.Int32)">
            <inheritdoc/>
        </member>
        <member name="T:Encog.MathUtil.Randomize.IRandomizer">
             <summary>
             Defines the interface for a class that is capable of randomizing the weights
             and bias values of a neural network.
             </summary>
            
        </member>
        <member name="M:Encog.MathUtil.Randomize.IRandomizer.Randomize(Encog.ML.IMLMethod)">
             <summary>
             Randomize the synapses and bias values in the basic network based on an
             array, modify the array. Previous values may be used, or they may be
             discarded, depending on the randomizer.
             </summary>
            
             <param name="network">A network to randomize.</param>
        </member>
        <member name="M:Encog.MathUtil.Randomize.IRandomizer.Randomize(System.Double)">
             <summary>
             Starting with the specified number, randomize it to the degree specified
             by this randomizer. This could be a totally new random number, or it
             could be based on the specified number.
             </summary>
            
             <param name="d">The number to randomize.</param>
             <returns>A randomized number.</returns>
        </member>
        <member name="M:Encog.MathUtil.Randomize.IRandomizer.Randomize(System.Double[])">
             <summary>
             Randomize the array based on an array, modify the array. Previous values
             may be used, or they may be discarded, depending on the randomizer.
             </summary>
            
             <param name="d">An array to randomize.</param>
        </member>
        <member name="M:Encog.MathUtil.Randomize.IRandomizer.Randomize(System.Double[][])">
             <summary>
             Randomize the 2d array based on an array, modify the array. Previous
             values may be used, or they may be discarded, depending on the
             randomizer.
             </summary>
            
             <param name="d">An array to randomize.</param>
        </member>
        <member name="M:Encog.MathUtil.Randomize.IRandomizer.Randomize(Encog.MathUtil.Matrices.Matrix)">
             <summary>
             Randomize the matrix based on an array, modify the array. Previous values
             may be used, or they may be discarded, depending on the randomizer.
             </summary>
            
             <param name="m">A matrix to randomize.</param>
        </member>
        <member name="M:Encog.MathUtil.Randomize.IRandomizer.Randomize(System.Double[],System.Int32,System.Int32)">
             <summary>
             Randomize an array.
             </summary>
            
             <param name="d">The array to randomize.</param>
             <param name="begin">The beginning element.</param>
             <param name="size">The size of the array.</param>
        </member>
        <member name="T:Encog.MathUtil.Randomize.RangeRandomizer">
             <summary>
             A randomizer that will create random weight and bias values that are between
             a specified range.
             </summary>
            
        </member>
        <member name="F:Encog.MathUtil.Randomize.RangeRandomizer._max">
             <summary>
             The maximum value for the random range.
             </summary>
            
        </member>
        <member name="F:Encog.MathUtil.Randomize.RangeRandomizer._min">
             <summary>
             The minimum value for the random range.
             </summary>
            
        </member>
        <member name="M:Encog.MathUtil.Randomize.RangeRandomizer.#ctor(System.Double,System.Double)">
             <summary>
             Construct a range randomizer.
             </summary>
            
             <param name="min">The minimum random value.</param>
             <param name="max">The maximum random value.</param>
        </member>
        <member name="P:Encog.MathUtil.Randomize.RangeRandomizer.Min">
            <value>the min</value>
        </member>
        <member name="P:Encog.MathUtil.Randomize.RangeRandomizer.Max">
            <value>the max</value>
        </member>
        <member name="M:Encog.MathUtil.Randomize.RangeRandomizer.RandomInt(System.Int32,System.Int32)">
            <summary>
            Produce a random int, within a specified range.
            </summary>
            <param name="min">The minimum value.</param>
            <param name="max">The maximum value.</param>
            <returns>The random int.</returns>
        </member>
        <member name="M:Encog.MathUtil.Randomize.RangeRandomizer.Randomize(System.Double,System.Double)">
             <summary>
             Generate a random number in the specified range.
             </summary>
            
             <param name="min">The minimum value.</param>
             <param name="max">The maximum value.</param>
             <returns>A random number.</returns>
        </member>
        <member name="M:Encog.MathUtil.Randomize.RangeRandomizer.Randomize(System.Double)">
             <summary>
             Generate a random number based on the range specified in the constructor.
             </summary>
            
             <param name="d">The range randomizer ignores this value.</param>
             <returns>The random number.</returns>
        </member>
        <member name="T:Encog.MathUtil.RBF.BasicRBF">
            <summary>
            Implements the basic features needed for an RBF.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.RBF.BasicRBF._center">
            <summary>
            The centers.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.RBF.BasicRBF._peak">
            <summary>
            The peak.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.RBF.BasicRBF._width">
            <summary>
            The width.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.RBF.BasicRBF.Centers">
            <summary>
            The centers.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.RBF.BasicRBF.Dimensions">
            <summary>
            The number of dimensions.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.RBF.BasicRBF.Peak">
            <summary>
            The peak.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.RBF.BasicRBF.Width">
            <summary>
            The width.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.RBF.BasicRBF.Calculate(System.Double[])">
            <summary>
            Calculate the output of the RBF.
            </summary>
            <param name="x">The input value.</param>
            <returns>The output value.</returns>
        </member>
        <member name="T:Encog.MathUtil.RBF.InverseMultiquadricFunction">
            <summary>
            Implements a radial function based on the inverse multiquadric function.
            
            Contributed to Encog By M.Dean and M.Fletcher
            University of Cambridge, Dept. of Physics, UK
            </summary>
        </member>
        <member name="M:Encog.MathUtil.RBF.InverseMultiquadricFunction.#ctor(System.Int32)">
            <summary>
            Create centered at zero, width 0, and peak 0.
            </summary>
            <param name="dimensions">The dimensions.</param>
        </member>
        <member name="M:Encog.MathUtil.RBF.InverseMultiquadricFunction.#ctor(System.Double,System.Double[],System.Double)">
            <summary>
            Construct a multi-dimension Inverse-Multiquadric function with the
            specified peak, centers and widths. 
            </summary>
            <param name="peak">The peak for all dimensions.</param>
            <param name="center">The centers for each dimension.</param>
            <param name="width">The widths for each dimension.</param>
        </member>
        <member name="M:Encog.MathUtil.RBF.InverseMultiquadricFunction.#ctor(System.Double,System.Double,System.Double)">
            <summary>
            Construct a single-dimension Inverse-Multiquadric function with the
            specified peak, centers and widths. 
            </summary>
            <param name="center">The peak for all dimensions.</param>
            <param name="peak">The centers for each dimension.</param>
            <param name="width">The widths for each dimension.</param>
        </member>
        <member name="M:Encog.MathUtil.RBF.InverseMultiquadricFunction.Calculate(System.Double[])">
            <summary>
            Calculate the output.
            </summary>
            <param name="x">Input value.</param>
            <returns>Output value.</returns>
        </member>
        <member name="T:Encog.MathUtil.RBF.MexicanHatFunction">
            <summary>
            Multi-dimensional Mexican Hat, or Ricker wavelet, function.
            
            It is usually only referred to as the "Mexican hat" in the Americas, due to
            cultural association with the "sombrero". In technical nomenclature this function
            is known as the Ricker wavelet, where it is frequently employed to model
            seismic data.
            
            http://en.wikipedia.org/wiki/Mexican_Hat_Function
            </summary>
        </member>
        <member name="M:Encog.MathUtil.RBF.MexicanHatFunction.#ctor(System.Int32)">
            <summary>
            Create centered at zero, width 0, and peak 0.
            </summary>
            <param name="dimensions"></param>
        </member>
        <member name="M:Encog.MathUtil.RBF.MexicanHatFunction.#ctor(System.Double,System.Double[],System.Double)">
            <summary>
            Construct a multi-dimension Mexican hat function with the specified peak,
            centers and widths. 
            </summary>
            <param name="peak">The peak for all dimensions.</param>
            <param name="center">The centers for each dimension.</param>
            <param name="width">The widths for each dimension.</param>
        </member>
        <member name="M:Encog.MathUtil.RBF.MexicanHatFunction.#ctor(System.Double,System.Double,System.Double)">
            <summary>
            Construct a single-dimension Mexican hat function with the specified peak,
            centers and widths. 
            </summary>
            <param name="center">The peak for all dimensions.</param>
            <param name="peak">The centers for each dimension.</param>
            <param name="width">The widths for each dimension.</param>
        </member>
        <member name="M:Encog.MathUtil.RBF.MexicanHatFunction.Calculate(System.Double[])">
            <summary>
            Calculate the output.
            </summary>
            <param name="x">Input value.</param>
            <returns>Output value.</returns>
        </member>
        <member name="T:Encog.MathUtil.RBF.MultiquadricFunction">
            <summary>
            Implements a radial function based on the multiquadric function.
            
            Contributed to Encog By M.Dean and M.Fletcher
            University of Cambridge, Dept. of Physics, UK
            </summary>
        </member>
        <member name="M:Encog.MathUtil.RBF.MultiquadricFunction.#ctor(System.Int32)">
            <summary>
            Create centered at zero, width 0, and peak 0.
            </summary>
            <param name="dimensions">The number of dimensions.</param>
        </member>
        <member name="M:Encog.MathUtil.RBF.MultiquadricFunction.#ctor(System.Double,System.Double[],System.Double)">
            <summary>
            Construct a multi-dimension Multiquadric function with the specified peak,
            centers and widths. 
            </summary>
            <param name="peak">The peak for all dimensions.</param>
            <param name="center">The centers for each dimension.</param>
            <param name="width">The widths for each dimension.</param>
        </member>
        <member name="M:Encog.MathUtil.RBF.MultiquadricFunction.#ctor(System.Double,System.Double,System.Double)">
            <summary>
            Construct a single-dimension Multiquadric function with the specified peak,
            centers and widths. 
            </summary>
            <param name="center">The peak for all dimensions.</param>
            <param name="peak">The centers for each dimension.</param>
            <param name="width">The widths for each dimension.</param>
        </member>
        <member name="M:Encog.MathUtil.RBF.MultiquadricFunction.Calculate(System.Double[])">
            <summary>
            Calculate the output.
            </summary>
            <param name="x">Input value.</param>
            <returns>Output value.</returns>
        </member>
        <member name="T:Encog.MathUtil.RBF.IRadialBasisFunction">
             <summary>
             A multi-dimension RBF.
             </summary>
            
        </member>
        <member name="P:Encog.MathUtil.RBF.IRadialBasisFunction.Peak">
            <summary>
            Set the peak.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.RBF.IRadialBasisFunction.Width">
            <summary>
            Set the width.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.RBF.IRadialBasisFunction.Dimensions">
            <value>The dimensions in this RBF.</value>
        </member>
        <member name="P:Encog.MathUtil.RBF.IRadialBasisFunction.Centers">
            <summary>
            Set the centers.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.RBF.IRadialBasisFunction.Calculate(System.Double[])">
             <summary>
             Calculate the RBF result for the specified value.
             </summary>
            
             <param name="x">The value to be passed into the RBF.</param>
             <returns>The RBF value.</returns>
        </member>
        <member name="T:Encog.MathUtil.RBF.RBFEnum">
            <summary>
            The implemented function types of the RBFs
            </summary>
        </member>
        <member name="F:Encog.MathUtil.RBF.RBFEnum.Gaussian">
            <summary>
            Regular Gaussian function.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.RBF.RBFEnum.Multiquadric">
            <summary>
            Multi quadric function.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.RBF.RBFEnum.InverseMultiquadric">
            <summary>
            Inverse multi quadric function.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.RBF.RBFEnum.MexicanHat">
            <summary>
            The Mexican hat function.
            </summary>
        </member>
        <member name="T:Encog.MathUtil.RBF.GaussianFunction">
            <summary>
            Implements a radial function based on the gaussian function.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.RBF.GaussianFunction.#ctor">
            <summary>
            Default constructor for persistance.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.RBF.GaussianFunction.#ctor(System.Int32)">
            <summary>
            Create centered at zero, width 0, and peak 0.
            </summary>
            <param name="dimensions">The number of dimensions.</param>
        </member>
        <member name="M:Encog.MathUtil.RBF.GaussianFunction.#ctor(System.Double,System.Double[],System.Double)">
            <summary>
            Construct a multi-dimension Gaussian function with the specified peak,
            centers and widths.
            </summary>
            <param name="peak">The peak for all dimensions.</param>
            <param name="center">The centers for each dimension.</param>
            <param name="width">The widths for each dimension.</param>
        </member>
        <member name="M:Encog.MathUtil.RBF.GaussianFunction.#ctor(System.Double,System.Double,System.Double)">
            <summary>
            Construct a single-dimension Gaussian function with the specified peak,
            centers and widths. 
            </summary>
            <param name="center">The peak for all dimensions.</param>
            <param name="peak">The centers for each dimension.</param>
            <param name="width">The widths for each dimension.</param>
        </member>
        <member name="M:Encog.MathUtil.RBF.GaussianFunction.Calculate(System.Double[])">
            <summary>
            Calculate the result from the function. 
            </summary>
            <param name="x">The parameters for the function, one for each dimension.</param>
            <returns>The result of the function.</returns>
        </member>
        <member name="T:Encog.MathUtil.VectorAlgebra">
            <summary>
            Basic vector algebra operators.
            Vectors are represented as arrays of doubles.
            
            This class was created to support the calculations 
            in the PSO algorithm.
            
            This class is thread safe.
            
            Contributed by:
            Geoffroy Noel
            https://github.com/goffer-looney 
            
            </summary>
        </member>
        <member name="M:Encog.MathUtil.VectorAlgebra.Add(System.Double[],System.Double[])">
            <summary>
            v1 = v1 + v2 
            </summary>
            <param name="v1">an array of doubles</param>
            <param name="v2">an array of doubles</param>
        </member>
        <member name="M:Encog.MathUtil.VectorAlgebra.Sub(System.Double[],System.Double[])">
            <summary>
            v1 = v1 - v2
            </summary>
            <param name="v1">an array of doubles</param>
            <param name="v2">an array of doubles</param>
        </member>
        <member name="M:Encog.MathUtil.VectorAlgebra.Neg(System.Double[])">
            <summary>
            v = -v 
            </summary>
            <param name="v">an array of doubles</param>
        </member>
        <member name="M:Encog.MathUtil.VectorAlgebra.MulRand(System.Double[],System.Double)">
            <summary>
             v = k * U(0,1) * v
            
            The components of the vector are multiplied 
            by k and a random number.
            A new random number is generated for each 
            component.    
            Thread-safety depends on Random.nextDouble()
            </summary>
            <param name="v">an array of doubles.</param>
            <param name="k">a scalar.</param>
        </member>
        <member name="M:Encog.MathUtil.VectorAlgebra.Mul(System.Double[],System.Double)">
             <summary>
             v = k * v
            
             The components of the vector are multiplied 
             by k.
             </summary>
             <param name="v">an array of doubles.</param>
             <param name="k">a scalar.</param>
        </member>
        <member name="M:Encog.MathUtil.VectorAlgebra.Copy(System.Double[],System.Double[])">
            <summary>
            dst = src 
            
            Copy a vector.
            </summary>
            <param name="dst">an array of doubles</param>
            <param name="src">an array of doubles</param>
        </member>
        <member name="M:Encog.MathUtil.VectorAlgebra.Randomise(System.Double[])">
            <summary>
            v = U(0, 0.1) 
            </summary>
            <param name="v">an array of doubles</param>
        </member>
        <member name="M:Encog.MathUtil.VectorAlgebra.Randomise(System.Double[],System.Double)">
             <summary>
             v = U(-1, 1) * maxValue
            
             Randomise each component of a vector to 
             [-maxValue, maxValue].
             thread-safety depends on Random.nextDouble(). 
             </summary>
             <param name="v">an array of doubles</param>
             <param name="maxValue">The max value.</param>
        </member>
        <member name="M:Encog.MathUtil.VectorAlgebra.ClampComponents(System.Double[],System.Double)">
            <summary>
            For each components, reset their value to maxValue if 
            their absolute value exceeds it.
            </summary>
            <param name="v">an array of doubles</param>
            <param name="maxValue">if -1 this function does nothing</param>
        </member>
        <member name="T:Encog.MathUtil.Convert">
            <summary>
            This class is used to convert strings into numeric values.  If the
            string holds a non-numeric value, a zero is returned.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Convert.String2Double(System.String)">
            <summary>
            Convert a string to a double.  Just make the number a zero
            if the string is invalid.
            </summary>
            <param name="str">The string.</param>
            <returns>The string converted to numeric.</returns>
        </member>
        <member name="M:Encog.MathUtil.Convert.String2Int(System.String)">
            <summary>
            Convert a string to an int.  Just make the number a zero
            if the string is invalid.
            </summary>
            <param name="str">The string.</param>
            <returns>The string converted to numeric.</returns>
        </member>
        <member name="T:Encog.MathUtil.Equilateral">
            <summary>
            Used to produce an array of activations to classify data into groups. This
            class is provided the number of groups, as well as the range that the
            activations should fall into.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Equilateral.MinEq">
            <summary>
            Minimum number of classes for equilateral.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.Equilateral._matrix">
            <summary>
            The matrix of values that was generated.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.Equilateral.#ctor(System.Int32,System.Double,System.Double)">
            <summary>
            Construct an equilateral matrix.
            </summary>
            <param name="count">The number of sets, these will be the rows in the matrix.</param>
            <param name="high">The high value for the outputs.</param>
            <param name="low">The low value for the outputs.</param>
        </member>
        <member name="M:Encog.MathUtil.Equilateral.Decode(System.Double[])">
            <summary>
            Decode a set of activations and see which set it has the lowest Euclidean
            distance from.
            </summary>
            <param name="activations">The output from the neural network.</param>
            <returns>The set that these activations were closest too.</returns>
        </member>
        <member name="M:Encog.MathUtil.Equilateral.Encode(System.Int32)">
            <summary>
            Get the activations for the specified set.
            </summary>
            <param name="set">The set to determine the activations for.</param>
            <returns>The activations for the specified sets.</returns>
        </member>
        <member name="M:Encog.MathUtil.Equilateral.Equilat(System.Int32,System.Double,System.Double)">
            <summary>
            Called internally to generate the matrix.
            </summary>
            <param name="n">The number of sets to generate for.</param>
            <param name="high">The high end of the range of values to generate.</param>
            <param name="low"> The low end of the range of values to generate.</param>
            <returns>One row for each set, the columns are the activations for that set.</returns>
        </member>
        <member name="M:Encog.MathUtil.Equilateral.GetDistance(System.Double[],System.Int32)">
            <summary>
            Get the Euclidean distance between the specified data and the set number.
            </summary>
            <param name="data">The data to check.</param>
            <param name="set">The set to check.</param>
            <returns>The distance.</returns>
        </member>
        <member name="M:Encog.MathUtil.Equilateral.GetSmallestDistance(System.Double[])">
            <summary>
            Get the smallest distance.
            </summary>
            <param name="data">The data to check.</param>
            <returns>The set with the smallest distance.</returns>
        </member>
        <member name="T:Encog.MathUtil.LinearCongruentialGenerator">
             <summary>
             A predictable random number generator. This is useful for unit tests and
             benchmarks where we want random numbers, but we want them to be the same each
             time. This class exists on both Java and C# so it can even provide consistent
             random numbers over the two platforms.
             
             Random numbers are created using a LCG.
             
             http://en.wikipedia.org/wiki/Linear_congruential_generator
            
             </summary>
        </member>
        <member name="F:Encog.MathUtil.LinearCongruentialGenerator.MaxRand">
            <summary>
            The maximum rand number that the standard GCC based LCG will generate.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.LinearCongruentialGenerator.#ctor(System.Int64)">
            <summary>
            Construct the default LCG.  You need only specify a seed.
            </summary>
            <param name="seed">The seed.</param>
        </member>
        <member name="M:Encog.MathUtil.LinearCongruentialGenerator.#ctor(System.Int64,System.Int64,System.Int64,System.Int64)">
            <summary>
            Create a LCG with the specified modulus, multiplier and increment. Unless
            you REALLY KNOW WHAT YOU ARE DOING, just use the constructor that just
            takes a seed. It will set these values to the same as set by the GCC C
            compiler. Setting these values wrong can create fairly useless random
            numbers.
            </summary>
            <param name="modulus">The modulus for the LCG algorithm.</param>
            <param name="multiplier">The multiplier for the LCG algorithm.</param>
            <param name="increment">The increment for the LCG algorithm.</param>
            <param name="seed">The seed for the LCG algorithm. Using the same seed will give
            the same random number sequence each time, whether in Java or
            DotNet.</param>
        </member>
        <member name="P:Encog.MathUtil.LinearCongruentialGenerator.Modulus">
            <summary>
            The modulus.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.LinearCongruentialGenerator.Multiplier">
            <summary>
            The multiplier.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.LinearCongruentialGenerator.Increment">
            <summary>
            The amount to increment.
            </summary>
        </member>
        <member name="P:Encog.MathUtil.LinearCongruentialGenerator.Seed">
            <summary>
            The current seed, set to an initial value and always holds the value of
            the last random number generated.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.LinearCongruentialGenerator.NextDouble">
            <summary>
            The next random number as a double between 0 and 1.
            </summary>
            <returns>The next double.</returns>
        </member>
        <member name="M:Encog.MathUtil.LinearCongruentialGenerator.NextLong">
            <summary>
            The next random number as a long between 0 and MAX_RAND.
            </summary>
            <returns>The next long.</returns>
        </member>
        <member name="M:Encog.MathUtil.LinearCongruentialGenerator.Range(System.Double,System.Double)">
            <summary>
            Generate a random number in the specified range.
            </summary>
            <param name="min">The minimum random number.</param>
            <param name="max">The maximum random number.</param>
            <returns>The generated random number.</returns>
        </member>
        <member name="T:Encog.MathUtil.MathConst">
            <summary>
            Math constants needed by Encog.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.MathConst.EulersNumber">
            <summary>
            Euler's number.
            </summary>
        </member>
        <member name="T:Encog.MathUtil.ThreadSafeRandom">
            <summary>
            A thread safe random number generator.
            </summary>
        </member>
        <member name="F:Encog.MathUtil.ThreadSafeRandom.Random">
            <summary>
            A non-thread-safe random number generator that uses a time-based seed.
            </summary>
        </member>
        <member name="M:Encog.MathUtil.ThreadSafeRandom.NextDouble">
            <summary>
            Generate a random number between 0 and 1.
            </summary>
            <returns></returns>
        </member>
        <member name="T:Encog.Mathutil.Randomize.FanInRandomizer">
             <summary>
             A randomizer that attempts to create starting weight values that are
             conducive to propagation training.
             This is one of the best randomizers offered in Encog, however, the Nguyen
             Widrow method generally performs better.
             From:
             Neural Networks - A Comprehensive Foundation, Haykin, chapter 6.7
             </summary>
            
        </member>
        <member name="F:Encog.Mathutil.Randomize.FanInRandomizer.Error">
             <summary>
             Error message. Can't use fan-in on a single number.
             </summary>
            
        </member>
        <member name="F:Encog.Mathutil.Randomize.FanInRandomizer.DefaultBoundary">
             <summary>
             The default boundary.
             </summary>
            
        </member>
        <member name="F:Encog.Mathutil.Randomize.FanInRandomizer._lowerBound">
             <summary>
             The lower bound. 
             </summary>
            
        </member>
        <member name="F:Encog.Mathutil.Randomize.FanInRandomizer._sqrt">
             <summary>
             Should the square root of the number of rows be used?
             </summary>
            
        </member>
        <member name="F:Encog.Mathutil.Randomize.FanInRandomizer._upperBound">
             <summary>
             The upper bound. 
             </summary>
            
        </member>
        <member name="M:Encog.Mathutil.Randomize.FanInRandomizer.#ctor">
             <summary>
             Create a fan-in randomizer with default values.
             </summary>
            
        </member>
        <member name="M:Encog.Mathutil.Randomize.FanInRandomizer.#ctor(System.Double,System.Boolean)">
             <summary>
             Construct a fan-in randomizer along the specified boundary. The min will
             be -boundary and the max will be boundary.
             </summary>
            
             <param name="boundary">The boundary for the fan-in.</param>
             <param name="sqrt"></param>
        </member>
        <member name="M:Encog.Mathutil.Randomize.FanInRandomizer.#ctor(System.Double,System.Double,System.Boolean)">
             <summary>
             Construct a fan-in randomizer. Use the specified bounds.
             </summary>
            
             <param name="aLowerBound">The lower bound.</param>
             <param name="anUpperBound">The upper bound.</param>
             <param name="sqrt"></param>
        </member>
        <member name="M:Encog.Mathutil.Randomize.FanInRandomizer.CalculateValue(System.Int32)">
             <summary>
             Calculate the fan-in value.
             </summary>
            
             <param name="rows">The number of rows.</param>
             <returns>The fan-in value.</returns>
        </member>
        <member name="M:Encog.Mathutil.Randomize.FanInRandomizer.CauseError">
             <summary>
             Throw an error if this class is used improperly.
             </summary>
            
        </member>
        <member name="M:Encog.Mathutil.Randomize.FanInRandomizer.Randomize(System.Double)">
             <summary>
             Starting with the specified number, randomize it to the degree specified
             by this randomizer. This could be a totally new random number, or it
             could be based on the specified number.
             </summary>
            
             <param name="d">The number to randomize.</param>
             <returns>A randomized number.</returns>
        </member>
        <member name="M:Encog.Mathutil.Randomize.FanInRandomizer.Randomize(System.Double[])">
             <summary>
             Randomize the array based on an array, modify the array. Previous values
             may be used, or they may be discarded, depending on the randomizer.
             </summary>
            
             <param name="d">An array to randomize.</param>
        </member>
        <member name="M:Encog.Mathutil.Randomize.FanInRandomizer.Randomize(System.Double[][])">
             <summary>
             Randomize the 2d array based on an array, modify the array. Previous
             values may be used, or they may be discarded, depending on the
             randomizer.
             </summary>
            
             <param name="d">An array to randomize.</param>
        </member>
        <member name="M:Encog.Mathutil.Randomize.FanInRandomizer.Randomize(Encog.MathUtil.Matrices.Matrix)">
             <summary>
             Randomize the matrix based on an array, modify the array. Previous values
             may be used, or they may be discarded, depending on the randomizer.
             </summary>
            
             <param name="m">A matrix to randomize.</param>
        </member>
        <member name="M:Encog.Mathutil.Randomize.FanInRandomizer.Randomize(Encog.Neural.Networks.BasicNetwork,System.Int32)">
             <summary>
             Randomize one level of a neural network.
             </summary>
            
             <param name="network">The network to randomize</param>
             <param name="fromLayer">The from level to randomize.</param>
        </member>
        <member name="T:Encog.ML.Anneal.SimulatedAnnealing`1">
             <summary>
             Simulated annealing is a common training method. This class implements a
             simulated annealing algorithm that can be used both for neural networks, as
             well as more general cases. This class is abstract, so a more specialized
             simulated annealing subclass will need to be created for each intended use.
             This book demonstrates how to use the simulated annealing algorithm to train
             feedforward neural networks, as well as find a solution to the traveling
             salesman problem.
             The name and inspiration come from annealing in metallurgy, a technique
             involving heating and controlled cooling of a material to increase the size
             of its crystals and reduce their defects. The heat causes the atoms to become
             unstuck from their initial positions (a local minimum of the internal energy)
             and wander randomly through states of higher energy; the slow cooling gives
             them more chances of finding configurations with lower internal energy than
             the initial one.
             </summary>
            
             <typeparam name="TUnitType">What type of data makes up the solution.</typeparam>
        </member>
        <member name="F:Encog.ML.Anneal.SimulatedAnnealing`1._cycles">
             <summary>
             The number of cycles that will be used.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Anneal.SimulatedAnnealing`1._shouldMinimize">
             <summary>
             Should the score be minimized.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Anneal.SimulatedAnnealing`1._temperature">
             <summary>
             The current temperature.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Anneal.SimulatedAnnealing`1.#ctor">
            <summary>
            Construct the object.  Default ShouldMinimize to true.
            </summary>
        </member>
        <member name="P:Encog.ML.Anneal.SimulatedAnnealing`1.Array">
            <summary>
            Subclasses must provide access to an array that makes up the solution.
            </summary>
        </member>
        <member name="P:Encog.ML.Anneal.SimulatedAnnealing`1.ArrayCopy">
            <summary>
            Get a copy of the array.
            </summary>
        </member>
        <member name="P:Encog.ML.Anneal.SimulatedAnnealing`1.Cycles">
            <value>the cycles to set</value>
        </member>
        <member name="P:Encog.ML.Anneal.SimulatedAnnealing`1.Score">
            <summary>
            Set the score.
            </summary>
        </member>
        <member name="P:Encog.ML.Anneal.SimulatedAnnealing`1.StartTemperature">
            <value>the startTemperature to set</value>
        </member>
        <member name="P:Encog.ML.Anneal.SimulatedAnnealing`1.StopTemperature">
            <value>the stopTemperature to set</value>
        </member>
        <member name="P:Encog.ML.Anneal.SimulatedAnnealing`1.Temperature">
            <value>the temperature to set</value>
        </member>
        <member name="P:Encog.ML.Anneal.SimulatedAnnealing`1.ShouldMinimize">
            <summary>
            Should the score be minimized.
            </summary>
        </member>
        <member name="M:Encog.ML.Anneal.SimulatedAnnealing`1.PerformCalculateScore">
             <summary>
             Subclasses should provide a method that evaluates the score for the
             current solution. Those solutions with a lower score are better.
             </summary>
            
             <returns>Return the score.</returns>
        </member>
        <member name="M:Encog.ML.Anneal.SimulatedAnnealing`1.Iteration">
             <summary>
             Called to perform one cycle of the annealing process.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Anneal.SimulatedAnnealing`1.PutArray(`0[])">
             <summary>
             Store the array.
             </summary>
            
             <param name="array">The array to be stored.</param>
        </member>
        <member name="M:Encog.ML.Anneal.SimulatedAnnealing`1.Randomize">
             <summary>
             Randomize the weight matrix.
             </summary>
            
        </member>
        <member name="T:Encog.ML.BasicML">
             <summary>
             A class that provides basic property functionality for the MLProperties
             interface.
             </summary>
            
        </member>
        <member name="F:Encog.ML.BasicML._properties">
             <summary>
             Properties about the neural network. Some NeuralLogic classes require
             certain properties to be set.
             </summary>
            
        </member>
        <member name="M:Encog.ML.BasicML.#ctor">
            <summary>
            Construct the object.
            </summary>
        </member>
        <member name="P:Encog.ML.BasicML.Properties">
            <value>A map of all properties.</value>
        </member>
        <member name="M:Encog.ML.BasicML.GetPropertyDouble(System.String)">
             <summary>
             Get the specified property as a double.
             </summary>
            
             <param name="name">The name of the property.</param>
             <returns>The property as a double.</returns>
        </member>
        <member name="M:Encog.ML.BasicML.GetPropertyLong(System.String)">
             <summary>
             Get the specified property as a long.
             </summary>
            
             <param name="name">The name of the specified property.</param>
             <returns>The value of the specified property.</returns>
        </member>
        <member name="M:Encog.ML.BasicML.GetPropertyString(System.String)">
             <summary>
             Get the specified property as a string.
             </summary>
            
             <param name="name">The name of the property.</param>
             <returns>The value of the property.</returns>
        </member>
        <member name="M:Encog.ML.BasicML.SetProperty(System.String,System.Double)">
             <summary>
             Set a property as a double.
             </summary>
            
             <param name="name">The name of the property.</param>
             <param name="d">The value of the property.</param>
        </member>
        <member name="M:Encog.ML.BasicML.SetProperty(System.String,System.Int64)">
             <summary>
             Set a property as a long.
             </summary>
            
             <param name="name">The name of the property.</param>
             <param name="l">The value of the property.</param>
        </member>
        <member name="M:Encog.ML.BasicML.SetProperty(System.String,System.String)">
             <summary>
             Set a property as a double.
             </summary>
            
             <param name="name">The name of the property.</param>
             <param name="v">The value of the property.</param>
        </member>
        <member name="M:Encog.ML.BasicML.UpdateProperties">
            <summary>
            Update from the propeties stored in the hash map.  Should be called 
            whenever the properties change and might need to be reloaded.
            </summary>
        </member>
        <member name="T:Encog.ML.Bayesian.BayesianChoice">
            <summary>
            A choice in a Bayesian network. Choices can be either discrete or continuous.
            For continuous choices the number must be made discrete by mapping it to
            discrete ranges.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.BayesianChoice._label">
            <summary>
            The label for this choice.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.BayesianChoice._max">
            <summary>
            The max values, if continuous, or the index if discrete.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.BayesianChoice._min">
            <summary>
            The min values, if continuous, or the index if discrete.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianChoice.#ctor(System.String,System.Double,System.Double)">
            <summary>
            Construct a continuous choice that covers the specified range. 
            </summary>
            <param name="label">The label for this choice.</param>
            <param name="min">The minimum value for this range.</param>
            <param name="max">The maximum value for this range.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianChoice.#ctor(System.String,System.Int32)">
            <summary>
            Construct a discrete choice for the specified index. 
            </summary>
            <param name="label">The label for this choice.</param>
            <param name="index">The index for this choice.</param>
        </member>
        <member name="P:Encog.ML.Bayesian.BayesianChoice.Label">
            <summary>
            Get the label.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BayesianChoice.Min">
            <summary>
            Get the min.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BayesianChoice.Max">
            <summary>
            Get the max.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BayesianChoice.IsIndex">
            <summary>
            True, if this choice has an index, as opposed to min/max. If the
            value has an idex, then it is discrete.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianChoice.ToString">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianChoice.ToFullString">
            <summary>
            A string representation of this choice.
            </summary>
            <returns>A string representation of this choice.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianChoice.CompareTo(Encog.ML.Bayesian.BayesianChoice)">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Bayesian.BayesianError">
            <summary>
            Indicates an error has occurred in the Bayesian Network classes.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianError.#ctor(System.String)">
            <summary>
            Construct a message exception.
            </summary>
            <param name="str">The message.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianError.#ctor(System.Exception)">
            <summary>
            Pass on an exception.
            </summary>
            <param name="e">The other exception.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianError.#ctor(System.String,System.Exception)">
            <summary>
            Pass on an exception.
            </summary>
            <param name="msg">The message.</param>
            <param name="e">The exception.</param>
        </member>
        <member name="T:Encog.ML.Bayesian.BayesianEvent">
            <summary>
            Events make up a Bayesian network. Each evidence or outcome event usually
            corresponds to one number in the training data.  A event is always discrete.
            However, continues values can be range-mapped to discrete values.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.BayesianEvent._children">
            <summary>
            The children, or events that use us as a given.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.BayesianEvent._choices">
            <summary>
            The discrete choices that make up the state of this event.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.BayesianEvent._label">
            <summary>
            The label for this event.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.BayesianEvent._parents">
            <summary>
            The parents, or given.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.BayesianEvent._table">
            <summary>
            The truth table for this event.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.BayesianEvent._maximumChoice">
            <summary>
            The value of the maximum choice.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.BayesianEvent._minimumChoice">
            <summary>
            THe value of the minimum choice.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.BayesianEvent._minimumChoiceIndex">
            <summary>
            The index of the minimum choice.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianEvent.#ctor(System.String,System.Collections.Generic.IEnumerable{Encog.ML.Bayesian.BayesianChoice})">
            <summary>
            Construct an event with the specified label and choices.
            </summary>
            <param name="theLabel">The label.</param>
            <param name="theChoices">The choices, or states.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianEvent.#ctor(System.String,System.Collections.Generic.IEnumerable{System.String})">
            <summary>
            Construct an event with the specified label and choices. 
            </summary>
            <param name="theLabel">The label.</param>
            <param name="theChoices">The choices, or states.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianEvent.#ctor(System.String)">
            <summary>
            Construct a boolean event.
            </summary>
            <param name="theLabel">The label.</param>
        </member>
        <member name="P:Encog.ML.Bayesian.BayesianEvent.Parents">
            <summary>
            the parents
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BayesianEvent.Children">
            <summary>
            the children
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BayesianEvent.Label">
            <summary>
            the label
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BayesianEvent.HasParents">
            <summary>
            True, if this event has parents.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BayesianEvent.HasChildren">
            <summary>
            True, if this event has parents.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BayesianEvent.Choices">
            <summary>
            the choices
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BayesianEvent.Table">
            <summary>
            the table
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BayesianEvent.IsBoolean">
            <summary>
            True, if this is a boolean event.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianEvent.AddChild(Encog.ML.Bayesian.BayesianEvent)">
            <summary>
            Add a child event.
            </summary>
            <param name="e">The child event.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianEvent.AddParent(Encog.ML.Bayesian.BayesianEvent)">
            <summary>
            Add a parent event.
            </summary>
            <param name="e">The parent event.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianEvent.ToFullString">
            <summary>
            A full string that contains all info for this event.
            </summary>
            <returns>A full string that contains all info for this event.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianEvent.ToString">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianEvent.CalculateParameterCount">
            <summary>
            The parameter count.
            </summary>
            <returns>The parameter count.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianEvent.FinalizeStructure">
            <summary>
            Finalize the structure.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianEvent.Validate">
            <summary>
            Validate the event.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianEvent.RollArgs(System.Double[])">
            <summary>
            Roll the specified arguments through all of the possible values, return
            false if we are at the final iteration. This is used to enumerate through
            all of the possible argument values of this event.
            </summary>
            <param name="args">The arguments to enumerate.</param>
            <returns>True if there are more iterations.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianEvent.RemoveAllRelations">
            <summary>
            Remove all relations.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianEvent.FormatEventName(Encog.ML.Bayesian.BayesianEvent,System.Int32)">
            <summary>
            Format the event name with +, - and =.  For example +a or -1, or a=red.
            </summary>
            <param name="theEvent">The event to format.</param>
            <param name="value">The value to format for.</param>
            <returns>The formatted name.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianEvent.HasGiven(System.String)">
            <summary>
            Return true if the event has the specified given event.
            </summary>
            <param name="l">The event to check for.</param>
            <returns>True if the event has the specified given.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianEvent.Reset">
            <summary>
            Reset the logic table.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianEvent.MatchChoiceToRange(System.Double)">
            <summary>
            Match a continuous value to a discrete range. This is how floating point
            numbers can be used as input to a Bayesian network.
            </summary>
            <param name="d">The continuous value.</param>
            <returns>The range that the value was mapped into.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianEvent.GetChoice(System.Int32)">
            <summary>
            Return the choice specified by the index.  This requires searching
            through a list.  Do not call in performance critical areas.
            </summary>
            <param name="arg">The argument number.</param>
            <returns>The bayesian choice found.</returns>
        </member>
        <member name="T:Encog.ML.Bayesian.BayesianNetwork">
            <summary>
            The Bayesian Network is a machine learning method that is based on
            probability, and particularly Bayes' Rule. The Bayesian Network also forms
            the basis for the Hidden Markov Model and Naive Bayesian Network. The
            Bayesian Network is either constructed directly or inferred from training
            data using an algorithm such as K2.
            
            http://www.heatonresearch.com/wiki/Bayesian_Network
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.BayesianNetwork.ChoicesTrueFalse">
            <summary>
            Default choices for a boolean event.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.BayesianNetwork._eventMap">
            <summary>
            Mapping between the event string names, and the actual events.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.BayesianNetwork._events">
            <summary>
            A listing of all of the events.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.BayesianNetwork._classificationProbabilities">
            <summary>
            The probabilities of each classification.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.BayesianNetwork._classificationTarget">
            <summary>
            Specifies the classification target.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.BayesianNetwork._inputPresent">
            <summary>
            Specifies if each input is present.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.#ctor">
            <summary>
            Construct a Bayesian network.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BayesianNetwork.Query">
            <summary>
            The current Bayesian query.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BayesianNetwork.EventMap">
            <summary>
            The mapping from string names to events.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BayesianNetwork.Events">
            <summary>
            The events.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BayesianNetwork.Contents">
            <summary>
            The contents as a string. Shows both events and dependences.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BayesianNetwork.ClassificationTarget">
            <summary>
            Get the classification target. 
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BayesianNetwork.ClassificationTargetEvent">
            <summary>
            The classification target.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BayesianNetwork.ClassificationStructure">
            <summary>
            Returns a string representation of the classification structure.
                    Of the form P(a|b,c,d)
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BayesianNetwork.HasValidClassificationTarget">
            <summary>
            True if this network has a valid classification target.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BayesianNetwork.InputCount">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Bayesian.BayesianNetwork.OutputCount">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.Classify(Encog.ML.Data.IMLData)">
            <summary>
            Classify the input. 
            </summary>
            <param name="input">The input to classify.</param>
            <returns>The classification.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.CalculateError(Encog.ML.Data.IMLDataSet)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.Reset">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.Reset(System.Int32)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.GetEvent(System.String)">
            <summary>
            Get an event based on the string label. 
            </summary>
            <param name="label">The label to locate.</param>
            <returns>The event found.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.GetEventError(System.String)">
            <summary>
            Get an event based on label, throw an error if not found.
            </summary>
            <param name="label">THe event label to find.</param>
            <returns>The event.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.EventExists(System.String)">
            <summary>
            Return true if the specified event exists. 
            </summary>
            <param name="label">The label we are searching for.</param>
            <returns>True, if the event exists by label.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.CreateEvent(Encog.ML.Bayesian.BayesianEvent)">
            <summary>
            Create, or register, the specified event with this bayesian network. 
            </summary>
            <param name="theEvent">The event to add.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.CreateEvent(System.String,System.Collections.Generic.IList{Encog.ML.Bayesian.BayesianChoice})">
            <summary>
            Create an event specified on the label and options provided. 
            </summary>
            <param name="label">The label to create this event as.</param>
            <param name="options">The options, or states, that this event can have.</param>
            <returns>The newly created event.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.CreateEvent(System.String,System.String[])">
            <summary>
            Create the specified events based on a variable number of options, or choices. 
            </summary>
            <param name="label">The label of the event to create.</param>
            <param name="options">The states that the event can have.</param>
            <returns>The newly created event.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.CreateDependency(Encog.ML.Bayesian.BayesianEvent,Encog.ML.Bayesian.BayesianEvent)">
            <summary>
            Create a dependency between two events. 
            </summary>
            <param name="parentEvent">The parent event.</param>
            <param name="childEvent">The child event.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.HasDependency(Encog.ML.Bayesian.BayesianEvent,Encog.ML.Bayesian.BayesianEvent)">
            <summary>
            Determine if the two events have a dependency. 
            </summary>
            <param name="parentEvent">The parent event.</param>
            <param name="childEvent">The child event.</param>
            <returns>True if a dependency exists.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.CreateDependency(Encog.ML.Bayesian.BayesianEvent,Encog.ML.Bayesian.BayesianEvent[])">
            <summary>
            Create a dependency between a parent and multiple children. 
            </summary>
            <param name="parentEvent">The parent event.</param>
            <param name="children">The child events.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.CreateDependency(System.String,System.String)">
            <summary>
            Create a dependency between two labels.
            </summary>
            <param name="parentEventLabel">The parent event.</param>
            <param name="childEventLabel">The child event.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.RemoveDependency(Encog.ML.Bayesian.BayesianEvent,Encog.ML.Bayesian.BayesianEvent)">
            <summary>
            Remove a dependency, if it it exists.
            </summary>
            <param name="parent">The parent event.</param>
            <param name="child">The child event.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.RemoveEvent(Encog.ML.Bayesian.BayesianEvent)">
            <summary>
            Remove the specified event.
            </summary>
            <param name="theEvent">The event to remove.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.ToString">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.CalculateParameterCount">
            <summary>
             Calculate the parameter count.
            </summary>
            <returns>The number of parameters in this Bayesian network.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.FinalizeStructure">
            <summary>
            Finalize the structure of this Bayesian network.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.Validate">
            <summary>
            Validate the structure of this Bayesian network.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.IsGiven(System.Collections.Generic.IEnumerable{Encog.ML.Bayesian.BayesianEvent},Encog.ML.Bayesian.BayesianEvent)">
            <summary>
            Determine if one Bayesian event is in an array of others. 
            </summary>
            <param name="given">The events to check.</param>
            <param name="e">See if e is amoung given.</param>
            <returns>True if e is amoung given.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.IsDescendant(Encog.ML.Bayesian.BayesianEvent,Encog.ML.Bayesian.BayesianEvent)">
            <summary>
            Determine if one event is a descendant of another.
            </summary>
            <param name="a">The event to check.</param>
            <param name="b">The event that has children.</param>
            <returns>True if a is amoung b's children.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.IsGivenOrDescendant(System.Collections.Generic.IEnumerable{Encog.ML.Bayesian.BayesianEvent},Encog.ML.Bayesian.BayesianEvent)">
            <summary>
            True if this event is given or conditionally dependant on the others. 
            </summary>
            <param name="given">The others to check.</param>
            <param name="e">The event to check.</param>
            <returns>True, if is given or descendant.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.IsCondIndependent(System.Boolean,Encog.ML.Bayesian.BayesianEvent,Encog.ML.Bayesian.BayesianEvent,System.Collections.Generic.IDictionary{Encog.ML.Bayesian.BayesianEvent,System.Object},Encog.ML.Bayesian.BayesianEvent[])">
            <summary>
            Help determine if one event is conditionally independent of another.
            </summary>
            <param name="previousHead">The previous head, as we traverse the list.</param>
            <param name="a">The event to check.</param>
            <param name="goal">List of events searched.</param>
            <param name="searched"></param>
            <param name="given">Given events.</param>
            <returns>True if conditionally independent.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.IsCondIndependent(Encog.ML.Bayesian.BayesianEvent,Encog.ML.Bayesian.BayesianEvent,Encog.ML.Bayesian.BayesianEvent[])">
            <summary>
            Determine if two events are conditionally independent.
            </summary>
            <param name="a">The first event.</param>
            <param name="b">The second event.</param>
            <param name="given">What is "given".</param>
            <returns>True of they are cond. independent.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.ComputeProbability(Encog.ML.Data.IMLData)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.DefineProbability(System.String,System.Double)">
            <summary>
            Define the probability for an event.
            </summary>
            <param name="line">The event.</param>
            <param name="probability">The probability.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.DefineProbability(System.String)">
            <summary>
            Define a probability.
            </summary>
            <param name="line">The line to define the probability.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.RequireEvent(System.String)">
            <summary>
            Require the specified event, thrown an error if it does not exist.
            </summary>
            <param name="label">The label.</param>
            <returns>The event.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.DefineRelationship(System.String)">
            <summary>
            Define a relationship.
            </summary>
            <param name="line">The relationship to define.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.PerformQuery(System.String)">
            <summary>
            Perform a query.
            </summary>
            <param name="line">The query.</param>
            <returns>The probability.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.UpdateProperties">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.GetEventIndex(Encog.ML.Bayesian.BayesianEvent)">
            <summary>
             Get the index of the given event.
            </summary>
            <param name="theEvent">The event to get the index of.</param>
            <returns>The index of the event.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.RemoveAllRelations">
            <summary>
            Remove all relations between nodes.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.DetermineClasses(Encog.ML.Data.IMLData)">
            <summary>
            Determine the classes for the specified input. 
            </summary>
            <param name="input">The input.</param>
            <returns>An array of class indexes.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.IsInputPresent(System.Int32)">
            <summary>
            Determine if the specified input is present. 
            </summary>
            <param name="idx">The index of the input.</param>
            <returns>True, if the input is present.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.BayesianNetwork.DefineClassificationStructure(System.String)">
            <summary>
            Define a classification structure of the form P(A|B) = P(C)
            </summary>
            <param name="line">The structure.</param>
        </member>
        <member name="T:Encog.ML.Bayesian.BIF.BIFDefinition">
            <summary>
            Holds a BIF definition.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.BIF.BIFDefinition._givenDefinitions">
            <summary>
            Given definitions.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.BIF.BIFDefinition._table">
            <summary>
            The table of probabilities.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BIF.BIFDefinition.ForDefinition">
            <summary>
            The "for" definition.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BIF.BIFDefinition.Table">
            <summary>
            The table of probabilities.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BIF.BIFDefinition.GivenDefinitions">
            <summary>
            The given defintions.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.BIF.BIFDefinition.SetTable(System.String)">
            <summary>
            Set the probabilities as a string.
            </summary>
            <param name="s">A space separated string.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.BIF.BIFDefinition.AddGiven(System.String)">
            <summary>
            Add a given.
            </summary>
            <param name="s">The given to add.</param>
        </member>
        <member name="T:Encog.ML.Bayesian.BIF.BIFVariable">
            <summary>
            A BIF variable.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BIF.BIFVariable.Name">
            <summary>
            The name of the variable.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.BIF.BIFVariable.Options">
            <summary>
            Options for this variable.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.BIF.BIFVariable.#ctor">
            <summary>
            Construct the variable.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.BIF.BIFVariable.AddOption(System.String)">
            <summary>
            Add an option to the variable.
            </summary>
            <param name="s">The option to add.</param>
        </member>
        <member name="T:Encog.ML.Bayesian.EventType">
            <summary>
            The type of event for a Bayesian Network.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.EventType.Evidence">
            <summary>
            The event is used as evidence to predict the outcome.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.EventType.Hidden">
            <summary>
            This event is neither evidence our outcome, but still 
            is involved in the Bayesian Graph.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.EventType.Outcome">
            <summary>
            The event is outcome, which means that we would like to get
            a value for given evidence.
            </summary>
        </member>
        <member name="T:Encog.ML.Bayesian.Parse.ParsedChoice">
            <summary>
            A parsed choice.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Parse.ParsedChoice._label">
            <summary>
            The label for this choice.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Parse.ParsedChoice._max">
            <summary>
            The max value for this choice.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Parse.ParsedChoice._min">
            <summary>
            The min value for this choice.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Parse.ParsedChoice.#ctor(System.String,System.Double,System.Double)">
            <summary>
            Construct a continuous choice, with a min and max. 
            </summary>
            <param name="label">The label, for this chocie.</param>
            <param name="min">The min value, for this choice.</param>
            <param name="max">The max value, for this choice.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.Parse.ParsedChoice.#ctor(System.String,System.Int32)">
            <summary>
            Construct a discrete value for this choice.
            </summary>
            <param name="label">The choice label.</param>
            <param name="index">The index.</param>
        </member>
        <member name="P:Encog.ML.Bayesian.Parse.ParsedChoice.Label">
            <summary>
            The label.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Parse.ParsedChoice.Min">
            <summary>
            The min value.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Parse.ParsedChoice.Max">
            <summary>
            The max value.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Parse.ParsedChoice.IsIndex">
            <summary>
            True, if this choice is indexed, or discrete.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Parse.ParsedChoice.ToString">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Bayesian.Parse.ParsedEvent">
            <summary>
            An event that has been parsed.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Parse.ParsedEvent.label">
            <summary>
            The event label.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Parse.ParsedEvent.Value">
            <summary>
            The event value.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Parse.ParsedEvent.list">
            <summary>
            The choices.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Parse.ParsedEvent.#ctor(System.String)">
            <summary>
            Construct a parsed even with the specified label.
            </summary>
            <param name="theLabel">The label.</param>
        </member>
        <member name="P:Encog.ML.Bayesian.Parse.ParsedEvent.Label">
            <summary>
            The label for this event.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Parse.ParsedEvent.ResolveValue(Encog.ML.Bayesian.BayesianEvent)">
            <summary>
            Resolve the event to an actual value.
            </summary>
            <param name="actualEvent">The actual event.</param>
            <returns>The value.</returns>
        </member>
        <member name="P:Encog.ML.Bayesian.Parse.ParsedEvent.ChoiceList">
            <summary>
            A list of choices.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Parse.ParsedEvent.ToString">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Bayesian.Parse.ParsedProbability">
            <summary>
            A probability that has been parsed. 
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Parse.ParsedProbability.baseEvents">
            <summary>
            The base events.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Parse.ParsedProbability.givenEvents">
            <summary>
            The given events.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Parse.ParsedProbability.AddGivenEvent(Encog.ML.Bayesian.Parse.ParsedEvent)">
            <summary>
            Add a given event.
            </summary>
            <param name="theEvent">The event to add.</param>
        </member>
        <!-- Проигнорирован некорректный комментарий XML для члена "M:Encog.ML.Bayesian.Parse.ParsedProbability.AddBaseEvent(Encog.ML.Bayesian.Parse.ParsedEvent)" -->
        <member name="M:Encog.ML.Bayesian.Parse.ParsedProbability.GetArgs(Encog.ML.Bayesian.BayesianNetwork)">
            <summary>
            Get the arguments to this event.
            </summary>
            <param name="network">The network.</param>
            <returns>The arguments.</returns>
        </member>
        <member name="P:Encog.ML.Bayesian.Parse.ParsedProbability.ChildEvent">
            <summary>
            The child events.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Parse.ParsedProbability.DefineTruthTable(Encog.ML.Bayesian.BayesianNetwork,System.Double)">
            <summary>
            Define the truth table. 
            </summary>
            <param name="network">The bayesian network.</param>
            <param name="result">The resulting probability.</param>
        </member>
        <member name="P:Encog.ML.Bayesian.Parse.ParsedProbability.BaseEvents">
            <summary>
            The base events.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Parse.ParsedProbability.GivenEvents">
            <summary>
            The given events.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Parse.ParsedProbability.DefineRelationships(Encog.ML.Bayesian.BayesianNetwork)">
            <summary>
            Define the relationships.
            </summary>
            <param name="network">The network.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.Parse.ParsedProbability.ToString">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Bayesian.Parse.ParseProbability">
            <summary>
            Parse a probability string.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Parse.ParseProbability.network">
            <summary>
            The network used.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Parse.ParseProbability.#ctor(Encog.ML.Bayesian.BayesianNetwork)">
            <summary>
            Parse the probability for the specified network. 
            </summary>
            <param name="theNetwork">The network to parse for.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.Parse.ParseProbability.AddEvents(Encog.Util.SimpleParser,System.Collections.Generic.IList{Encog.ML.Bayesian.Parse.ParsedEvent},System.String)">
            <summary>
            Add events, as they are pased.
            </summary>
            <param name="parser">The parser.</param>
            <param name="results">The events found.</param>
            <param name="delim">The delimiter to use.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.Parse.ParseProbability.Parse(System.String)">
            <summary>
            Parse the given line.
            </summary>
            <param name="line">The line to parse.</param>
            <returns>The parsed probability.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.Parse.ParseProbability.ParseProbabilityList(Encog.ML.Bayesian.BayesianNetwork,System.String)">
            <summary>
            Parse a probability list. 
            </summary>
            <param name="network">The network to parse for.</param>
            <param name="line">The line to parse.</param>
            <returns>The parsed list.</returns>
        </member>
        <member name="T:Encog.ML.Bayesian.PersistBayes">
            <summary>
            Persist a bayes network.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.PersistBayes.FileVersion">
            <summary>
            The file version.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.PersistBayes.Read(System.IO.Stream)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.PersistBayes.Save(System.IO.Stream,System.Object)">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Bayesian.PersistBayes.PersistClassString">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Bayesian.PersistBayes.NativeType">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Bayesian.Query.BasicQuery">
            <summary>
            Provides basic functionality for a Bayesian query. This class is abstract,
            and is not used directly. Rather, other queries make use of it.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Query.BasicQuery._events">
            <summary>
            A mapping of the events to event states.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Query.BasicQuery._evidenceEvents">
            <summary>
            The evidence events.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Query.BasicQuery._network">
            <summary>
            The network to be queried.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Query.BasicQuery._outcomeEvents">
            <summary>
            The outcome events.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.BasicQuery.#ctor">
            <summary>
            Default constructor.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.BasicQuery.#ctor(Encog.ML.Bayesian.BayesianNetwork)">
            <summary>
            Construct a basic query.
            </summary>
            <param name="theNetwork">The network to use for this query.</param>
        </member>
        <member name="P:Encog.ML.Bayesian.Query.BasicQuery.IsNeededEvidence">
            <summary>
            Determines if the evidence events have values that satisfy the
            needed case. This is used for sampling.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Query.BasicQuery.SatisfiesDesiredOutcome">
            <summary>
            True, if the current state satisifies the desired outcome.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.BasicQuery.FinalizeStructure">
            <summary>
            Finalize the query structure.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Query.BasicQuery.Network">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Bayesian.Query.BasicQuery.Events">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Bayesian.Query.BasicQuery.EvidenceEvents">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Bayesian.Query.BasicQuery.OutcomeEvents">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.BasicQuery.LocateEventTypes">
            <summary>
            Called to locate the evidence and outcome events.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.BasicQuery.Reset">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.BasicQuery.DefineEventType(Encog.ML.Bayesian.BayesianEvent,Encog.ML.Bayesian.EventType)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.BasicQuery.GetEventState(Encog.ML.Bayesian.BayesianEvent)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.BasicQuery.GetEventType(Encog.ML.Bayesian.BayesianEvent)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.BasicQuery.SetEventValue(Encog.ML.Bayesian.BayesianEvent,System.Boolean)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.BasicQuery.SetEventValue(Encog.ML.Bayesian.BayesianEvent,System.Int32)">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Bayesian.Query.BasicQuery.Problem">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.BasicQuery.Clone">
            <summary>
            Clone the object.
            </summary>
            <returns>A clone of the object.</returns>
        </member>
        <member name="P:Encog.ML.Bayesian.Query.BasicQuery.Probability">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.BasicQuery.Execute">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Bayesian.Query.Enumeration.EnumerationQuery">
            <summary>
            An enumeration query allows probabilistic queries on a Bayesian network.
            Enumeration works by calculating every combination of hidden nodes and using
            total probability. This results in an accurate deterministic probability.
            However, enumeration can be slow for large Bayesian networks. For a quick
            estimate of probability the sampling query can be used.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Query.Enumeration.EnumerationQuery._enumerationEvents">
            <summary>
            The events that we will enumerate over.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Query.Enumeration.EnumerationQuery._probability">
            <summary>
            The calculated probability.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.Enumeration.EnumerationQuery.#ctor(Encog.ML.Bayesian.BayesianNetwork)">
            <summary>
            Construct the enumeration query.
            </summary>
            <param name="theNetwork">The Bayesian network to query.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.Enumeration.EnumerationQuery.#ctor">
            <summary>
            Default constructor.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Query.Enumeration.EnumerationQuery.Probability">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.Enumeration.EnumerationQuery.ResetEnumeration(System.Boolean,System.Boolean)">
            <summary>
            Reset the enumeration events. Always reset the hidden events. Optionally
            reset the evidence and outcome.
            </summary>
            <param name="includeEvidence">True if the evidence is to be reset.</param>
            <param name="includeOutcome">True if the outcome is to be reset.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.Enumeration.EnumerationQuery.Forward">
            <summary>
            Roll the enumeration events forward by one.
            </summary>
            <returns>False if there are no more values to roll into, which means we're
            done.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.Enumeration.EnumerationQuery.ObtainArgs(Encog.ML.Bayesian.BayesianEvent)">
            <summary>
            Obtain the arguments for an event.
            </summary>
            <param name="theEvent">The event.</param>
            <returns>The arguments.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.Enumeration.EnumerationQuery.CalculateProbability(Encog.ML.Bayesian.Query.EventState)">
            <summary>
            Calculate the probability for a state.
            </summary>
            <param name="state">The state to calculate.</param>
            <returns>The probability.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.Enumeration.EnumerationQuery.PerformEnumeration">
            <summary>
            Perform a single enumeration. 
            </summary>
            <returns>The result.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.Enumeration.EnumerationQuery.Execute">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.Enumeration.EnumerationQuery.ToString">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.Enumeration.EnumerationQuery.Roll(System.Collections.Generic.IList{Encog.ML.Bayesian.BayesianEvent},System.Int32[])">
            <summary>
            Roll the enumeration events forward by one.
            </summary>
            <param name="enumerationEvents">The events to roll.</param>
            <param name="args">The arguments to roll.</param>
            <returns>False if there are no more values to roll into, which means we're
                    done.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.Enumeration.EnumerationQuery.Clone">
            <summary>
            A clone of this object.
            </summary>
            <returns>A clone of this object.</returns>
        </member>
        <member name="T:Encog.ML.Bayesian.Query.EventState">
            <summary>
            Holds the state of an event during a query. This allows the event to actually
            hold a value, as well as an anticipated value (compareValue).
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Query.EventState._event">
            <summary>
            The event that this state is connected to.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Query.EventState._value">
            <summary>
            The current value of this event.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.EventState.#ctor(Encog.ML.Bayesian.BayesianEvent)">
            <summary>
            Construct an event state for the specified event. 
            </summary>
            <param name="theEvent">The event to create a state for.</param>
        </member>
        <member name="P:Encog.ML.Bayesian.Query.EventState.IsCalculated">
            <summary>
            Has this event been calculated yet?
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Query.EventState.CurrentEventType">
            <summary>
            The type of event that this is for the query.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Query.EventState.CompareValue">
            <summary>
            The value that we are comparing to, for probability.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Query.EventState.Value">
            <summary>
            The value.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Query.EventState.Event">
            <summary>
            The event.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Query.EventState.IsSatisfied">
            <summary>
            Is this event satisified.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.EventState.Randomize(System.Int32[])">
            <summary>
            Randomize according to the arguments.
            </summary>
            <param name="args">The arguments.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.EventState.ToString">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.EventState.ToSimpleString(Encog.ML.Bayesian.Query.EventState)">
            <summary>
            Convert a state to a simple string. (probability expression) 
            </summary>
            <param name="state">The state.</param>
            <returns>A probability expression as a string.</returns>
        </member>
        <member name="T:Encog.ML.Bayesian.Query.IBayesianQuery">
            <summary>
            A Bayesian query. This is used to query a Bayesian network and determine a
            the probability of an output, given some input. The input is called evidence,
            and the output is the outcome. This results in a final probability of the
            output being what you specified.
            
            You can easily change the events between evidence and outcome, this allows
            the Bayesian network to be queried in nearly any way.  It is also possible to
            omit missing evidence to handle missing data.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Query.IBayesianQuery.Network">
            <summary>
            The Bayesian network that we are using this query for.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Query.IBayesianQuery.Events">
            <summary>
            A mapping of events to event states.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Query.IBayesianQuery.EvidenceEvents">
            <summary>
            The evidence events (inputs).
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Query.IBayesianQuery.OutcomeEvents">
            <summary>
            The outcome events (outputs).
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Query.IBayesianQuery.Problem">
            <summary>
            Return a string that represents this query as a probability "problem".
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Query.IBayesianQuery.Probability">
            <summary>
            Obtains the probability after execute has been called.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.IBayesianQuery.Reset">
            <summary>
            Reset all event types back to hidden.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.IBayesianQuery.DefineEventType(Encog.ML.Bayesian.BayesianEvent,Encog.ML.Bayesian.EventType)">
            <summary>
            Define an event type to be either hidden(default), evidence(input) or
            outcome (output).
            </summary>
            <param name="theEvent">The event to define.</param>
            <param name="et">The new event type.         */</param>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.IBayesianQuery.GetEventState(Encog.ML.Bayesian.BayesianEvent)">
            <summary>
            Get the event state for a given event.
            </summary>
            <param name="theEvent">The event to get the state for.</param>
            <returns>The event state.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.IBayesianQuery.GetEventType(Encog.ML.Bayesian.BayesianEvent)">
            <summary>
             Get the event type.
            </summary>
            <param name="theEvent">The event to check.</param>
            <returns>The current event type for this event.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.IBayesianQuery.SetEventValue(Encog.ML.Bayesian.BayesianEvent,System.Boolean)">
            <summary>
            Set the event value to a boolean.
            </summary>
            <param name="theEvent">The event.</param>
            <param name="b">The value.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.IBayesianQuery.SetEventValue(Encog.ML.Bayesian.BayesianEvent,System.Int32)">
            <summary>
            Set the event value as a class item.
            </summary>
            <param name="theEvent">The event to set.</param>
            <param name="d">An integer class item.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.IBayesianQuery.Execute">
            <summary>
            Execute the query.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.IBayesianQuery.FinalizeStructure">
            <summary>
            Finalize the structure, once all events and dependencies are in place.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.IBayesianQuery.LocateEventTypes">
            <summary>
            Called to locate the evidence and outcome events.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.IBayesianQuery.Clone">
            <summary>
            Clone the object.
            </summary>
            <returns>A clone of this object.</returns>
        </member>
        <member name="T:Encog.ML.Bayesian.Query.Sample.SamplingQuery">
            <summary>
            A sampling query allows probabilistic queries on a Bayesian network. Sampling
            works by actually simulating the probabilities using a random number
            generator. A sample size must be specified. The higher the sample size, the
            more accurate the probability will be. However, the higher the sampling size,
            the longer it takes to run the query.
            
            An enumeration query is more precise than the sampling query. However, the
            enumeration query will become slow as the size of the Bayesian network grows.
            Sampling can often be used for a quick estimation of a probability.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Query.Sample.SamplingQuery.DefaultSampleSize">
            <summary>
            The default sample size.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Query.Sample.SamplingQuery._goodSamples">
            <summary>
            The number of samples that matched the result the query is looking for.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Query.Sample.SamplingQuery._totalSamples">
            <summary>
            The total number of samples generated. This should match sampleSize at
            the end of a query.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Query.Sample.SamplingQuery._usableSamples">
            <summary>
            The number of usable samples. This is the set size for the average
            probability.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.Sample.SamplingQuery.#ctor(Encog.ML.Bayesian.BayesianNetwork)">
            <summary>
            Construct a sampling query. 
            </summary>
            <param name="theNetwork">The network that will be queried.</param>
        </member>
        <member name="P:Encog.ML.Bayesian.Query.Sample.SamplingQuery.SampleSize">
            <summary>
            The sample size.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Query.Sample.SamplingQuery.Probability">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.Sample.SamplingQuery.ObtainArgs(Encog.ML.Bayesian.BayesianEvent)">
            <summary>
            Obtain the arguments for an event. 
            </summary>
            <param name="e">The event.</param>
            <returns>The arguments for that event, based on the other event values.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.Sample.SamplingQuery.RandomizeEvents(Encog.ML.Bayesian.Query.EventState)">
            <summary>
            Set all events to random values, based on their probabilities. 
            </summary>
            <param name="eventState">The event state.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.Sample.SamplingQuery.CountUnCalculated">
            <summary>
            The number of events that are still uncalculated.
            </summary>
            <returns>The uncalculated count.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.Sample.SamplingQuery.Execute">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.Sample.SamplingQuery.DumpCurrentState">
            <summary>
            The current state as a string.
            </summary>
            <returns>The state.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.Sample.SamplingQuery.Clone">
            <summary>
            Clone the object.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Encog.ML.Bayesian.Query.Sample.SamplingQuery.ToString">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Bayesian.Table.BayesianTable">
            <summary>
            Holds a Bayesian truth table.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Table.BayesianTable._event">
            <summary>
            The event that owns this truth table.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Table.BayesianTable._lines">
            <summary>
            The lines of the truth table.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Table.BayesianTable.#ctor(Encog.ML.Bayesian.BayesianEvent)">
            <summary>
            Construct a Bayes truth table.
            </summary>
            <param name="theEvent">The lines of the truth table.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.Table.BayesianTable.Reset">
            <summary>
            Reset the truth table to zero.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Table.BayesianTable.AddLine(System.Double,System.Boolean,System.Boolean[])">
            <summary>
            Add a new line.
            </summary>
            <param name="prob">The probability.</param>
            <param name="result">The resulting probability.</param>
            <param name="args">The arguments.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.Table.BayesianTable.AddLine(System.Double,System.Int32,System.Boolean[])">
            <summary>
            Add a new line.
            </summary>
            <param name="prob">The probability.</param>
            <param name="result">The resulting probability.</param>
            <param name="args">The arguments.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.Table.BayesianTable.AddLine(System.Double,System.Int32,System.Int32[])">
            <summary>
            Add a new line.
            </summary>
            <param name="prob">The probability.</param>
            <param name="result">The resulting probability.</param>
            <param name="args">The arguments.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.Table.BayesianTable.Validate">
            <summary>
            Validate the truth table.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Table.BayesianTable.GenerateRandom(System.Int32[])">
            <summary>
            Generate a random sampling based on this truth table.
            </summary>
            <param name="args">The arguemtns.</param>
            <returns>The result.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.Table.BayesianTable.ToString">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Bayesian.Table.BayesianTable.Lines">
            <summary>
            The lines of this truth table.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Table.BayesianTable.FindLine(System.Int32,System.Int32[])">
            <summary>
            Find the specified truth table line.
            </summary>
            <param name="result">The result sought.</param>
            <param name="args">The arguments.</param>
            <returns>The line that matches.</returns>
        </member>
        <member name="P:Encog.ML.Bayesian.Table.BayesianTable.MaxLines">
            <summary>
            The maximum number of lines this truth table would have.
            </summary>
        </member>
        <member name="T:Encog.ML.Bayesian.Table.TableLine">
            <summary>
            A line from a Bayesian truth table.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Table.TableLine._arguments">
            <summary>
            The arguments.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Table.TableLine._result">
            <summary>
            The result.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Table.TableLine.#ctor(System.Double,System.Int32,System.Int32[])">
            <summary>
            Construct a truth table line. 
            </summary>
            <param name="prob">The probability.</param>
            <param name="result">The result.</param>
            <param name="args">The arguments.</param>
        </member>
        <member name="P:Encog.ML.Bayesian.Table.TableLine.Probability">
            <summary>
            The probability.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Table.TableLine.Arguments">
            <summary>
            Arguments.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Table.TableLine.Result">
            <summary>
            Result.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Table.TableLine.ToString">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.Table.TableLine.CompareArgs(System.Int32[])">
            <summary>
            Compare this truth line's arguments to others. 
            </summary>
            <param name="args">The other arguments to compare to.</param>
            <returns>True if the same.</returns>
        </member>
        <member name="T:Encog.ML.Bayesian.Training.BayesianInit">
            <summary>
            The method by which a Bayesian network should be initialized.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Training.BayesianInit.InitNoChange">
            <summary>
            No init, do not change anything.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Training.BayesianInit.InitEmpty">
            <summary>
            Start with no connections.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Training.BayesianInit.InitNaiveBayes">
            <summary>
            Init as Naive Bayes.
            </summary>
        </member>
        <member name="T:Encog.ML.Bayesian.Training.Estimator.EstimatorNone">
            <summary>
            A Bayesian estimator that does nothing.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.Estimator.EstimatorNone.Init(Encog.ML.Bayesian.Training.TrainBayesian,Encog.ML.Bayesian.BayesianNetwork,Encog.ML.Data.IMLDataSet)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.Estimator.EstimatorNone.Iteration">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Bayesian.Training.Estimator.IBayesEstimator">
            <summary>
            An estimator is used during Bayesian training to determine optimal probability values.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.Estimator.IBayesEstimator.Init(Encog.ML.Bayesian.Training.TrainBayesian,Encog.ML.Bayesian.BayesianNetwork,Encog.ML.Data.IMLDataSet)">
            <summary>
            Init the estimator.
            </summary>
            <param name="theTrainer">The trainer.</param>
            <param name="theNetwork">The network.</param>
            <param name="theData">The data.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.Estimator.IBayesEstimator.Iteration">
            <summary>
            Perform an iteration.
            </summary>
            <returns>True, if we should contune.</returns>
        </member>
        <member name="T:Encog.ML.Bayesian.Training.Estimator.SimpleEstimator">
            <summary>
            A simple probability estimator.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.Estimator.SimpleEstimator.Init(Encog.ML.Bayesian.Training.TrainBayesian,Encog.ML.Bayesian.BayesianNetwork,Encog.ML.Data.IMLDataSet)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.Estimator.SimpleEstimator.Iteration">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.Estimator.SimpleEstimator.CalculateProbability(Encog.ML.Bayesian.BayesianEvent,System.Int32,System.Int32[])">
            <summary>
            Calculate the probability.
            </summary>
            <param name="e">The event.</param>
            <param name="result">The result.</param>
            <param name="args">The arguments.</param>
            <returns>The probability.</returns>
        </member>
        <member name="T:Encog.ML.Bayesian.Training.Search.IBayesSearch">
            <summary>
            Search for a good Bayes structure.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.Search.IBayesSearch.Init(Encog.ML.Bayesian.Training.TrainBayesian,Encog.ML.Bayesian.BayesianNetwork,Encog.ML.Data.IMLDataSet)">
            <summary>
            Init the search object.
            </summary>
            <param name="theTrainer">The trainer to use.</param>
            <param name="theNetwork">The network to use.</param>
            <param name="theData">The data to use.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.Search.IBayesSearch.Iteration">
            <summary>
            Perform an iteration. 
            </summary>
            <returns>True to continue.</returns>
        </member>
        <member name="T:Encog.ML.Bayesian.Training.Search.k2.SearchK2">
            <summary>
            Search for optimal Bayes structure with K2.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Training.Search.k2.SearchK2._nodeOrdering">
            <summary>
            The node ordering.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Training.Search.k2.SearchK2._data">
            <summary>
            The data to use.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Training.Search.k2.SearchK2._index">
            <summary>
            The current index.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Training.Search.k2.SearchK2._lastCalculatedP">
            <summary>
            The last calculated value for p.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Training.Search.k2.SearchK2._network">
            <summary>
            The network to optimize.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Training.Search.k2.SearchK2._train">
            <summary>
            The trainer being used.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.Search.k2.SearchK2.Init(Encog.ML.Bayesian.Training.TrainBayesian,Encog.ML.Bayesian.BayesianNetwork,Encog.ML.Data.IMLDataSet)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.Search.k2.SearchK2.Iteration">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.Search.k2.SearchK2.OrderNodes">
            <summary>
            Basically the goal here is to get the classification target, if it exists,
            to go first. This will greatly enhance K2's effectiveness.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.Search.k2.SearchK2.FindZ(Encog.ML.Bayesian.BayesianEvent,System.Int32,System.Double)">
            <summary>
            Find the value for z.
            </summary>
            <param name="e">The event that we are clauclating for.</param>
            <param name="n">The value for n.</param>
            <param name="old">The old value.</param>
            <returns>The new value for z.</returns>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.Search.k2.SearchK2.CalculateN(Encog.ML.Bayesian.BayesianNetwork,Encog.ML.Bayesian.BayesianEvent,System.Collections.Generic.IList{Encog.ML.Bayesian.BayesianEvent},System.Int32[],System.Int32)">
            <summary>
            Calculate the value N, which is the number of cases, from the training data, where the
            desiredValue matches the training data.  Only cases where the parents match the specifed
            parent instance are considered.
            </summary>
            <param name="network">The network to calculate for.</param>
            <param name="e">The event we are calculating for. (variable i)</param>
            <param name="parents">The parents of the specified event we are considering.</param>
            <param name="parentInstance">The parent instance we are looking for.</param>
            <param name="desiredValue">The desired value.</param>
            <returns>The value N. </returns>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.Search.k2.SearchK2.CalculateN(Encog.ML.Bayesian.BayesianNetwork,Encog.ML.Bayesian.BayesianEvent,System.Collections.Generic.IList{Encog.ML.Bayesian.BayesianEvent},System.Int32[])">
            <summary>
            Calculate the value N, which is the number of cases, from the training data, where the
            desiredValue matches the training data.  Only cases where the parents match the specifed
            parent instance are considered.
            </summary>
            <param name="network">The network to calculate for.</param>
            <param name="e">The event we are calculating for. (variable i)</param>
            <param name="parents">The parents of the specified event we are considering.</param>
            <param name="parentInstance">The parent instance we are looking for.</param>
            <returns>The value N. </returns>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.Search.k2.SearchK2.CalculateG(Encog.ML.Bayesian.BayesianNetwork,Encog.ML.Bayesian.BayesianEvent,System.Collections.Generic.IList{Encog.ML.Bayesian.BayesianEvent})">
            <summary>
            Calculate G. 
            </summary>
            <param name="network">The network to calculate for.</param>
            <param name="e">The event to calculate for.</param>
            <param name="parents">The parents.</param>
            <returns>The value for G.</returns>
        </member>
        <member name="T:Encog.ML.Bayesian.Training.Search.SearchNone">
            <summary>
            Simple class to perform no search for optimal network structure.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.Search.SearchNone.Init(Encog.ML.Bayesian.Training.TrainBayesian,Encog.ML.Bayesian.BayesianNetwork,Encog.ML.Data.IMLDataSet)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.Search.SearchNone.Iteration">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Bayesian.Training.TrainBayesian">
            <summary>
            Train a Bayesian network.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Training.TrainBayesian._data">
            <summary>
            The data used for training.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Training.TrainBayesian._estimator">
            <summary>
            The method used to estimate the probabilities.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Training.TrainBayesian._maximumParents">
            <summary>
            The maximum parents a node should have.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Training.TrainBayesian._network">
            <summary>
            The network to train.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Training.TrainBayesian._search">
            <summary>
            The method used to search for the best network structure.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Training.TrainBayesian._holdQuery">
            <summary>
            Used to hold the query.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Training.TrainBayesian._initNetwork">
            <summary>
            The method used to setup the initial Bayesian network.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Training.TrainBayesian._p">
            <summary>
            The phase that training is currently in.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.TrainBayesian.#ctor(Encog.ML.Bayesian.BayesianNetwork,Encog.ML.Data.IMLDataSet,System.Int32)">
            <summary>
            Construct a Bayesian trainer. Use K2 to search, and the SimpleEstimator
            to estimate probability.  Init as Naive Bayes
            </summary>
            <param name="theNetwork">The network to train.</param>
            <param name="theData">The data to train.</param>
            <param name="theMaximumParents">The max number of parents.</param>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.TrainBayesian.#ctor(Encog.ML.Bayesian.BayesianNetwork,Encog.ML.Data.IMLDataSet,System.Int32,Encog.ML.Bayesian.Training.BayesianInit,Encog.ML.Bayesian.Training.Search.IBayesSearch,Encog.ML.Bayesian.Training.Estimator.IBayesEstimator)">
            <summary>
            Construct a Bayesian trainer. 
            </summary>
            <param name="theNetwork">The network to train.</param>
            <param name="theData">The data to train with.</param>
            <param name="theMaximumParents">The maximum number of parents.</param>
            <param name="theInit">How to init the new Bayes network.</param>
            <param name="theSearch">The search method.</param>
            <param name="theEstimator">The estimation mehod.</param>
        </member>
        <member name="P:Encog.ML.Bayesian.Training.TrainBayesian.TrainingDone">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Bayesian.Training.TrainBayesian.CanContinue">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Bayesian.Training.TrainBayesian.Method">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Bayesian.Training.TrainBayesian.Network">
            <summary>
            Returns the network.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Training.TrainBayesian.MaximumParents">
            <summary>
            The maximum parents a node can have.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Training.TrainBayesian.Search">
            <summary>
            The search method.
            </summary>
        </member>
        <member name="P:Encog.ML.Bayesian.Training.TrainBayesian.InitNetwork">
            <summary>
            The init method.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.TrainBayesian.InitNaiveBayes">
            <summary>
            Init to Naive Bayes.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.TrainBayesian.IterationInit">
            <summary>
            Handle iterations for the Init phase.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.TrainBayesian.IterationSearch">
            <summary>
            Handle iterations for the Search phase.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.TrainBayesian.IterationSearchDone">
            <summary>
            Handle iterations for the Search Done phase.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.TrainBayesian.IterationProbability">
            <summary>
            Handle iterations for the Probability phase.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.TrainBayesian.IterationFinish">
            <summary>
            Handle iterations for the Finish phase.
            </summary>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.TrainBayesian.Iteration">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.TrainBayesian.Pause">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Bayesian.Training.TrainBayesian.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Bayesian.Training.TrainBayesian.Phase">
            <summary>
            What phase of training are we in?
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Training.TrainBayesian.Phase.Init">
            <summary>
            Init phase.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Training.TrainBayesian.Phase.Search">
            <summary>
            Searching for a network structure.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Training.TrainBayesian.Phase.SearchDone">
            <summary>
            Search complete.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Training.TrainBayesian.Phase.Probability">
            <summary>
            Finding probabilities.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Training.TrainBayesian.Phase.Finish">
            <summary>
            Finished training.
            </summary>
        </member>
        <member name="F:Encog.ML.Bayesian.Training.TrainBayesian.Phase.Terminated">
            <summary>
            Training terminated.
            </summary>
        </member>
        <member name="T:Encog.ML.Data.Basic.BasicMLComplexData">
            <summary>
            This class implements a data object that can hold complex numbers.  It 
            implements the interface MLData, so it can be used with nearly any Encog 
            machine learning method.  However, not all Encog machine learning methods 
            are designed to work with complex numbers.  A Encog machine learning method 
            that does not support complex numbers will only be dealing with the 
            real-number portion of the complex number. 
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Basic.BasicMLComplexData._data">
            <summary>
            The data held by this object.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLComplexData.#ctor(System.Double[])">
            <summary>
            Construct this object with the specified data.  Use only real numbers. 
            </summary>
            <param name="d">The data to construct this object with.</param>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLComplexData.#ctor(Encog.MathUtil.ComplexNumber[])">
            <summary>
            Construct this object with the specified data. Use complex numbers. 
            </summary>
            <param name="d">The data to construct this object with.</param>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLComplexData.#ctor(System.Int32)">
            <summary>
            Construct this object with blank data and a specified size. 
            </summary>
            <param name="size">The amount of data to store.</param>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLComplexData.#ctor(Encog.ML.Data.IMLData)">
            <summary>
            Construct a new BasicMLData object from an existing one. This makes a
            copy of an array. If MLData is not complex, then only reals will be 
            created. 
            </summary>
            <param name="d">The object to be copied.</param>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLComplexData.Clear">
            <summary>
            Clear all values to zero.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLComplexData.Clone">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLComplexData.ComplexData">
            <summary>
            The complex numbers.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLComplexData.GetComplexData(System.Int32)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLComplexData.SetComplexData(System.Int32,Encog.MathUtil.ComplexNumber)">
            <summary>
            Set a data element to a complex number. 
            </summary>
            <param name="index">The index to set.</param>
            <param name="d">The complex number.</param>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLComplexData.SetComplexData(Encog.MathUtil.ComplexNumber[])">
            <summary>
            Set the complex data array.
            </summary>
            <param name="d">A new complex data array.</param>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLComplexData.Item(System.Int32)">
            <summary>
            Access the data by index.
            </summary>
            <param name="x">The index to access.</param>
            <returns></returns>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLComplexData.Data">
            <summary>
            Get the data as an array.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLComplexData.Count">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLComplexData.ToString">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLComplexData.CreateCentroid">
            <summary>
            Not supported.
            </summary>
            <returns>Nothing.</returns>
        </member>
        <member name="T:Encog.ML.Data.Basic.BasicMLData">
            <summary>
            Basic implementation of the NeuralData interface that stores the
            data in an array.  
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLData.#ctor(System.Double[])">
            <summary>
            Construct this object with the specified data. 
            </summary>
            <param name="d">The data to construct this object with.</param>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLData.#ctor(System.Int32)">
            <summary>
            Construct this object with blank data and a specified size.
            </summary>
            <param name="size">The amount of data to store.</param>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLData.Item(System.Int32)">
            <summary>
            Access the data by index.
            </summary>
            <param name="x">The index to access.</param>
            <returns></returns>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLData.Data">
            <summary>
            Get the data as an array.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLData.Count">
            <summary>
            Get the count of data items.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLData.ToString">
            <summary>
            Convert the object to a string.
            </summary>
            <returns>The object as a string.</returns>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLData.Clone">
            <summary>
            Clone this object.
            </summary>
            <returns>A clone of this object.</returns>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLData.Clear">
            <summary>
            Clear to zero.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLData.CreateCentroid">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLData.Plus(Encog.ML.Data.IMLData)">
            <summary>
            Add one data element to another.  This does not modify the object.
            </summary>
            <param name="o">The other data element</param>
            <returns>The result.</returns>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLData.Times(System.Double)">
            <summary>
            Multiply one data element with another.  This does not modify the object.
            </summary>
            <param name="d">The other data element</param>
            <returns>The result.</returns>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLData.Minus(Encog.ML.Data.IMLData)">
            <summary>
            Subtract one data element from another.  This does not modify the object.
            </summary>
            <param name="o">The other data element</param>
            <returns>The result.</returns>
        </member>
        <member name="T:Encog.ML.Data.Basic.BasicMLDataCentroid">
            <summary>
            A basic implementation of a centroid.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Basic.BasicMLDataCentroid.value">
            <summary>
            The value this centroid is based on.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataCentroid.#ctor(Encog.ML.Data.IMLData)">
            <summary>
            Construct the centroid. 
            </summary>
            <param name="o">The object to base the centroid on.</param>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataCentroid.Add(Encog.ML.Data.IMLData)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataCentroid.Remove(Encog.ML.Data.IMLData)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataCentroid.Distance(Encog.ML.Data.IMLData)">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Data.Basic.BasicMLDataPair">
            <summary>
            Basic implementation of a data pair.  Holds both input and ideal data.
            If this is unsupervised training then ideal should be null.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Basic.BasicMLDataPair._ideal">
            <summary>
            The the expected output from the neural network, or null
            for unsupervised training.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Basic.BasicMLDataPair._input">
            <summary>
            The training input to the neural network.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Basic.BasicMLDataPair._significance">
            <summary>
            The significance.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataPair.#ctor(Encog.ML.Data.IMLData,Encog.ML.Data.IMLData)">
            <summary>
            Construct a BasicMLDataPair class with the specified input
            and ideal values.
            </summary>
            <param name="input">The input to the neural network.</param>
            <param name="ideal">The expected results from the neural network.</param>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataPair.#ctor(Encog.ML.Data.IMLData)">
            <summary>
            Construct a data pair that only includes input. (unsupervised)
            </summary>
            <param name="input">The input data.</param>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLDataPair.Input">
            <summary>
            The input data.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLDataPair.Ideal">
            <summary>
            The ideal data.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataPair.ToString">
            <summary>
            Convert object to a string.
            </summary>
            <returns>The object as a string.</returns>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLDataPair.IsSupervised">
            <summary>
            Deterimine if this pair is supervised or unsupervised.
            </summary>
            <returns>True if this is a supervised pair.</returns>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataPair.Clone">
            <summary>
            Clone this object.
            </summary>
            <returns>A clone of this object.</returns>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataPair.CreatePair(System.Int32,System.Int32)">
            <summary>
            Create a new neural data pair object of the correct size for the neural
            network that is being trained. This object will be passed to the getPair
            method to allow the neural data pair objects to be copied to it.
            </summary>
            <param name="inputSize">The size of the input data.</param>
            <param name="idealSize">The size of the ideal data.</param>
            <returns>A new neural data pair object.</returns>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLDataPair.IdealArray">
            <summary>
            The supervised ideal data.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLDataPair.InputArray">
            <summary>
            The input array.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLDataPair.Supervised">
            <summary>
            Returns true, if supervised.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLDataPair.Significance">
            <summary>
            The significance of this training element.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataPair.CreateCentroid">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Data.Basic.BasicMLDataPairCentroid">
            <summary>
            A centroid for BasicMLDataPair
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Basic.BasicMLDataPairCentroid._value">
            <summary>
            The value the centroid is based on.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataPairCentroid.#ctor(Encog.ML.Data.Basic.BasicMLDataPair)">
            <summary>
            Construct the centroid. 
            </summary>
            <param name="o"> The pair to base the centroid on.</param>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataPairCentroid.Remove(Encog.ML.Data.IMLDataPair)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataPairCentroid.Distance(Encog.ML.Data.IMLDataPair)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataPairCentroid.Add(Encog.ML.Data.IMLDataPair)">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Data.Basic.BasicMLDataSet">
            <summary>
            Basic implementation of the NeuralDataSet class.  This class simply
            stores the neural data in an ArrayList.  This class is memory based, 
            so large enough datasets could cause memory issues.  Many other dataset
            types extend this class.
            </summary>
        </member>
        <member name="T:Encog.ML.Data.Basic.BasicMLDataSet.BasicNeuralEnumerator">
            <summary>
            The enumerator for the basic neural data set.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Basic.BasicMLDataSet.BasicNeuralEnumerator._current">
            <summary>
            The current index.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Basic.BasicMLDataSet.BasicNeuralEnumerator._owner">
            <summary>
            The owner.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataSet.BasicNeuralEnumerator.#ctor(Encog.ML.Data.Basic.BasicMLDataSet)">
            <summary>
            Construct an enumerator.
            </summary>
            <param name="owner">The owner of the enumerator.</param>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLDataSet.BasicNeuralEnumerator.Current">
            <summary>
            The current data item.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataSet.BasicNeuralEnumerator.Dispose">
            <summary>
            Dispose of this object.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLDataSet.BasicNeuralEnumerator.System#Collections#IEnumerator#Current">
            <summary>
            The current item.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataSet.BasicNeuralEnumerator.MoveNext">
            <summary>
            Move to the next item.
            </summary>
            <returns>True if there is a next item.</returns>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataSet.BasicNeuralEnumerator.Reset">
            <summary>
            Reset to the beginning.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLDataSet.Data">
            <summary>
            Access to the list of data items.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Basic.BasicMLDataSet._data">
            <summary>
            The data held by this object.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataSet.#ctor(System.Collections.Generic.IList{Encog.ML.Data.IMLDataPair})">
            <summary>
            Construct a data set from an already created list. Mostly used to
            duplicate this class.
            </summary>
            <param name="data">The data to use.</param>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataSet.#ctor(Encog.ML.Data.IMLDataSet)">
             <summary>
             Copy whatever dataset type is specified into a memory dataset.
             </summary>
            
             <param name="set">The dataset to copy.</param>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataSet.#ctor(System.Double[][],System.Double[][])">
            <summary>
            Construct a data set from an input and idea array.
            </summary>
            <param name="input">The input into the neural network for training.</param>
            <param name="ideal">The idea into the neural network for training.</param>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataSet.#ctor">
            <summary>
            Construct a basic neural data set.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLDataSet.IdealSize">
            <summary>
            Get the ideal size, or zero for unsupervised.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLDataSet.InputSize">
            <summary>
            Get the input size.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataSet.Add(Encog.ML.Data.IMLData)">
            <summary>
            Add the specified data to the set.  Add unsupervised data.
            </summary>
            <param name="data1">The data to add to the set.</param>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataSet.Add(Encog.ML.Data.IMLData,Encog.ML.Data.IMLData)">
            <summary>
            Add supervised data to the set.
            </summary>
            <param name="inputData">The input data.</param>
            <param name="idealData">The ideal data.</param>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataSet.Add(Encog.ML.Data.IMLDataPair)">
            <summary>
            Add a pair to the set.
            </summary>
            <param name="inputData">The pair to add to the set.</param>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataSet.Close">
            <summary>
            Close the neural data set.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataSet.GetEnumerator">
            <summary>
            Get an enumerator to access the data with.
            </summary>
            <returns>An enumerator.</returns>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataSet.System#Collections#IEnumerable#GetEnumerator">
            <summary>
            Get an enumerator to access the data with.
            </summary>
            <returns>An enumerator.</returns>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLDataSet.IsSupervised">
            <summary>
            Determine if the dataset is supervised.  It is assumed that all pairs
            are either supervised or not.  So we can determine the entire set by
            looking at the first item.  If the set is empty then return false, or
            unsupervised.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataSet.Clone">
            <summary>
            Clone this object.
            </summary>
            <returns>A clone of this object.</returns>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLDataSet.Count">
            <summary>
            The number of records in this data set.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataSet.GetRecord(System.Int32,Encog.ML.Data.IMLDataPair)">
            <summary>
            Get one record from the data set.
            </summary>
            <param name="index">The index to read.</param>
            <param name="pair">The pair to read into.</param>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLDataSet.OpenAdditional">
            <summary>
            Open an additional instance of this dataset.
            </summary>
            <returns>The new instance of this dataset.</returns>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLDataSet.Supervised">
            <summary>
            Return true if supervised.
            </summary>
        </member>
        <member name="T:Encog.ML.Data.Basic.BasicMLSequenceSet">
            <summary>
            A basic implementation of the MLSequenceSet.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Basic.BasicMLSequenceSet._sequences">
            <summary>
            The data held by this object.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLSequenceSet.#ctor">
            <summary>
            Default constructor.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLSequenceSet.#ctor(System.Double[][],System.Double[][])">
            <summary>
            Construct a data set from an input and ideal array.
            </summary>
            <param name="input">The input into the machine learning method for training.</param>
            <param name="ideal">The ideal output for training.</param>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLSequenceSet.#ctor(System.Collections.Generic.IList{Encog.ML.Data.IMLDataPair})">
            <summary>
            Construct a data set from an already created list. Mostly used to
            duplicate this class.
            </summary>
            <param name="theData">The data to use.</param>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLSequenceSet.#ctor(Encog.ML.Data.IMLDataSet)">
            <summary>
            Copy whatever dataset type is specified into a memory dataset. 
            </summary>
            <param name="set">The dataset to copy.</param>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLSequenceSet.Add(Encog.ML.Data.IMLData)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLSequenceSet.Add(Encog.ML.Data.IMLData,Encog.ML.Data.IMLData)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLSequenceSet.Add(Encog.ML.Data.IMLDataPair)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLSequenceSet.Close">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLSequenceSet.IdealSize">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLSequenceSet.InputSize">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLSequenceSet.GetRecord(System.Int32,Encog.ML.Data.IMLDataPair)">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLSequenceSet.Count">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLSequenceSet.Supervised">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLSequenceSet.OpenAdditional">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLSequenceSet.SequenceCount">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLSequenceSet.GetSequence(System.Int32)">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLSequenceSet.Sequences">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLSequenceSet.Add(Encog.ML.Data.IMLDataSet)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLSequenceSet.GetEnumerator">
            <summary>
            Get an enumerator to access the data with.
            </summary>
            <returns>An enumerator.</returns>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLSequenceSet.Item(System.Int32)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLSequenceSet.Clone">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Data.Basic.BasicMLSequenceSet.BasicMLSequenceSetEnumerator">
            <summary>
            Enumerate.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Basic.BasicMLSequenceSet.BasicMLSequenceSetEnumerator._owner">
            <summary>
            The owner.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Basic.BasicMLSequenceSet.BasicMLSequenceSetEnumerator._currentIndex">
            <summary>
            The index that the iterator is currently at.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Basic.BasicMLSequenceSet.BasicMLSequenceSetEnumerator._currentSequenceIndex">
            <summary>
            The sequence index.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLSequenceSet.BasicMLSequenceSetEnumerator.#ctor(Encog.ML.Data.Basic.BasicMLSequenceSet)">
            <summary>
            Construct an enumerator.
            </summary>
            <param name="owner">The owner of the enumerator.</param>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLSequenceSet.BasicMLSequenceSetEnumerator.Current">
            <summary>
            The current data item.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLSequenceSet.BasicMLSequenceSetEnumerator.Dispose">
            <summary>
            Dispose of this object.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Basic.BasicMLSequenceSet.BasicMLSequenceSetEnumerator.System#Collections#IEnumerator#Current">
            <summary>
            The current item.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLSequenceSet.BasicMLSequenceSetEnumerator.MoveNext">
            <summary>
            Move to the next item.
            </summary>
            <returns>True if there is a next item.</returns>
        </member>
        <member name="M:Encog.ML.Data.Basic.BasicMLSequenceSet.BasicMLSequenceSetEnumerator.Reset">
            <summary>
            Reset to the beginning.
            </summary>
        </member>
        <member name="T:Encog.ML.Data.Buffer.BinaryDataLoader">
            <summary>
            This class is used, together with a CODEC, to move data to/from the Encog
            binary training file format. The same Encog binary files can be used on all
            Encog platforms. CODEC's are used to import/export with other formats, such
            as CSV.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.BinaryDataLoader._codec">
            <summary>
            The CODEC to use.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BinaryDataLoader.#ctor(Encog.ML.Data.Buffer.CODEC.IDataSetCODEC)">
            <summary>
            Construct a loader with the specified CODEC. 
            </summary>
            <param name="codec">The codec to use.</param>
        </member>
        <member name="P:Encog.ML.Data.Buffer.BinaryDataLoader.Status">
            <summary>
            Used to report the status.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Buffer.BinaryDataLoader.CODEC">
            <summary>
            The CODEC that is being used.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BinaryDataLoader.External2Binary(System.String)">
            <summary>
            Convert an external file format, such as CSV, to the Encog binary
            training format. 
            </summary>
            <param name="binaryFile">The binary file to create.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BinaryDataLoader.Binary2External(System.String)">
            <summary>
            Convert an Encog binary file to an external form, such as CSV. 
            </summary>
            <param name="binaryFile">THe binary file to use.</param>
        </member>
        <member name="T:Encog.ML.Data.Buffer.BufferedDataError">
            <summary>
            Errors thrown by the buffered data objects.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BufferedDataError.#ctor(System.String)">
            <summary>
            Construct a message exception.
            </summary>
            <param name="str">The message.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BufferedDataError.#ctor(System.Exception)">
            <summary>
            Pass on an exception.
            </summary>
            <param name="e">The other exception.</param>
        </member>
        <member name="T:Encog.ML.Data.Buffer.BufferedMLDataSet">
            <summary>
            This class is not memory based, so very long files can be used, without
            running out of memory. This dataset uses a Encog binary training file as a
            buffer.
            
            When used with a slower access dataset, such as CSV, XML or SQL, where
            parsing must occur, this dataset can be used to load from the slower dataset
            and train at much higher speeds.
            
            If you are going to create a binary file, by using the add methods, you must
            call beginLoad to cause Encog to open an output file. Once the data has been
            loaded, call endLoad. You can also use the BinaryDataLoader class, with a
            CODEC, to load many other popular external formats.
            
            The binary files produced by this class are in the Encog binary training
            format, and can be used with any Encog platform. Encog binary files are
            stored using "little endian" numbers.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.BufferedMLDataSet.ErrorAdd">
            <summary>
            Error message for ADD.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.BufferedMLDataSet._loading">
            <summary>
            True, if we are in the process of loading.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.BufferedMLDataSet._file">
            <summary>
            The file being used.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.BufferedMLDataSet._egb">
            <summary>
            The EGB file we are working wtih.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.BufferedMLDataSet._additional">
            <summary>
            Additional sets that were opened.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.BufferedMLDataSet._owner">
            <summary>
            The owner.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BufferedMLDataSet.#ctor(System.String)">
            <summary>
            Construct a buffered dataset using the specified file. 
            </summary>
            <param name="binaryFile">The file to read/write binary data to/from.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BufferedMLDataSet.GetEnumerator">
            <summary>
            Create an enumerator.
            </summary>
            <returns>The enumerator</returns>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BufferedMLDataSet.Open">
            <summary>
            Open the binary file for reading.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Buffer.BufferedMLDataSet.Count">
            <summary>
            The record count.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BufferedMLDataSet.GetRecord(System.Int32,Encog.ML.Data.IMLDataPair)">
            <summary>
            Read an individual record. 
            </summary>
            <param name="index">The zero-based index. Specify 0 for the first record, 1 for
            the second, and so on.</param>
            <param name="pair">The data to read.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BufferedMLDataSet.OpenAdditional">
            <summary>
            Open an additional training set.
            </summary>
            <returns>An additional training set.</returns>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BufferedMLDataSet.Add(Encog.ML.Data.IMLData)">
            <summary>
            Add only input data, for an unsupervised dataset. 
            </summary>
            <param name="data1">The data to be added.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BufferedMLDataSet.Add(Encog.ML.Data.IMLData,Encog.ML.Data.IMLData)">
            <summary>
            Add both the input and ideal data. 
            </summary>
            <param name="inputData">The input data.</param>
            <param name="idealData">The ideal data.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BufferedMLDataSet.Add(Encog.ML.Data.IMLDataPair)">
            <summary>
            Add a data pair of both input and ideal data. 
            </summary>
            <param name="pair">The pair to add.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BufferedMLDataSet.Close">
            <summary>
            Close the dataset.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Buffer.BufferedMLDataSet.IdealSize">
            <summary>
            The ideal data size.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Buffer.BufferedMLDataSet.InputSize">
            <summary>
            The input data size.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Buffer.BufferedMLDataSet.Supervised">
            <summary>
            True if this dataset is supervised.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BufferedMLDataSet.RemoveAdditional(Encog.ML.Data.Buffer.BufferedMLDataSet)">
            <summary>
            Remove an additional dataset that was created. 
            </summary>
            <param name="child">The additional dataset to remove.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BufferedMLDataSet.BeginLoad(System.Int32,System.Int32)">
            <summary>
            Begin loading to the binary file. After calling this method the add
            methods may be called. 
            </summary>
            <param name="inputSize">The input size.</param>
            <param name="idealSize">The ideal size.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BufferedMLDataSet.EndLoad">
            <summary>
            This method should be called once all the data has been loaded. The
            underlying file will be closed. The binary fill will then be opened for
            reading.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Buffer.BufferedMLDataSet.BinaryFile">
            <summary>
            The binary file used.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Buffer.BufferedMLDataSet.EGB">
            <summary>
            The EGB file to use.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BufferedMLDataSet.LoadToMemory">
            <summary>
            Load the binary dataset to memory.  Memory access is faster. 
            </summary>
            <returns>A memory dataset.</returns>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BufferedMLDataSet.Load(Encog.ML.Data.IMLDataSet)">
            <summary>
            Load the specified training set. 
            </summary>
            <param name="training">The training set to load.</param>
        </member>
        <member name="P:Encog.ML.Data.Buffer.BufferedMLDataSet.Owner">
            <summary>
            The owner.  Set when create additional is used.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Buffer.BufferedMLDataSet.Item(System.Int32)">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Data.Buffer.BufferedNeuralDataSetEnumerator">
            <summary>
            An enumerator to move through the buffered data set.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.BufferedNeuralDataSetEnumerator._data">
            <summary>
            The dataset being iterated over.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.BufferedNeuralDataSetEnumerator._current">
            <summary>
            The current record.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.BufferedNeuralDataSetEnumerator._currentRecord">
            <summary>
            The current record.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BufferedNeuralDataSetEnumerator.#ctor(Encog.ML.Data.Buffer.BufferedMLDataSet)">
            <summary>
            Construct the buffered enumerator. This is where the file is actually
            opened.
            </summary>
            <param name="owner">The object that created this enumeration.</param>
        </member>
        <member name="P:Encog.ML.Data.Buffer.BufferedNeuralDataSetEnumerator.Current">
            <summary>
            Get the current record
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BufferedNeuralDataSetEnumerator.Dispose">
            <summary>
            Dispose of the enumerator.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BufferedNeuralDataSetEnumerator.MoveNext">
            <summary>
            Move to the next element.
            </summary>
            <returns>True if there are more elements to read.</returns>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BufferedNeuralDataSetEnumerator.Reset">
            <summary>
            Not implemented.
            </summary>
            <exception cref="T:System.NotImplementedException"></exception>
        </member>
        <member name="M:Encog.ML.Data.Buffer.BufferedNeuralDataSetEnumerator.Close">
            <summary>
            Close the enumerator, and the underlying file.
            </summary>
        </member>
        <member name="T:Encog.ML.Data.Buffer.CODEC.ArrayDataCODEC">
            <summary>
            A CODEC used for arrays.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.CODEC.ArrayDataCODEC._ideal">
            <summary>
            The ideal array.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.CODEC.ArrayDataCODEC._idealSize">
            <summary>
            The number of ideal elements.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.CODEC.ArrayDataCODEC._index">
            <summary>
            The current index.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.CODEC.ArrayDataCODEC._input">
            <summary>
            The input array.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.CODEC.ArrayDataCODEC._inputSize">
            <summary>
            The number of input elements.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.ArrayDataCODEC.#ctor(System.Double[][],System.Double[][])">
            <summary>
            Construct an array CODEC. 
            </summary>
            <param name="input">The input array.</param>
            <param name="ideal">The ideal array.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.ArrayDataCODEC.#ctor">
            <summary>
            Default constructor.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Buffer.CODEC.ArrayDataCODEC.Input">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Data.Buffer.CODEC.ArrayDataCODEC.Ideal">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Data.Buffer.CODEC.ArrayDataCODEC.InputSize">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Data.Buffer.CODEC.ArrayDataCODEC.IdealSize">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.ArrayDataCODEC.Read(System.Double[],System.Double[],System.Double@)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.ArrayDataCODEC.Write(System.Double[],System.Double[],System.Double)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.ArrayDataCODEC.PrepareWrite(System.Int32,System.Int32,System.Int32)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.ArrayDataCODEC.PrepareRead">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.ArrayDataCODEC.Close">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Data.Buffer.CODEC.CSVDataCODEC">
            <summary>
            A CODEC used to read/write data from/to a CSV data file. There are two
            constructors provided, one is for reading, the other for writing. Make sure
            you use the correct one for your intended purpose.
            
            This CODEC is typically used with the BinaryDataLoader, to load external data
            into the Encog binary training format.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.CODEC.CSVDataCODEC._file">
            <summary>
            The external CSV file.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.CODEC.CSVDataCODEC._format">
            <summary>
            The CSV format to use.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.CODEC.CSVDataCODEC._headers">
            <summary>
            True, if headers are present in the CSV file.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.CODEC.CSVDataCODEC._idealCount">
            <summary>
            The size of the ideal data.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.CODEC.CSVDataCODEC._inputCount">
            <summary>
            The size of the input data.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.CODEC.CSVDataCODEC._output">
            <summary>
            A file used to output the CSV file.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.CODEC.CSVDataCODEC._readCSV">
            <summary>
            The utility to assist in reading the CSV file.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.CODEC.CSVDataCODEC._significance">
            <summary>
            Should a significance column be expected.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.CSVDataCODEC.#ctor(System.String,Encog.Util.CSV.CSVFormat,System.Boolean,System.Int32,System.Int32,System.Boolean)">
            <summary>
            Create a CODEC to load data from CSV to binary. 
            </summary>
            <param name="file">The CSV file to load.</param>
            <param name="format">The format that the CSV file is in.</param>
            <param name="headers">True, if there are headers.</param>
            <param name="inputCount">The number of input columns.</param>
            <param name="idealCount">The number of ideal columns.</param>
            <param name="significance">Is there a signficance column.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.CSVDataCODEC.#ctor(System.String,Encog.Util.CSV.CSVFormat,System.Boolean)">
            <summary>
            Constructor to create CSV from binary.
            </summary>
            <param name="file">The CSV file to create.</param>
            <param name="format">The format for that CSV file.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.CSVDataCODEC.Read(System.Double[],System.Double[],System.Double@)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.CSVDataCODEC.Write(System.Double[],System.Double[],System.Double)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.CSVDataCODEC.PrepareWrite(System.Int32,System.Int32,System.Int32)">
            <summary>
            Prepare to write to a CSV file. 
            </summary>
            <param name="recordCount">The total record count, that will be written.</param>
            <param name="inputSize">The input size.</param>
            <param name="idealSize">The ideal size.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.CSVDataCODEC.PrepareRead">
            <summary>
            Prepare to read from the CSV file.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Buffer.CODEC.CSVDataCODEC.InputSize">
            <inheritDoc/>
        </member>
        <member name="P:Encog.ML.Data.Buffer.CODEC.CSVDataCODEC.IdealSize">
            <inheritDoc/>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.CSVDataCODEC.Close">
            <inheritDoc/>
        </member>
        <member name="T:Encog.ML.Data.Buffer.CODEC.IDataSetCODEC">
            <summary>
            A CODEC is used to encode and decode data. The DataSetCODEC is designed to
            move data to/from the Encog binary training file format, used by
            BufferedMlDataSet. CODECs are provided for such items as CSV files,
            arrays and many other sources.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Buffer.CODEC.IDataSetCODEC.InputSize">
            <summary>
            The size of the input data.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Buffer.CODEC.IDataSetCODEC.IdealSize">
            <summary>
            The size of the ideal data.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.IDataSetCODEC.Read(System.Double[],System.Double[],System.Double@)">
            <summary>
            Read one record of data from an external source.
            </summary>
            <param name="input">The input data array.</param>
            <param name="ideal">The ideal data array.</param>
            <param name="significance">The signficance. (by reff)</param>
            <returns>True, if there is more data to be read.</returns>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.IDataSetCODEC.Write(System.Double[],System.Double[],System.Double)">
            <summary>
            Write one record of data to an external destination. 
            </summary>
            <param name="input">The input data array.</param>
            <param name="ideal">The ideal data array.</param>
            <returns>True, if there is more data to be read.</returns>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.IDataSetCODEC.PrepareWrite(System.Int32,System.Int32,System.Int32)">
            <summary>
            Prepare to write to an external data destination. 
            </summary>
            <param name="recordCount">The total record count, that will be written.</param>
            <param name="inputSize">The input size.</param>
            <param name="idealSize">The ideal size.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.IDataSetCODEC.PrepareRead">
            <summary>
            Prepare to read from an external data source.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.IDataSetCODEC.Close">
            <summary>
            Close any open files.
            </summary>
        </member>
        <member name="T:Encog.ML.Data.Buffer.CODEC.NeuralDataSetCODEC">
            <summary>
            A CODEC that works with the NeuralDataSet class.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.CODEC.NeuralDataSetCODEC._dataset">
            <summary>
            The dataset.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.CODEC.NeuralDataSetCODEC._enumerator">
            <summary>
            The iterator used to read through the dataset.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.CODEC.NeuralDataSetCODEC._idealSize">
            <summary>
            The number of ideal elements.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.CODEC.NeuralDataSetCODEC._inputSize">
            <summary>
            The number of input elements.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.NeuralDataSetCODEC.#ctor(Encog.ML.Data.IMLDataSet)">
            <summary>
            Construct a CODEC. 
            </summary>
            <param name="dataset">The dataset to use.</param>
        </member>
        <member name="P:Encog.ML.Data.Buffer.CODEC.NeuralDataSetCODEC.InputSize">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Data.Buffer.CODEC.NeuralDataSetCODEC.IdealSize">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.NeuralDataSetCODEC.Read(System.Double[],System.Double[],System.Double@)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.NeuralDataSetCODEC.Write(System.Double[],System.Double[],System.Double)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.NeuralDataSetCODEC.PrepareWrite(System.Int32,System.Int32,System.Int32)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.NeuralDataSetCODEC.PrepareRead">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.NeuralDataSetCODEC.Close">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Data.Buffer.CODEC.SQLCODEC">
            <summary>
            A CODEC designed to work with SQL.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.CODEC.SQLCODEC._connection">
            <summary>
            The database connection.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.CODEC.SQLCODEC._idealSize">
            <summary>
            What is the size of the ideal data?
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.CODEC.SQLCODEC._inputSize">
            <summary>
            What is the size of the input data?
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.CODEC.SQLCODEC._statement">
            <summary>
            The SQL statement being used.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.CODEC.SQLCODEC._results">
            <summary>
            Holds results from the SQL query.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.SQLCODEC.#ctor(System.String,System.Int32,System.Int32,System.String)">
            <summary>
            Create a SQL neural data set.
            </summary>
            <param name="sql">The SQL to execute.</param>
            <param name="inputSize">The size of the input data being read.</param>
            <param name="idealSize">The size of the ideal output data being read.</param>
            <param name="connectString">The connection string.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.SQLCODEC.Read(System.Double[],System.Double[],System.Double@)">
            <summary>
            Read a record.
            </summary>
            <param name="input">The input data.</param>
            <param name="ideal">The ideal data.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.SQLCODEC.Write(System.Double[],System.Double[],System.Double)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.SQLCODEC.PrepareWrite(System.Int32,System.Int32,System.Int32)">
            <summary>
            Prepare to write.
            </summary>
            <param name="recordCount">The record count.</param>
            <param name="inputSize">The input size.</param>
            <param name="idealSize">The ideal size.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.SQLCODEC.PrepareRead">
            <summary>
            Prepare to read.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Buffer.CODEC.SQLCODEC.InputSize">
            <summary>
            The input size.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Buffer.CODEC.SQLCODEC.IdealSize">
            <summary>
            The ideal size.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Buffer.CODEC.SQLCODEC.Close">
            <summary>
            Close the codec.
            </summary>
        </member>
        <member name="T:Encog.ML.Data.Buffer.EncogEGBFile">
            <summary>
            Reads in little endian form.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.EncogEGBFile.DoubleSize">
            <summary>
            The size of a double.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.EncogEGBFile.HeaderSize">
            <summary>
            The size of the file header.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.EncogEGBFile._file">
            <summary>
            The file that we are working with.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.EncogEGBFile._binaryReader">
            <summary>
            The binary reader.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.EncogEGBFile._binaryWriter">
            <summary>
            The binary writer.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.EncogEGBFile._idealCount">
            <summary>
            The number of ideal values per record.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.EncogEGBFile._inputCount">
            <summary>
            The number of input values per record.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.EncogEGBFile._numberOfRecords">
            <summary>
            The number of records int he file.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.EncogEGBFile._recordCount">
            <summary>
            The number of values in a record, this is the input and ideal combined.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.EncogEGBFile._recordSize">
            <summary>
            The size of a record.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.EncogEGBFile._stream">
            <summary>
            The underlying file.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Buffer.EncogEGBFile.#ctor(System.String)">
            <summary>
            Construct an EGB file. 
            </summary>
            <param name="file">The file.</param>
        </member>
        <member name="P:Encog.ML.Data.Buffer.EncogEGBFile.InputCount">
            <summary>
            The input count.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Buffer.EncogEGBFile.IdealCount">
            <summary>
            The ideal count.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Buffer.EncogEGBFile.Stream">
            <summary>
            The stream.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Buffer.EncogEGBFile.RecordCount">
            <summary>
            The record count.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Buffer.EncogEGBFile.RecordSize">
            <summary>
            The record size.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Buffer.EncogEGBFile.NumberOfRecords">
            <summary>
            The number of records.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Buffer.EncogEGBFile.Create(System.Int32,System.Int32)">
            <summary>
            Create a new RGB file. 
            </summary>
            <param name="inputCount">The input count.</param>
            <param name="idealCount">The ideal count.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.EncogEGBFile.Open">
            <summary>
            Open an existing EGB file.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Buffer.EncogEGBFile.Close">
            <summary>
            Close the file.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Buffer.EncogEGBFile.CalculateIndex(System.Int64)">
            <summary>
            Calculate the index for the specified row. 
            </summary>
            <param name="row">The row to calculate for.</param>
            <returns>The index.</returns>
        </member>
        <member name="M:Encog.ML.Data.Buffer.EncogEGBFile.CalculateIndex(System.Int32,System.Int32)">
            <summary>
            Read a row and column. 
            </summary>
            <param name="row">The row, or record, to read.</param>
            <param name="col">The column to read.</param>
            <returns>THe value read.</returns>
        </member>
        <member name="M:Encog.ML.Data.Buffer.EncogEGBFile.SetLocation(System.Int32)">
            <summary>
            Set the current location to the specified row. 
            </summary>
            <param name="row">The row.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.EncogEGBFile.Write(System.Int32,System.Int32,System.Double)">
            <summary>
            Write the specified row and column. 
            </summary>
            <param name="row">The row.</param>
            <param name="col">The column.</param>
            <param name="v">The value.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.EncogEGBFile.Write(System.Int32,System.Double[])">
            <summary>
            Write an array at the specified record.
            </summary>
            <param name="row">The record to write.</param>
            <param name="v">The array to write.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.EncogEGBFile.Write(System.Double[])">
            <summary>
            Write an array. 
            </summary>
            <param name="v">The array to write.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.EncogEGBFile.Write(System.Byte)">
            <summary>
            Write a byte. 
            </summary>
            <param name="b">The byte to write.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.EncogEGBFile.Write(System.Double)">
            <summary>
            Write a double. 
            </summary>
            <param name="d">The double to write.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.EncogEGBFile.Read(System.Int32,System.Int32)">
            <summary>
            Read a row and column. 
            </summary>
            <param name="row">The row to read.</param>
            <param name="col">The column to read.</param>
            <returns>The value read.</returns>
        </member>
        <member name="M:Encog.ML.Data.Buffer.EncogEGBFile.Read(System.Int32,System.Double[])">
            <summary>
            Read a double array at the specified record. 
            </summary>
            <param name="row">The record to read.</param>
            <param name="d">The array to read into.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.EncogEGBFile.Read(System.Double[])">
            <summary>
            Read an array of doubles. 
            </summary>
            <param name="d">The array to read into.</param>
        </member>
        <member name="M:Encog.ML.Data.Buffer.EncogEGBFile.Read">
            <summary>
            Read a single double. 
            </summary>
            <returns>The double read.</returns>
        </member>
        <member name="T:Encog.ML.Data.Buffer.MemoryDataLoader">
            <summary>
            This class is used, together with a CODEC, load training data from some 
            external file into an Encog memory-based training set.  
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Buffer.MemoryDataLoader._codec">
            <summary>
            The CODEC to use.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Buffer.MemoryDataLoader.#ctor(Encog.ML.Data.Buffer.CODEC.IDataSetCODEC)">
            <summary>
            Construct a loader with the specified CODEC. 
            </summary>
            <param name="codec">The codec to use.</param>
        </member>
        <member name="P:Encog.ML.Data.Buffer.MemoryDataLoader.Status">
            <summary>
            Used to report the status.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Buffer.MemoryDataLoader.Result">
            <summary>
            The dataset to load to.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Buffer.MemoryDataLoader.CODEC">
            <summary>
            The CODEC that is being used.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Buffer.MemoryDataLoader.External2Memory">
            <summary>
            Convert an external file format, such as CSV, to an Encog memory training set. 
            </summary>
        </member>
        <member name="T:Encog.ML.Data.Folded.FoldedDataSet">
            <summary>
            A folded data set allows you to "fold" the data into several equal(or nearly
            equal) datasets. You then have the ability to select which fold the dataset
            will process. This is very useful for crossvalidation.
            
            This dataset works off of an underlying dataset. By default there are no
            folds (fold size 1). Call the fold method to create more folds. 
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Folded.FoldedDataSet.AddNotSupported">
            <summary>
            Error message: adds are not supported.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Folded.FoldedDataSet._underlying">
            <summary>
            The underlying dataset.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Folded.FoldedDataSet._currentFold">
            <summary>
            The fold that we are currently on.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Folded.FoldedDataSet._currentFoldOffset">
            <summary>
            The offset to the current fold.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Folded.FoldedDataSet._currentFoldSize">
            <summary>
            The size of the current fold.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Folded.FoldedDataSet._foldSize">
            <summary>
            The size of all folds, except the last fold, the last fold may have a
            different number.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Folded.FoldedDataSet._lastFoldSize">
            <summary>
            The size of the last fold.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Folded.FoldedDataSet._numFolds">
            <summary>
            The total number of folds. Or 0 if the data has not been folded yet.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Folded.FoldedDataSet.#ctor(Encog.ML.Data.IMLDataSet)">
            <summary>
            Create a folded dataset. 
            </summary>
            <param name="underlying">The underlying folded dataset.</param>
        </member>
        <member name="P:Encog.ML.Data.Folded.FoldedDataSet.Owner">
            <summary>
            The owner object(from openAdditional)
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Folded.FoldedDataSet.CurrentFold">
            <summary>
            The current fold.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Folded.FoldedDataSet.CurrentFoldOffset">
            <summary>
            The current fold offset.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Folded.FoldedDataSet.CurrentFoldSize">
            <summary>
            The current fold size.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Folded.FoldedDataSet.NumFolds">
            <summary>
            The number of folds.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Folded.FoldedDataSet.Underlying">
            <summary>
            The underlying dataset.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Folded.FoldedDataSet.Add(Encog.ML.Data.IMLData)">
            <summary>
            Not supported.
            </summary>
            <param name="data1">Not used.</param>
        </member>
        <member name="M:Encog.ML.Data.Folded.FoldedDataSet.Add(Encog.ML.Data.IMLData,Encog.ML.Data.IMLData)">
            <summary>
            Not supported.
            </summary>
            <param name="inputData">Not used.</param>
            <param name="idealData">Not used.</param>
        </member>
        <member name="M:Encog.ML.Data.Folded.FoldedDataSet.Add(Encog.ML.Data.IMLDataPair)">
            <summary>
            Not supported.
            </summary>
            <param name="inputData">Not used.</param>
        </member>
        <member name="M:Encog.ML.Data.Folded.FoldedDataSet.Close">
            <summary>
            Close the dataset.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Folded.FoldedDataSet.IdealSize">
            <summary>
            The ideal size.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Folded.FoldedDataSet.InputSize">
            <summary>
            The input size.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Folded.FoldedDataSet.GetRecord(System.Int32,Encog.ML.Data.IMLDataPair)">
            <summary>
            Get a record.
            </summary>
            <param name="index">The index.</param>
            <param name="pair">The record.</param>
        </member>
        <member name="P:Encog.ML.Data.Folded.FoldedDataSet.Count">
            <summary>
            The record count.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Folded.FoldedDataSet.Supervised">
            <summary>
            True if this is a supervised set.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Folded.FoldedDataSet.OpenAdditional">
            <summary>
            Open an additional dataset.
            </summary>
            <returns>The dataset.</returns>
        </member>
        <member name="M:Encog.ML.Data.Folded.FoldedDataSet.GetEnumerator">
            <summary>
            Get an enumberator.
            </summary>
            <returns>The enumerator.</returns>
        </member>
        <member name="M:Encog.ML.Data.Folded.FoldedDataSet.Fold(System.Int32)">
            <summary>
            Fold the dataset. Must be done before the dataset is used. 
            </summary>
            <param name="numFolds">The number of folds.</param>
        </member>
        <member name="P:Encog.ML.Data.Folded.FoldedDataSet.Item(System.Int32)">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Data.Folded.FoldedEnumerator">
            <summary>
            The enumerator for a folded dataset.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Folded.FoldedEnumerator._owner">
            <summary>
            The owner.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Folded.FoldedEnumerator._currentIndex">
            <summary>
            The current index.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Folded.FoldedEnumerator._currentPair">
            <summary>
            The current data item.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Folded.FoldedEnumerator.#ctor(Encog.ML.Data.Folded.FoldedDataSet)">
            <summary>
            Construct an enumerator.
            </summary>
            <param name="owner">The owner.</param>
        </member>
        <member name="P:Encog.ML.Data.Folded.FoldedEnumerator.Current">
            <summary>
            The current object.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Folded.FoldedEnumerator.Dispose">
            <summary>
            Not supported.
            </summary>
            <exception cref="T:System.NotImplementedException"></exception>
        </member>
        <member name="M:Encog.ML.Data.Folded.FoldedEnumerator.MoveNext">
            <summary>
            Move to the next record.
            </summary>
            <returns>True, if we were able to move to the next record.</returns>
        </member>
        <member name="M:Encog.ML.Data.Folded.FoldedEnumerator.Reset">
            <summary>
            Not implemented.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Folded.FoldedEnumerator.System#Collections#IEnumerator#Current">
            <summary>
            The current object.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Folded.FoldedEnumerator.HasNext">
            <summary>
            Determine if there is a next record.
            </summary>
            <returns>True, if there is a next record.</returns>
        </member>
        <member name="T:Encog.ML.Data.Image.ImageMLData">
            <summary>
            An extension of the BasicMLData class that is designed to hold images for
            input into a neural network. This class should only be used with the
            ImageNeuralDataSet collection.
            
            This class provides the ability to associate images with the elements of a
            dataset. These images will be downsampled to the resolution specified in the
            ImageNeuralData set class that they are added to.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Image.ImageMLData.#ctor(System.Drawing.Bitmap)">
            <summary>
            Construct an object based on an image.
            </summary>
            <param name="image">The image to use.</param>
        </member>
        <member name="P:Encog.ML.Data.Image.ImageMLData.Image">
            <summary>
            The image associated with this class.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Image.ImageMLData.Downsample(Encog.Util.DownSample.IDownSample,System.Boolean,System.Int32,System.Int32,System.Double,System.Double)">
            <summary>
            Downsample, and copy, the image contents into the data of this object.
            Calling this method has no effect on the image, as the same image can be
            downsampled multiple times to different resolutions.
            </summary>
            <param name="downsampler">The downsampler object to use.</param>
            <param name="findBounds">Should the bounds be located and cropped.</param>
            <param name="height">The height to downsample to.</param>
            <param name="width">The width to downsample to.</param>
            <param name="hi">The high value to normalize to.</param>
            <param name="lo">The low value to normalize to.</param>
        </member>
        <member name="M:Encog.ML.Data.Image.ImageMLData.ToString">
            <summary>
            Return a string representation of this object.
            </summary>
            <returns>The string form of this object.</returns>
        </member>
        <member name="T:Encog.ML.Data.Image.ImageMLDataSet">
            <summary>
            Store a collection of images for training with a neural network. This class
            collects and then downsamples images for use with a neural network. This is a
            memory based class, so large datasets can run out of memory.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Image.ImageMLDataSet.MUST_USE_IMAGE">
            <summary>
            Error message to inform the caller that only ImageNeuralData objects can
            be used with this collection.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Image.ImageMLDataSet.downsampler">
            <summary>
            The downsampler to use.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Image.ImageMLDataSet.findBounds">
            <summary>
            Should the bounds be found and cropped.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Image.ImageMLDataSet.hi">
            <summary>
            The high value to normalize to.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Image.ImageMLDataSet.lo">
            <summary>
            The low value to normalize to.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Image.ImageMLDataSet.height">
            <summary>
            The height to downsample to.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Image.ImageMLDataSet.width">
            <summary>
            The width to downsample to.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Image.ImageMLDataSet.#ctor(Encog.Util.DownSample.IDownSample,System.Boolean,System.Double,System.Double)">
            <summary>
            Construct this class with the specified downsampler.
            </summary>
            <param name="downsampler">The downsampler to use.</param>
            <param name="findBounds">Should the bounds be found and clipped.</param>
            <param name="hi">The high value to normalize to.</param>
            <param name="lo">The low value to normalize to.</param>
        </member>
        <member name="P:Encog.ML.Data.Image.ImageMLDataSet.Height">
            <summary>
            The height.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Image.ImageMLDataSet.Width">
            <summary>
            The width.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Image.ImageMLDataSet.Add(Encog.ML.Data.IMLData)">
            <summary>
            Add the specified data, must be an ImageNeuralData class.
            </summary>
            <param name="data">The data The object to add.</param>
        </member>
        <member name="M:Encog.ML.Data.Image.ImageMLDataSet.Add(Encog.ML.Data.IMLData,Encog.ML.Data.IMLData)">
            <summary>
            Add the specified input and ideal object to the collection.
            </summary>
            <param name="inputData">The image to train with.</param>
            <param name="idealData">The expected otuput form this image.</param>
        </member>
        <member name="M:Encog.ML.Data.Image.ImageMLDataSet.Add(Encog.ML.Data.IMLDataPair)">
            <summary>
            Add input and expected output. This is used for supervised training.
            </summary>
            <param name="inputData">The input data to train on.</param>
        </member>
        <member name="M:Encog.ML.Data.Image.ImageMLDataSet.Downsample(System.Int32,System.Int32)">
            <summary>
            Downsample all images and generate training data.
            </summary>
            <param name="height">The height to downsample to.</param>
            <param name="width">The width to downsample to.</param>
        </member>
        <member name="T:Encog.ML.Data.IMLComplexData">
            <summary>
            This class implements a data object that can hold complex numbers.  It 
            implements the interface MLData, so it can be used with nearly any Encog 
            machine learning method.  However, not all Encog machine learning methods 
            are designed to work with complex numbers.  A Encog machine learning method 
            that does not support complex numbers will only be dealing with the 
            real-number portion of the complex number.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.IMLComplexData.ComplexData">
            <summary>
            The complex numbers.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.IMLComplexData.GetComplexData(System.Int32)">
            <summary>
            Get the complex data at the specified index. 
            </summary>
            <param name="index">The index to get the complex data at.</param>
            <returns>The complex data.</returns>
        </member>
        <member name="M:Encog.ML.Data.IMLComplexData.SetComplexData(Encog.MathUtil.ComplexNumber[])">
            <summary>
            Set the complex number array.
            </summary>
            <param name="theData">The new array.</param>
        </member>
        <member name="M:Encog.ML.Data.IMLComplexData.SetComplexData(System.Int32,Encog.MathUtil.ComplexNumber)">
            <summary>
            Set a data element to a complex number.
            </summary>
            <param name="index">The index to set.</param>
            <param name="d">The complex number.</param>
        </member>
        <member name="T:Encog.ML.Data.IMLData">
            <summary>
            Neural data, basically an array of values.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.IMLData.Item(System.Int32)">
            <summary>
            Get or set the specified index.
            </summary>
            <param name="x">The index to access.</param>
            <returns></returns>
        </member>
        <member name="P:Encog.ML.Data.IMLData.Data">
            <summary>
            Allowes indexed access to the data.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.IMLData.Count">
            <summary>
            How many elements in this data structure.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.IMLData.Clear">
            <summary>
            Clear the data to zero values.
            </summary>
        </member>
        <member name="T:Encog.ML.Data.IMLDataError">
            <summary>
            The base Encog neural data error.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.IMLDataError.#ctor(System.String)">
            <summary>
            Construct a message exception.
            </summary>
            <param name="str">The message.</param>
        </member>
        <member name="M:Encog.ML.Data.IMLDataError.#ctor(System.Exception)">
            <summary>
            Pass on an exception.
            </summary>
            <param name="e">The other exception.</param>
        </member>
        <member name="T:Encog.ML.Data.IMLDataPair">
            <summary>
            A neural data pair holds both the input and ideal data.  If this
            is an unsupervised data element, then only input is provided.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.IMLDataPair.Input">
            <summary>
            The input that the neural network.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.IMLDataPair.Ideal">
            <summary>
            The ideal data that the neural network should produce
            for the specified input.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.IMLDataPair.Supervised">
            <summary>
            True if this training pair is supervised.  That is, it has 
            both input and ideal data.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.IMLDataPair.IdealArray">
            <summary>
            The supervised ideal data.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.IMLDataPair.InputArray">
            <summary>
            The input array.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.IMLDataPair.Significance">
            <summary>
            The significance of this training element.
            </summary>
        </member>
        <member name="T:Encog.ML.Data.IMLDataSet">
            <summary>
            An interface designed to abstract classes that store neural data. This
            interface is designed to provide NeuralDataPair objects. This can be used to
            train neural networks using both supervised and unsupervised training.
            
            Some implementations of this interface are memory based. That is they store
            the entire contents of the dataset in memory.
            
            Other implementations of this interface are not memory based. These
            implementations read in data as it is needed. This allows very large datasets
            to be used. Typically the add methods are not supported on non-memory based
            datasets.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.IMLDataSet.IdealSize">
            <summary>
            The size of the ideal data, 0 if no ideal data.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.IMLDataSet.InputSize">
            <summary>
            The size of the input data.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.IMLDataSet.Count">
            <summary>
            The number of records in the data set.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.IMLDataSet.Supervised">
            <summary>
            Return true if supervised.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.IMLDataSet.Add(Encog.ML.Data.IMLData)">
            <summary>
            Add a NeuralData object to the dataset. This is used with unsupervised
            training, as no ideal output is provided. Note: not all implemenations
            support the add methods. 
            </summary>
            <param name="data1">The data to add.</param>
        </member>
        <member name="M:Encog.ML.Data.IMLDataSet.Add(Encog.ML.Data.IMLData,Encog.ML.Data.IMLData)">
            <summary>
            Add a set of input and ideal data to the dataset. This is used with
            supervised training, as ideal output is provided. Note: not all
            implementations support the add methods.
            </summary>
            <param name="inputData">Input data.</param>
            <param name="idealData">Ideal data.</param>
        </member>
        <member name="M:Encog.ML.Data.IMLDataSet.Add(Encog.ML.Data.IMLDataPair)">
            <summary>
            Add a NeuralData object to the dataset. This is used with unsupervised
            training, as no ideal output is provided. Note: not all implementations
            support the add methods. 
            </summary>
            <param name="inputData">A NeuralDataPair object that contains both input and ideal
            data.</param>
        </member>
        <member name="M:Encog.ML.Data.IMLDataSet.Close">
            <summary>
            Close this datasource and release any resources obtained by it, including
            any iterators created. 
            </summary>
        </member>
        <member name="M:Encog.ML.Data.IMLDataSet.GetEnumerator">
            <summary>
            Get an enumerator to access the data.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Encog.ML.Data.IMLDataSet.GetRecord(System.Int32,Encog.ML.Data.IMLDataPair)">
            <summary>
            Get one record from the data set.
            </summary>
            <param name="index">The index to read.</param>
            <param name="pair">The pair to read into.</param>
        </member>
        <member name="M:Encog.ML.Data.IMLDataSet.OpenAdditional">
            <summary>
            Open an additional instance of this dataset.
            </summary>
            <returns>The new instance of this dataset.</returns>
        </member>
        <member name="P:Encog.ML.Data.IMLDataSet.Item(System.Int32)">
            <summary>
            Get the specified record.
            </summary>
            <param name="x">The index to access.</param>
            <returns></returns>
        </member>
        <member name="T:Encog.ML.Data.IMLSequenceSet">
            <summary>
            A sequence set is a collection of data sets. Where each individual data set
            is one "unbroken sequence" within the sequence set. This allows individual
            observations to occur individually, indicating a break between them.
            
            The sequence set, itself, is a data set, so it can be used with any Encog
            trainer. However, not all trainers are aware of sequence sets. Further, some
            machine learning methods are unaffected by them. Sequence sets are typically
            used with Hidden Markov Models (HMM)'s.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.IMLSequenceSet.StartNewSequence">
            <summary>
            Cause a "break" in the data by creating a the beginning of a new sequence.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.IMLSequenceSet.SequenceCount">
            <summary>
            Get a count of the number of sequences.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.IMLSequenceSet.GetSequence(System.Int32)">
            <summary>
            Get an individual sequence. 
            </summary>
            <param name="i">The index to get.</param>
            <returns>The sequence.</returns>
        </member>
        <member name="P:Encog.ML.Data.IMLSequenceSet.Sequences">
            <summary>
            A list of all of the sequences.
            </summary>
            <returns>The index of the sequence.</returns>
        </member>
        <member name="M:Encog.ML.Data.IMLSequenceSet.Add(Encog.ML.Data.IMLDataSet)">
            <summary>
            Add a new sequence. 
            </summary>
            <param name="sequence">The sequence to add.</param>
        </member>
        <member name="T:Encog.ML.Data.Market.Loader.CSVFinal">
            <summary>
            Use this class to loads CSVs and places them in a MarketDataset.
            You must call GetFile to point to the CSV you want to use.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Market.Loader.CSVFinal.ReadAndCallLoader(Encog.ML.Data.Market.TickerSymbol,System.Collections.Generic.IEnumerable{Encog.ML.Data.Market.MarketDataType},System.DateTime,System.DateTime,System.String)">
            <summary>
            Reads the CSV and call loader.
            Used internally to load the csv and place data in the marketdataset.
            </summary>
            <param name="symbol">The symbol.</param>
            <param name="neededTypes">The needed types.</param>
            <param name="from">From.</param>
            <param name="to">To.</param>
            <param name="File">The file.</param>
            <returns></returns>
        </member>
        <member name="P:Encog.ML.Data.Market.Loader.CSVFinal.DateFormat">
            <summary>
            Gets or sets the date format for the whole csv file.
            </summary>
            <value>
            The date format.
            </value>
        </member>
        <member name="M:Encog.ML.Data.Market.Loader.CSVFinal.SetDateFormat(System.String)">
            <summary>
            Sets the date format for the csv file.
            </summary>
            <param name="stringFormat">The string format.</param>
        </member>
        <member name="M:Encog.ML.Data.Market.Loader.CSVFinal.GetFile(System.String)">
            <summary>
            Gets the file we want to parse.
            </summary>
            <param name="file">The file.</param>
            <returns></returns>
        </member>
        <member name="F:Encog.ML.Data.Market.Loader.CSVFormLoader.components">
            <summary>
            Required designer variable.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Market.Loader.CSVFormLoader.Dispose(System.Boolean)">
            <summary>
            Clean up any resources being used.
            </summary>
            <param name="disposing">true if managed resources should be disposed; otherwise, false.</param>
        </member>
        <member name="M:Encog.ML.Data.Market.Loader.CSVFormLoader.InitializeComponent">
            <summary>
            Required method for Designer support - do not modify
            the contents of this method with the code editor.
            </summary>
        </member>
        <member name="T:Encog.ML.Data.Market.Loader.CSVLoader">
            <summary>
            CSVLoader class.
            This class is used to load CSV's into a 
            </summary>
        </member>
        <member name="T:Encog.ML.Data.Market.Loader.IMarketLoader">
            <summary>
            A market loader for financial information.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Market.Loader.IMarketLoader.Load(Encog.ML.Data.Market.TickerSymbol,System.Collections.Generic.IList{Encog.ML.Data.Market.MarketDataType},System.DateTime,System.DateTime)">
            <summary>
            Load the specified ticker symbol for the specified date.
            </summary>
            <param name="ticker">The ticker symbol to load.</param>
            <param name="dataNeeded">Which data is actually needed.</param>
            <param name="from">Beginning date for load.</param>
            <param name="to">Ending date for load.</param>
            <returns>A collection of LoadedMarketData objects that was loaded.</returns>
        </member>
        <member name="M:Encog.ML.Data.Market.Loader.IMarketLoader.GetFile(System.String)">
            <summary>
            Gets the file we want to parse.
            </summary>
            <param name="file">The file.</param>
            <returns></returns>
        </member>
        <member name="T:Encog.ML.Data.Market.Loader.LoadedMarketData">
            <summary>
            Market data loaded from a source.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.Loader.LoadedMarketData._data">
            <summary>
            The data that was collection for the sample date.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.Loader.LoadedMarketData._ticker">
            <summary>
            What is the ticker symbol for this data sample.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Market.Loader.LoadedMarketData.#ctor(System.DateTime,Encog.ML.Data.Market.TickerSymbol)">
            <summary>
            Construct one sample of market data.
            </summary>
            <param name="when">When was this sample taken.</param>
            <param name="ticker">What is the ticker symbol for this data.</param>
        </member>
        <member name="P:Encog.ML.Data.Market.Loader.LoadedMarketData.When">
            <summary>
            When is this data from.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Market.Loader.LoadedMarketData.Ticker">
            <summary>
            The ticker symbol that this data was from.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Market.Loader.LoadedMarketData.Data">
            <summary>
            The data that was downloaded.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Market.Loader.LoadedMarketData.CompareTo(Encog.ML.Data.Market.Loader.LoadedMarketData)">
            <summary>
            Compare this object with another of the same type.
            </summary>
            <param name="other">The other object to compare.</param>
            <returns>Zero if equal, greater or less than zero to indicate order.</returns>
        </member>
        <member name="M:Encog.ML.Data.Market.Loader.LoadedMarketData.SetData(Encog.ML.Data.Market.MarketDataType,System.Double)">
            <summary>
            Set the specified type of data.
            </summary>
            <param name="t">The type of data to set.</param>
            <param name="d">The value to set.</param>
        </member>
        <member name="M:Encog.ML.Data.Market.Loader.LoadedMarketData.GetData(Encog.ML.Data.Market.MarketDataType)">
            <summary>
            Get the specified data type.
            </summary>
            <param name="t">The type of data to get.</param>
            <returns>The value.</returns>
        </member>
        <member name="T:Encog.ML.Data.Market.Loader.LoaderError">
            <summary>
            The base error for when market data is loaded.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Market.Loader.LoaderError.#ctor(System.String)">
            <summary>
            Construct a message exception.
            </summary>
            <param name="str">The message.</param>
        </member>
        <member name="M:Encog.ML.Data.Market.Loader.LoaderError.#ctor(System.Exception)">
            <summary>
            Pass on an exception.
            </summary>
            <param name="e">The other exception.</param>
        </member>
        <member name="T:Encog.ML.Data.Market.Loader.YahooFinanceLoader">
            <summary>
            This class loads financial data from Yahoo.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Market.Loader.YahooFinanceLoader.Load(Encog.ML.Data.Market.TickerSymbol,System.Collections.Generic.IList{Encog.ML.Data.Market.MarketDataType},System.DateTime,System.DateTime)">
            <summary>
            Load the specified financial data. 
            </summary>
            <param name="ticker">The ticker symbol to load.</param>
            <param name="dataNeeded">The financial data needed.</param>
            <param name="from">The beginning date to load data from.</param>
            <param name="to">The ending date to load data to.</param>
            <returns>A collection of LoadedMarketData objects that represent the data
            loaded.</returns>
        </member>
        <member name="M:Encog.ML.Data.Market.Loader.YahooFinanceLoader.BuildURL(Encog.ML.Data.Market.TickerSymbol,System.DateTime,System.DateTime)">
            <summary>
            This method builds a URL to load data from Yahoo Finance for a neural
            network to train with.
            </summary>
            <param name="ticker">The ticker symbol to access.</param>
            <param name="from">The beginning date.</param>
            <param name="to">The ending date.</param>
            <returns>The URL to read from</returns>
        </member>
        <member name="T:Encog.ML.Data.Market.MarketDataDescription">
            <summary>
            This class is used to describe the type of financial data that is needed.
            Each piece of data can be used for input, prediction or both. If used for
            input, it will be used as data to help predict. If used for prediction, it
            will be one of the values predicted. It is possible, and quite common, to use
            data from both input and prediction.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.MarketDataDescription._dataType">
            <summary>
            The type of data to be loaded from the specified ticker symbol.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.MarketDataDescription._ticker">
            <summary>
            The ticker symbol to be loaded.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Market.MarketDataDescription.#ctor(Encog.ML.Data.Market.TickerSymbol,Encog.ML.Data.Market.MarketDataType,Encog.ML.Data.Temporal.TemporalDataDescription.Type,Encog.Engine.Network.Activation.IActivationFunction,System.Boolean,System.Boolean)">
            <summary>
            Construct a MarketDataDescription item.
            </summary>
            <param name="ticker">The ticker symbol to use.</param>
            <param name="dataType">The data type needed.</param>
            <param name="type">The normalization type.</param>
            <param name="activationFunction"> The activation function to apply to this data, can be null.</param>
            <param name="input">Is this field used for input?</param>
            <param name="predict">Is this field used for prediction?</param>
        </member>
        <member name="M:Encog.ML.Data.Market.MarketDataDescription.#ctor(Encog.ML.Data.Market.TickerSymbol,Encog.ML.Data.Market.MarketDataType,Encog.ML.Data.Temporal.TemporalDataDescription.Type,System.Boolean,System.Boolean)">
            <summary>
            Construct a MarketDataDescription item.
            </summary>
            <param name="ticker">The ticker symbol to use.</param>
            <param name="dataType">The data type needed.</param>
            <param name="type">The normalization type.</param>
            <param name="input">Is this field used for input?</param>
            <param name="predict">Is this field used for prediction?</param>
        </member>
        <member name="M:Encog.ML.Data.Market.MarketDataDescription.#ctor(Encog.ML.Data.Market.TickerSymbol,Encog.ML.Data.Market.MarketDataType,System.Boolean,System.Boolean)">
            <summary>
            Construct a MarketDataDescription item.
            </summary>
            <param name="ticker">The ticker symbol to use.</param>
            <param name="dataType">The data type needed.</param>
            <param name="input">Is this field used for input?</param>
            <param name="predict">Is this field used for prediction?</param>
        </member>
        <member name="P:Encog.ML.Data.Market.MarketDataDescription.Ticker">
            <summary>
            The ticker symbol.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Market.MarketDataDescription.DataType">
            <summary>
            The data type that this is.
            </summary>
        </member>
        <member name="T:Encog.ML.Data.Market.MarketDataType">
            <summary>
            The types of market data that can be used.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.MarketDataType.Open">
            <summary>
            The market open for the day.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.MarketDataType.Close">
            <summary>
            The market close for the day.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.MarketDataType.Volume">
            <summary>
            The volume for the day.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.MarketDataType.AdjustedClose">
            <summary>
            The adjusted close.  Adjusted for splits and dividends.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.MarketDataType.High">
            <summary>
            The high for the day.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.MarketDataType.Low">
            <summary>
            The low for the day.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.MarketDataType.Trade">
            <summary>
            A trade (Tick data).
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.MarketDataType.Quote">
            <summary>
            A quote (bid /ask)
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.MarketDataType.Bid">
            <summary>
            The bid from a quote
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.MarketDataType.Ask">
            <summary>
            The ask price from a quote
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.MarketDataType.BidSize">
            <summary>
            the bid volume from a quote.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.MarketDataType.AskSize">
            <summary>
            the ask size from a quote.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.MarketDataType.RangeOpenClose">
            <summary>
            Range from Open to Close (Absolute).
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.MarketDataType.RangeHighLow">
            <summary>
            Rangr from High to Low.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.MarketDataType.RangeOpenCloseNonAbsolute">
            <summary>
            Range Open to Close not using absolute numbers (No Math.Abs(Open - Close)) , this gives a directional range.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.MarketDataType.PercentageMove">
            <summary>
            Percentage moves from one bar to the next.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.MarketDataType.Weighted">
            <summary>
            The weighted prices. ( High + Low + 2 * Close) /4.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.MarketDataType.Median">
            <summary>
            The median of closing prices (high + low) /2
            </summary>
        </member>
        <member name="T:Encog.ML.Data.Market.MarketError">
            <summary>
            The base error for the market data set.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Market.MarketError.#ctor(System.String)">
            <summary>
            Construct a message exception.
            </summary>
            <param name="str">The message.</param>
        </member>
        <member name="M:Encog.ML.Data.Market.MarketError.#ctor(System.Exception)">
            <summary>
            Pass on an exception.
            </summary>
            <param name="e">The other exception.</param>
        </member>
        <member name="T:Encog.ML.Data.Market.MarketMLDataSet">
            <summary>
            A data set that is designed to hold market data. This class is based on the
            TemporalNeuralDataSet.  This class is designed to load financial data from
            external sources.  This class is designed to track financial data across days.
            However, it should be usable with other levels of granularity as well. 
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.MarketMLDataSet._loader">
            <summary>
            The loader to use to obtain the data.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.MarketMLDataSet._pointIndex">
            <summary>
            A map between the data points and actual data.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Market.MarketMLDataSet.#ctor(Encog.ML.Data.Market.Loader.IMarketLoader,System.Int64,System.Int64)">
            <summary>
            Construct a market data set object.
            </summary>
            <param name="loader">The loader to use to get the financial data.</param>
            <param name="inputWindowSize">The input window size, that is how many datapoints do we use to predict.</param>
            <param name="predictWindowSize">How many datapoints do we want to predict.</param>
        </member>
        <member name="M:Encog.ML.Data.Market.MarketMLDataSet.#ctor(Encog.ML.Data.Market.Loader.IMarketLoader,System.Int64,System.Int64,Encog.Util.Time.TimeUnit)">
            <summary>
            Initializes a new instance of the <see cref="T:Encog.ML.Data.Market.MarketMLDataSet"/> class.
            </summary>
            <param name="loader">The loader.</param>
            <param name="inputWindowSize">Size of the input window.</param>
            <param name="predictWindowSize">Size of the predict window.</param>
            <param name="unit">The time unit to use.</param>
        </member>
        <member name="P:Encog.ML.Data.Market.MarketMLDataSet.Loader">
            <summary>
            The loader that is being used for this set.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Market.MarketMLDataSet.AddDescription(Encog.ML.Data.Temporal.TemporalDataDescription)">
            <summary>
            Add one description of the type of market data that we are seeking at
            each datapoint.
            </summary>
            <param name="desc"></param>
        </member>
        <member name="M:Encog.ML.Data.Market.MarketMLDataSet.CreatePoint(System.DateTime)">
            <summary>
            Create a datapoint at the specified date.
            </summary>
            <param name="when">The date to create the point at.</param>
            <returns>Returns the TemporalPoint created for the specified date.</returns>
        </member>
        <member name="M:Encog.ML.Data.Market.MarketMLDataSet.Load(System.DateTime,System.DateTime)">
            <summary>
            Load data from the loader.
            </summary>
            <param name="begin">The beginning date.</param>
            <param name="end">The ending date.</param>
        </member>
        <member name="M:Encog.ML.Data.Market.MarketMLDataSet.LoadPointFromMarketData(Encog.ML.Data.Market.TickerSymbol,Encog.ML.Data.Temporal.TemporalPoint,Encog.ML.Data.Market.Loader.LoadedMarketData)">
            <summary>
            Load one point of market data.
            </summary>
            <param name="ticker">The ticker symbol to load.</param>
            <param name="point">The point to load at.</param>
            <param name="item">The item being loaded.</param>
        </member>
        <member name="M:Encog.ML.Data.Market.MarketMLDataSet.LoadSymbol(Encog.ML.Data.Market.TickerSymbol,System.DateTime,System.DateTime)">
            <summary>
            Load one ticker symbol.
            </summary>
            <param name="ticker">The ticker symbol to load.</param>
            <param name="from">Load data from this date.</param>
            <param name="to">Load data to this date.</param>
        </member>
        <member name="T:Encog.ML.Data.Market.MarketPoint">
            <summary>
            Hold one market datapoint.  This class is based on the TemporalPoint,
            however it is designed to take its sequence number from a date.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.MarketPoint._when">
            <summary>
            When to hold the data from.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Market.MarketPoint.#ctor(System.DateTime,System.Int32)">
            <summary>
            Construct a MarketPoint with the specified date and size.
            </summary>
            <param name="when">When is this data from.</param>
            <param name="size">What is the size of the data.</param>
        </member>
        <member name="P:Encog.ML.Data.Market.MarketPoint.When">
            <summary>
            When is this point from.
            </summary>
        </member>
        <member name="T:Encog.ML.Data.Market.TickerSymbol">
            <summary>
            A ticker symbol.  Holds the exchange and the symbol.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.TickerSymbol._exchange">
            <summary>
            The exchange.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Market.TickerSymbol._symbol">
            <summary>
            The ticker symbol.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Market.TickerSymbol.#ctor(System.String)">
            <summary>
            Construct a ticker symbol with no exchange.
            </summary>
            <param name="symbol">The ticker symbol</param>
        </member>
        <member name="M:Encog.ML.Data.Market.TickerSymbol.#ctor(System.String,System.String)">
            <summary>
            Construct a ticker symbol with exchange.
            </summary>
            <param name="symbol">The ticker symbol.</param>
            <param name="exchange">The exchange.</param>
        </member>
        <member name="P:Encog.ML.Data.Market.TickerSymbol.Symbol">
            <summary>
            The stock symbol.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Market.TickerSymbol.Exchange">
            <summary>
            The exchange that this stock is on.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Market.TickerSymbol.Equals(Encog.ML.Data.Market.TickerSymbol)">
            <summary>
            Determine if two ticker symbols equal each other.
            </summary>
            <param name="other">The other ticker symbol.</param>
            <returns>True if the two symbols equal.</returns>
        </member>
        <member name="T:Encog.ML.Data.MLDataError">
            <summary>
            Indicates an error has occurred in the data.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.MLDataError.#ctor(System.String)">
            <summary>
            Construct a message exception.
            </summary>
            <param name="str">The message.</param>
        </member>
        <member name="M:Encog.ML.Data.MLDataError.#ctor(System.Exception)">
            <summary>
            Pass on an exception.
            </summary>
            <param name="e">The other exception.</param>
        </member>
        <member name="M:Encog.ML.Data.MLDataError.#ctor(System.String,System.Exception)">
            <summary>
            Pass on an exception.
            </summary>
            <param name="msg">The message.</param>
            <param name="e">The exception.</param>
        </member>
        <member name="T:Encog.ML.Data.Specific.BiPolarMLData">
            <summary>
            A NeuralData implementation designed to work with bipolar data.
            Bipolar data contains two values.  True is stored as 1, and false
            is stored as -1.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Specific.BiPolarMLData._data">
            <summary>
            The data held by this object.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Specific.BiPolarMLData.#ctor(System.Boolean[])">
            <summary>
            Construct this object with the specified data. 
            </summary>
            <param name="d">The data to create this object with.</param>
        </member>
        <member name="M:Encog.ML.Data.Specific.BiPolarMLData.#ctor(System.Int32)">
            <summary>
            Construct a data object with the specified size.
            </summary>
            <param name="size">The size of this data object.</param>
        </member>
        <member name="P:Encog.ML.Data.Specific.BiPolarMLData.Item(System.Int32)">
            <summary>
            Allowes indexed access to the data.
            </summary>
            <param name="x">The index.</param>
            <returns>The value at the specified index.</returns>
        </member>
        <member name="P:Encog.ML.Data.Specific.BiPolarMLData.Data">
            <summary>
            Get the data as an array.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Specific.BiPolarMLData.Count">
            <summary>
            The size of the array.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Specific.BiPolarMLData.GetBoolean(System.Int32)">
            <summary>
            Get the specified data item as a boolean.
            </summary>
            <param name="i"></param>
            <returns></returns>
        </member>
        <member name="M:Encog.ML.Data.Specific.BiPolarMLData.Clone">
            <summary>
            Clone this object.
            </summary>
            <returns>A clone of this object.</returns>
        </member>
        <member name="M:Encog.ML.Data.Specific.BiPolarMLData.SetBoolean(System.Int32,System.Boolean)">
            <summary>
            Set the value as a boolean.
            </summary>
            <param name="index">The index.</param>
            <param name="b">The boolean value.</param>
        </member>
        <member name="M:Encog.ML.Data.Specific.BiPolarMLData.Clear">
            <summary>
            Clear to false.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Specific.BiPolarMLData.ToString">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Data.Specific.BiPolarMLData.CreateCentroid">
            <summary>
            Not supported.
            </summary>
            <returns>Nothing.</returns>
        </member>
        <member name="T:Encog.ML.Data.Specific.CSVMLDataSet">
            <summary>
            An implementation of the MLDataSet interface designed to provide a CSV
            file to the neural network. This implementation uses the BasicMLData to
            hold the data being read. This class has no ability to write CSV files.
            The columns of the CSV file will specify both the input and ideal 
            columns.  
            
            This class is not memory based, so very long files can be used, 
            without running out of memory.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Specific.CSVMLDataSet._filename">
            <summary>
            The CSV filename to read from.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Specific.CSVMLDataSet._format">
            <summary>
            The format that separates the columns, defaults to a comma.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Specific.CSVMLDataSet._headers">
            <summary>
            Specifies if headers are present on the first row.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Specific.CSVMLDataSet._idealSize">
            <summary>
            The number of columns of ideal data.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Specific.CSVMLDataSet._inputSize">
            <summary>
            The number of columns of input data.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Specific.CSVMLDataSet.#ctor(System.String,System.Int32,System.Int32,System.Boolean)">
            <summary>
            Construct this data set using a comma as a delimiter.
            </summary>
            <param name="filename">The CSV filename to read.</param>
            <param name="inputSize">The number of columns that make up the input set.</param>
            <param name="idealSize">The number of columns that make up the ideal set.</param>
            <param name="headers">True if headers are present on the first line.</param>
        </member>
        <member name="M:Encog.ML.Data.Specific.CSVMLDataSet.#ctor(System.String,System.Int32,System.Int32,System.Boolean,Encog.Util.CSV.CSVFormat,System.Boolean)">
            <summary>
            Construct this data set using a comma as a delimiter.
            </summary>
            <param name="filename">The CSV filename to read.</param>
            <param name="inputSize">The number of columns that make up the input set.</param>
            <param name="idealSize">The number of columns that make up the ideal set.</param>
            <param name="headers">True if headers are present on the first line.</param>
            <param name="format">The format to use.</param>
        </member>
        <member name="P:Encog.ML.Data.Specific.CSVMLDataSet.Filename">
            <summary>
            Get the filename for the CSV file.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Specific.CSVMLDataSet.Format">
            <summary>
            The delimiter.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Specific.CSVMLDataSet.Headers">
            <summary>
            True if the first row specifies field names.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Specific.CSVMLDataSet.IdealSize">
            <summary>
            The amount of ideal data.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Specific.CSVMLDataSet.InputSize">
            <summary>
            The amount of input data.
            </summary>
        </member>
        <member name="T:Encog.ML.Data.Specific.SQLMLDataSet">
            <summary>
            A dataset based on a SQL query. This is not a memory based dataset, so it can
            handle very large datasets without a memory issue. and can handle very large
            datasets.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Specific.SQLMLDataSet.#ctor(System.String,System.Int32,System.Int32,System.String)">
            <summary>
            Create a SQL neural data set.
            </summary>
            <param name="sql">The SQL to execute.</param>
            <param name="inputSize">The size of the input data being read.</param>
            <param name="idealSize">The size of the ideal output data being read.</param>
            <param name="connectString">The connection string.</param>
        </member>
        <member name="T:Encog.ML.Data.Temporal.TemporalDataDescription">
            <summary>
            This class describes one unit of input, or output, to a temporal neural
            network. Data can be both an input and output. Inputs are used to attempt
            predict the output.
            </summary>
        </member>
        <member name="T:Encog.ML.Data.Temporal.TemporalDataDescription.Type">
            <summary>
            The type of data requested.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Temporal.TemporalDataDescription.Type.Raw">
            <summary>
            Data in its raw, unmodified form.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Temporal.TemporalDataDescription.Type.PercentChange">
            <summary>
            The percent change.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Temporal.TemporalDataDescription.Type.DeltaChange">
            <summary>
            The difference change.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Temporal.TemporalDataDescription._activationFunction">
            <summary>
            Should an activation function be used?
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Temporal.TemporalDataDescription._type">
            <summary>
            What type of data is requested?
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalDataDescription.#ctor(Encog.Engine.Network.Activation.IActivationFunction,System.Double,System.Double,Encog.ML.Data.Temporal.TemporalDataDescription.Type,System.Boolean,System.Boolean)">
            <summary>
            Construct a data description item. Set both low and high to zero for
            unbounded.
            </summary>
            <param name="activationFunction">What activation function should be used?</param>
            <param name="low">What is the lowest allowed value.</param>
            <param name="high">What is the highest allowed value.</param>
            <param name="type">What type of data is this.</param>
            <param name="input">Used for input?</param>
            <param name="predict">Used for prediction?</param>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalDataDescription.#ctor(Encog.Engine.Network.Activation.IActivationFunction,Encog.ML.Data.Temporal.TemporalDataDescription.Type,System.Boolean,System.Boolean)">
            <summary>
            Construct a data description with an activation function, but no range.
            </summary>
            <param name="activationFunction">The activation function.</param>
            <param name="type">The type of data.</param>
            <param name="input">Used for input?</param>
            <param name="predict">Used for prediction?</param>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalDataDescription.#ctor(Encog.ML.Data.Temporal.TemporalDataDescription.Type,System.Boolean,System.Boolean)">
            <summary>
            Construct a data description with no activation function or range.
            </summary>
            <param name="type">The type of data.</param>
            <param name="input">Used for input?</param>
            <param name="predict">Used for prediction?</param>
        </member>
        <member name="P:Encog.ML.Data.Temporal.TemporalDataDescription.Low">
            <summary>
            The lowest allowed data.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Temporal.TemporalDataDescription.High">
            <summary>
            The highest allowed value.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Temporal.TemporalDataDescription.IsInput">
            <summary>
            Is this data input?  Or is it to be predicted.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Temporal.TemporalDataDescription.IsPredict">
            <summary>
            Determine if this is a predicted value.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Temporal.TemporalDataDescription.Index">
            <summary>
            Get the index.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Temporal.TemporalDataDescription.DescriptionType">
            <summary>
            The type of data this is.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Temporal.TemporalDataDescription.ActivationFunction">
            <summary>
            The activation function for this layer.
            </summary>
        </member>
        <member name="T:Encog.ML.Data.Temporal.TemporalError">
            <summary>
            An error occured related to the temporal data set.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalError.#ctor(System.String)">
            <summary>
            Construct a message exception.
            </summary>
            <param name="str">The message.</param>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalError.#ctor(System.Exception)">
            <summary>
            Pass on an exception.
            </summary>
            <param name="e">The other exception.</param>
        </member>
        <member name="T:Encog.ML.Data.Temporal.TemporalMLDataSet">
            <summary>
            This class implements a temporal neural data set. A temporal neural dataset
            is designed to use a neural network to predict.
            
            A temporal dataset is a stream of data over a time range. This time range is
            broken up into "points". Each point can contain one or more values. These
            values are either the values that you would like to predict, or use to
            predict. It is possible for a value to be both predicted and used to predict.
            For example, if you were trying to predict a trend in a stock's price
            fluctuations you might very well use the security price for both.
            
            Each point that we have data for is stored in the TemporalPoint class. Each
            TemporalPoint will contain one more data values. These data values are
            described by the TemporalDataDescription class. For example, if you had five
            TemporalDataDescription objects added to this class, each Temporal point
            object would contain five values.
            
            Points are arranged by sequence number.  No two points can have the same 
            sequence numbers.  Methods are provided to allow you to add points using the
            Date class.  These dates are resolved to sequence number using the level
            of granularity specified for this class.  No two points can occupy the same
            granularity increment.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Temporal.TemporalMLDataSet.AddNotSupported">
            <summary>
            Error message: adds are not supported.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Temporal.TemporalMLDataSet._descriptions">
            <summary>
            Descriptions of the data needed.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Temporal.TemporalMLDataSet._points">
            <summary>
            The temporal points at which we have data.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Temporal.TemporalMLDataSet._desiredSetSize">
            <summary>
            How big would we like the input size to be.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Temporal.TemporalMLDataSet._highSequence">
            <summary>
            The highest sequence.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Temporal.TemporalMLDataSet._inputNeuronCount">
            <summary>
            How many input neurons will be used.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Temporal.TemporalMLDataSet._inputWindowSize">
            <summary>
            The size of the input window, this is the data being used to predict.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Temporal.TemporalMLDataSet._lowSequence">
            <summary>
            The lowest sequence.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Temporal.TemporalMLDataSet._outputNeuronCount">
            <summary>
            How many output neurons will there be.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Temporal.TemporalMLDataSet._predictWindowSize">
            <summary>
            The size of the prediction window.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Temporal.TemporalMLDataSet._sequenceGrandularity">
            <summary>
            What is the granularity of the temporal points? Days, months, years,
            etc?
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Temporal.TemporalMLDataSet._startingPoint">
            <summary>
            What is the date for the first temporal point.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalMLDataSet.#ctor(System.Int32,System.Int32)">
            <summary>
            Construct a dataset.
            </summary>
            <param name="inputWindowSize">What is the input window size.</param>
            <param name="predictWindowSize">What is the prediction window size.</param>
        </member>
        <member name="P:Encog.ML.Data.Temporal.TemporalMLDataSet.Descriptions">
            <summary>
            The data descriptions.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Temporal.TemporalMLDataSet.Points">
            <summary>
            The points, or time slices to take data from.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Temporal.TemporalMLDataSet.InputWindowSize">
            <summary>
            Get the size of the input window.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Temporal.TemporalMLDataSet.PredictWindowSize">
            <summary>
            The prediction window size.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Temporal.TemporalMLDataSet.LowSequence">
            <summary>
            The low value for the sequence.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Temporal.TemporalMLDataSet.HighSequence">
            <summary>
            The high value for the sequence.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Temporal.TemporalMLDataSet.DesiredSetSize">
            <summary>
            The desired dataset size.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Temporal.TemporalMLDataSet.InputNeuronCount">
            <summary>
            The number of input neurons.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Temporal.TemporalMLDataSet.OutputNeuronCount">
            <summary>
            The number of output neurons.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Temporal.TemporalMLDataSet.StartingPoint">
            <summary>
            The starting point.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Temporal.TemporalMLDataSet.SequenceGrandularity">
            <summary>
            The size of the timeslices.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalMLDataSet.AddDescription(Encog.ML.Data.Temporal.TemporalDataDescription)">
            <summary>
            Add a data description.
            </summary>
            <param name="desc">The data description to add.</param>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalMLDataSet.Clear">
            <summary>
            Clear the entire dataset.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalMLDataSet.Add(Encog.ML.Data.IMLData,Encog.ML.Data.IMLData)">
            <summary>
            Adding directly is not supported. Rather, add temporal points and
            generate the training data.
            </summary>
            <param name="inputData">Not used</param>
            <param name="idealData">Not used</param>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalMLDataSet.Add(Encog.ML.Data.IMLDataPair)">
            <summary>
            Adding directly is not supported. Rather, add temporal points and
            generate the training data.
            </summary>
            <param name="inputData">Not used.</param>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalMLDataSet.Add(Encog.ML.Data.IMLData)">
            <summary>
            Adding directly is not supported. Rather, add temporal points and
            generate the training data.
            </summary>
            <param name="data">Not used.</param>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalMLDataSet.CreatePoint(System.Int32)">
            <summary>
            Create a temporal data point using a sequence number. They can also be
            created using time. No two points should have the same sequence number.
            </summary>
            <param name="sequence">The sequence number.</param>
            <returns>A new TemporalPoint object.</returns>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalMLDataSet.GetSequenceFromDate(System.DateTime)">
            <summary>
            Create a sequence number from a time. The first date will be zero, and
            subsequent dates will be increased according to the grandularity
            specified. 
            </summary>
            <param name="when">The date to generate the sequence number for.</param>
            <returns>A sequence number.</returns>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalMLDataSet.CreatePoint(System.DateTime)">
            <summary>
            Create a temporal point from a time. Using the grandularity each date is
            given a unique sequence number. No two dates that fall in the same
            grandularity should be specified.
            </summary>
            <param name="when">The time that this point should be created at.</param>
            <returns>The point TemporalPoint created.</returns>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalMLDataSet.CalculatePointsInRange">
            <summary>
            Calculate how many points are in the high and low range. These are the
            points that the training set will be generated on.
            </summary>
            <returns>The number of points.</returns>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalMLDataSet.CalculateActualSetSize">
            <summary>
            Calculate the actual set size, this is the number of training set entries
            that will be generated.
            </summary>
            <returns>The size of the training set.</returns>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalMLDataSet.CalculateNeuronCounts">
            <summary>
            Calculate how many input and output neurons will be needed for the
            current data.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalMLDataSet.IsPointInRange(Encog.ML.Data.Temporal.TemporalPoint)">
            <summary>
            Is the specified point within the range. If a point is in the selection
            range, then the point will be used to generate the training sets.
            </summary>
            <param name="point">The point to consider.</param>
            <returns>True if the point is within the range.</returns>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalMLDataSet.GenerateInputNeuralData(System.Int32)">
            <summary>
            Generate input neural data for the specified index.
            </summary>
            <param name="index">The index to generate neural data for.</param>
            <returns>The input neural data generated.</returns>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalMLDataSet.GetDataRaw(Encog.ML.Data.Temporal.TemporalDataDescription,System.Int32)">
            <summary>
            Get data between two points in raw form.
            </summary>
            <param name="desc">The data description.</param>
            <param name="index">The index to get data from.</param>
            <returns>The requested data.</returns>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalMLDataSet.GetDataDeltaChange(Encog.ML.Data.Temporal.TemporalDataDescription,System.Int32)">
            <summary>
            Get data between two points in delta form.
            </summary>
            <param name="desc">The data description.</param>
            <param name="index">The index to get data from.</param>
            <returns>The requested data.</returns>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalMLDataSet.GetDataPercentChange(Encog.ML.Data.Temporal.TemporalDataDescription,System.Int32)">
            <summary>
            Get data between two points in percent form.
            </summary>
            <param name="desc">The data description.</param>
            <param name="index">The index to get data from.</param>
            <returns>The requested data.</returns>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalMLDataSet.FormatData(Encog.ML.Data.Temporal.TemporalDataDescription,System.Int32)">
            <summary>
            Format data according to the type specified in the description.
            </summary>
            <param name="desc">The data description.</param>
            <param name="index">The index to format the data at.</param>
            <returns>The formatted data.</returns>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalMLDataSet.GenerateOutputNeuralData(System.Int32)">
            <summary>
            Generate neural ideal data for the specified index.
            </summary>
            <param name="index">The index to generate for.</param>
            <returns>The neural data generated.</returns>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalMLDataSet.CalculateStartIndex">
            <summary>
            Calculate the index to start at.
            </summary>
            <returns>The starting point.</returns>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalMLDataSet.SortPoints">
            <summary>
            Sort the points.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalMLDataSet.Generate">
            <summary>
            Generate the training sets.
            </summary>
        </member>
        <member name="T:Encog.ML.Data.Temporal.TemporalPoint">
            <summary>
            A point in tme for a temporal data set.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Temporal.TemporalPoint._data">
            <summary>
            The data for this point.
            </summary>
        </member>
        <member name="F:Encog.ML.Data.Temporal.TemporalPoint._sequence">
            <summary>
            The sequence number for this point.
            </summary>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalPoint.#ctor(System.Int32)">
            <summary>
            Construct a temporal point of the specified size.
            </summary>
            <param name="size">The size to create the temporal point for.</param>
        </member>
        <member name="P:Encog.ML.Data.Temporal.TemporalPoint.Data">
            <summary>
            Allowes indexed access to the data.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Temporal.TemporalPoint.Sequence">
            <summary>
            The sequence number, used to sort.
            </summary>
        </member>
        <member name="P:Encog.ML.Data.Temporal.TemporalPoint.Item(System.Int32)">
            <summary>
            Allowes indexed access to the data.
            </summary>
            <param name="x">The index.</param>
            <returns>The data at the specified index.</returns>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalPoint.CompareTo(Encog.ML.Data.Temporal.TemporalPoint)">
            <summary>
            Compare two temporal points.
            </summary>
            <param name="that">The other temporal point to compare.</param>
            <returns>Returns 0 if they are equal, less than 0 if this point is less,
            greater than zero if this point is greater.</returns>
        </member>
        <member name="M:Encog.ML.Data.Temporal.TemporalPoint.ToString">
            Convert this point to string form.
            @return This point as a string.
        </member>
        <member name="T:Encog.ML.Factory.Method.BayesianFactory">
            <summary>
            Factory to create Bayesian networks
            </summary>
        </member>
        <member name="M:Encog.ML.Factory.Method.BayesianFactory.Create(System.String,System.Int32,System.Int32)">
            <summary>
            Create a bayesian network.
            </summary>
            <param name="architecture">The architecture to use.</param>
            <param name="input">The input neuron count.</param>
            <param name="output">The output neuron count.</param>
            <returns>The new bayesian network.</returns>
        </member>
        <member name="T:Encog.ML.Factory.Method.FeedforwardFactory">
             <summary>
             A factor to create feedforward networks.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.Method.FeedforwardFactory.CantDefineAct">
             <summary>
             Error.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.Method.FeedforwardFactory._factory">
            <summary>
            The activation function factory to use.
            </summary>
        </member>
        <member name="M:Encog.ML.Factory.Method.FeedforwardFactory.Create(System.String,System.Int32,System.Int32)">
             <summary>
             Create a feed forward network.
             </summary>
            
             <param name="architecture">The architecture string to use.</param>
             <param name="input">The input count.</param>
             <param name="output">The output count.</param>
             <returns>The feedforward network.</returns>
        </member>
        <member name="T:Encog.ML.Factory.Method.PNNFactory">
             <summary>
             A factory to create PNN networks.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.Method.PNNFactory.MaxLayers">
             <summary>
             The max layer count.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Factory.Method.PNNFactory.Create(System.String,System.Int32,System.Int32)">
             <summary>
             Create a PNN network.
             </summary>
            
             <param name="architecture">THe architecture string to use.</param>
             <param name="input">The input count.</param>
             <param name="output">The output count.</param>
             <returns>The RBF network.</returns>
        </member>
        <member name="T:Encog.ML.Factory.Method.RBFNetworkFactory">
             <summary>
             A factory to create RBF networks.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.Method.RBFNetworkFactory.MaxLayers">
             <summary>
             The max layer count.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Factory.Method.RBFNetworkFactory.Create(System.String,System.Int32,System.Int32)">
             <summary>
             Create a RBF network.
             </summary>
            
             <param name="architecture">THe architecture string to use.</param>
             <param name="input">The input count.</param>
             <param name="output">The output count.</param>
             <returns>The RBF network.</returns>
        </member>
        <member name="T:Encog.ML.Factory.Method.SOMFactory">
             <summary>
             A factory that is used to produce self-organizing maps.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Factory.Method.SOMFactory.Create(System.String,System.Int32,System.Int32)">
             <summary>
             Create a SOM.
             </summary>
            
             <param name="architecture">The architecture string.</param>
             <param name="input">The input count.</param>
             <param name="output">The output count.</param>
             <returns>The newly created SOM.</returns>
        </member>
        <member name="T:Encog.ML.Factory.Method.SRNFactory">
             <summary>
             A factory that creates simple recurrent neural networks (SRN's), i.e.
             Elmann and Jordan.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.Method.SRNFactory.MaxLayers">
             <summary>
             The max layer count.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Factory.Method.SRNFactory.Create(System.String,System.Int32,System.Int32)">
             <summary>
             Create the SRN.
             </summary>
            
             <param name="architecture">The architecture string.</param>
             <param name="input">The input count.</param>
             <param name="output">The output count.</param>
             <returns>The newly created SRN.</returns>
        </member>
        <member name="T:Encog.ML.Factory.Method.SVMFactory">
             <summary>
             A factory that is used to create support vector machines (SVM).
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.Method.SVMFactory.MAX_LAYERS">
             <summary>
             The max layer count.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Factory.Method.SVMFactory.Create(System.String,System.Int32,System.Int32)">
             <summary>
             Create the SVM.
             </summary>
            
             <param name="architecture">The architecture string.</param>
             <param name="input">The input count.</param>
             <param name="output">The output count.</param>
             <returns>The newly created SVM.</returns>
        </member>
        <member name="T:Encog.ML.Factory.MLMethodFactory">
             <summary>
             This factory is used to create machine learning methods.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLMethodFactory.TypeBayesian">
            <summary>
            String constant for a bayesian neural network.
            </summary>
        </member>
        <member name="F:Encog.ML.Factory.MLMethodFactory.TypeFeedforward">
             <summary>
             String constant for feedforward neural networks.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLMethodFactory.TypeRbfnetwork">
             <summary>
             String constant for RBF neural networks.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLMethodFactory.TypeSVM">
             <summary>
             String constant for support vector machines.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLMethodFactory.TypeSOM">
             <summary>
             String constant for SOMs.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLMethodFactory.TypePNN">
             <summary>
             A probabilistic neural network. Supports both PNN and GRNN.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Factory.MLMethodFactory.Create(System.String,System.String,System.Int32,System.Int32)">
             <summary>
             Create a new machine learning method.
             </summary>
            
             <param name="methodType">The method to create.</param>
             <param name="architecture">The architecture string.</param>
             <param name="input">The input count.</param>
             <param name="output">The output count.</param>
             <returns>The newly created machine learning method.</returns>
        </member>
        <member name="T:Encog.ML.Factory.MLTrainFactory">
             <summary>
             This factory is used to create trainers for machine learning methods.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.PropertyMaxParents">
            <summary>
            The maximum number of parents for K2.
            </summary>
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.PropertyParticles">
            <summary>
             The number of particles.
            </summary>
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.TypeNelderMead">
            <summary>
            Nelder Mead training for Bayesian.
            </summary>
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.TypeBayesian">
            <summary>
            K2 training for Bayesian.
            </summary>
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.TypePSO">
            <summary>
            PSO training.
            </summary>
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.TypeRPROP">
             <summary>
             String constant for RPROP training.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.TypeQPROP">
             <summary>
             String constant for RPROP training.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.TypeBackprop">
             <summary>
             String constant for backprop training.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.TypeSCG">
             <summary>
             String constant for SCG training.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.TypeLma">
             <summary>
             String constant for LMA training.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.TypeSVM">
             <summary>
             String constant for SVM training.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.TypeSVMSearch">
             <summary>
             String constant for SVM-Search training.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.TypeSOMNeighborhood">
             <summary>
             String constant for SOM-Neighborhood training.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.TypeSOMCluster">
             <summary>
             String constant for SOM-Cluster training.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.PropertyLearningRate">
             <summary>
             Property for learning rate.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.PropertyLearningMomentum">
             <summary>
             Property for momentum.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.PropertyInitialUpdate">
             <summary>
             Property for init update.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.PropertyMaxStep">
             <summary>
             Property for max step.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.PropertyBayesianRegularization">
             <summary>
             Property for bayes reg.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.PropertyGamma">
             <summary>
             Property for gamma.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.PropertyC">
             <summary>
             Property for constant.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.PropertyPropertyNeighborhood">
             <summary>
             Property for neighborhood.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.PropertyIterations">
             <summary>
             Property for iterations.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.PropertyStartLearningRate">
             <summary>
             Property for starting learning rate.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.PropertyEndLearningRate">
             <summary>
             Property for ending learning rate.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.PropertyStartRadius">
             <summary>
             Property for starting radius.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.PropertyEndRadius">
             <summary>
             Property for ending radius.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.PropertyNeighborhood">
             <summary>
             Property for neighborhood.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.PropertyRBFType">
             <summary>
             Property for rbf type.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.PropertyDimensions">
             <summary>
             Property for dimensions.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.Cycles">
             <summary>
             The number of cycles.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.PropertyTemperatureStart">
             <summary>
             The starting temperature.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.PropertyTemperatureStop">
             <summary>
             The ending temperature.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.TypeAnneal">
             <summary>
             Use simulated annealing.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.PropertyPopulationSize">
             <summary>
             Population size.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.PropertyMutation">
             <summary>
             Percent to mutate.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.PropertyMate">
             <summary>
             Percent to mate.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.TypeGenetic">
             <summary>
             Genetic training.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.TypeManhattan">
             <summary>
             Manhattan training.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.TypeSvd">
             <summary>
             RBF-SVD training.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.MLTrainFactory.TypePNN">
             <summary>
             PNN training.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Factory.MLTrainFactory.#ctor">
            <summary>
            Construct the boject.
            </summary>
        </member>
        <member name="M:Encog.ML.Factory.MLTrainFactory.Create(Encog.ML.IMLMethod,Encog.ML.Data.IMLDataSet,System.String,System.String)">
             <summary>
             Create a trainer.
             </summary>
            
             <param name="method">The method to train.</param>
             <param name="training">The training data.</param>
             <param name="type">Type type of trainer.</param>
             <param name="args">The training args.</param>
             <returns>The new training method.</returns>
        </member>
        <member name="T:Encog.ML.Factory.Parse.ArchitectureLayer">
             <summary>
             Holds the parse results for one layer.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.Parse.ArchitectureLayer._paras">
             <summary>
             Holds any paramaters that were specified for the layer.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Factory.Parse.ArchitectureLayer.#ctor">
            <summary>
            Construct the object.
            </summary>
        </member>
        <member name="P:Encog.ML.Factory.Parse.ArchitectureLayer.Count">
            <value>the count to set</value>
        </member>
        <member name="P:Encog.ML.Factory.Parse.ArchitectureLayer.Name">
            <value>the name to set</value>
        </member>
        <member name="P:Encog.ML.Factory.Parse.ArchitectureLayer.Params">
            <value>the params</value>
        </member>
        <member name="P:Encog.ML.Factory.Parse.ArchitectureLayer.Bias">
            <value>the bias to set</value>
        </member>
        <member name="P:Encog.ML.Factory.Parse.ArchitectureLayer.UsedDefault">
            <value>the usedDefault to set</value>
        </member>
        <member name="T:Encog.ML.Factory.Parse.ArchitectureParse">
             <summary>
             This class is used to parse a Encog architecture string.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Factory.Parse.ArchitectureParse.ParseLayer(System.String,System.Int32)">
             <summary>
             parse a layer.
             </summary>
            
             <param name="line">The line to parse.</param>
             <param name="defaultValue">The default value.</param>
             <returns>The parsed ArchitectureLayer.</returns>
        </member>
        <member name="M:Encog.ML.Factory.Parse.ArchitectureParse.ParseLayers(System.String)">
             <summary>
             Parse all layers from a line of text.
             </summary>
            
             <param name="line">The line of text.</param>
             <returns>A list of the parsed layers.</returns>
        </member>
        <member name="M:Encog.ML.Factory.Parse.ArchitectureParse.ParseName(Encog.Util.SimpleParser)">
             <summary>
             Parse a name.
             </summary>
            
             <param name="parser">The parser to use.</param>
             <returns>The name.</returns>
        </member>
        <member name="M:Encog.ML.Factory.Parse.ArchitectureParse.ParseParams(System.String)">
             <summary>
             Parse parameters.
             </summary>
            
             <param name="line">The line to parse.</param>
             <returns>The parsed values.</returns>
        </member>
        <member name="M:Encog.ML.Factory.Parse.ArchitectureParse.ParseValue(Encog.Util.SimpleParser)">
             <summary>
             Parse a value.
             </summary>
            
             <param name="parser">The parser to use.</param>
             <returns>The newly parsed value.</returns>
        </member>
        <member name="T:Encog.ML.Factory.Train.AnnealFactory">
             <summary>
             A factory to create simulated annealing trainers.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Factory.Train.AnnealFactory.Create(Encog.ML.IMLMethod,Encog.ML.Data.IMLDataSet,System.String)">
             <summary>
             Create an annealing trainer.
             </summary>
            
             <param name="method">The method to use.</param>
             <param name="training">The training data to use.</param>
             <param name="argsStr">The arguments to use.</param>
             <returns>The newly created trainer.</returns>
        </member>
        <member name="T:Encog.ML.Factory.Train.BackPropFactory">
             <summary>
             A factory for backpropagation training.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Factory.Train.BackPropFactory.Create(Encog.ML.IMLMethod,Encog.ML.Data.IMLDataSet,System.String)">
             <summary>
             Create a backpropagation trainer.
             </summary>
            
             <param name="method">The method to use.</param>
             <param name="training">The training data to use.</param>
             <param name="argsStr">The arguments to use.</param>
             <returns>The newly created trainer.</returns>
        </member>
        <member name="T:Encog.ML.Factory.Train.ClusterSOMFactory">
             <summary>
             Create a trainer that uses the SOM cluster training method.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Factory.Train.ClusterSOMFactory.Create(Encog.ML.IMLMethod,Encog.ML.Data.IMLDataSet,System.String)">
             <summary>
             Create a cluster SOM trainer.
             </summary>
            
             <param name="method">The method to use.</param>
             <param name="training">The training data to use.</param>
             <param name="argsStr">The arguments to use.</param>
             <returns>The newly created trainer.</returns>
        </member>
        <member name="T:Encog.ML.Factory.Train.GeneticFactory">
             <summary>
             A factory to create genetic algorithm trainers.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Factory.Train.GeneticFactory.Create(Encog.ML.IMLMethod,Encog.ML.Data.IMLDataSet,System.String)">
             <summary>
             Create an annealing trainer.
             </summary>
            
             <param name="method">The method to use.</param>
             <param name="training">The training data to use.</param>
             <param name="argsStr">The arguments to use.</param>
             <returns>The newly created trainer.</returns>
        </member>
        <member name="T:Encog.ML.Factory.Train.LMAFactory">
             <summary>
             This class is a factory to create the LMA training method.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Factory.Train.LMAFactory.Create(Encog.ML.IMLMethod,Encog.ML.Data.IMLDataSet,System.String)">
             <summary>
             Create a LMA trainer.
             </summary>
            
             <param name="method">The method to use.</param>
             <param name="training">The training data to use.</param>
             <param name="argsStr">The arguments to use.</param>
             <returns>The newly created trainer.</returns>
        </member>
        <member name="T:Encog.ML.Factory.Train.ManhattanFactory">
             <summary>
             A factory for Manhattan training.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Factory.Train.ManhattanFactory.Create(Encog.ML.IMLMethod,Encog.ML.Data.IMLDataSet,System.String)">
             <summary>
             Create a Manhattan trainer.
             </summary>
            
             <param name="method">The method to use.</param>
             <param name="training">The training data to use.</param>
             <param name="argsStr">The arguments to use.</param>
             <returns>The newly created trainer.</returns>
        </member>
        <member name="T:Encog.ML.Factory.Train.NeighborhoodSOMFactory">
             <summary>
             Train an SOM network with a neighborhood method.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Factory.Train.NeighborhoodSOMFactory.Create(Encog.ML.IMLMethod,Encog.ML.Data.IMLDataSet,System.String)">
             <summary>
             Create a LMA trainer.
             </summary>
            
             <param name="method">The method to use.</param>
             <param name="training">The training data to use.</param>
             <param name="argsStr">The arguments to use.</param>
             <returns>The newly created trainer.</returns>
        </member>
        <member name="M:Encog.ML.Factory.Train.NelderMeadFactory.Create(Encog.ML.IMLMethod,Encog.ML.Data.IMLDataSet,System.String)">
            <summary>
            Create a Nelder Mead trainer.
            </summary>
            <param name="method">The method to use.</param>
            <param name="training">The training data to use.</param>
            <param name="argsStr">The arguments to use.</param>
            <returns>The newly created trainer.</returns>
        </member>
        <member name="T:Encog.ML.Factory.Train.PNNTrainFactory">
             <summary>
             A factory used to create PNN trainers. 
             </summary>
            
        </member>
        <member name="M:Encog.ML.Factory.Train.PNNTrainFactory.Create(Encog.ML.IMLMethod,Encog.ML.Data.IMLDataSet,System.String)">
             <summary>
             Create a PNN trainer.
             </summary>
            
             <param name="method">The method to use.</param>
             <param name="training">The training data to use.</param>
             <param name="args">The arguments to use.</param>
             <returns>The newly created trainer.</returns>
        </member>
        <member name="T:Encog.ML.Factory.Train.PSOFactory">
            <summary>
            Factory to create PSO trainers.
            </summary>
        </member>
        <member name="M:Encog.ML.Factory.Train.PSOFactory.Create(Encog.ML.IMLMethod,Encog.ML.Data.IMLDataSet,System.String)">
            <summary>
            Create a PSO trainer.
            </summary>
            <param name="method">The method to use.</param>
            <param name="training">The training data to use.</param>
            <param name="argsStr">The arguments to use.</param>
            <returns>The newly created trainer.</returns>
        </member>
        <member name="T:Encog.ML.Factory.Train.QuickPropFactory">
            <summary>
            A factory for quick propagation training.
            </summary>
        </member>
        <member name="M:Encog.ML.Factory.Train.QuickPropFactory.Create(Encog.ML.IMLMethod,Encog.ML.Data.IMLDataSet,System.String)">
            <summary>
            Create a quick propagation trainer.
            </summary>
            <param name="method">The method to use.</param>
            <param name="training">The training data to use.</param>
            <param name="argsStr">The arguments to use.</param>
            <returns>The newly created trainer.</returns>
        </member>
        <member name="T:Encog.ML.Factory.Train.RBFSVDFactory">
             <summary>
             This factory is used to create a SVD trainer for an RBF network.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Factory.Train.RBFSVDFactory.Create(Encog.ML.IMLMethod,Encog.ML.Data.IMLDataSet,System.String)">
             <summary>
             Create a RBF-SVD trainer.
             </summary>
            
             <param name="method">The method to use.</param>
             <param name="training">The training data to use.</param>
             <param name="args">The arguments to use.</param>
             <returns>The newly created trainer.</returns>
        </member>
        <member name="T:Encog.ML.Factory.Train.RPROPFactory">
             <summary>
             A factory that creates RPROP trainers.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Factory.Train.RPROPFactory.Create(Encog.ML.IMLMethod,Encog.ML.Data.IMLDataSet,System.String)">
             <summary>
             Create a RPROP trainer.
             </summary>
            
             <param name="method">The method to use.</param>
             <param name="training">The training data to use.</param>
             <param name="argsStr">The arguments to use.</param>
             <returns>The newly created trainer.</returns>
        </member>
        <member name="T:Encog.ML.Factory.Train.SCGFactory">
             <summary>
             A factory used to create SCG trainers. 
             </summary>
            
        </member>
        <member name="M:Encog.ML.Factory.Train.SCGFactory.Create(Encog.ML.IMLMethod,Encog.ML.Data.IMLDataSet,System.String)">
             <summary>
             Create a SCG trainer.
             </summary>
            
             <param name="method">The method to use.</param>
             <param name="training">The training data to use.</param>
             <param name="args">The arguments to use.</param>
             <returns>The newly created trainer.</returns>
        </member>
        <member name="T:Encog.ML.Factory.Train.SVMFactory">
             <summary>
             A factory to create SVM trainers.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Factory.Train.SVMFactory.Create(Encog.ML.IMLMethod,Encog.ML.Data.IMLDataSet,System.String)">
             <summary>
             Create a SVM trainer.
             </summary>
            
             <param name="method">The method to use.</param>
             <param name="training">The training data to use.</param>
             <param name="argsStr">The arguments to use.</param>
             <returns>The newly created trainer.</returns>
        </member>
        <member name="T:Encog.ML.Factory.Train.SVMSearchFactory">
             <summary>
             A factory that creates SVM-search trainers.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.Train.SVMSearchFactory.PropertyGamma1">
             <summary>
             Property for gamma.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.Train.SVMSearchFactory.PropertyC1">
             <summary>
             Property for constant.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.Train.SVMSearchFactory.PropertyGamma2">
             <summary>
             Property for gamma.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.Train.SVMSearchFactory.PropertyC2">
             <summary>
             Property for constant.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.Train.SVMSearchFactory.PropertyGammaStep">
             <summary>
             Property for gamma.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Factory.Train.SVMSearchFactory.PropertyCStep">
             <summary>
             Property for constant.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Factory.Train.SVMSearchFactory.Create(Encog.ML.IMLMethod,Encog.ML.Data.IMLDataSet,System.String)">
             <summary>
             Create a SVM trainer.
             </summary>
            
             <param name="method">The method to use.</param>
             <param name="training">The training data to use.</param>
             <param name="argsStr">The arguments to use.</param>
             <returns>The newly created trainer.</returns>
        </member>
        <member name="M:Encog.ML.Factory.Train.TrainBayesianFactory.Create(Encog.ML.IMLMethod,Encog.ML.Data.IMLDataSet,System.String)">
            Create a K2 trainer.
            
            @param method
                       The method to use.
            @param training
                       The training data to use.
            @param argsStr
                       The arguments to use.
            @return The newly created trainer.
        </member>
        <member name="T:Encog.ML.Genetic.BasicGeneticAlgorithm">
             <summary>
             Provides a basic implementation of a genetic algorithm.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.BasicGeneticAlgorithm._first">
             <summary>
             Is this the first iteration.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.BasicGeneticAlgorithm.#ctor">
            <summary>
            Construct the object.
            </summary>
        </member>
        <member name="M:Encog.ML.Genetic.BasicGeneticAlgorithm.Iteration">
            <summary>
            Modify the weight matrix and bias values based on the last call to
            calcError.
            </summary>
        </member>
        <member name="T:Encog.ML.Genetic.Crossover.ICrossover">
             <summary>
             Specifies how "crossover" or mating happens.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.Crossover.ICrossover.Mate(Encog.ML.Genetic.Genome.Chromosome,Encog.ML.Genetic.Genome.Chromosome,Encog.ML.Genetic.Genome.Chromosome,Encog.ML.Genetic.Genome.Chromosome)">
             <summary>
             Mate two chromosomes.
             </summary>
            
             <param name="mother">The mother.</param>
             <param name="father">The father.</param>
             <param name="offspring1">The first offspring.</param>
             <param name="offspring2">The second offspring.</param>
        </member>
        <member name="T:Encog.ML.Genetic.Crossover.Splice">
             <summary>
             A simple cross over where genes are simply "spliced". Genes are allowed to
             repeat.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Crossover.Splice._cutLength">
             <summary>
             The cut length.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.Crossover.Splice.#ctor(System.Int32)">
             <summary>
             Create a slice crossover with the specified cut length.
             </summary>
            
             <param name="theCutLength">The cut length.</param>
        </member>
        <member name="M:Encog.ML.Genetic.Crossover.Splice.Mate(Encog.ML.Genetic.Genome.Chromosome,Encog.ML.Genetic.Genome.Chromosome,Encog.ML.Genetic.Genome.Chromosome,Encog.ML.Genetic.Genome.Chromosome)">
             <summary>
             Assuming this chromosome is the "mother" mate with the passed in
             "father".
             </summary>
            
             <param name="mother">The mother.</param>
             <param name="father">The father.</param>
             <param name="offspring1">Returns the first offspring</param>
             <param name="offspring2">Returns the second offspring.</param>
        </member>
        <member name="T:Encog.ML.Genetic.Crossover.SpliceNoRepeat">
            <summary>
            A simple cross over where genes are simply "spliced".
            Genes are not allowed to repeat.
            </summary>
        </member>
        <member name="F:Encog.ML.Genetic.Crossover.SpliceNoRepeat._cutLength">
            <summary>
            The cut length.
            </summary>
        </member>
        <member name="M:Encog.ML.Genetic.Crossover.SpliceNoRepeat.#ctor(System.Int32)">
            <summary>
            Construct a splice crossover.
            </summary>
            <param name="cutLength">The cut length.</param>
        </member>
        <member name="M:Encog.ML.Genetic.Crossover.SpliceNoRepeat.Mate(Encog.ML.Genetic.Genome.Chromosome,Encog.ML.Genetic.Genome.Chromosome,Encog.ML.Genetic.Genome.Chromosome,Encog.ML.Genetic.Genome.Chromosome)">
            <summary>
            Assuming this chromosome is the "mother" mate with the passed in
            "father".
            </summary>
            <param name="mother">The mother.</param>
            <param name="father">The father.</param>
            <param name="offspring1">The first offspring.</param>
            <param name="offspring2">The second offspring.</param>
        </member>
        <member name="M:Encog.ML.Genetic.Crossover.SpliceNoRepeat.GetNotTaken(Encog.ML.Genetic.Genome.Chromosome,System.Collections.Generic.IList{Encog.ML.Genetic.Genes.IGene})">
            <summary>
            Get a list of the genes that have not been taken before. This is useful
            if you do not wish the same gene to appear more than once in a
            chromosome.
            </summary>
            <param name="source">The pool of genes to select from.</param>
            <param name="taken">An array of the taken genes.</param>
            <returns>Those genes in source that are not taken.</returns>
        </member>
        <member name="T:Encog.ML.Genetic.Genes.BasicGene">
             <summary>
             Implements the basic functionality for a gene. This is an abstract class.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Genes.BasicGene._enabled">
             <summary>
             Is this gene enabled?
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Genes.BasicGene._id">
             <summary>
             ID of this gene, -1 for unassigned.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Genes.BasicGene._innovationId">
             <summary>
             Innovation ID, -1 for unassigned.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.Genes.BasicGene.#ctor">
            <summary>
            Construct the object.
            </summary>
        </member>
        <member name="M:Encog.ML.Genetic.Genes.BasicGene.CompareTo(Encog.ML.Genetic.Genes.IGene)">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Genetic.Genes.BasicGene.Id">
            <summary>
            Set the id for this gene.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Genes.BasicGene.InnovationId">
            <summary>
            Set the innovation id for this gene.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Genes.BasicGene.Enabled">
            <value>True, if this gene is enabled.</value>
        </member>
        <member name="M:Encog.ML.Genetic.Genes.BasicGene.Copy(Encog.ML.Genetic.Genes.IGene)">
             <summary>
             from Encog.ml.genetic.genes.Gene
             </summary>
            
        </member>
        <member name="T:Encog.ML.Genetic.Genes.CharGene">
             <summary>
             A gene that holds a single character.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Genes.CharGene._value">
             <summary>
             The character value of the gene.
             </summary>
            
        </member>
        <member name="P:Encog.ML.Genetic.Genes.CharGene.Value">
             <summary>
             Set the value of this gene.
             </summary>
            
             <value>The new value of this gene.</value>
        </member>
        <member name="M:Encog.ML.Genetic.Genes.CharGene.Copy(Encog.ML.Genetic.Genes.IGene)">
             <summary>
             Copy another gene to this gene.
             </summary>
            
             <param name="gene">The source gene.</param>
        </member>
        <member name="M:Encog.ML.Genetic.Genes.CharGene.ToString">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Genetic.Genes.DoubleGene">
             <summary>
             A gene that contains a floating point value.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Genes.DoubleGene._value">
             <summary>
             The value of this gene.
             </summary>
            
        </member>
        <member name="P:Encog.ML.Genetic.Genes.DoubleGene.Value">
             <summary>
             Set the value of the gene.
             </summary>
            
             <value>The gene's value.</value>
        </member>
        <member name="M:Encog.ML.Genetic.Genes.DoubleGene.Copy(Encog.ML.Genetic.Genes.IGene)">
             <summary>
             Copy another gene to this one.
             </summary>
            
             <param name="gene">The other gene to copy.</param>
        </member>
        <member name="M:Encog.ML.Genetic.Genes.DoubleGene.ToString">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Genetic.Genes.IGene">
             <summary>
             Describes a gene. A gene is the smallest piece of genetic information in
             Encog.
             </summary>
            
        </member>
        <member name="P:Encog.ML.Genetic.Genes.IGene.Id">
             <summary>
             Get the ID of this gene, -1 for undefined.
             </summary>
            
             <value>The ID of this gene.</value>
        </member>
        <member name="P:Encog.ML.Genetic.Genes.IGene.InnovationId">
            <value>The innovation ID of this gene.</value>
        </member>
        <member name="P:Encog.ML.Genetic.Genes.IGene.Enabled">
             <summary>
             Determine if this gene is enabled.
             </summary>
            
             <value>True if this gene is enabled.</value>
        </member>
        <member name="M:Encog.ML.Genetic.Genes.IGene.Copy(Encog.ML.Genetic.Genes.IGene)">
             <summary>
             Copy another gene to this one.
             </summary>
            
             <param name="gene">The other gene to copy.</param>
        </member>
        <member name="T:Encog.ML.Genetic.Genes.IntegerGene">
             <summary>
             A gene that contains an integer value.
             </summary>
            
        </member>
        <member name="P:Encog.ML.Genetic.Genes.IntegerGene.Value">
            <summary>
            Set the value of this gene.
            </summary>
        </member>
        <member name="M:Encog.ML.Genetic.Genes.IntegerGene.Copy(Encog.ML.Genetic.Genes.IGene)">
            <summary>
            Copy another gene to this one.
            </summary>
        </member>
        <member name="M:Encog.ML.Genetic.Genes.IntegerGene.Equals(System.Object)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Genetic.Genes.IntegerGene.GetHashCode">
            <returns>a hash code.</returns>
        </member>
        <member name="M:Encog.ML.Genetic.Genes.IntegerGene.ToString">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Genetic.GeneticAlgorithm">
             <summary>
             Implements a genetic algorithm. This is an abstract class. Other classes are
             provided by Encog use this base class to train neural networks or provide an
             answer to the traveling salesman problem.
             The genetic algorithm is also capable of using a thread pool to speed
             execution.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.GeneticAlgorithm._calculateScore">
             <summary>
             The score calculation object.
             </summary>
            
        </member>
        <member name="P:Encog.ML.Genetic.GeneticAlgorithm.CalculateScore">
            <summary>
            Set the score calculation object.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.GeneticAlgorithm.ThreadCount">
            <summary>
            The thread count.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.GeneticAlgorithm.Comparator">
            <summary>
            Set the comparator.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.GeneticAlgorithm.Crossover">
            <summary>
            Set the crossover object.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.GeneticAlgorithm.MatingPopulation">
            <summary>
            Set the mating population percent.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.GeneticAlgorithm.Mutate">
            <summary>
            Set the mutate object.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.GeneticAlgorithm.MutationPercent">
            <summary>
            Set the mutation percent.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.GeneticAlgorithm.PercentToMate">
            <summary>
            Set the percent to mate.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.GeneticAlgorithm.Population">
            <summary>
            Set the population.
            </summary>
        </member>
        <member name="M:Encog.ML.Genetic.GeneticAlgorithm.AddSpeciesMember(Encog.ML.Genetic.Species.ISpecies,Encog.ML.Genetic.Genome.IGenome)">
             <summary>
             Add a genome.
             </summary>
            
             <param name="species">The species to add.</param>
             <param name="genome">The genome to add.</param>
        </member>
        <member name="M:Encog.ML.Genetic.GeneticAlgorithm.PerformCalculateScore(Encog.ML.Genetic.Genome.IGenome)">
             <summary>
             Calculate the score for this genome. The genome's score will be set.
             </summary>
            
             <param name="g">The genome to calculate for.</param>
        </member>
        <member name="M:Encog.ML.Genetic.GeneticAlgorithm.Iteration">
             <summary>
             Perform one training iteration.
             </summary>
            
        </member>
        <member name="T:Encog.ML.Genetic.GeneticError">
             <summary>
             An error raised by the genetic algorithm.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.GeneticError.#ctor(System.String)">
             <summary>
             Construct a message exception.
             </summary>
            
             <param name="msg">The exception message.</param>
        </member>
        <member name="M:Encog.ML.Genetic.GeneticError.#ctor(System.String,System.Exception)">
             <summary>
             Construct an exception that holds another exception.
             </summary>
            
             <param name="msg">A message.</param>
             <param name="t">The other exception.</param>
        </member>
        <member name="M:Encog.ML.Genetic.GeneticError.#ctor(System.Exception)">
             <summary>
             Construct an exception that holds another exception.
             </summary>
            
             <param name="t">The other exception.</param>
        </member>
        <member name="T:Encog.ML.Genetic.Genome.BasicGenome">
             <summary>
             A basic abstract genome. Provides base functionality.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Genome.BasicGenome._ga">
            <summary>
            The genetic algorithm.
            </summary>
        </member>
        <member name="F:Encog.ML.Genetic.Genome.BasicGenome._chromosomes">
             <summary>
             The chromosomes for this gene.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Genome.BasicGenome._adjustedScore">
             <summary>
             The adjusted score.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Genome.BasicGenome._amountToSpawn">
             <summary>
             The amount to spawn.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Genome.BasicGenome._genomeID">
             <summary>
             The genome id.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Genome.BasicGenome._organism">
             <summary>
             The organism generated by this gene.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Genome.BasicGenome._population">
             <summary>
             The population this genome belongs to.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Genome.BasicGenome._score">
             <summary>
             The score of this genome.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.Genome.BasicGenome.#ctor">
            <summary>
            Construct the bo
            </summary>
        </member>
        <member name="M:Encog.ML.Genetic.Genome.BasicGenome.CalculateGeneCount">
            <returns>The number of genes in this genome.</returns>
        </member>
        <member name="M:Encog.ML.Genetic.Genome.BasicGenome.Equals(Encog.ML.Genetic.Genome.IGenome)">
            <inheritDoc/>
        </member>
        <member name="M:Encog.ML.Genetic.Genome.BasicGenome.CompareTo(Encog.ML.Genetic.Genome.IGenome)">
            <inheritDoc/>
        </member>
        <member name="P:Encog.ML.Genetic.Genome.BasicGenome.AdjustedScore">
             <summary>
             Set the adjusted score.
             </summary>
            
             <value>The score.</value>
        </member>
        <member name="P:Encog.ML.Genetic.Genome.BasicGenome.AmountToSpawn">
            <summary>
            Set the amount to spawn.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Genome.BasicGenome.Chromosomes">
            <value>The number of chromosomes.</value>
        </member>
        <member name="P:Encog.ML.Genetic.Genome.BasicGenome.GA">
            <summary>
            Set the genetic algorithm to use.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Genome.BasicGenome.GenomeID">
            <summary>
            Set the genome id.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Genome.BasicGenome.Organism">
            <summary>
            Set the organism.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Genome.BasicGenome.Population">
            <value>the population to set</value>
        </member>
        <member name="P:Encog.ML.Genetic.Genome.BasicGenome.Score">
            <summary>
            Set the score.
            </summary>
        </member>
        <member name="M:Encog.ML.Genetic.Genome.BasicGenome.Mate(Encog.ML.Genetic.Genome.IGenome,Encog.ML.Genetic.Genome.IGenome,Encog.ML.Genetic.Genome.IGenome)">
             <summary>
             Mate two genomes. Will loop over all chromosomes.
             </summary>
            
             <param name="father">The father.</param>
             <param name="child1">The first child.</param>
             <param name="child2">The second child.</param>
        </member>
        <member name="M:Encog.ML.Genetic.Genome.BasicGenome.Decode">
             <summary>
             from Encog.ml.genetic.genome.Genome
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.Genome.BasicGenome.Encode">
             <summary>
             from Encog.ml.genetic.genome.Genome
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.Genome.BasicGenome.ToString">
            <inheritdoc />
        </member>
        <member name="T:Encog.ML.Genetic.Genome.ICalculateGenomeScore">
             <summary>
             Genetic Algorithms need a class to calculate the score.
             </summary>
            
        </member>
        <member name="P:Encog.ML.Genetic.Genome.ICalculateGenomeScore.ShouldMinimize">
            <returns>True if the goal is to minimize the score.</returns>
        </member>
        <member name="M:Encog.ML.Genetic.Genome.ICalculateGenomeScore.CalculateScore(Encog.ML.Genetic.Genome.IGenome)">
             <summary>
             Calculate this genome's score.
             </summary>
            
             <param name="genome">The genome.</param>
             <returns>The score.</returns>
        </member>
        <member name="T:Encog.ML.Genetic.Genome.Chromosome">
             <summary>
             Implements a chromosome to genetic algorithm. This is an abstract class.
             Other classes are provided in this book that use this base class to train
             neural networks or provide an answer to the traveling salesman problem. 
             Chromosomes are made up of genes. 
             Genomes in this genetic algorithm consist of one or more chromosomes. 
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Genome.Chromosome._genes">
             <summary>
             The individual elements of this chromosome.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.Genome.Chromosome.#ctor">
            <summary>
            Construct the object.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Genome.Chromosome.Genes">
             <summary>
             Used the get the entire gene list.
             </summary>
            
             <value>the genes</value>
        </member>
        <member name="M:Encog.ML.Genetic.Genome.Chromosome.Add(Encog.ML.Genetic.Genes.IGene)">
             <summary>
             Add a gene.
             </summary>
            
             <param name="gene">The gene to add.</param>
        </member>
        <member name="M:Encog.ML.Genetic.Genome.Chromosome.Get(System.Int32)">
             <summary>
             Get an individual gene.
             </summary>
            
             <param name="i">The index of the gene.</param>
             <returns>The gene.</returns>
        </member>
        <member name="M:Encog.ML.Genetic.Genome.Chromosome.GetGene(System.Int32)">
             <summary>
             Get the specified gene.
             </summary>
            
             <param name="gene">The specified gene.</param>
             <returns>The gene specified.</returns>
        </member>
        <member name="M:Encog.ML.Genetic.Genome.Chromosome.Size">
            <returns>The number of genes in this chromosome.</returns>
        </member>
        <member name="T:Encog.ML.Genetic.Genome.IGenome">
             <summary>
             A genome is the basic blueprint for creating an organism in Encog. A genome
             is made up of one or more chromosomes, which are in turn made up of genes.
             </summary>
            
        </member>
        <member name="P:Encog.ML.Genetic.Genome.IGenome.AdjustedScore">
            <summary>
            Set the adjusted score.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Genome.IGenome.AmountToSpawn">
            <summary>
            Set the amount to spawn.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Genome.IGenome.Chromosomes">
            <value>The chromosomes that make up this genome.</value>
        </member>
        <member name="P:Encog.ML.Genetic.Genome.IGenome.GA">
            <summary>
            Set the GA used by this genome. This is normally a transient field and
            only used during training.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Genome.IGenome.GenomeID">
            <summary>
            Set the genome ID.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Genome.IGenome.Organism">
            <value>The organism produced by this genome.</value>
        </member>
        <member name="P:Encog.ML.Genetic.Genome.IGenome.Population">
            <summary>
            Set the population that this genome belongs to.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Genome.IGenome.Score">
            <summary>
            Set the score.
            </summary>
        </member>
        <member name="M:Encog.ML.Genetic.Genome.IGenome.CalculateGeneCount">
            <returns>The number of genes in this genome.</returns>
        </member>
        <member name="M:Encog.ML.Genetic.Genome.IGenome.Decode">
             <summary>
             Use the genes to update the organism.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.Genome.IGenome.Encode">
             <summary>
             Use the organism to update the genes.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.Genome.IGenome.Mate(Encog.ML.Genetic.Genome.IGenome,Encog.ML.Genetic.Genome.IGenome,Encog.ML.Genetic.Genome.IGenome)">
             <summary>
             Mate with another genome and produce two children.
             </summary>
            
             <param name="father">The father genome.</param>
             <param name="child1">The first child.</param>
             <param name="child2">The second child.</param>
        </member>
        <member name="T:Encog.ML.Genetic.Genome.GenomeComparator">
             <summary>
             Used to compare two genomes, a score object is used.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Genome.GenomeComparator._calculateScore">
             <summary>
             The method to calculate the score.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.Genome.GenomeComparator.#ctor(Encog.ML.Genetic.Genome.ICalculateGenomeScore)">
             <summary>
             Construct the genome comparator.
             </summary>
            
             <param name="theCalculateScore">The score calculation object to use.</param>
        </member>
        <member name="P:Encog.ML.Genetic.Genome.GenomeComparator.CalculateScore">
            <value>The score calculation object.</value>
        </member>
        <member name="M:Encog.ML.Genetic.Genome.GenomeComparator.Compare(Encog.ML.Genetic.Genome.IGenome,Encog.ML.Genetic.Genome.IGenome)">
             <summary>
             Compare two genomes.
             </summary>
            
             <param name="genome1">The first genome.</param>
             <param name="genome2">The second genome.</param>
             <returns>Zero if equal, or less than or greater than zero to indicate
             order.</returns>
        </member>
        <member name="M:Encog.ML.Genetic.Genome.GenomeComparator.ApplyBonus(System.Double,System.Double)">
             <summary>
             Apply a bonus, this is a simple percent that is applied in the direction
             specified by the "should minimize" property of the score function.
             </summary>
            
             <param name="v">The current value.</param>
             <param name="bonus">The bonus.</param>
             <returns>The resulting value.</returns>
        </member>
        <member name="M:Encog.ML.Genetic.Genome.GenomeComparator.ApplyPenalty(System.Double,System.Double)">
             <summary>
             Apply a penalty, this is a simple percent that is applied in the
             direction specified by the "should minimize" property of the score
             function.
             </summary>
            
             <param name="v">The current value.</param>
             <param name="bonus">The penalty.</param>
             <returns>The resulting value.</returns>
        </member>
        <member name="M:Encog.ML.Genetic.Genome.GenomeComparator.BestScore(System.Double,System.Double)">
             <summary>
             Determine the best score from two scores, uses the "should minimize"
             property of the score function.
             </summary>
            
             <param name="d1">The first score.</param>
             <param name="d2">The second score.</param>
             <returns>The best score.</returns>
        </member>
        <member name="M:Encog.ML.Genetic.Genome.GenomeComparator.IsBetterThan(System.Double,System.Double)">
             <summary>
             Determine if one score is better than the other.
             </summary>
            
             <param name="d1">The first score to compare.</param>
             <param name="d2">The second score to compare.</param>
             <returns>True if d1 is better than d2.</returns>
        </member>
        <member name="T:Encog.ML.Genetic.Innovation.BasicInnovation">
            <summary>
            Provides basic functionality for an innovation.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Innovation.BasicInnovation.InnovationID">
            <summary>
            Set the innovation id.
            </summary>
        </member>
        <member name="T:Encog.ML.Genetic.Innovation.BasicInnovationList">
             <summary>
             Provides basic functionality for a list of innovations.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Innovation.BasicInnovationList._list">
             <summary>
             The list of innovations.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.Innovation.BasicInnovationList.#ctor">
            <summary>
            Construct the object.
            </summary>
        </member>
        <member name="M:Encog.ML.Genetic.Innovation.BasicInnovationList.Add(Encog.ML.Genetic.Innovation.IInnovation)">
             <summary>
             Add an innovation.
             </summary>
            
             <param name="innovation">The innovation to add.</param>
        </member>
        <member name="M:Encog.ML.Genetic.Innovation.BasicInnovationList.Get(System.Int32)">
             <summary>
             Get a specific innovation, by index.
             </summary>
            
             <param name="id">The innovation index id.</param>
             <returns>The innovation.</returns>
        </member>
        <member name="P:Encog.ML.Genetic.Innovation.BasicInnovationList.Innovations">
            <value>A list of innovations.</value>
        </member>
        <member name="T:Encog.ML.Genetic.Innovation.IInnovation">
             <summary>
             Provides the interface for an innovation. An innovation is a enhancement that
             was tried to the genome.
             </summary>
            
        </member>
        <member name="P:Encog.ML.Genetic.Innovation.IInnovation.InnovationID">
            <summary>
            Set the innovation id.
            </summary>
        </member>
        <member name="T:Encog.ML.Genetic.Innovation.IInnovationList">
             <summary>
             Defines a list of innovations.
             </summary>
            
        </member>
        <member name="P:Encog.ML.Genetic.Innovation.IInnovationList.Innovations">
            <value>A list of innovations.</value>
        </member>
        <member name="M:Encog.ML.Genetic.Innovation.IInnovationList.Add(Encog.ML.Genetic.Innovation.IInnovation)">
             <summary>
             Add an innovation.
             </summary>
            
             <param name="innovation">The innovation added.</param>
        </member>
        <member name="M:Encog.ML.Genetic.Innovation.IInnovationList.Get(System.Int32)">
             <summary>
             Get the innovation specified by index.
             </summary>
            
             <param name="id">The index.</param>
             <returns>The innovation.</returns>
        </member>
        <member name="T:Encog.ML.Genetic.MateWorker">
             <summary>
             This class is used in conjunction with a thread pool. This allows the genetic
             algorithm to offload all of those calculations to a thread pool.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.MateWorker._child1">
             <summary>
             The first child.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.MateWorker._child2">
             <summary>
             The second child.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.MateWorker._father">
             <summary>
             The father.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.MateWorker._mother">
             <summary>
             The mother.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.MateWorker.#ctor(Encog.ML.Genetic.Genome.IGenome,Encog.ML.Genetic.Genome.IGenome,Encog.ML.Genetic.Genome.IGenome,Encog.ML.Genetic.Genome.IGenome)">
            <param name="theMother">The mother.</param>
            <param name="theFather">The father.</param>
            <param name="theChild1">The first child.</param>
            <param name="theChild2">The second child.</param>
        </member>
        <member name="M:Encog.ML.Genetic.MateWorker.Run">
             <summary>
             Mate the two chromosomes.
             </summary>
            
        </member>
        <member name="T:Encog.ML.Genetic.Mutate.IMutate">
             <summary>
             Defines how a chromosome is mutated.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.Mutate.IMutate.PerformMutation(Encog.ML.Genetic.Genome.Chromosome)">
             <summary>
             Perform a mutation on the specified chromosome.
             </summary>
            
             <param name="chromosome">The chromosome to mutate.</param>
        </member>
        <member name="T:Encog.ML.Genetic.Mutate.MutatePerturb">
             <summary>
             A simple mutation based on random numbers.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Mutate.MutatePerturb._perturbAmount">
             <summary>
             The amount to perturb by.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.Mutate.MutatePerturb.#ctor(System.Double)">
             <summary>
             Construct a perturb mutation.
             </summary>
            
             <param name="thePerturbAmount">The amount to mutate by(percent).</param>
        </member>
        <member name="M:Encog.ML.Genetic.Mutate.MutatePerturb.PerformMutation(Encog.ML.Genetic.Genome.Chromosome)">
             <summary>
             Perform a perturb mutation on the specified chromosome.
             </summary>
            
             <param name="chromosome">The chromosome to mutate.</param>
        </member>
        <member name="T:Encog.ML.Genetic.Mutate.MutateShuffle">
             <summary>
             A simple mutation where genes are shuffled.
             This mutation will not produce repeated genes.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.Mutate.MutateShuffle.PerformMutation(Encog.ML.Genetic.Genome.Chromosome)">
             <summary>
             Perform a shuffle mutation.
             </summary>
            
             <param name="chromosome">The chromosome to mutate.</param>
        </member>
        <member name="T:Encog.ML.Genetic.Population.BasicPopulation">
            <summary>
            Defines the basic functionality for a population of genomes.
            </summary>
        </member>
        <member name="F:Encog.ML.Genetic.Population.BasicPopulation.DefaultOldAgePenalty">
             <summary>
             Thed default old age penalty.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Population.BasicPopulation.DefaultOldAgeThreshold">
             <summary>
             The default old age threshold.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Population.BasicPopulation.DefaultSurvivalRate">
             <summary>
             The default survival rate.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Population.BasicPopulation.DefaultYouthBonus">
             <summary>
             The default youth penalty.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Population.BasicPopulation.DefaultYouthThreshold">
             <summary>
             The default youth threshold.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Population.BasicPopulation._geneIDGenerate">
             <summary>
             Generate gene id's.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Population.BasicPopulation._genomeIDGenerate">
             <summary>
             Generate genome id's.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Population.BasicPopulation._genomes">
             <summary>
             The population.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Population.BasicPopulation._innovationIDGenerate">
             <summary>
             Generate innovation id's.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Population.BasicPopulation._speciesIDGenerate">
             <summary>
             Generate species id's.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Population.BasicPopulation._youngBonusAgeThreshold">
             <summary>
             The young threshold.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.Population.BasicPopulation.#ctor">
             <summary>
             Construct an empty population.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.Population.BasicPopulation.#ctor(System.Int32)">
            <summary>
            Construct a population.
            </summary>
            <param name="thePopulationSize">The population size.</param>
        </member>
        <member name="P:Encog.ML.Genetic.Population.BasicPopulation.GeneIDGenerate">
            <value>the geneIDGenerate</value>
        </member>
        <member name="P:Encog.ML.Genetic.Population.BasicPopulation.GenomeIDGenerate">
            <value>the genomeIDGenerate</value>
        </member>
        <member name="P:Encog.ML.Genetic.Population.BasicPopulation.InnovationIDGenerate">
            <value>the innovationIDGenerate</value>
        </member>
        <member name="P:Encog.ML.Genetic.Population.BasicPopulation.Name">
            <summary>
            Set the name.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Population.BasicPopulation.SpeciesIDGenerate">
            <value>the speciesIDGenerate</value>
        </member>
        <member name="M:Encog.ML.Genetic.Population.BasicPopulation.Add(Encog.ML.Genetic.Genome.IGenome)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Genetic.Population.BasicPopulation.AssignGeneID">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Genetic.Population.BasicPopulation.AssignGenomeID">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Genetic.Population.BasicPopulation.AssignInnovationID">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Genetic.Population.BasicPopulation.AssignSpeciesID">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Genetic.Population.BasicPopulation.Claim(Encog.ML.Genetic.GeneticAlgorithm)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Genetic.Population.BasicPopulation.Clear">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Genetic.Population.BasicPopulation.Get(System.Int32)">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Genetic.Population.BasicPopulation.Best">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Genetic.Population.BasicPopulation.Genomes">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Genetic.Population.BasicPopulation.Innovations">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Genetic.Population.BasicPopulation.OldAgePenalty">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Genetic.Population.BasicPopulation.OldAgeThreshold">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Genetic.Population.BasicPopulation.PopulationSize">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Genetic.Population.BasicPopulation.Species">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Genetic.Population.BasicPopulation.SurvivalRate">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Genetic.Population.BasicPopulation.YoungBonusAgeThreshold">
            <value>the youngBonusAgeThreshold to set</value>
        </member>
        <member name="P:Encog.ML.Genetic.Population.BasicPopulation.YoungScoreBonus">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Genetic.Population.BasicPopulation.YoungBonusAgeThreshhold">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Genetic.Population.BasicPopulation.Size">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Genetic.Population.BasicPopulation.Sort">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Genetic.Population.IPopulation">
             <summary>
             Defines a population of genomes.
             </summary>
            
        </member>
        <member name="P:Encog.ML.Genetic.Population.IPopulation.Best">
            <value>The best genome in the population.</value>
        </member>
        <member name="P:Encog.ML.Genetic.Population.IPopulation.Genomes">
            <value>The genomes in the population.</value>
        </member>
        <member name="P:Encog.ML.Genetic.Population.IPopulation.Innovations">
            <summary>
            Set the innovations collection.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Population.IPopulation.OldAgePenalty">
            <summary>
            Set the old age penalty.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Population.IPopulation.OldAgeThreshold">
            <summary>
            Set the age at which a genome is considered "old".
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Population.IPopulation.PopulationSize">
            <summary>
            Set the max population size.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Population.IPopulation.Species">
            <value>A list of species.</value>
        </member>
        <member name="P:Encog.ML.Genetic.Population.IPopulation.SurvivalRate">
             <summary>
             Set the survival rate.
             </summary>
            
             <value>The survival rate.</value>
        </member>
        <member name="P:Encog.ML.Genetic.Population.IPopulation.YoungBonusAgeThreshold">
            <value>The age, below which, a genome is considered "young".</value>
        </member>
        <member name="P:Encog.ML.Genetic.Population.IPopulation.YoungScoreBonus">
            <summary>
            Set the youth score bonus.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Population.IPopulation.YoungBonusAgeThreshhold">
             <summary>
             Set the age at which genoms are considered young.
             </summary>
            
             <value>The age.</value>
        </member>
        <member name="M:Encog.ML.Genetic.Population.IPopulation.Add(Encog.ML.Genetic.Genome.IGenome)">
             <summary>
             Add a genome to the population.
             </summary>
            
             <param name="genome">The genome to add.</param>
        </member>
        <member name="M:Encog.ML.Genetic.Population.IPopulation.AssignGeneID">
            <returns>Assign a gene id.</returns>
        </member>
        <member name="M:Encog.ML.Genetic.Population.IPopulation.AssignGenomeID">
            <returns>Assign a genome id.</returns>
        </member>
        <member name="M:Encog.ML.Genetic.Population.IPopulation.AssignInnovationID">
            <returns>Assign an innovation id.</returns>
        </member>
        <member name="M:Encog.ML.Genetic.Population.IPopulation.AssignSpeciesID">
            <returns>Assign a species id.</returns>
        </member>
        <member name="M:Encog.ML.Genetic.Population.IPopulation.Clear">
             <summary>
             Clear all genomes from this population.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.Population.IPopulation.Get(System.Int32)">
             <summary>
             Get a genome by index.  Index 0 is the best genome.
             </summary>
            
             <param name="i">The genome to get.</param>
             <returns>The genome at the specified index.</returns>
        </member>
        <member name="M:Encog.ML.Genetic.Population.IPopulation.Size">
            <returns>The size of the population.</returns>
        </member>
        <member name="M:Encog.ML.Genetic.Population.IPopulation.Sort">
             <summary>
             Sort the population by best score.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.Population.IPopulation.Claim(Encog.ML.Genetic.GeneticAlgorithm)">
             <summary>
             Claim the population, before training.
             </summary>
            
             <param name="ga">The GA that is claiming.</param>
        </member>
        <member name="T:Encog.ML.Genetic.Population.PopulationConst">
            <summary>
            Constants for the population.
            </summary>
        </member>
        <member name="F:Encog.ML.Genetic.Population.PopulationConst.PropertyNextGeneID">
             <summary>
             Property tag for the next gene id.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Population.PopulationConst.PropertyNextGenomeID">
             <summary>
             Property tag for the next genome id.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Population.PopulationConst.PropertyNextInnovationID">
             <summary>
             Property tag for the next innovation id.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Population.PopulationConst.PropertyNextSpeciesID">
             <summary>
             Property tag for the next species id.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Population.PopulationConst.PropertyOldAgePenalty">
             <summary>
             Property tag for the old age penalty.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Population.PopulationConst.PropertyOldAgeThreshold">
             <summary>
             Property tag for the old age threshold.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Population.PopulationConst.PropertyPopulationSize">
             <summary>
             Property tag for the population size.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Population.PopulationConst.PropertySurvivalRate">
             <summary>
             Property tag for the survival rate.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Population.PopulationConst.PropertyYoungAgeBonus">
             <summary>
             Property tag for the young age bonus.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Population.PopulationConst.PropertyYoungAgeThreshold">
             <summary>
             Property tag for the young age threshold.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Population.PopulationConst.PropertyGenomes">
             <summary>
             Property tag for the genomes collection.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Population.PopulationConst.PropertyInnovations">
             <summary>
             Property tag for the innovations collection.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Population.PopulationConst.PropertySpecies">
             <summary>
             Property tag for the species collection.
             </summary>
            
        </member>
        <member name="T:Encog.ML.Genetic.Selection.IParentSelection">
             <summary>
             Will be expanded in the future.  Will define how
             parents are selected.
             </summary>
            
        </member>
        <member name="T:Encog.ML.Genetic.Selection.TruncateSelection">
             <summary>
             Will be expanded in the future, will define a way
             parents are selected.
             </summary>
            
        </member>
        <member name="T:Encog.ML.Genetic.Species.BasicSpecies">
             <summary>
             Provides basic functionality for a species.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Species.BasicSpecies._members">
             <summary>
             The list of genomes.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Species.BasicSpecies._age">
             <summary>
             The age of this species.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Species.BasicSpecies._bestScore">
             <summary>
             The best score.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Species.BasicSpecies._gensNoImprovement">
             <summary>
             The number of generations with no improvement.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Species.BasicSpecies._leader">
             <summary>
             The leader.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Species.BasicSpecies._leaderID">
            <summary>
            The id of the leader.
            </summary>
        </member>
        <member name="F:Encog.ML.Genetic.Species.BasicSpecies._population">
             <summary>
             The owner class.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Species.BasicSpecies._spawnsRequired">
             <summary>
             The number of spawns required.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Genetic.Species.BasicSpecies._speciesID">
             <summary>
             The species id.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.Species.BasicSpecies.#ctor">
             <summary>
             Default constructor, used mainly for persistence.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.Species.BasicSpecies.#ctor(Encog.ML.Genetic.Population.IPopulation,Encog.ML.Genetic.Genome.IGenome,System.Int64)">
             <summary>
             Construct a species.
             </summary>
            
             <param name="thePopulation">The population the species belongs to.</param>
             <param name="theFirst">The first genome in the species.</param>
             <param name="theSpeciesID">The species id.</param>
        </member>
        <member name="P:Encog.ML.Genetic.Species.BasicSpecies.Population">
            <value>the population to set</value>
        </member>
        <member name="P:Encog.ML.Genetic.Species.BasicSpecies.TempLeaderID">
             <summary>
             Set the leader id. This value is not persisted, it is used only for
             loading.
             </summary>
            
             <value>the leaderID to set</value>
        </member>
        <member name="M:Encog.ML.Genetic.Species.BasicSpecies.CalculateSpawnAmount">
             <summary>
             Calculate the amount to spawn.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.Species.BasicSpecies.ChooseParent">
             <summary>
             Choose a parent to mate. Choose from the population, determined by the
             survival rate. From this pool, a random parent is chosen.
             </summary>
            
             <returns>The parent.</returns>
        </member>
        <member name="P:Encog.ML.Genetic.Species.BasicSpecies.Age">
             <summary>
             Set the age of this species.
             </summary>
            
             <value>The age of this species.</value>
        </member>
        <member name="P:Encog.ML.Genetic.Species.BasicSpecies.BestScore">
             <summary>
             Set the best score.
             </summary>
            
             <value>The best score.</value>
        </member>
        <member name="P:Encog.ML.Genetic.Species.BasicSpecies.GensNoImprovement">
             <summary>
             Set the number of generations with no improvement.
             </summary>
            
             <value>The number of generations.</value>
        </member>
        <member name="P:Encog.ML.Genetic.Species.BasicSpecies.Leader">
             <summary>
             Set the leader.
             </summary>
            
             <value>The new leader.</value>
        </member>
        <member name="P:Encog.ML.Genetic.Species.BasicSpecies.Members">
            <value>The members of this species.</value>
        </member>
        <member name="P:Encog.ML.Genetic.Species.BasicSpecies.NumToSpawn">
            <value>The number to spawn.</value>
        </member>
        <member name="P:Encog.ML.Genetic.Species.BasicSpecies.SpawnsRequired">
            <summary>
            Set the number of spawns required.
            </summary>
        </member>
        <member name="M:Encog.ML.Genetic.Species.BasicSpecies.Purge">
             <summary>
             Purge all members, increase age by one and count the number of
             generations with no improvement.
             </summary>
            
        </member>
        <member name="P:Encog.ML.Genetic.Species.BasicSpecies.SpeciesID">
            <summary>
            Set the species id.
            </summary>
        </member>
        <member name="T:Encog.ML.Genetic.Species.ISpecies">
             <summary>
             Defines the features used in a species. A species is a group of genomes.
             </summary>
            
        </member>
        <member name="P:Encog.ML.Genetic.Species.ISpecies.Age">
            <summary>
            Set the age of this species.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Species.ISpecies.BestScore">
            <summary>
            Set the best score.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Species.ISpecies.GensNoImprovement">
            <summary>
            Set the number of generations with no improvement.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Species.ISpecies.Leader">
            <summary>
            Set the leader of this species.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Species.ISpecies.Members">
            <value>The numbers of this species.</value>
        </member>
        <member name="P:Encog.ML.Genetic.Species.ISpecies.NumToSpawn">
            <value>The number of genomes this species will try to spawn into the
            next generation.</value>
        </member>
        <member name="P:Encog.ML.Genetic.Species.ISpecies.SpawnsRequired">
            <summary>
            Set the number of spawns required.
            </summary>
        </member>
        <member name="P:Encog.ML.Genetic.Species.ISpecies.SpeciesID">
            <value>The species ID.</value>
        </member>
        <member name="M:Encog.ML.Genetic.Species.ISpecies.CalculateSpawnAmount">
             <summary>
             Calculate the amount that a species will spawn.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Genetic.Species.ISpecies.ChooseParent">
             <summary>
             Choose a worthy parent for mating.
             </summary>
            
             <returns>The parent genome.</returns>
        </member>
        <member name="M:Encog.ML.Genetic.Species.ISpecies.Purge">
             <summary>
             Purge old unsuccessful genomes.
             </summary>
            
        </member>
        <member name="T:Encog.ML.HMM.Alog.ForwardBackwardCalculator">
            <summary>
            The forward-backward algorithm is an inference algorithm for hidden Markov
            models which computes the posterior marginals of all hidden state variables
            given a sequence of observations.
            </summary>
        </member>
        <member name="F:Encog.ML.HMM.Alog.ForwardBackwardCalculator.Alpha">
            <summary>
            Alpha matrix.
            </summary>
        </member>
        <member name="F:Encog.ML.HMM.Alog.ForwardBackwardCalculator.Beta">
            <summary>
            Beta matrix.
            </summary>
        </member>
        <member name="F:Encog.ML.HMM.Alog.ForwardBackwardCalculator.probability">
            <summary>
            Probability.
            </summary>
        </member>
        <member name="M:Encog.ML.HMM.Alog.ForwardBackwardCalculator.#ctor">
            <summary>
            Construct an empty object.
            </summary>
        </member>
        <member name="M:Encog.ML.HMM.Alog.ForwardBackwardCalculator.#ctor(Encog.ML.Data.IMLDataSet,Encog.ML.HMM.HiddenMarkovModel)">
            <summary>
            Construct the forward/backward calculator. 
            </summary>
            <param name="oseq">The sequence to use.</param>
            <param name="hmm">THe hidden markov model to use.</param>
        </member>
        <member name="M:Encog.ML.HMM.Alog.ForwardBackwardCalculator.#ctor(Encog.ML.Data.IMLDataSet,Encog.ML.HMM.HiddenMarkovModel,System.Boolean,System.Boolean)">
            <summary>
            Construct the object. 
            </summary>
            <param name="oseq">The sequence.</param>
            <param name="hmm">The hidden markov model to use.</param>
            <param name="doAlpha">Do alpha?</param>
            <param name="doBeta">Do beta?</param>
        </member>
        <member name="M:Encog.ML.HMM.Alog.ForwardBackwardCalculator.AlphaElement(System.Int32,System.Int32)">
            <summary>
            Alpha element.
            </summary>
            <param name="t">The row.</param>
            <param name="i">The column.</param>
            <returns>The element.</returns>
        </member>
        <member name="M:Encog.ML.HMM.Alog.ForwardBackwardCalculator.BetaElement(System.Int32,System.Int32)">
            <summary>
            Beta element, best element. 
            </summary>
            <param name="t">From.</param>
            <param name="i">To.</param>
            <returns>The element.</returns>
        </member>
        <member name="M:Encog.ML.HMM.Alog.ForwardBackwardCalculator.ComputeAlpha(Encog.ML.HMM.HiddenMarkovModel,Encog.ML.Data.IMLDataSet)">
            <summary>
            Compute alpha. 
            </summary>
            <param name="hmm">The hidden markov model.</param>
            <param name="oseq">The sequence.</param>
        </member>
        <member name="M:Encog.ML.HMM.Alog.ForwardBackwardCalculator.ComputeAlphaInit(Encog.ML.HMM.HiddenMarkovModel,Encog.ML.Data.IMLDataPair,System.Int32)">
            <summary>
            Compute the alpha init. 
            </summary>
            <param name="hmm">THe hidden markov model.</param>
            <param name="o">The element.</param>
            <param name="i">The state.</param>
        </member>
        <member name="M:Encog.ML.HMM.Alog.ForwardBackwardCalculator.ComputeAlphaStep(Encog.ML.HMM.HiddenMarkovModel,Encog.ML.Data.IMLDataPair,System.Int32,System.Int32)">
            <summary>
            Compute the alpha step. 
            </summary>
            <param name="hmm">The hidden markov model.</param>
            <param name="o">The sequence element.</param>
            <param name="t">The alpha step.</param>
            <param name="j">The column.</param>
        </member>
        <member name="M:Encog.ML.HMM.Alog.ForwardBackwardCalculator.ComputeBeta(Encog.ML.HMM.HiddenMarkovModel,Encog.ML.Data.IMLDataSet)">
            <summary>
            Compute the beta step. 
            </summary>
            <param name="hmm">The hidden markov model.</param>
            <param name="oseq">The sequence.</param>
        </member>
        <member name="M:Encog.ML.HMM.Alog.ForwardBackwardCalculator.ComputeBetaStep(Encog.ML.HMM.HiddenMarkovModel,Encog.ML.Data.IMLDataPair,System.Int32,System.Int32)">
            <summary>
            Compute the beta step. 
            </summary>
            <param name="hmm">The hidden markov model.</param>
            <param name="o">THe data par to compute.</param>
            <param name="t">THe matrix row.</param>
            <param name="i">THe matrix column.</param>
        </member>
        <member name="M:Encog.ML.HMM.Alog.ForwardBackwardCalculator.ComputeProbability(Encog.ML.Data.IMLDataSet,Encog.ML.HMM.HiddenMarkovModel,System.Boolean,System.Boolean)">
            <summary>
            Compute the probability. 
            </summary>
            <param name="oseq">The sequence.</param>
            <param name="hmm">THe hidden markov model.</param>
            <param name="doAlpha">Perform alpha step?</param>
            <param name="doBeta">Perform beta step?</param>
        </member>
        <member name="M:Encog.ML.HMM.Alog.ForwardBackwardCalculator.Probability">
            <summary>
            The probability.
            </summary>
            <returns>The probability.</returns>
        </member>
        <member name="T:Encog.ML.HMM.Alog.ForwardBackwardScaledCalculator">
            <summary>
            The forward-backward algorithm is an inference algorithm for hidden Markov
            models which computes the posterior marginals of all hidden state variables
            given a sequence of observations. This version makes use of scaling, and will
            not generate underflows with long sequences.
            </summary>
        </member>
        <member name="F:Encog.ML.HMM.Alog.ForwardBackwardScaledCalculator._ctFactors">
            <summary>
            The factors.
            </summary>
        </member>
        <member name="F:Encog.ML.HMM.Alog.ForwardBackwardScaledCalculator._lnProbability">
            <summary>
            Log probability.
            </summary>
        </member>
        <member name="M:Encog.ML.HMM.Alog.ForwardBackwardScaledCalculator.#ctor(Encog.ML.Data.IMLDataSet,Encog.ML.HMM.HiddenMarkovModel)">
            <summary>
            Construct the calculator.
            </summary>
            <param name="seq">The sequences.</param>
            <param name="hmm">The Hidden Markov Model.</param>
        </member>
        <member name="M:Encog.ML.HMM.Alog.ForwardBackwardScaledCalculator.#ctor(Encog.ML.Data.IMLDataSet,Encog.ML.HMM.HiddenMarkovModel,System.Boolean,System.Boolean)">
            <summary>
            Construct the calculator.
            </summary>
            <param name="seq">The sequence.</param>
            <param name="hmm">The HMM.</param>
            <param name="doAlpha">Should alpha be calculated.</param>
            <param name="doBeta">Should beta be calculated.</param>
        </member>
        <member name="M:Encog.ML.HMM.Alog.ForwardBackwardScaledCalculator.ComputeAlpha(Encog.ML.HMM.HiddenMarkovModel,Encog.ML.Data.IMLDataSet)">
            <summary>
            Compute alpha.
            </summary>
            <param name="hmm">The HMM.</param>
            <param name="seq">The sequence.</param>
        </member>
        <member name="M:Encog.ML.HMM.Alog.ForwardBackwardScaledCalculator.ComputeBeta(Encog.ML.HMM.HiddenMarkovModel,Encog.ML.Data.IMLDataSet)">
            <summary>
            Compute beta.
            </summary>
            <param name="hmm">The HMM.</param>
            <param name="oseq">The sequence.</param>
        </member>
        <member name="M:Encog.ML.HMM.Alog.ForwardBackwardScaledCalculator.ComputeProbability(Encog.ML.Data.IMLDataSet,Encog.ML.HMM.HiddenMarkovModel,System.Boolean,System.Boolean)">
            <summary>
            Compute the probability.
            </summary>
            <param name="seq">The sequence.</param>
            <param name="hmm">The HMM.</param>
            <param name="doAlha">The alpha.</param>
            <param name="doBeta">The beta.</param>
        </member>
        <member name="T:Encog.ML.HMM.Alog.KullbackLeiblerDistanceCalculator">
            <summary>
            This class produces a Kullback-Leibler estimation of the distance between two
            HMMs. This allows the similarity of two different HMM's to be evaluated.
            
            ^ Kullback, S.; Leibler, R.A. (1951). "On Information and Sufficiency".
            Annals of Mathematical Statistics 22 (1): 79-86. doi:10.1214/aoms/1177729694.
            MR39968.
            </summary>
        </member>
        <member name="T:Encog.ML.HMM.Alog.MarkovGenerator">
            <summary>
            This class is used to generate random sequences based on a Hidden Markov
            Model. These sequences represent the random probabilities that the HMM
            models.
            </summary>
        </member>
        <member name="T:Encog.ML.HMM.Alog.ViterbiCalculator">
            <summary>
            The Viterbi algorithm is used to find the most likely sequence of hidden
            states (called the Viterbi path) that results in a sequence of observed
            events. Used for the Markov information sources, and more generally, hidden
            Markov models (HMM).
            
            Viterbi AJ (April 1967).
            "Error bounds for convolutional codes and an asymptotically optimum decoding algorithm"
            . IEEE Transactions on Information Theory 13 (2): 260-269.
            doi:10.1109/TIT.1967.1054010.
            </summary>
        </member>
        <member name="T:Encog.ML.HMM.Distributions.ContinousDistribution">
            <summary>
            A continuous distribution represents an infinite range of choices between two
            real numbers. A gaussian distribution is used to distribute the probability.
            </summary>
        </member>
        <member name="F:Encog.ML.HMM.Distributions.ContinousDistribution._covariance">
            <summary>
            The covariance matrix.
            </summary>
        </member>
        <member name="F:Encog.ML.HMM.Distributions.ContinousDistribution._dimension">
            <summary>
            The dimensions.
            </summary>
        </member>
        <member name="F:Encog.ML.HMM.Distributions.ContinousDistribution._mean">
            <summary>
            The means for each dimension.
            </summary>
        </member>
        <member name="F:Encog.ML.HMM.Distributions.ContinousDistribution._randomizer">
            <summary>
            Random number generator.
            </summary>
        </member>
        <member name="F:Encog.ML.HMM.Distributions.ContinousDistribution._cd">
            <summary>
            Used to perform a decomposition.
            </summary>
        </member>
        <member name="F:Encog.ML.HMM.Distributions.ContinousDistribution._covarianceDet">
            <summary>
            The covariance determinant.
            </summary>
        </member>
        <member name="F:Encog.ML.HMM.Distributions.ContinousDistribution._covarianceInv">
            <summary>
            The covariance inverse.
            </summary>
        </member>
        <member name="F:Encog.ML.HMM.Distributions.ContinousDistribution._covarianceL">
            <summary>
            The covariance left side.
            </summary>
        </member>
        <member name="M:Encog.ML.HMM.Distributions.ContinousDistribution.#ctor(System.Double[],System.Double[][])">
            <summary>
            Construct a continuous distribution. 
            </summary>
            <param name="mean">The mean.</param>
            <param name="covariance">The covariance.</param>
        </member>
        <member name="M:Encog.ML.HMM.Distributions.ContinousDistribution.#ctor(System.Int32)">
            <summary>
            Construct a continuous distribution with the specified number of dimensions. 
            </summary>
            <param name="dimension">The dimensions.</param>
        </member>
        <member name="P:Encog.ML.HMM.Distributions.ContinousDistribution.Mean">
            <summary>
            The mean for the dimensions of the gaussian curve.
            </summary>
        </member>
        <member name="P:Encog.ML.HMM.Distributions.ContinousDistribution.Covariance">
            <summary>
            The covariance matrix.
            </summary>
        </member>
        <member name="M:Encog.ML.HMM.Distributions.ContinousDistribution.Fit(Encog.ML.Data.IMLDataSet)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.HMM.Distributions.ContinousDistribution.Fit(Encog.ML.Data.IMLDataSet,System.Double[])">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.HMM.Distributions.ContinousDistribution.Generate">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.HMM.Distributions.ContinousDistribution.Probability(Encog.ML.Data.IMLDataPair)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.HMM.Distributions.ContinousDistribution.Encog#ML#HMM#Distributions#IStateDistribution#Clone">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.HMM.Distributions.ContinousDistribution.Update(System.Double[][])">
            <summary>
            Update the covariance.  
            </summary>
            <param name="covariance">The new covariance.</param>
        </member>
        <member name="T:Encog.ML.HMM.Distributions.DiscreteDistribution">
            <summary>
            A discrete distribution is a distribution with a finite set of states that it
            can be in.
            </summary>
        </member>
        <member name="F:Encog.ML.HMM.Distributions.DiscreteDistribution._probabilities">
            <summary>
            The probabilities of moving between states.
            </summary>
        </member>
        <member name="M:Encog.ML.HMM.Distributions.DiscreteDistribution.#ctor(System.Double[][])">
            <summary>
            Construct a discrete distribution with the specified probabilities.
            </summary>
            <param name="theProbabilities">The probabilities.</param>
        </member>
        <member name="M:Encog.ML.HMM.Distributions.DiscreteDistribution.#ctor(System.Int32[])">
            <summary>
            Construct a discrete distribution.
            </summary>
            <param name="cx">The count of each.</param>
        </member>
        <member name="P:Encog.ML.HMM.Distributions.DiscreteDistribution.Probabilities">
            <summary>
            The state probabilities.
            </summary>
        </member>
        <member name="M:Encog.ML.HMM.Distributions.DiscreteDistribution.Fit(Encog.ML.Data.IMLDataSet)">
            <summary>
            Fit this distribution to the specified data.
            </summary>
            <param name="co">THe data to fit to.</param>
        </member>
        <member name="M:Encog.ML.HMM.Distributions.DiscreteDistribution.Fit(Encog.ML.Data.IMLDataSet,System.Double[])">
            <summary>
            Fit this distribution to the specified data, with weights. 
            </summary>
            <param name="co">The data to fit to.</param>
            <param name="weights">The weights.</param>
        </member>
        <member name="M:Encog.ML.HMM.Distributions.DiscreteDistribution.Generate">
            <summary>
            Generate a random sequence.
            </summary>
            <returns>The random element.</returns>
        </member>
        <member name="M:Encog.ML.HMM.Distributions.DiscreteDistribution.Probability(Encog.ML.Data.IMLDataPair)">
            <summary>
            Determine the probability of the specified data pair. 
            </summary>
            <param name="o">THe data pair.</param>
            <returns>The probability.</returns>
        </member>
        <member name="M:Encog.ML.HMM.Distributions.DiscreteDistribution.Encog#ML#HMM#Distributions#IStateDistribution#Clone">
            <summary>
            Clone.
            </summary>
            <returns>A clone of the distribution.</returns>
        </member>
        <member name="T:Encog.ML.HMM.Distributions.IStateDistribution">
            <summary>
            This class represents a "state distribution". This is the means by which the
            probabilities between the states and observations are mapped. Currently two
            are supported. Use ContinousDistribution to use a Gaussian-based continuous
            distribution. Use DiscreteDistribution for a item-based distribution.
            </summary>
        </member>
        <member name="M:Encog.ML.HMM.Distributions.IStateDistribution.Clone">
            <summary>
            Clone this distribution.
            </summary>
            <returns>A clone of this distribution.</returns>
        </member>
        <member name="M:Encog.ML.HMM.Distributions.IStateDistribution.Fit(Encog.ML.Data.IMLDataSet)">
            <summary>
            Fit this distribution to the specified data set.
            </summary>
            <param name="set">The data set to fit to.</param>
        </member>
        <member name="M:Encog.ML.HMM.Distributions.IStateDistribution.Fit(Encog.ML.Data.IMLDataSet,System.Double[])">
            <summary>
            Fit this distribution to the specified data set, given the specified
            weights, per element. 
            </summary>
            <param name="set">The data set to fit to.</param>
            <param name="weights">The weights.</param>
        </member>
        <member name="M:Encog.ML.HMM.Distributions.IStateDistribution.Generate">
            <summary>
            Generate a random data pair, based on the probabilities.
            </summary>
            <returns>A random data pair.</returns>
        </member>
        <member name="M:Encog.ML.HMM.Distributions.IStateDistribution.Probability(Encog.ML.Data.IMLDataPair)">
            <summary>
            Determine the probability of the specified data pair.
            </summary>
            <param name="o">The pair to consider.</param>
            <returns>The probability.</returns>
        </member>
        <!-- Проигнорирован некорректный комментарий XML для члена "T:Encog.ML.HMM.HiddenMarkovModel" -->
        <member name="F:Encog.ML.HMM.HiddenMarkovModel.pi">
            <summary>
            The initial probabilities for each state.
            </summary>
        </member>
        <member name="F:Encog.ML.HMM.HiddenMarkovModel._transitionProbability">
            <summary>
            The transitional probabilities between the states.
            </summary>
        </member>
        <member name="M:Encog.ML.HMM.HiddenMarkovModel.#ctor(System.Int32)">
            <summary>
            Construct a discrete HMM with the specified number of states.
            </summary>
            <param name="states">The number of states.</param>
        </member>
        <member name="P:Encog.ML.HMM.HiddenMarkovModel.Pi">
            <summary>
            Initial state probabilities.
            </summary>
        </member>
        <member name="P:Encog.ML.HMM.HiddenMarkovModel.TransitionProbability">
            <summary>
            The probabilities of moving from one state to another.
            </summary>
        </member>
        <member name="T:Encog.ML.HMM.PersistHMM">
            <summary>
            Persist a HMM.
            </summary>
        </member>
        <member name="P:Encog.ML.HMM.PersistHMM.FileVersion">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.HMM.PersistHMM.PersistClassString">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.HMM.PersistHMM.Read(System.IO.Stream)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.HMM.PersistHMM.Save(System.IO.Stream,System.Object)">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.HMM.PersistHMM.NativeType">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.HMM.Train.BW.BaseBaumWelch">
            <summary>
            This class provides the base implementation for Baum-Welch learning for
            HMM's. There are currently two implementations provided.
            
            TrainBaumWelch - Regular Baum Welch Learning.
            
            TrainBaumWelchScaled - Regular Baum Welch Learning, which can handle
            underflows in long sequences.
            
            L. E. Baum, T. Petrie, G. Soules, and N. Weiss,
            "A maximization technique occurring in the statistical analysis of probabilistic functions of Markov chains"
            , Ann. Math. Statist., vol. 41, no. 1, pp. 164-171, 1970.
            
            Hidden Markov Models and the Baum-Welch Algorithm, IEEE Information Theory
            </summary>
        </member>
        <member name="T:Encog.ML.HMM.Train.BW.TrainBaumWelch">
            <summary>
            Baum Welch Learning allows a HMM to be constructed from a series of sequence
            observations. This implementation of Baum Welch does not scale and is
            susceptible to underflows in long sequences of data.
            
            Baum Welch requires a starting point. You should create a HMM that has a
            reasonable guess as to the observation and transition probabilities. If you
            can make no such guess, you should consider using KMeans training.
            
            L. E. Baum, T. Petrie, G. Soules, and N. Weiss,
            "A maximization technique occurring in the statistical analysis of probabilistic functions of Markov chains"
            , Ann. Math. Statist., vol. 41, no. 1, pp. 164-171, 1970.
            
            Hidden Markov Models and the Baum-Welch Algorithm, IEEE Information Theory
            Society Newsletter, Dec. 2003.
            </summary>
        </member>
        <member name="T:Encog.ML.HMM.Train.BW.TrainBaumWelchScaled">
            <summary>
            Baum Welch Learning allows a HMM to be constructed from a series of sequence
            observations. This implementation of Baum Welch scales and is not as 
            susceptible to underflows in long sequences of data as the regular Baum Welch
            algorithm.
            
            Baum Welch requires a starting point.  You should create a HMM that has a
            reasonable guess as to the observation and transition probabilities.  If you 
            can make no such guess, you should consider using KMeans training.
            
            L. E. Baum, T. Petrie, G. Soules, and N. Weiss,
            "A maximization technique occurring in the statistical analysis of probabilistic functions of Markov chains"
            , Ann. Math. Statist., vol. 41, no. 1, pp. 164-171, 1970.
            
            Hidden Markov Models and the Baum-Welch Algorithm, IEEE Information Theory
            Society Newsletter, Dec. 2003.
            </summary>
        </member>
        <member name="T:Encog.ML.HMM.Train.KMeans.Clusters">
            <summary>
            Clusters used for the KMeans HMM training algorithm.
            </summary>
        </member>
        <member name="F:Encog.ML.HMM.Train.KMeans.Clusters._clusters">
            <summary>
            A list of all of the clusters.
            </summary>
        </member>
        <member name="F:Encog.ML.HMM.Train.KMeans.Clusters._clustersHash">
            <summary>
            Provide quick access to the clusters.
            </summary>
        </member>
        <member name="M:Encog.ML.HMM.Train.KMeans.Clusters.#ctor(System.Int32,Encog.ML.Data.IMLDataSet)">
            <summary>
            Construct the clusters objects. 
            </summary>
            <param name="k">The number of clusters to have.</param>
            <param name="observations">The observations.</param>
        </member>
        <member name="M:Encog.ML.HMM.Train.KMeans.Clusters.Cluster(System.Int32)">
            <summary>
            Get the speicified cluster. 
            </summary>
            <param name="n">The number.</param>
            <returns>The items in that cluster.</returns>
        </member>
        <member name="M:Encog.ML.HMM.Train.KMeans.Clusters.Cluster(Encog.ML.Data.IMLDataPair)">
            <summary>
            Get the cluster for the specified data pair. 
            </summary>
            <param name="o">The data pair to use..</param>
            <returns>The cluster the pair is in.</returns>
        </member>
        <member name="M:Encog.ML.HMM.Train.KMeans.Clusters.IsInCluster(Encog.ML.Data.IMLDataPair,System.Int32)">
            <summary>
            Determine if the specified object is in one of the clusters. 
            </summary>
            <param name="o">The object to check.</param>
            <param name="x">The cluster.</param>
            <returns>True if the object is in the cluster.</returns>
        </member>
        <member name="M:Encog.ML.HMM.Train.KMeans.Clusters.Put(Encog.ML.Data.IMLDataPair,System.Int32)">
            <summary>
            Put an object into the specified cluster. 
            </summary>
            <param name="o">The object.</param>
            <param name="n">The cluster number.</param>
        </member>
        <member name="M:Encog.ML.HMM.Train.KMeans.Clusters.Remove(Encog.ML.Data.IMLDataPair,System.Int32)">
            <summary>
            Remove an object from the specified cluster. 
            </summary>
            <param name="o">The object to remove.</param>
            <param name="n">The cluster to remove from.</param>
        </member>
        <member name="T:Encog.ML.HMM.Train.KMeans.TrainKMeans">
            <summary>
            Train a Hidden Markov Model (HMM) with the KMeans algorithm. Makes use of
            KMeans clustering to estimate the transitional and observational
            probabilities for the HMM.
            
            Unlike Baum Welch training, this method does not require a prior estimate of
            the HMM model, it starts from scratch.
            
            Faber, Clustering and the Continuous k-Means Algorithm, Los Alamos Science,
            no. 22, 1994.
            </summary>
        </member>
        <member name="F:Encog.ML.HMM.Train.KMeans.TrainKMeans._clusters">
            <summary>
            The clusters.
            </summary>
        </member>
        <member name="F:Encog.ML.HMM.Train.KMeans.TrainKMeans._modelHmm">
            <summary>
            The HMM to use as a model.
            </summary>
        </member>
        <member name="F:Encog.ML.HMM.Train.KMeans.TrainKMeans._states">
            <summary>
            The number of states.
            </summary>
        </member>
        <member name="F:Encog.ML.HMM.Train.KMeans.TrainKMeans._training">
            <summary>
            The training data.
            </summary>
        </member>
        <member name="F:Encog.ML.HMM.Train.KMeans.TrainKMeans._done">
            <summary>
            Keep track of if we are done.
            </summary>
        </member>
        <member name="F:Encog.ML.HMM.Train.KMeans.TrainKMeans._method">
            <summary>
            The current HMM.
            </summary>
        </member>
        <member name="M:Encog.ML.HMM.Train.KMeans.TrainKMeans.#ctor(Encog.ML.HMM.HiddenMarkovModel,Encog.ML.Data.IMLSequenceSet)">
            <summary>
            Construct a KMeans trainer. 
            </summary>
            <param name="method">The HMM.</param>
            <param name="sequences">The training data.</param>
        </member>
        <member name="P:Encog.ML.HMM.Train.KMeans.TrainKMeans.IterationNumber">
            <summary>
            The iteration number that we are currently on.
            </summary>
        </member>
        <member name="M:Encog.ML.HMM.Train.KMeans.TrainKMeans.AddStrategy(Encog.ML.Train.Strategy.IStrategy)">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.HMM.Train.KMeans.TrainKMeans.CanContinue">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.HMM.Train.KMeans.TrainKMeans.FinishTraining">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.HMM.Train.KMeans.TrainKMeans.Error">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.HMM.Train.KMeans.TrainKMeans.ImplementationType">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.HMM.Train.KMeans.TrainKMeans.Method">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.HMM.Train.KMeans.TrainKMeans.Strategies">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.HMM.Train.KMeans.TrainKMeans.Training">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.HMM.Train.KMeans.TrainKMeans.TrainingDone">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.HMM.Train.KMeans.TrainKMeans.Iteration">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.HMM.Train.KMeans.TrainKMeans.Iteration(System.Int32)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.HMM.Train.KMeans.TrainKMeans.Pause">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.HMM.Train.KMeans.TrainKMeans.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.HMM.Train.KMeans.TrainKMeans.LearnOpdf(Encog.ML.HMM.HiddenMarkovModel)">
            <summary>
            Learn the distribution. 
            </summary>
            <param name="hmm">The HMM.</param>
        </member>
        <member name="M:Encog.ML.HMM.Train.KMeans.TrainKMeans.LearnPi(Encog.ML.HMM.HiddenMarkovModel)">
            <summary>
            Learn Pi, the starting probabilities. 
            </summary>
            <param name="hmm">The HMM.</param>
        </member>
        <member name="M:Encog.ML.HMM.Train.KMeans.TrainKMeans.LearnTransition(Encog.ML.HMM.HiddenMarkovModel)">
            <summary>
            Learn the state transitions. 
            </summary>
            <param name="hmm">The HMM.</param>
        </member>
        <member name="M:Encog.ML.HMM.Train.KMeans.TrainKMeans.OptimizeCluster(Encog.ML.HMM.HiddenMarkovModel)">
            <summary>
            Optimize the clusters. 
            </summary>
            <param name="hmm">The HMM.</param>
            <returns>True if the cluster was not modified.</returns>
        </member>
        <member name="T:Encog.ML.IMLStateSequence">
            <summary>
            A state sequence ML method, for example a Hidden Markov Model.
            </summary>
        </member>
        <member name="M:Encog.ML.IMLStateSequence.GetStatesForSequence(Encog.ML.Data.IMLDataSet)">
            <summary>
            Get the sates for the given sequence.
            </summary>
            <param name="oseq">The sequence.</param>
            <returns>The states.</returns>
        </member>
        <member name="M:Encog.ML.IMLStateSequence.Probability(Encog.ML.Data.IMLDataSet)">
            <summary>
            Determine the probability of the specified sequence.
            </summary>
            <param name="oseq">The sequence.</param>
            <returns>The probability.</returns>
        </member>
        <member name="M:Encog.ML.IMLStateSequence.Probability(Encog.ML.Data.IMLDataSet,System.Int32[])">
            <summary>
            Determine the probability for the specified sequence and states.
            </summary>
            <param name="seq">The sequence.</param>
            <param name="states">The states.</param>
            <returns>The probability.</returns>
        </member>
        <member name="T:Encog.ML.KMeans.BasicCluster">
            <summary>
            Holds a cluster of MLData items that have been clustered 
            by the KMeansClustering class.
            </summary>
        </member>
        <member name="F:Encog.ML.KMeans.BasicCluster._data">
            <summary>
            The contents of the cluster.
            </summary>
        </member>
        <member name="M:Encog.ML.KMeans.BasicCluster.#ctor(Encog.Util.KMeans.Cluster{Encog.ML.Data.Basic.BasicMLDataPair})">
            <summary>
            Construct a cluster from another. 
            </summary>
            <param name="cluster">The other cluster.</param>
        </member>
        <member name="P:Encog.ML.KMeans.BasicCluster.Centroid">
            <summary>
            The centroid.
            </summary>
        </member>
        <member name="M:Encog.ML.KMeans.BasicCluster.Add(Encog.ML.Data.IMLData)">
            <summary>
            Add to the cluster. 
            </summary>
            <param name="pair">The pair to add.</param>
        </member>
        <member name="M:Encog.ML.KMeans.BasicCluster.CreateDataSet">
            <summary>
            Create a dataset from the clustered data. 
            </summary>
            <returns>The dataset.</returns>
        </member>
        <member name="M:Encog.ML.KMeans.BasicCluster.Get(System.Int32)">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.KMeans.BasicCluster.Data">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.KMeans.BasicCluster.Remove(Encog.ML.Data.IMLData)">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.KMeans.BasicCluster.Count">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Kmeans.KMeansClustering">
             <summary>
             This class performs a basic K-Means clustering. This class can be used on
             either supervised or unsupervised data. For supervised data, the ideal values
             will be ignored.
             http://en.wikipedia.org/wiki/Kmeans
             </summary>
            
        </member>
        <member name="F:Encog.ML.Kmeans.KMeansClustering._k">
            <summary>
            Number of clusters.
            </summary>
        </member>
        <member name="F:Encog.ML.Kmeans.KMeansClustering._kmeans">
            <summary>
            The kmeans utility.
            </summary>
        </member>
        <member name="F:Encog.ML.Kmeans.KMeansClustering._clusters">
            <summary>
            The clusters
            </summary>
        </member>
        <member name="M:Encog.ML.Kmeans.KMeansClustering.#ctor(System.Int32,Encog.ML.Data.IMLDataSet)">
            <summary>
            Construct the K-Means object.
            </summary>
            <param name="theK">The number of clusters to use.</param>
            <param name="theSet">The dataset to cluster.</param>
        </member>
        <member name="M:Encog.ML.Kmeans.KMeansClustering.Iteration">
            <summary>
            Perform a single training iteration.
            </summary>
        </member>
        <member name="M:Encog.ML.Kmeans.KMeansClustering.Iteration(System.Int32)">
            <summary>
            The number of iterations to perform.
            </summary>
            <param name="count">The count of iterations.</param>
        </member>
        <member name="P:Encog.ML.Kmeans.KMeansClustering.Clusters">
            <summary>
            The clusters.
            </summary>
        </member>
        <member name="P:Encog.ML.Kmeans.KMeansClustering.Count">
            <summary>
            The number of clusters.
            </summary>
        </member>
        <member name="T:Encog.ML.IMLAutoAssocation">
             <summary>
             Defines a MLMethod that can handle autoassocation.  Autoassociation is a 
             simple form of pattern recognition where the MLMethod echos back the 
             exact pattern that the input most closely matches.  For example, if the 
             autoassociative MLMethod were trained to recognize an 8x8 grid of 
             characters, the return value would be the entire 8x8 grid of the 
             character recognized.
             This is the type of recognition performed by Hopfield Networks.  It is
             also an optional recognition form used by GR/PNN's.  This is a form of
             unsupervised training.
             </summary>
            
        </member>
        <member name="T:Encog.ML.IMLClassification">
             <summary>
             This interface defines a MLMethod that is used for classification.  
             Classification defines the output to be a class.  A MLMethod that uses 
             classification is attempting to use the input to place items into 
             classes.  It is assumed that an item will only be in one single class.  
             If an item can be in multiple classes, one option is to create additional 
             classes that represent the compound classes.
             </summary>
            
        </member>
        <member name="M:Encog.ML.IMLClassification.Classify(Encog.ML.Data.IMLData)">
             <summary>
             Classify the input into a group.
             </summary>
            
             <param name="input">The input data to classify.</param>
             <returns>The group that the data was classified into.</returns>
        </member>
        <member name="T:Encog.ML.IMLCluster">
             <summary>
             Defines a cluster. Usually used with the MLClustering method to break input
             into clusters.
             </summary>
            
        </member>
        <member name="P:Encog.ML.IMLCluster.Data">
            <value>The data in this cluster.</value>
        </member>
        <member name="M:Encog.ML.IMLCluster.Add(Encog.ML.Data.IMLData)">
             <summary>
             Add data to this cluster.
             </summary>
            
             <param name="pair">The data to add.</param>
        </member>
        <member name="M:Encog.ML.IMLCluster.CreateDataSet">
             <summary>
             Create a machine learning dataset from the data.
             </summary>
            
             <returns>A dataset.</returns>
        </member>
        <member name="M:Encog.ML.IMLCluster.Get(System.Int32)">
             <summary>
             Get the specified data item by index.
             </summary>
            
             <param name="pos">The index of the data item to get.</param>
             <returns>The data item.</returns>
        </member>
        <member name="M:Encog.ML.IMLCluster.Remove(Encog.ML.Data.IMLData)">
             <summary>
             Remove the specified item.
             </summary>
            
             <param name="data">The item to remove.</param>
        </member>
        <member name="P:Encog.ML.IMLCluster.Count">
            <returns>The number of items.</returns>
        </member>
        <member name="T:Encog.ML.IMLClustering">
             <summary>
             A machine learning method that is used to break data into clusters.  The 
             number of clusters is usually defined beforehand.  This differs from 
             the MLClassification method in that the data is clustered as an entire 
             group.  If additional data must be clustered later, the entire group 
             must be reclustered.
             </summary>
            
        </member>
        <member name="P:Encog.ML.IMLClustering.Clusters">
            <value>The clusters.</value>
        </member>
        <member name="M:Encog.ML.IMLClustering.Iteration">
             <summary>
             Perform the training iteration.
             </summary>
            
        </member>
        <member name="M:Encog.ML.IMLClustering.Iteration(System.Int32)">
             <summary>
             Perform the specified number of training iterations.
             </summary>
            
             <param name="count">The number of training iterations.</param>
        </member>
        <member name="P:Encog.ML.IMLClustering.Count">
            <returns>The number of clusters.</returns>
        </member>
        <member name="T:Encog.ML.IMLContext">
             <summary>
             Defines a MLMethod that can hold context.  This allows the context to be 
             cleared.  Examples of MLMethod objects that support this are NEAT, 
             Elmann and Jordan.
             </summary>
            
        </member>
        <member name="M:Encog.ML.IMLContext.ClearContext">
             <summary>
             Clear the context.
             </summary>
            
        </member>
        <member name="T:Encog.ML.IMLEncodable">
             <summary>
             Defines a Machine Learning Method that can be encoded to a double array.  
             This is very useful for certain training, such as genetic algorithms 
             and simulated annealing. 
             </summary>
            
        </member>
        <member name="M:Encog.ML.IMLEncodable.EncodedArrayLength">
            <returns>The length of an encoded array.</returns>
        </member>
        <member name="M:Encog.ML.IMLEncodable.EncodeToArray(System.Double[])">
             <summary>
             Encode the object to the specified array.
             </summary>
            
             <param name="encoded">The array.</param>
        </member>
        <member name="M:Encog.ML.IMLEncodable.DecodeFromArray(System.Double[])">
             <summary>
             Decode an array to this object.
             </summary>
            
             <param name="encoded">The encoded array.</param>
        </member>
        <member name="T:Encog.ML.IMLError">
             <summary>
             Defines Machine Learning Method that can calculate an error based on a 
             data set.
             </summary>
            
        </member>
        <member name="M:Encog.ML.IMLError.CalculateError(Encog.ML.Data.IMLDataSet)">
             <summary>
             Calculate the error of the ML method, given a dataset.
             </summary>
            
             <param name="data">The dataset.</param>
             <returns>The error.</returns>
        </member>
        <member name="T:Encog.ML.IMLInput">
             <summary>
             Defines a MLMethod that accepts input.  Input is defined as a simple 
             array of double values.  Many machine learning methods, such as neural 
             networks and support vector machines receive input this way, and thus 
             implement this interface.  Others, such as clustering, do not.
             </summary>
            
        </member>
        <member name="P:Encog.ML.IMLInput.InputCount">
            <value>The input.</value>
        </member>
        <member name="T:Encog.ML.IMLInputOutput">
             <summary>
             This is a convenience interface that combines MLInput and MLOutput.  
             Together these define a MLMethod that both accepts input and 
             produces output.
             Input and output are defined as a simple array of double values.  
             Many machine learning methods, such as neural networks and 
             support vector machines handle input and output in this way, 
             and thus implement this interface.  Others, such as clustering, 
             do not.
             </summary>
            
        </member>
        <member name="T:Encog.ML.IMLMethod">
             <summary>
             This interface is the base for all Encog Machine Learning methods.  It 
             defines very little, other than the fact that a subclass is a Machine 
             Learning Method.  A MLMethod is an algorithm that accepts data and 
             provides some sort of insight into it.  This could be a neural network, 
             support vector machine, clustering algorithm, or something else entirely.
             Many MLMethods must be trained by a MLTrain object before they are useful.
             </summary>
            
        </member>
        <member name="T:Encog.ML.IMLOutput">
             <summary>
             Defines a MLMethod that produces output.  Input is defined as a simple 
             array of double values.  Many machine learning methods, such as neural 
             networks and support vector machines produce output this way, and thus 
             implement this interface.  Others, such as clustering, do not.
             </summary>
            
        </member>
        <member name="P:Encog.ML.IMLOutput.OutputCount">
            <value>The output count.</value>
        </member>
        <member name="T:Encog.ML.IMLProperties">
             <summary>
             Defines a Machine Learning Method that holds properties.
             </summary>
            
        </member>
        <member name="P:Encog.ML.IMLProperties.Properties">
            <value>A map of all properties.</value>
        </member>
        <member name="M:Encog.ML.IMLProperties.GetPropertyDouble(System.String)">
             <summary>
             Get the specified property as a double.
             </summary>
            
             <param name="name">The name of the property.</param>
             <returns>The property as a double.</returns>
        </member>
        <member name="M:Encog.ML.IMLProperties.GetPropertyLong(System.String)">
             <summary>
             Get the specified property as a long.
             </summary>
            
             <param name="name">The name of the specified property.</param>
             <returns>The value of the specified property.</returns>
        </member>
        <member name="M:Encog.ML.IMLProperties.GetPropertyString(System.String)">
             <summary>
             Get the specified property as a string.
             </summary>
            
             <param name="name">The name of the property.</param>
             <returns>The value of the property.</returns>
        </member>
        <member name="M:Encog.ML.IMLProperties.SetProperty(System.String,System.Double)">
             <summary>
             Set a property as a double.
             </summary>
            
             <param name="name">The name of the property.</param>
             <param name="d">The value of the property.</param>
        </member>
        <member name="M:Encog.ML.IMLProperties.SetProperty(System.String,System.Int64)">
             <summary>
             Set a property as a long.
             </summary>
            
             <param name="name">The name of the property.</param>
             <param name="l">The value of the property.</param>
        </member>
        <member name="M:Encog.ML.IMLProperties.SetProperty(System.String,System.String)">
             <summary>
             Set a property as a double.
             </summary>
            
             <param name="name">The name of the property.</param>
             <param name="v">The value of the property.</param>
        </member>
        <member name="M:Encog.ML.IMLProperties.UpdateProperties">
             <summary>
             Update any objeccts when a property changes.
             </summary>
            
        </member>
        <member name="T:Encog.ML.IMLRegression">
             <summary>
             Defines a Machine Learning Method that supports regression.  Regression 
             takes an input and produces numeric output.  Function approximation 
             uses regression.  Contrast this to classification, which uses the input 
             to assign a class.
             </summary>
            
        </member>
        <member name="M:Encog.ML.IMLRegression.Compute(Encog.ML.Data.IMLData)">
             <summary>
             Compute regression.
             </summary>
            
             <param name="input">The input data.</param>
             <returns>The output data.</returns>
        </member>
        <member name="T:Encog.ML.IMLResettable">
             <summary>
             Defines a Machine Learning Method that can be reset to an untrained 
             starting point.  Most weight based machine learning methods, such
             as neural networks support this.  Support vector machines do not.
             </summary>
            
        </member>
        <member name="M:Encog.ML.IMLResettable.Reset">
             <summary>
             Reset the weights.
             </summary>
            
        </member>
        <member name="M:Encog.ML.IMLResettable.Reset(System.Int32)">
             <summary>
             Reset the weights with a seed.
             </summary>
            
             <param name="seed">The seed value.</param>
        </member>
        <member name="T:Encog.ML.TrainingImplementationType">
             <summary>
             Specifies the type of training that an object provides.
             </summary>
            
        </member>
        <member name="F:Encog.ML.TrainingImplementationType.Iterative">
             <summary>
             Iterative - Each iteration attempts to improve the machine 
             learning method.
             </summary>
            
        </member>
        <member name="F:Encog.ML.TrainingImplementationType.Background">
             <summary>
             Background - Training continues in the background until it is
             either finished or is stopped.
             </summary>
            
        </member>
        <member name="F:Encog.ML.TrainingImplementationType.OnePass">
             <summary>
             Single Pass - Only one iteration is necessary.
             </summary>
            
        </member>
        <member name="T:Encog.ML.Train.Strategy.EarlyStoppingStrategy">
             <summary>
             Stop early when validation set no longer improves.
            
             Based on the following paper:
             
             @techreport{Prechelt94c,
             author    = {Lutz Prechelt},
             title     = {{PROBEN1} --- {A} Set of Benchmarks and Benchmarking
                          Rules for Neural Network Training Algorithms},
             institution = {Fakult\"at f\"ur Informatik, Universit\"at Karlsruhe},
             year      = {1994},
             number    = {21/94},
             address   = {D-76128 Karlsruhe, Germany},
             month     = sep,
             note      = {Anonymous FTP: /pub/pa\-pers/tech\-reports/1994/1994-21.ps.Z
                          on ftp.ira.uka.de},
             }
             
             </summary>
        </member>
        <member name="F:Encog.ML.Train.Strategy.EarlyStoppingStrategy._alpha">
            <summary>
            Alpha value, calculated for early stopping. Once "gl" is above alpha, training will stop.
            </summary>
        </member>
        <member name="F:Encog.ML.Train.Strategy.EarlyStoppingStrategy._stripLength">
            <summary>
            Validation strip length.
            </summary>
        </member>
        <member name="F:Encog.ML.Train.Strategy.EarlyStoppingStrategy._testSet">
            <summary>
            The test set.
            </summary>
        </member>
        <member name="F:Encog.ML.Train.Strategy.EarlyStoppingStrategy._validationSet">
            <summary>
            The validation set.
            </summary>
        </member>
        <member name="F:Encog.ML.Train.Strategy.EarlyStoppingStrategy._calc">
            <summary>
            The error calculation.
            </summary>
        </member>
        <member name="F:Encog.ML.Train.Strategy.EarlyStoppingStrategy._eOpt">
            <summary>
            eOpt value, calculated for early stopping.  
            The lowest validation error so far.
            </summary>
        </member>
        <member name="F:Encog.ML.Train.Strategy.EarlyStoppingStrategy._gl">
            <summary>
            gl value, calculated for early stopping.
            </summary>
        </member>
        <member name="F:Encog.ML.Train.Strategy.EarlyStoppingStrategy._lastCheck">
            <summary>
            The last time the test set was checked.
            </summary>
        </member>
        <member name="F:Encog.ML.Train.Strategy.EarlyStoppingStrategy._stop">
            <summary>
            Has training stopped.
            </summary>
        </member>
        <member name="F:Encog.ML.Train.Strategy.EarlyStoppingStrategy._testError">
            <summary>
            Current test error.
            </summary>
        </member>
        <member name="F:Encog.ML.Train.Strategy.EarlyStoppingStrategy._train">
            <summary>
            The trainer.
            </summary>
        </member>
        <member name="F:Encog.ML.Train.Strategy.EarlyStoppingStrategy._trainingError">
            <summary>
            Current training error.
            </summary>
        </member>
        <member name="F:Encog.ML.Train.Strategy.EarlyStoppingStrategy._validationError">
            <summary>
            Current validation error.
            </summary>
        </member>
        <member name="M:Encog.ML.Train.Strategy.EarlyStoppingStrategy.#ctor(Encog.ML.Data.IMLDataSet,Encog.ML.Data.IMLDataSet)">
            <summary>
            Construct the early stopping strategy.
            Use default operating parameters. 
            </summary>
            <param name="theValidationSet">The validation set.</param>
            <param name="theTestSet">The test set.</param>
        </member>
        <member name="M:Encog.ML.Train.Strategy.EarlyStoppingStrategy.#ctor(Encog.ML.Data.IMLDataSet,Encog.ML.Data.IMLDataSet,System.Int32,System.Double,System.Double)">
            <summary>
            Construct the early stopping strategy. 
            </summary>
            <param name="theValidationSet">The validation set.</param>
            <param name="theTestSet">The test set.</param>
            <param name="theStripLength">The number of training set elements to validate.</param>
            <param name="theAlpha">Stop once GL is below this value.</param>
            <param name="theMinEfficiency">The minimum training efficiency to stop.</param>
        </member>
        <member name="P:Encog.ML.Train.Strategy.EarlyStoppingStrategy.TrainingError">
            <summary>
            The training error.
            </summary>
        </member>
        <member name="P:Encog.ML.Train.Strategy.EarlyStoppingStrategy.TestError">
            <summary>
            The test error.
            </summary>
        </member>
        <member name="P:Encog.ML.Train.Strategy.EarlyStoppingStrategy.ValidationError">
            <summary>
            The validation error.
            </summary>
        </member>
        <member name="P:Encog.ML.Train.Strategy.EarlyStoppingStrategy.Opt">
            <summary>
            The Opt.
            </summary>
        </member>
        <member name="P:Encog.ML.Train.Strategy.EarlyStoppingStrategy.Gl">
            <summary>
            The GL.
            </summary>
        </member>
        <member name="P:Encog.ML.Train.Strategy.EarlyStoppingStrategy.StripLength">
            <summary>
            The strip length.
            </summary>
        </member>
        <member name="P:Encog.ML.Train.Strategy.EarlyStoppingStrategy.StripOpt">
            <summary>
            StripOpt.
            </summary>
        </member>
        <member name="P:Encog.ML.Train.Strategy.EarlyStoppingStrategy.StripEfficiency">
            <summary>
            The strip efficiency.
            </summary>
        </member>
        <member name="P:Encog.ML.Train.Strategy.EarlyStoppingStrategy.MinEfficiency">
            <summary>
            The minimum efficicency to allow before stopping.
            </summary>
        </member>
        <member name="M:Encog.ML.Train.Strategy.EarlyStoppingStrategy.Init(Encog.ML.Train.IMLTrain)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Train.Strategy.EarlyStoppingStrategy.PreIteration">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Train.Strategy.EarlyStoppingStrategy.PostIteration">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Train.Strategy.EarlyStoppingStrategy.ShouldStop">
            <summary>
            Returns true if we should stop.
            </summary>
            <returns>Returns true if we should stop.</returns>
        </member>
        <member name="T:Encog.ML.Train.Strategy.End.EndIterationsStrategy">
            <summary>
            End the training when a specified number of iterations has been reached.
            </summary>
        </member>
        <member name="M:Encog.ML.Train.Strategy.End.EndIterationsStrategy.#ctor(System.Int32)">
            <summary>
            Construct the object, specify the max number of iterations.
            </summary>
            <param name="maxIterations">The number of iterations.</param>
        </member>
        <member name="M:Encog.ML.Train.Strategy.End.EndIterationsStrategy.ShouldStop">
             <summary>
             
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.Strategy.End.EndIterationsStrategy.Init(Encog.ML.Train.IMLTrain)">
             <summary>
             
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.Strategy.End.EndIterationsStrategy.PostIteration">
             <summary>
             
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.Strategy.End.EndIterationsStrategy.PreIteration">
             <summary>
             
             </summary>
            
        </member>
        <member name="T:Encog.ML.Train.Strategy.End.EndMaxErrorStrategy">
            <summary>
            End training once the error falls below a specified level.
            </summary>
        </member>
        <member name="F:Encog.ML.Train.Strategy.End.EndMaxErrorStrategy._maxError">
            <summary>
            The max error.
            </summary>
        </member>
        <member name="F:Encog.ML.Train.Strategy.End.EndMaxErrorStrategy._started">
            <summary>
            Has training started.
            </summary>
        </member>
        <member name="F:Encog.ML.Train.Strategy.End.EndMaxErrorStrategy._train">
            <summary>
            The trainer.
            </summary>
        </member>
        <member name="M:Encog.ML.Train.Strategy.End.EndMaxErrorStrategy.#ctor(System.Double)">
            <summary>
            Construct the object, specify the max error.
            </summary>
            <param name="maxError">The max error.</param>
        </member>
        <member name="M:Encog.ML.Train.Strategy.End.EndMaxErrorStrategy.ShouldStop">
             <summary>
             
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.Strategy.End.EndMaxErrorStrategy.Init(Encog.ML.Train.IMLTrain)">
             <summary>
             
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.Strategy.End.EndMaxErrorStrategy.PostIteration">
             <summary>
             
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.Strategy.End.EndMaxErrorStrategy.PreIteration">
             <summary>
             
             </summary>
            
        </member>
        <member name="T:Encog.ML.Train.Strategy.End.EndMinutesStrategy">
            <summary>
            End training when a specified number of minutes is up.
            </summary>
        </member>
        <member name="F:Encog.ML.Train.Strategy.End.EndMinutesStrategy._minutes">
            <summary>
            The number of minutes to train for.
            </summary>
        </member>
        <member name="F:Encog.ML.Train.Strategy.End.EndMinutesStrategy._minutesLeft">
            <summary>
            The number of minutes that are left.
            </summary>
        </member>
        <member name="F:Encog.ML.Train.Strategy.End.EndMinutesStrategy._started">
            <summary>
            True if training has started.
            </summary>
        </member>
        <member name="F:Encog.ML.Train.Strategy.End.EndMinutesStrategy._startedTime">
            <summary>
            The starting time for training.
            </summary>
        </member>
        <member name="M:Encog.ML.Train.Strategy.End.EndMinutesStrategy.#ctor(System.Int32)">
            <summary>
            Construct the strategy object.
            </summary>
            <param name="minutes"></param>
        </member>
        <member name="P:Encog.ML.Train.Strategy.End.EndMinutesStrategy.MinutesLeft">
            <value>the minutesLeft</value>
        </member>
        <member name="P:Encog.ML.Train.Strategy.End.EndMinutesStrategy.Minutes">
            <value>the minutes</value>
        </member>
        <member name="M:Encog.ML.Train.Strategy.End.EndMinutesStrategy.ShouldStop">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Train.Strategy.End.EndMinutesStrategy.Init(Encog.ML.Train.IMLTrain)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Train.Strategy.End.EndMinutesStrategy.PostIteration">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.Train.Strategy.End.EndMinutesStrategy.PreIteration">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.Train.Strategy.End.IEndTrainingStrategy">
            <summary>
            A training strategy that specifies when to end training.
            </summary>
        </member>
        <member name="M:Encog.ML.Train.Strategy.End.IEndTrainingStrategy.ShouldStop">
            <returns>True if training should stop.</returns>
        </member>
        <member name="T:Encog.ML.Train.Strategy.Greedy">
             <summary>
             A simple greedy strategy. If the last iteration did not improve training,
             then discard it. Care must be taken with this strategy, as sometimes a
             training algorithm may need to temporarily decrease the error level before
             improving it.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.Greedy._lastError">
             <summary>
             The error rate from the previous iteration.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.Greedy._lastNetwork">
             <summary>
             The last state of the network, so that we can restore to this
             state if needed.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.Greedy._method">
            <summary>
            The method training.
            </summary>
        </member>
        <member name="F:Encog.ML.Train.Strategy.Greedy._ready">
             <summary>
             Has one iteration passed, and we are now ready to start 
             evaluation.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.Greedy._train">
             <summary>
             The training algorithm that is using this strategy.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.Strategy.Greedy.Init(Encog.ML.Train.IMLTrain)">
             <summary>
             Initialize this strategy.
             </summary>
            
             <param name="train">The training algorithm.</param>
        </member>
        <member name="M:Encog.ML.Train.Strategy.Greedy.PostIteration">
             <summary>
             Called just after a training iteration.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.Strategy.Greedy.PreIteration">
             <summary>
             Called just before a training iteration.
             </summary>
            
        </member>
        <member name="T:Encog.ML.Train.Strategy.HybridStrategy">
             <summary>
             A hybrid stragey allows a secondary training algorithm to be used. Once the
             primary algorithm is no longer improving by much, the secondary will be used.
             Using simulated annealing in as a secondary to one of the propagation methods
             is often a very efficient combination as it can help the propagation method
             escape a local minimum. This is particularly true with backpropagation.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.HybridStrategy.DefaultMinImprovement">
             <summary>
             The default minimum improvement before we switch to the alternate
             training method.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.HybridStrategy.DefaultTolerateCycles">
             <summary>
             The default number of cycles to tolerate bad improvement for.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.HybridStrategy.DefaultAlternateCycles">
             <summary>
             The default number of cycles to use the alternate training for.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.HybridStrategy._altTrain">
             <summary>
             The alternate training method.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.HybridStrategy._alternateCycles">
             <summary>
             How many cycles to engage the alternate algorithm for.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.HybridStrategy._minImprovement">
             <summary>
             The minimum improvement before the alternate training 
             algorithm is considered.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.HybridStrategy._tolerateMinImprovement">
             <summary>
             The number of minimal improvement to tolerate before the
             alternate training algorithm is used.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.HybridStrategy._lastError">
             <summary>
             The error rate from the previous iteration.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.HybridStrategy._lastHybrid">
             <summary>
             The last time the alternate training algorithm was used.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.HybridStrategy._lastImprovement">
             <summary>
             The last improvement.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.HybridStrategy._mainTrain">
             <summary>
             The primary training method.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.HybridStrategy._ready">
             <summary>
             Has one iteration passed, and we are now ready to start 
             evaluation.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.Strategy.HybridStrategy.#ctor(Encog.ML.Train.IMLTrain)">
             <summary>
             Construct a hybrid strategy with the default minimum improvement
             and toleration cycles.
             </summary>
            
             <param name="altTrain">The alternative training strategy.</param>
        </member>
        <member name="M:Encog.ML.Train.Strategy.HybridStrategy.#ctor(Encog.ML.Train.IMLTrain,System.Double,System.Int32,System.Int32)">
             <summary>
             Create a hybrid strategy.
             </summary>
            
             <param name="altTrain">The alternate training algorithm.</param>
             <param name="minImprovement">The minimum improvement to switch algorithms.</param>
             <param name="tolerateMinImprovement"></param>
             <param name="alternateCycles"></param>
        </member>
        <member name="M:Encog.ML.Train.Strategy.HybridStrategy.Init(Encog.ML.Train.IMLTrain)">
             <summary>
             Initialize this strategy.
             </summary>
            
             <param name="train">The training algorithm.</param>
        </member>
        <member name="M:Encog.ML.Train.Strategy.HybridStrategy.PostIteration">
             <summary>
             Called just after a training iteration.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.Strategy.HybridStrategy.PreIteration">
             <summary>
             Called just before a training iteration.
             </summary>
            
        </member>
        <member name="T:Encog.ML.Train.Strategy.RequiredImprovementStrategy">
             <summary>
             The reset strategy will reset the weights if the neural network fails to improve by the specified amount over a number of cycles. 
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.RequiredImprovementStrategy._acceptableThreshold">
             <summary>
             If the error is below this, then never reset.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.RequiredImprovementStrategy._cycles">
             <summary>
             The number of cycles to reach the required minimum error.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.RequiredImprovementStrategy._required">
             <summary>
             The required minimum error.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.RequiredImprovementStrategy._badCycleCount">
             <summary>
             How many bad cycles have there been so far.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.RequiredImprovementStrategy._lastError">
             <summary>
             The last error.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.RequiredImprovementStrategy._method">
            <summary>
            The method being trained.
            </summary>
        </member>
        <member name="F:Encog.ML.Train.Strategy.RequiredImprovementStrategy._train">
             <summary>
             The training algorithm that is using this strategy.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.Strategy.RequiredImprovementStrategy.#ctor(System.Double,System.Int32)">
             <summary>
             Construct a reset strategy. The error rate must fall below the required
             rate in the specified number of cycles, or the neural network will be
             reset to random weights and bias values.
             </summary>
            
             <param name="required">The required error rate.</param>
             <param name="cycles">The number of cycles to reach that rate.</param>
        </member>
        <member name="M:Encog.ML.Train.Strategy.RequiredImprovementStrategy.#ctor(System.Double,System.Double,System.Int32)">
             <summary>
             Construct a reset strategy. The error rate must fall below the required
             rate in the specified number of cycles, or the neural network will be
             reset to random weights and bias values.
             </summary>
            
             <param name="required">The required error rate.</param>
             <param name="threshold">The accepted threshold, don't reset if error is below this.</param>
             <param name="cycles">The number of cycles to reach that rate.</param>
        </member>
        <member name="M:Encog.ML.Train.Strategy.RequiredImprovementStrategy.#ctor(System.Int32)">
             <summary>
             Reset if there is not at least a 1% improvement for 5 cycles. Don't reset
             if below 10%.
             </summary>
            
             <param name="cycles"></param>
        </member>
        <member name="M:Encog.ML.Train.Strategy.RequiredImprovementStrategy.Init(Encog.ML.Train.IMLTrain)">
             <summary>
             Initialize this strategy.
             </summary>
            
             <param name="train">The training algorithm.</param>
        </member>
        <member name="M:Encog.ML.Train.Strategy.RequiredImprovementStrategy.PostIteration">
             <summary>
             Called just after a training iteration.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.Strategy.RequiredImprovementStrategy.PreIteration">
             <summary>
             Called just before a training iteration.
             </summary>
            
        </member>
        <member name="T:Encog.ML.Train.Strategy.ResetStrategy">
             <summary>
             The reset strategy will reset the weights if the neural network fails to fall
             below a specified error by a specified number of cycles. This can be useful
             to throw out initially "bad/hard" random initializations of the weight
             matrix.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.ResetStrategy._cycles">
             <summary>
             The number of cycles to reach the required minimum error.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.ResetStrategy._required">
             <summary>
             The required minimum error.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.ResetStrategy._badCycleCount">
             <summary>
             How many bad cycles have there been so far.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.ResetStrategy._method">
            <summary>
            The method being trained.
            </summary>
        </member>
        <member name="F:Encog.ML.Train.Strategy.ResetStrategy._train">
             <summary>
             The training algorithm that is using this strategy.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.Strategy.ResetStrategy.#ctor(System.Double,System.Int32)">
             <summary>
             Construct a reset strategy.  The error rate must fall
             below the required rate in the specified number of cycles,
             or the neural network will be reset to random weights and
             bias values.
             </summary>
            
             <param name="required">The required error rate.</param>
             <param name="cycles">The number of cycles to reach that rate.</param>
        </member>
        <member name="M:Encog.ML.Train.Strategy.ResetStrategy.Init(Encog.ML.Train.IMLTrain)">
             <summary>
             Initialize this strategy.
             </summary>
            
             <param name="train">The training algorithm.</param>
        </member>
        <member name="M:Encog.ML.Train.Strategy.ResetStrategy.PostIteration">
             <summary>
             Called just after a training iteration.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.Strategy.ResetStrategy.PreIteration">
             <summary>
             Called just before a training iteration.
             </summary>
            
        </member>
        <member name="T:Encog.ML.Train.Strategy.StopTrainingStrategy">
             <summary>
             This strategy will indicate once training is no longer improving the neural
             network by a specified amount, over a specified number of cycles. This allows
             the program to automatically determine when to stop training.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.StopTrainingStrategy.DefaultMinImprovement">
             <summary>
             The default minimum improvement before training stops.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.StopTrainingStrategy.DefaultTolerateCycles">
             <summary>
             The default number of cycles to tolerate.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.StopTrainingStrategy._minImprovement">
             <summary>
             The minimum improvement before training stops.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.StopTrainingStrategy._toleratedCycles">
             <summary>
             The number of cycles to tolerate the minimum improvement.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.StopTrainingStrategy._badCycles">
             <summary>
             The number of bad training cycles.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.StopTrainingStrategy._bestError">
             <summary>
             The error rate from the previous iteration.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.StopTrainingStrategy._lastError">
             <summary>
             The error rate from the previous iteration.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.StopTrainingStrategy._ready">
             <summary>
             Has one iteration passed, and we are now ready to start evaluation.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.StopTrainingStrategy._shouldStop">
             <summary>
             Flag to indicate if training should stop.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.Strategy.StopTrainingStrategy._train">
             <summary>
             The training algorithm that is using this strategy.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.Strategy.StopTrainingStrategy.#ctor">
             <summary>
             Construct the strategy with default options.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.Strategy.StopTrainingStrategy.#ctor(System.Double,System.Int32)">
             <summary>
             Construct the strategy with the specified parameters.
             </summary>
            
             <param name="minImprovement">The minimum accepted improvement.</param>
             <param name="toleratedCycles">The number of cycles to tolerate before stopping.</param>
        </member>
        <member name="M:Encog.ML.Train.Strategy.StopTrainingStrategy.Init(Encog.ML.Train.IMLTrain)">
             <summary>
             
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.Strategy.StopTrainingStrategy.PostIteration">
             <summary>
             
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.Strategy.StopTrainingStrategy.PreIteration">
             <summary>
             
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.Strategy.StopTrainingStrategy.ShouldStop">
             <summary>
             
             </summary>
            
        </member>
        <member name="T:Encog.ML.Train.Strategy.IStrategy">
             <summary>
             Training strategies can be added to training algorithms.  Training 
             strategies allow different additional logic to be added to an existing
             training algorithm.  There are a number of different training strategies
             that can perform various tasks, such as adjusting the learning rate or 
             momentum, or terminating training when improvement diminishes.  Other 
             strategies are provided as well.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.Strategy.IStrategy.Init(Encog.ML.Train.IMLTrain)">
             <summary>
             Initialize this strategy.
             </summary>
            
             <param name="train">The training algorithm.</param>
        </member>
        <member name="M:Encog.ML.Train.Strategy.IStrategy.PreIteration">
             <summary>
             Called just before a training iteration.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.Strategy.IStrategy.PostIteration">
             <summary>
             Called just after a training iteration.
             </summary>
            
        </member>
        <member name="T:Encog.ML.Train.BasicTraining">
             <summary>
             An abstract class that implements basic training for most training
             algorithms. Specifically training strategies can be added to enhance the
             training.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.BasicTraining._strategies">
             <summary>
             The training strategies to use.
             </summary>
            
        </member>
        <member name="F:Encog.ML.Train.BasicTraining._iteration">
             <summary>
             The current iteration.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.BasicTraining.#ctor(Encog.ML.TrainingImplementationType)">
            <summary>
            Construct the object, specify the implementation type.
            </summary>
            <param name="implementationType"></param>
        </member>
        <member name="M:Encog.ML.Train.BasicTraining.AddStrategy(Encog.ML.Train.Strategy.IStrategy)">
             <summary>
             Training strategies can be added to improve the training results. There
             are a number to choose from, and several can be used at once.
             </summary>
            
             <param name="strategy">The strategy to add.</param>
        </member>
        <member name="M:Encog.ML.Train.BasicTraining.FinishTraining">
             <summary>
             Should be called after training has completed and the iteration method
             will not be called any further.
             </summary>
            
        </member>
        <member name="P:Encog.ML.Train.BasicTraining.Error">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.Train.BasicTraining.IterationNumber">
            <value>the iteration to set</value>
        </member>
        <member name="P:Encog.ML.Train.BasicTraining.Strategies">
            <value>The strategies to use.</value>
        </member>
        <member name="P:Encog.ML.Train.BasicTraining.Training">
            <summary>
            Set the training object that this strategy is working with.
            </summary>
        </member>
        <member name="P:Encog.ML.Train.BasicTraining.TrainingDone">
            <value>True if training can progress no further.</value>
        </member>
        <member name="M:Encog.ML.Train.BasicTraining.Iteration(System.Int32)">
             <summary>
             Perform the specified number of training iterations. This is a basic
             implementation that just calls iteration the specified number of times.
             However, some training methods, particularly with the GPU, benefit
             greatly by calling with higher numbers than 1.
             </summary>
            
             <param name="count">The number of training iterations.</param>
        </member>
        <member name="P:Encog.ML.Train.BasicTraining.ImplementationType">
            <summary>
            The implementation type.
            </summary>
        </member>
        <member name="P:Encog.ML.Train.BasicTraining.CanContinue">
             <summary>
             from Encog.ml.train.MLTrain
             </summary>
            
        </member>
        <member name="P:Encog.ML.Train.BasicTraining.Method">
             <summary>
             from Encog.ml.train.MLTrain
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.BasicTraining.Iteration">
             <summary>
             from Encog.ml.train.MLTrain
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.BasicTraining.Pause">
             <summary>
             from Encog.ml.train.MLTrain
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.BasicTraining.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
             <summary>
             from Encog.ml.train.MLTrain
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.BasicTraining.PostIteration">
             <summary>
             Call the strategies after an iteration.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.BasicTraining.PreIteration">
             <summary>
             Call the strategies before an iteration.
             </summary>
            
        </member>
        <member name="T:Encog.ML.Train.IMLTrain">
             <summary>
             Defines a training method for a machine learning method.  Most MLMethod 
             objects need to be trained in some way before they are ready for use.
             </summary>
            
        </member>
        <member name="P:Encog.ML.Train.IMLTrain.ImplementationType">
            <value>The training implementation type.</value>
        </member>
        <member name="P:Encog.ML.Train.IMLTrain.TrainingDone">
            <value>True if training can progress no further.</value>
        </member>
        <member name="P:Encog.ML.Train.IMLTrain.Training">
            <value>The training data to use.</value>
        </member>
        <member name="P:Encog.ML.Train.IMLTrain.Error">
            <summary>
            Returns the training error. This value is calculated as the
            training data is evaluated by the iteration function. This has
            two important ramifications. First, the value returned by
            getError() is meaningless prior to a call to iteration. Secondly,
            the error is calculated BEFORE training is applied by the call to
            iteration. The timing of the error calculation is done for
            performance reasons.
            </summary>
        </member>
        <member name="P:Encog.ML.Train.IMLTrain.IterationNumber">
            <summary>
            Set the current training iteration.
            </summary>
        </member>
        <member name="P:Encog.ML.Train.IMLTrain.CanContinue">
            <returns>True if the training can be paused, and later continued.</returns>
        </member>
        <member name="P:Encog.ML.Train.IMLTrain.Method">
            <summary>
            Get the current best machine learning method from the training.
            </summary>
        </member>
        <member name="P:Encog.ML.Train.IMLTrain.Strategies">
            <value>The strategies to use.</value>
        </member>
        <member name="M:Encog.ML.Train.IMLTrain.Iteration">
             <summary>
             Perform one iteration of training.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.IMLTrain.FinishTraining">
             <summary>
             Should be called once training is complete and no more iterations are
             needed. Calling iteration again will simply begin the training again, and
             require finishTraining to be called once the new training session is
             complete.
             It is particularly important to call finishTraining for multithreaded
             training techniques.
             </summary>
            
        </member>
        <member name="M:Encog.ML.Train.IMLTrain.Iteration(System.Int32)">
             <summary>
             Perform a number of training iterations.
             </summary>
            
             <param name="count">The number of iterations to perform.</param>
        </member>
        <member name="M:Encog.ML.Train.IMLTrain.Pause">
             <summary>
             Pause the training to continue later.
             </summary>
            
             <returns>A training continuation object.</returns>
        </member>
        <member name="M:Encog.ML.Train.IMLTrain.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
             <summary>
             Resume training.
             </summary>
            
             <param name="state">The training continuation object to use to continue.</param>
        </member>
        <member name="M:Encog.ML.Train.IMLTrain.AddStrategy(Encog.ML.Train.Strategy.IStrategy)">
             <summary>
             Training strategies can be added to improve the training results. There
             are a number to choose from, and several can be used at once.
             </summary>
            
             <param name="strategy">The strategy to add.</param>
        </member>
        <member name="T:Encog.ML.SVM.KernelType">
             <summary>
             The type of SVM kernel in use.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.KernelType.Linear">
             <summary>
             Linear kernel.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.KernelType.Poly">
             <summary>
             Poly kernel.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.KernelType.RadialBasisFunction">
             <summary>
             Radial basis function kernel.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.KernelType.Sigmoid">
             <summary>
             Sigmoid kernel.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.KernelType.Precomputed">
             <summary>
             Precomputed kernel.
             </summary>
            
        </member>
        <member name="T:Encog.ML.SVM.PersistSVM">
             <summary>
             Persist a SVM.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.PersistSVM.ParamC">
             <summary>
             The parameter to hold the const C.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.PersistSVM.ParamCacheSize">
             <summary>
             The parameter to hold the cache size.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.PersistSVM.ParamCoef0">
             <summary>
             The parameter to hold the coef0.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.PersistSVM.ParamDegree">
             <summary>
             The parameter to hold the degree.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.PersistSVM.ParamEps">
             <summary>
             The parameter to hold the eps.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.PersistSVM.ParamGamma">
             <summary>
             The parameter to hold the gamma.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.PersistSVM.ParamKernelType">
             <summary>
             The parameter to hold the kernel type.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.PersistSVM.ParamNumWeight">
             <summary>
             The parameter to hold the number of weights.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.PersistSVM.ParamNu">
             <summary>
             The parameter to hold the nu.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.PersistSVM.ParamP">
             <summary>
             The parameter to hold the p.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.PersistSVM.ParamProbability">
             <summary>
             The parameter to hold the probability.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.PersistSVM.ParamShrinking">
             <summary>
             The parameter to hold the shrinking.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.PersistSVM.ParamStartIterations">
             <summary>
             The parameter to hold the statIterations.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.PersistSVM.ParamSVMType">
             <summary>
             The parameter to hold the SVM type.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.PersistSVM.ParamWeight">
             <summary>
             The paramater to hold the weight.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.PersistSVM.ParamWeightLabel">
             <summary>
             The parameter to hold the weight label.
             </summary>
            
        </member>
        <member name="P:Encog.ML.SVM.PersistSVM.NativeType">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.SVM.PersistSVM.FileVersion">
            <value>The file version.</value>
        </member>
        <member name="P:Encog.ML.SVM.PersistSVM.PersistClassString">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.SVM.PersistSVM.Read(System.IO.Stream)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.SVM.PersistSVM.Save(System.IO.Stream,System.Object)">
            <inheritdoc/>
        </member>
        <member name="T:Encog.ML.SVM.SupportVectorMachine">
            <summary>
            This is a network that is backed by one or more Support Vector Machines
            (SVM). It is designed to function very similarly to an Encog neural network,
            and is largely interchangeable with an Encog neural network.
            The support vector machine supports several types. Regression is used when
            you want the network to predict a value, given the input. Function
            approximation is a good example of regression. Classification is used when
            you want the SVM to group the input data into one or more classes.
            Support Vector Machines typically have a single output. Neural networks can
            have multiple output neurons. To get around this issue, this class will
            create multiple SVM's if there is more than one output specified.
            Because a SVM is trained quite differently from a neural network, none of the
            neural network training classes will work. This class must be trained using
            SVMTrain.
            </summary>
        </member>
        <member name="F:Encog.ML.SVM.SupportVectorMachine.DefaultDegree">
             <summary>
             The default degree.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.SupportVectorMachine.DefaultCoef0">
             <summary>
             The default COEF0.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.SupportVectorMachine.DefaultNu">
             <summary>
             The default NU.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.SupportVectorMachine.DefaultCacheSize">
             <summary>
             The default cache size.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.SupportVectorMachine.DefaultC">
             <summary>
             The default C.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.SupportVectorMachine.DefaultEps">
             <summary>
             The default EPS.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.SupportVectorMachine.DefaultP">
             <summary>
             The default P.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.SupportVectorMachine._paras">
             <summary>
             The params for the model.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.SupportVectorMachine._inputCount">
             <summary>
             The input count.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.SupportVectorMachine._model">
             <summary>
             The SVM model to use.
             </summary>
            
        </member>
        <member name="M:Encog.ML.SVM.SupportVectorMachine.#ctor">
             <summary>
             Construct the SVM.
             </summary>
            
        </member>
        <member name="M:Encog.ML.SVM.SupportVectorMachine.#ctor(System.Int32,System.Boolean)">
             <summary>
             Construct an SVM network. For regression it will use an epsilon support
             vector. Both types will use an RBF kernel.
             </summary>
            
             <param name="theInputCount">The input count.</param>
             <param name="regression">True if this network is used for regression.</param>
        </member>
        <member name="M:Encog.ML.SVM.SupportVectorMachine.#ctor(System.Int32,Encog.ML.SVM.SVMType,Encog.ML.SVM.KernelType)">
             <summary>
             Construct a SVM network.
             </summary>
            
             <param name="theInputCount">The input count.</param>
             <param name="svmType">The type of SVM.</param>
             <param name="kernelType">The SVM kernal type.</param>
        </member>
        <member name="M:Encog.ML.SVM.SupportVectorMachine.#ctor(Encog.MathUtil.LIBSVM.svm_model)">
             <summary>
             Construct a SVM from a model.
             </summary>
            
             <param name="theModel">The model.</param>
        </member>
        <member name="P:Encog.ML.SVM.SupportVectorMachine.KernelType">
            <value>The kernel type.</value>
        </member>
        <member name="P:Encog.ML.SVM.SupportVectorMachine.Model">
            <summary>
            Set the model.
            </summary>
        </member>
        <member name="P:Encog.ML.SVM.SupportVectorMachine.Params">
            <value>The SVM params for each of the outputs.</value>
        </member>
        <member name="P:Encog.ML.SVM.SupportVectorMachine.SVMType">
            <value>The SVM type.</value>
        </member>
        <member name="M:Encog.ML.SVM.SupportVectorMachine.Classify(Encog.ML.Data.IMLData)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.SVM.SupportVectorMachine.CalculateError(Encog.ML.Data.IMLDataSet)">
             <summary>
             Calculate the error for this SVM.
             </summary>
            
             <param name="data">The training set.</param>
             <returns>The error percentage.</returns>
        </member>
        <member name="M:Encog.ML.SVM.SupportVectorMachine.Compute(Encog.ML.Data.IMLData)">
             <summary>
             Compute the output for the given input.
             </summary>
            
             <param name="input">The input to the SVM.</param>
             <returns>The results from the SVM.</returns>
        </member>
        <member name="P:Encog.ML.SVM.SupportVectorMachine.InputCount">
             <summary>
             Set the input count.
             </summary>
            
             <value>The new input count.</value>
        </member>
        <member name="P:Encog.ML.SVM.SupportVectorMachine.OutputCount">
            <value>For a SVM, the output count is always one.</value>
        </member>
        <member name="M:Encog.ML.SVM.SupportVectorMachine.MakeSparse(Encog.ML.Data.IMLData)">
             <summary>
             Convert regular Encog MLData into the "sparse" data needed by an SVM.
             </summary>
            
             <param name="data">The data to convert.</param>
             <returns>The SVM sparse data.</returns>
        </member>
        <member name="M:Encog.ML.SVM.SupportVectorMachine.UpdateProperties">
             <summary>
             Not needed, no properties to update.
             </summary>
            
        </member>
        <member name="T:Encog.ML.SVM.SVMType">
             <summary>
             Supports both class and new support vector calculations, as well as one-class
             distribution.
             For more information about the two "new" support vector types, as well as the
             one-class SVM, refer to the following articles.
             B. Sch?lkopf, A. Smola, R. Williamson, and P. L. Bartlett. New support vector
             algorithms. Neural Computation, 12, 2000, 1207-1245.
             B. Sch?lkopf, J. Platt, J. Shawe-Taylor, A. J. Smola, and R. C. Williamson.
             Estimating the support of a high-dimensional distribution. Neural
             Computation, 13, 2001, 1443-1471.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.SVMType.SupportVectorClassification">
             <summary>
             Support vector for classification.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.SVMType.NewSupportVectorClassification">
             <summary>
             New support vector for classification. For more information see the
             citations in the class header.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.SVMType.SupportVectorOneClass">
             <summary>
             One class distribution estimation.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.SVMType.EpsilonSupportVectorRegression">
             <summary>
             Support vector for regression. Use Epsilon.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.SVMType.NewSupportVectorRegression">
             <summary>
             A "new" support vector machine for regression. For more information see
             the citations in the class header.
             </summary>
            
        </member>
        <member name="T:Encog.ML.SVM.Training.EncodeSVMProblem">
             <summary>
             Encode an Encog dataset as a SVM problem.
             </summary>
            
        </member>
        <member name="M:Encog.ML.SVM.Training.EncodeSVMProblem.Encode(Encog.ML.Data.IMLDataSet,System.Int32)">
             <summary>
             Encode the Encog dataset.
             </summary>
            
             <param name="training">The training data.</param>
             <param name="outputIndex"></param>
             <returns>The SVM problem.</returns>
        </member>
        <member name="T:Encog.ML.SVM.Training.SVMSearchTrain">
             <summary>
             Provides training for Support Vector Machine networks.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMSearchTrain.DefaultConstBegin">
             <summary>
             The default starting number for C.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMSearchTrain.DefaultConstEnd">
             <summary>
             The default ending number for C.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMSearchTrain.DefaultConstStep">
             <summary>
             The default step for C.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMSearchTrain.DefaultGammaBegin">
             <summary>
             The default gamma begin.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMSearchTrain.DefaultGammaEnd">
             <summary>
             The default gamma end.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMSearchTrain.DefaultGammaStep">
             <summary>
             The default gamma step.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMSearchTrain._internalTrain">
             <summary>
             The internal training object, used for the search.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMSearchTrain._network">
             <summary>
             The network that is to be trained.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMSearchTrain._bestConst">
             <summary>
             The best values found for C.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMSearchTrain._bestError">
             <summary>
             The best error.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMSearchTrain._bestGamma">
             <summary>
             The best values found for gamma.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMSearchTrain._constBegin">
             <summary>
             The beginning value for C.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMSearchTrain._constEnd">
             <summary>
             The ending value for C.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMSearchTrain._constStep">
             <summary>
             The step value for C.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMSearchTrain._currentConst">
             <summary>
             The current C.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMSearchTrain._currentGamma">
             <summary>
             The current gamma.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMSearchTrain._fold">
             <summary>
             The number of folds.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMSearchTrain._gammaBegin">
             <summary>
             The beginning value for gamma.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMSearchTrain._gammaEnd">
             <summary>
             The ending value for gamma.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMSearchTrain._gammaStep">
             <summary>
             The step value for gamma.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMSearchTrain._isSetup">
             <summary>
             Is the network setup.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMSearchTrain._trainingDone">
             <summary>
             Is the training done.
             </summary>
            
        </member>
        <member name="M:Encog.ML.SVM.Training.SVMSearchTrain.#ctor(Encog.ML.SVM.SupportVectorMachine,Encog.ML.Data.IMLDataSet)">
             <summary>
             Construct a trainer for an SVM network.
             </summary>
            
             <param name="method">The method to train.</param>
             <param name="training">The training data for this network.</param>
        </member>
        <member name="P:Encog.ML.SVM.Training.SVMSearchTrain.CanContinue">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.SVM.Training.SVMSearchTrain.ConstBegin">
            <value>the constBegin to set</value>
        </member>
        <member name="P:Encog.ML.SVM.Training.SVMSearchTrain.ConstEnd">
            <value>the constEnd to set</value>
        </member>
        <member name="P:Encog.ML.SVM.Training.SVMSearchTrain.ConstStep">
            <value>the constStep to set</value>
        </member>
        <member name="P:Encog.ML.SVM.Training.SVMSearchTrain.Fold">
            <value>the fold to set</value>
        </member>
        <member name="P:Encog.ML.SVM.Training.SVMSearchTrain.GammaBegin">
            <value>the gammaBegin to set</value>
        </member>
        <member name="P:Encog.ML.SVM.Training.SVMSearchTrain.GammaEnd">
            <value>the gammaEnd to set.</value>
        </member>
        <member name="P:Encog.ML.SVM.Training.SVMSearchTrain.GammaStep">
            <value>the gammaStep to set</value>
        </member>
        <member name="P:Encog.ML.SVM.Training.SVMSearchTrain.Method">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.SVM.Training.SVMSearchTrain.TrainingDone">
            <value>True if the training is done.</value>
        </member>
        <member name="M:Encog.ML.SVM.Training.SVMSearchTrain.FinishTraining">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.SVM.Training.SVMSearchTrain.Iteration">
            <summary>
            Perform one training iteration.
            </summary>
        </member>
        <member name="M:Encog.ML.SVM.Training.SVMSearchTrain.Pause">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.SVM.Training.SVMSearchTrain.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.SVM.Training.SVMSearchTrain.Setup">
             <summary>
             Setup to train the SVM.
             </summary>
            
        </member>
        <member name="T:Encog.ML.SVM.Training.SVMTrain">
             <summary>
             Provides training for Support Vector Machine networks.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMTrain.DefaultConstBegin">
             <summary>
             The default starting number for C.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMTrain.DefaultConstEnd">
             <summary>
             The default ending number for C.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMTrain.DefaultConstStep">
             <summary>
             The default step for C.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMTrain.DefaultGammaBegin">
             <summary>
             The default gamma begin.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMTrain.DefaultGammaEnd">
             <summary>
             The default gamma end.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMTrain.DefaultGammaStep">
             <summary>
             The default gamma step.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMTrain._network">
             <summary>
             The network that is to be trained.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMTrain._problem">
             <summary>
             The problem to train for.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMTrain._c">
             <summary>
             The const c value.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMTrain._fold">
             <summary>
             The number of folds.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMTrain._gamma">
             <summary>
             The gamma value.
             </summary>
            
        </member>
        <member name="F:Encog.ML.SVM.Training.SVMTrain._trainingDone">
             <summary>
             Is the training done.
             </summary>
            
        </member>
        <member name="M:Encog.ML.SVM.Training.SVMTrain.#ctor(Encog.ML.SVM.SupportVectorMachine,Encog.ML.Data.IMLDataSet)">
             <summary>
             Construct a trainer for an SVM network.
             </summary>
            
             <param name="method">The network to train.</param>
             <param name="dataSet">The training data for this network.</param>
        </member>
        <member name="P:Encog.ML.SVM.Training.SVMTrain.CanContinue">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.SVM.Training.SVMTrain.C">
            <summary>
            Set the constant C.
            </summary>
        </member>
        <member name="P:Encog.ML.SVM.Training.SVMTrain.Fold">
            <summary>
            Set the number of folds.
            </summary>
        </member>
        <member name="P:Encog.ML.SVM.Training.SVMTrain.Gamma">
            <summary>
            Set the gamma.
            </summary>
        </member>
        <member name="P:Encog.ML.SVM.Training.SVMTrain.Method">
            <inheritdoc/>
        </member>
        <member name="P:Encog.ML.SVM.Training.SVMTrain.Problem">
            <value>The problem being trained.</value>
        </member>
        <member name="P:Encog.ML.SVM.Training.SVMTrain.TrainingDone">
            <value>True if the training is done.</value>
        </member>
        <member name="M:Encog.ML.SVM.Training.SVMTrain.Evaluate(Encog.MathUtil.LIBSVM.svm_parameter,Encog.MathUtil.LIBSVM.svm_problem,System.Double[])">
             <summary>
             Evaluate the error for the specified model.
             </summary>
            
             <param name="param">The params for the SVN.</param>
             <param name="prob">The problem to evaluate.</param>
             <param name="target">The output values from the SVN.</param>
             <returns>The calculated error.</returns>
        </member>
        <member name="M:Encog.ML.SVM.Training.SVMTrain.Iteration">
             <summary>
             Perform either a train or a cross validation.  If the folds property is 
             greater than 1 then cross validation will be done.  Cross validation does 
             not produce a usable model, but it does set the error. 
             If you are cross validating try C and Gamma values until you have a good 
             error rate.  Then use those values to train, producing the final model.
             </summary>
            
        </member>
        <member name="M:Encog.ML.SVM.Training.SVMTrain.Pause">
            <inheritdoc/>
        </member>
        <member name="M:Encog.ML.SVM.Training.SVMTrain.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.ART.BasicART">
             <summary>
             Adaptive Resonance Theory (ART) is a form of neural network developed 
             by Stephen Grossberg and Gail Carpenter. There are several versions 
             of the ART neural network, which are numbered ART-1, ART-2 and ART-3. 
             The ART neural network is trained using either a supervised or 
             unsupervised learning algorithm, depending on the version of ART being 
             used. ART neural networks are used for pattern recognition and prediction.
             Plasticity is an important part for all Adaptive Resonance Theory (ART) 
             neural networks. Unlike most neural networks, ART networks do not have 
             a distinct training and usage stage. The ART network will learn as it is 
             used. 
             </summary>
            
        </member>
        <member name="F:Encog.Neural.ART.BasicART.PropertyA1">
             <summary>
             Neural network property, the A1 parameter.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.ART.BasicART.PropertyB1">
             <summary>
             Neural network property, the B1 parameter.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.ART.BasicART.PropertyC1">
             <summary>
             Neural network property, the C1 parameter.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.ART.BasicART.PropertyD1">
             <summary>
             Neural network property, the D1 parameter.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.ART.BasicART.PropertyL">
             <summary>
             Neural network property, the L parameter.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.ART.BasicART.PropertyVigilance">
             <summary>
             Neural network property, the vigilance parameter.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.ART.BasicART.PropertyNoWinner">
             <summary>
             Neural network property for no winner.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.ART.BasicART.UpdateProperties">
             <summary>
             
             </summary>
            
        </member>
        <member name="T:Encog.Neural.ART.ART1">
            <summary>
            Implements an ART1 neural network. An ART1 neural network is trained to
            recognize bipolar patterns as it is presented data. There is no distinct
            learning phase, like there is with other neural network types.
            The ART1 neural network is a type of Adaptive Resonance Theory (ART) neural 
            network. ART1 was developed by Stephen Grossberg and Gail Carpenter. 
            This neural network type supports only bipolar input. The ART1 neural 
            network is trained as it is used. New patterns are presented to the ART1 
            network, and they are classified into either new, or existing, classes. 
            Once the maximum number of classes have been used the network will report 
            that it is out of classes. ART1 neural networks are used for classification. 
            There are essentially 2 layers in an ART1 network. The first, named the 
            F1 layer, acts as the input. The F1 layer receives bipolar patterns that 
            the network is to classify. The F2 layer specifies the maximum number 
            classes that the ART1 network can recognize. 
            Plasticity is an important part for all Adaptive Resonance Theory (ART) 
            neural networks. Unlike most neural networks, ART1 does not have a 
            distinct training and usage stage. The ART1 network will learn as it is 
            used. 
            </summary>
        </member>
        <member name="F:Encog.Neural.ART.ART1._a1">
             <summary>
             A parameter for F1 layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.ART.ART1._b1">
             <summary>
             B parameter for F1 layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.ART.ART1._c1">
             <summary>
             C parameter for F1 layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.ART.ART1._d1">
             <summary>
             D parameter for F1 layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.ART.ART1._f1Count">
             <summary>
             The F1 layer neuron count.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.ART.ART1._f2Count">
             <summary>
             The F2 layer neuron count.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.ART.ART1._inhibitF2">
            <summary>
            Allows members of the F2 layer to be inhibited.
            </summary>
        </member>
        <member name="F:Encog.Neural.ART.ART1._l">
             <summary>
             L parameter for net.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.ART.ART1._noWinner">
             <summary>
             This is the value that is returned if there is no winner.  
             This value is generally set to the number of classes, plus 1.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.ART.ART1._outputF1">
             <summary>
             The output from the F1 layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.ART.ART1._outputF2">
             <summary>
             The output from the F2 layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.ART.ART1._vigilance">
             <summary>
             The vigilance parameter.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.ART.ART1._weightsF1ToF2">
             <summary>
             Weights from f1 to f2.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.ART.ART1._weightsF2ToF1">
             <summary>
             Weights from f2 to f1.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.ART.ART1.#ctor">
             <summary>
             Default constructor, used mainly for persistence.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.ART.ART1.#ctor(System.Int32,System.Int32)">
             <summary>
             Construct the ART1 network.
             </summary>
            
             <param name="theF1Count">The neuron count for the f1 layer.</param>
             <param name="theF2Count">The neuron count for the f2 layer.</param>
        </member>
        <member name="P:Encog.Neural.ART.ART1.A1">
             <summary>
             Set the A1 parameter.
             </summary>
            
             <value>The new value.</value>
        </member>
        <member name="P:Encog.Neural.ART.ART1.B1">
            <summary>
            Set the B1 parameter.
            </summary>
        </member>
        <member name="P:Encog.Neural.ART.ART1.C1">
             <summary>
             Set the C1 parameter.
             </summary>
            
             <value>The new value.</value>
        </member>
        <member name="P:Encog.Neural.ART.ART1.D1">
             <summary>
             Set the D1 parameter.
             </summary>
            
             <value>The new value.</value>
        </member>
        <member name="P:Encog.Neural.ART.ART1.F1Count">
            <summary>
            Set the F1 count.  The F1 layer is the input layer.
            </summary>
        </member>
        <member name="P:Encog.Neural.ART.ART1.F2Count">
             <summary>
             Set the F2 count.  The F2 layer is the output layer.
             </summary>
            
             <value>The count.</value>
        </member>
        <member name="P:Encog.Neural.ART.ART1.L">
             <summary>
             Set the L parameter.
             </summary>
            
             <value>The new value.</value>
        </member>
        <member name="P:Encog.Neural.ART.ART1.NoWinner">
            <summary>
            This is the value that is returned if there is no winner.  
            This value is generally set to the index of the last classes, plus 1.
            For example, if there were 3 classes, the network would return 0-2 to
            represent what class was found, in this case the no winner property
            would be set to 3.
            </summary>
        </member>
        <member name="P:Encog.Neural.ART.ART1.Vigilance">
            <summary>
            Set the vigilance.
            </summary>
        </member>
        <member name="P:Encog.Neural.ART.ART1.WeightsF1ToF2">
            <summary>
            Set the f1 to f2 matrix.
            </summary>
        </member>
        <member name="P:Encog.Neural.ART.ART1.WeightsF2ToF1">
            <summary>
            Set the f2 to f1 matrix.
            </summary>
        </member>
        <member name="P:Encog.Neural.ART.ART1.Winner">
            <value>The winning neuron.</value>
        </member>
        <member name="P:Encog.Neural.ART.ART1.HasWinner">
            <returns>Does this network have a "winner"?</returns>
        </member>
        <member name="P:Encog.Neural.ART.ART1.Input">
            <summary>
            Set the input to the neural network.
            </summary>
        </member>
        <member name="M:Encog.Neural.ART.ART1.Classify(Encog.ML.Data.IMLData)">
             <summary>
             Classify the input data to a class number.
             </summary>
            
             <param name="input">The input data.</param>
             <returns>The class that the data belongs to.</returns>
        </member>
        <member name="P:Encog.Neural.ART.ART1.InputCount">
            <summary>
            The input count.
            </summary>
        </member>
        <member name="P:Encog.Neural.ART.ART1.OutputCount">
            <value>The number of neurons in the output count, which is the f2 layer
            count.</value>
        </member>
        <member name="M:Encog.Neural.ART.ART1.Reset">
             <summary>
             Reset the weight matrix back to starting values.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.ART.ART1.Reset(System.Int32)">
             <summary>
             Reset with a specic seed.
             </summary>
            
             <param name="seed">The seed to reset with.</param>
        </member>
        <member name="M:Encog.Neural.ART.ART1.AdjustWeights">
             <summary>
             Adjust the weights for the pattern just presented.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.ART.ART1.Compute(Encog.ML.Data.Specific.BiPolarMLData,Encog.ML.Data.Specific.BiPolarMLData)">
             <summary>
             Compute the output from the ART1 network. This can be called directly or
             used by the BasicNetwork class. Both input and output should be bipolar
             numbers.
             </summary>
            
             <param name="input">The input to the network.</param>
             <param name="output">The output from the network.</param>
        </member>
        <member name="M:Encog.Neural.ART.ART1.Compute(Encog.ML.Data.IMLData)">
             <summary>
             Compute the output for the BasicNetwork class.
             </summary>
            
             <param name="input">The input to the network.</param>
             <returns>The output from the network.</returns>
        </member>
        <member name="M:Encog.Neural.ART.ART1.ComputeF1(Encog.ML.Data.Specific.BiPolarMLData)">
             <summary>
             Compute the output from the F1 layer.
             </summary>
            
             <param name="input">The input to the F1 layer.</param>
        </member>
        <member name="M:Encog.Neural.ART.ART1.ComputeF2">
             <summary>
             Compute the output from the F2 layer.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.ART.ART1.GetOutput(Encog.ML.Data.Specific.BiPolarMLData)">
             <summary>
             Copy the output from the network to another object.
             </summary>
            
             <param name="output">The target object for the output from the network.</param>
        </member>
        <member name="M:Encog.Neural.ART.ART1.Magnitude(Encog.ML.Data.Specific.BiPolarMLData)">
             <summary>
             Get the magnitude of the specified input.
             </summary>
            
             <param name="input">The input to calculate the magnitude for.</param>
             <returns>The magnitude of the specified pattern.</returns>
        </member>
        <member name="T:Encog.Neural.ART.PersistART1">
             <summary>
             Persist an ART1 network.  
             </summary>
            
        </member>
        <member name="P:Encog.Neural.ART.PersistART1.FileVersion">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.ART.PersistART1.PersistClassString">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.ART.PersistART1.Read(System.IO.Stream)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.ART.PersistART1.Save(System.IO.Stream,System.Object)">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.ART.PersistART1.NativeType">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.BAM.BAMNetwork">
             <summary>
             Bidirectional associative memory (BAM) is a type of neural network 
             developed by Bart Kosko in 1988. The BAM is a recurrent neural network 
             that works similarly that allows patterns of different lengths to be 
             mapped bidirectionally to other patterns. This allows it to act as 
             almost a two-way hash map. During training the BAM is fed pattern pairs. 
             The two halves of each pattern do not have to be the to be of the 
             same length. However all patterns must be of the same overall structure. 
             The BAM can be fed a distorted pattern on either side and will attempt 
             to map to the correct value.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.BAM.BAMNetwork._f1Count">
             <summary>
             Neurons in the F1 layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.BAM.BAMNetwork._f2Count">
             <summary>
             Neurons in the F2 layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.BAM.BAMNetwork._weightsF1ToF2">
             <summary>
             The weights between the F1 and F2 layers.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.BAM.BAMNetwork._weightsF2ToF1">
             <summary>
             The weights between the F1 and F2 layers.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.BAM.BAMNetwork.#ctor">
             <summary>
             Default constructor, used mainly for persistence.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.BAM.BAMNetwork.#ctor(System.Int32,System.Int32)">
             <summary>
             Construct the BAM network.
             </summary>
            
             <param name="theF1Count">The F1 count.</param>
             <param name="theF2Count">The F2 count.</param>
        </member>
        <member name="P:Encog.Neural.BAM.BAMNetwork.F1Count">
            <summary>
            Set the F1 neuron count.
            </summary>
        </member>
        <member name="P:Encog.Neural.BAM.BAMNetwork.F2Count">
            <summary>
            Set the F2 neuron count.
            </summary>
        </member>
        <member name="P:Encog.Neural.BAM.BAMNetwork.WeightsF1ToF2">
            <summary>
            Set the weights for F1 to F2.
            </summary>
        </member>
        <member name="P:Encog.Neural.BAM.BAMNetwork.WeightsF2ToF1">
            <summary>
            Set the weights for F2 to F1.
            </summary>
        </member>
        <member name="M:Encog.Neural.BAM.BAMNetwork.AddPattern(Encog.ML.Data.IMLData,Encog.ML.Data.IMLData)">
             <summary>
             Add a pattern to the neural network.
             </summary>
            
             <param name="inputPattern">The input pattern.</param>
             <param name="outputPattern">The output pattern(for this input).</param>
        </member>
        <member name="M:Encog.Neural.BAM.BAMNetwork.Clear">
             <summary>
             Clear any connection weights.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.BAM.BAMNetwork.Compute(Encog.ML.Data.IMLData)">
             <summary>
             Setup the network logic, read parameters from the network. NOT USED, call
             compute(NeuralInputData).
             </summary>
            
             <param name="input">NOT USED</param>
             <returns>NOT USED</returns>
        </member>
        <member name="M:Encog.Neural.BAM.BAMNetwork.Compute(Encog.Neural.Networks.NeuralDataMapping)">
             <summary>
             Compute the network for the specified input.
             </summary>
            
             <param name="input">The input to the network.</param>
             <returns>The output from the network.</returns>
        </member>
        <member name="M:Encog.Neural.BAM.BAMNetwork.GetWeight(Encog.MathUtil.Matrices.Matrix,Encog.ML.Data.IMLData,System.Int32,System.Int32)">
             <summary>
             Get the specified weight.
             </summary>
            
             <param name="matrix">The matrix to use.</param>
             <param name="input">The input, to obtain the size from.</param>
             <param name="x"></param>
             <param name="y"></param>
             <returns>The value from the matrix.</returns>
        </member>
        <member name="M:Encog.Neural.BAM.BAMNetwork.PropagateLayer(Encog.MathUtil.Matrices.Matrix,Encog.ML.Data.IMLData,Encog.ML.Data.IMLData)">
             <summary>
             Propagate the layer.
             </summary>
            
             <param name="matrix">The matrix for this layer.</param>
             <param name="input">The input pattern.</param>
             <param name="output">The output pattern.</param>
             <returns>True if the network has become stable.</returns>
        </member>
        <member name="M:Encog.Neural.BAM.BAMNetwork.UpdateProperties">
             <summary>
             
             </summary>
            
        </member>
        <member name="T:Encog.Neural.BAM.PersistBAM">
             <summary>
             Persist the BAM network.
             </summary>
            
        </member>
        <member name="P:Encog.Neural.BAM.PersistBAM.FileVersion">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.BAM.PersistBAM.PersistClassString">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.BAM.PersistBAM.Read(System.IO.Stream)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.BAM.PersistBAM.Save(System.IO.Stream,System.Object)">
             <summary>
             
             </summary>
            
        </member>
        <member name="P:Encog.Neural.BAM.PersistBAM.NativeType">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.CPN.CPNNetwork">
             <summary>
             Counterpropagation Neural Networks (CPN) were developed by Professor 
             Robert Hecht-Nielsen in 1987. CPN neural networks are a hybrid neural 
             network, employing characteristics of both a feedforward neural 
             network and a self-organzing map (SOM). The CPN is composed of 
             three layers, the input, the instar and the outstar. The connection 
             from the input to the instar layer is competitive, with only one 
             neuron being allowed to win. The connection between the instar and 
             outstar is feedforward. The layers are trained separately, 
             using instar training and outstar training. The CPN network is 
             good at regression.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.CPN.CPNNetwork._inputCount">
             <summary>
             The number of neurons in the input layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.CPN.CPNNetwork._instarCount">
             <summary>
             The number of neurons in the instar, or hidden, layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.CPN.CPNNetwork._outstarCount">
             <summary>
             The number of neurons in the outstar, or output, layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.CPN.CPNNetwork._weightsInputToInstar">
             <summary>
             The weights from the input to the instar layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.CPN.CPNNetwork._weightsInstarToOutstar">
             <summary>
             The weights from the instar to the outstar layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.CPN.CPNNetwork._winnerCount">
             <summary>
             The number of winning neurons.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.CPN.CPNNetwork.#ctor(System.Int32,System.Int32,System.Int32,System.Int32)">
             <summary>
             Construct the counterpropagation neural network.
             </summary>
            
             <param name="theInputCount">The number of input neurons.</param>
             <param name="theInstarCount">The number of instar neurons.</param>
             <param name="theOutstarCount">The number of outstar neurons.</param>
             <param name="theWinnerCount">The winner count.</param>
        </member>
        <member name="P:Encog.Neural.CPN.CPNNetwork.InstarCount">
            <value>The instar count, same as the input count.</value>
        </member>
        <member name="P:Encog.Neural.CPN.CPNNetwork.OutstarCount">
            <value>The outstar count, same as the output count.</value>
        </member>
        <member name="P:Encog.Neural.CPN.CPNNetwork.WeightsInputToInstar">
            <value>The weights between the input and instar.</value>
        </member>
        <member name="P:Encog.Neural.CPN.CPNNetwork.WeightsInstarToOutstar">
            <value>The weights between the instar and outstar.</value>
        </member>
        <member name="P:Encog.Neural.CPN.CPNNetwork.WinnerCount">
            <value>The winner count.</value>
        </member>
        <member name="M:Encog.Neural.CPN.CPNNetwork.CalculateError(Encog.ML.Data.IMLDataSet)">
             <summary>
             Calculate the error for this neural network.
             </summary>
            
             <param name="data">The training set.</param>
             <returns>The error percentage.</returns>
        </member>
        <member name="M:Encog.Neural.CPN.CPNNetwork.Compute(Encog.ML.Data.IMLData)">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.CPN.CPNNetwork.InputCount">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.CPN.CPNNetwork.OutputCount">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.CPN.CPNNetwork.Reset">
             <summary>
             
             </summary>
            
        </member>
        <member name="M:Encog.Neural.CPN.CPNNetwork.Reset(System.Int32)">
             <summary>
             
             </summary>
            
        </member>
        <member name="M:Encog.Neural.CPN.CPNNetwork.ComputeInstar(Encog.ML.Data.IMLData)">
             <summary>
             Compute the instar layer.
             </summary>
            
             <param name="input">The input.</param>
             <returns>The output.</returns>
        </member>
        <member name="M:Encog.Neural.CPN.CPNNetwork.ComputeOutstar(Encog.ML.Data.IMLData)">
             <summary>
             Compute the outstar layer.
             </summary>
            
             <param name="input">The input.</param>
             <returns>The output.</returns>
        </member>
        <member name="M:Encog.Neural.CPN.CPNNetwork.UpdateProperties">
             <summary>
             
             </summary>
            
        </member>
        <member name="T:Encog.Neural.CPN.PersistCPN">
             <summary>
             Persist a CPN network.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.CPN.PersistCPN.PropertyInputToInstar">
             <summary>
             The input to instar property.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.CPN.PersistCPN.PropertyInstarToInput">
             <summary>
             The instar to input property.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.CPN.PersistCPN.PropertyWinnerCount">
             <summary>
             The winner count property.
             </summary>
            
        </member>
        <member name="P:Encog.Neural.CPN.PersistCPN.NativeType">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.CPN.PersistCPN.FileVersion">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.CPN.PersistCPN.PersistClassString">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.CPN.PersistCPN.Read(System.IO.Stream)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.CPN.PersistCPN.Save(System.IO.Stream,System.Object)">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.CPN.Training.TrainInstar">
             <summary>
             Used for Instar training of a CPN neural network. A CPN network is a hybrid
             supervised/unsupervised network. The Instar training handles the unsupervised
             portion of the training.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.CPN.Training.TrainInstar._network">
             <summary>
             The network being trained.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.CPN.Training.TrainInstar._training">
             <summary>
             The training data. This is unsupervised training, so only the input
             portion of the training data will be used.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.CPN.Training.TrainInstar._learningRate">
             <summary>
             The learning rate.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.CPN.Training.TrainInstar._mustInit">
             <summary>
             If the weights have not been initialized, then they can be initialized
             before training begins. This will be done on the first iteration.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.CPN.Training.TrainInstar.#ctor(Encog.Neural.CPN.CPNNetwork,Encog.ML.Data.IMLDataSet,System.Double,System.Boolean)">
             <summary>
             Construct the instar training object.
             </summary>
            
             <param name="theNetwork">The network to be trained.</param>
             <param name="theTraining">The training data.</param>
             <param name="theLearningRate">The learning rate.</param>
             <param name="theInitWeights">training elements as instar neurons.</param>
        </member>
        <member name="P:Encog.Neural.CPN.Training.TrainInstar.CanContinue">
            <inheritdoc />
        </member>
        <member name="P:Encog.Neural.CPN.Training.TrainInstar.Method">
            <inheritdoc />
        </member>
        <member name="P:Encog.Neural.CPN.Training.TrainInstar.LearningRate">
            <inheritdoc />
        </member>
        <member name="M:Encog.Neural.CPN.Training.TrainInstar.InitWeights">
             <summary>
             Approximate the weights based on the input values.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.CPN.Training.TrainInstar.Iteration">
            <inheritdoc />
        </member>
        <member name="M:Encog.Neural.CPN.Training.TrainInstar.Pause">
            <inheritdoc />
        </member>
        <member name="M:Encog.Neural.CPN.Training.TrainInstar.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
            <inheritdoc />
        </member>
        <member name="T:Encog.Neural.CPN.Training.TrainOutstar">
             <summary>
             Used for Instar training of a CPN neural network. A CPN network is a hybrid
             supervised/unsupervised network. The Outstar training handles the supervised
             portion of the training.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.CPN.Training.TrainOutstar._network">
             <summary>
             The network being trained.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.CPN.Training.TrainOutstar._training">
             <summary>
             The training data. Supervised training, so both input and ideal must be
             provided.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.CPN.Training.TrainOutstar._learningRate">
             <summary>
             The learning rate.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.CPN.Training.TrainOutstar._mustInit">
             <summary>
             If the weights have not been initialized, then they must be initialized
             before training begins. This will be done on the first iteration.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.CPN.Training.TrainOutstar.#ctor(Encog.Neural.CPN.CPNNetwork,Encog.ML.Data.IMLDataSet,System.Double)">
             <summary>
             Construct the outstar trainer.
             </summary>
            
             <param name="theNetwork">The network to train.</param>
             <param name="theTraining">The training data, must provide ideal outputs.</param>
             <param name="theLearningRate">The learning rate.</param>
        </member>
        <member name="P:Encog.Neural.CPN.Training.TrainOutstar.CanContinue">
            <inheritdoc />
        </member>
        <member name="P:Encog.Neural.CPN.Training.TrainOutstar.Method">
            <inheritdoc />
        </member>
        <member name="P:Encog.Neural.CPN.Training.TrainOutstar.LearningRate">
            <inheritdoc />
        </member>
        <member name="M:Encog.Neural.CPN.Training.TrainOutstar.InitWeight">
             <summary>
             Approximate the weights based on the input values.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.CPN.Training.TrainOutstar.Iteration">
            <inheritdoc />
        </member>
        <member name="M:Encog.Neural.CPN.Training.TrainOutstar.Pause">
            <inheritdoc />
        </member>
        <member name="M:Encog.Neural.CPN.Training.TrainOutstar.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
            <inheritdoc />
        </member>
        <member name="T:Encog.Neural.Data.Basic.BasicNeuralData">
            <summary>
            This is an alias class for Encog 2.5 compatibility.  This class aliases 
            BasicMLData.  Newer code should use BasicMLData in place of this class.
            </summary>
        </member>
        <member name="M:Encog.Neural.Data.Basic.BasicNeuralData.#ctor(System.Double[])">
            <summary>
            Construct the object from an array.
            </summary>
            <param name="d">The array to base on.</param>
        </member>
        <member name="M:Encog.Neural.Data.Basic.BasicNeuralData.#ctor(System.Int32)">
            <summary>
            Construct an empty array of the specified size.
            </summary>
            <param name="size">The size.</param>
        </member>
        <member name="T:Encog.Neural.Data.Basic.BasicNeuralDataPair">
            <summary>
            This is an alias class for Encog 2.5 compatibility.  This class aliases 
            BasicMLDataPair.  Newer code should use BasicMLDataPair in place of this class.
            </summary>
        </member>
        <member name="M:Encog.Neural.Data.Basic.BasicNeuralDataPair.#ctor(Encog.ML.Data.IMLData,Encog.ML.Data.IMLData)">
            <summary>
            Construct the pair from input and ideal for supervised.
            </summary>
            <param name="input">The input data.</param>
            <param name="ideal">The ideal data.</param>
        </member>
        <member name="M:Encog.Neural.Data.Basic.BasicNeuralDataPair.#ctor(Encog.ML.Data.IMLData)">
            <summary>
            Construct the pair from input only for unsupervised.
            </summary>
            <param name="input">The input data.</param>
        </member>
        <member name="T:Encog.Neural.Data.Basic.BasicNeuralDataSet">
            <summary>
            This is an alias class for Encog 2.5 compatibility.  This class aliases 
            BasicMLDataSet.  Newer code should use BasicMLDataSet in place of this class.
            </summary>
        </member>
        <member name="M:Encog.Neural.Data.Basic.BasicNeuralDataSet.#ctor(System.Double[][],System.Double[][])">
            <summary>
            Construct a data set from input and ideal.
            </summary>
            <param name="input">The input data.</param>
            <param name="ideal">The ideal data.</param>
        </member>
        <member name="T:Encog.Neural.Error.ATanErrorFunction">
            <summary>
            An ATan based error function.  This is often used either with QuickProp
            or alone.  This can improve the training time of a propagation
            trained neural network.
            </summary>
        </member>
        <member name="M:Encog.Neural.Error.ATanErrorFunction.CalculateError(System.Double[],System.Double[],System.Double[])">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.Error.IErrorFunction">
            <summary>
            An error function.  This is used to calculate the errors for the
            output layer during propagation training.
            </summary>
        </member>
        <member name="M:Encog.Neural.Error.IErrorFunction.CalculateError(System.Double[],System.Double[],System.Double[])">
            <summary>
            Calculate the error.
            </summary>
            <param name="ideal">The ideal values.</param>
            <param name="actual">The actual values.</param>
            <param name="error">The rror output.</param>
        </member>
        <member name="T:Encog.Neural.Error.LinearErrorFunction">
            <summary>
            The standard linear error function, simply returns the difference 
            between the actual and ideal.
            </summary>
        </member>
        <member name="M:Encog.Neural.Error.LinearErrorFunction.CalculateError(System.Double[],System.Double[],System.Double[])">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.Flat.FlatLayer">
             <summary>
             Used to configure a flat layer. Flat layers are not kept by a Flat Network,
             beyond setup.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatLayer._count">
             <summary>
             The neuron count.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatLayer._biasActivation">
             <summary>
             The bias activation, usually 1 for bias or 0 for no bias.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatLayer._contextFedBy">
             <summary>
             The layer that feeds this layer's context.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Flat.FlatLayer.#ctor(Encog.Engine.Network.Activation.IActivationFunction,System.Int32,System.Double)">
             <summary>
             Construct a flat layer.
             </summary>
            
             <param name="activation">The activation function.</param>
             <param name="count">The neuron count.</param>
             <param name="biasActivation">The bias activation.</param>
        </member>
        <member name="P:Encog.Neural.Flat.FlatLayer.Activation">
            <value>the activation to set</value>
        </member>
        <member name="P:Encog.Neural.Flat.FlatLayer.BiasActivation">
            <summary>
            Set the bias activation.
            </summary>
        </member>
        <member name="P:Encog.Neural.Flat.FlatLayer.ContextCount">
            <value>The number of neurons our context is fed by.</value>
        </member>
        <member name="P:Encog.Neural.Flat.FlatLayer.ContextFedBy">
            <summary>
            Set the layer that this layer's context is fed by.
            </summary>
        </member>
        <member name="P:Encog.Neural.Flat.FlatLayer.Count">
            <value>the count</value>
        </member>
        <member name="P:Encog.Neural.Flat.FlatLayer.TotalCount">
            <value>The total number of neurons on this layer, includes context, bias
            and regular.</value>
        </member>
        <member name="M:Encog.Neural.Flat.FlatLayer.HasBias">
            <returns>the bias</returns>
        </member>
        <member name="M:Encog.Neural.Flat.FlatLayer.ToString">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.Flat.FlatNetwork">
             <summary>
             Implements a flat (vector based) neural network in the Encog Engine. This is
             meant to be a very highly efficient feedforward, or simple recurrent, neural
             network. It uses a minimum of objects and is designed with one principal in
             mind-- SPEED. Readability, code reuse, object oriented programming are all
             secondary in consideration.
             Vector based neural networks are also very good for GPU processing. The flat
             network classes will make use of the GPU if you have enabled GPU processing.
             See the Encog class for more info.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatNetwork.DefaultBiasActivation">
             <summary>
             The default bias activation.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatNetwork.NoBiasActivation">
             <summary>
             The value that indicates that there is no bias activation.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatNetwork._activationFunctions">
             <summary>
             The activation types.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatNetwork._beginTraining">
             <summary>
             The layer that training should begin on.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatNetwork._biasActivation">
             <summary>
             The bias activation for each layer. This is usually either 1, for a bias,
             or zero for no bias.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatNetwork._connectionLimit">
             <summary>
             The limit, under which, all a cconnection is not considered to exist.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatNetwork._contextTargetOffset">
             <summary>
             The context target for each layer. This is how the backwards connections
             are formed for the recurrent neural network. Each layer either has a
             zero, which means no context target, or a layer number that indicates the
             target layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatNetwork._contextTargetSize">
             <summary>
             The size of each of the context targets. If a layer's contextTargetOffset
             is zero, its contextTargetSize should also be zero. The contextTargetSize
             should always match the feed count of the targeted context layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatNetwork._endTraining">
             <summary>
             The layer that training should end on.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatNetwork._hasContext">
             <summary>
             True if the network has context.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatNetwork._inputCount">
             <summary>
             The number of input neurons in this network.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatNetwork._isLimited">
             <summary>
             Does this network have some connections disabled.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatNetwork._layerContextCount">
             <summary>
             The number of context neurons in each layer. These context neurons will
             feed the next layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatNetwork._layerCounts">
             <summary>
             The number of neurons in each of the layers.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatNetwork._layerFeedCounts">
             <summary>
             The number of neurons in each layer that are actually fed by neurons in
             the previous layer. Bias neurons, as well as context neurons, are not fed
             from the previous layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatNetwork._layerIndex">
             <summary>
             An index to where each layer begins (based on the number of neurons in
             each layer).
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatNetwork._layerOutput">
             <summary>
             The outputs from each of the neurons, after activation applied.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatNetwork._layerSums">
             <summary>
             The sums from each of the neurons, before activation applied.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatNetwork._outputCount">
             <summary>
             The number of output neurons in this network.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatNetwork._weightIndex">
             <summary>
             The index to where the weights that are stored at for a given layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatNetwork._weights">
             <summary>
             The weights for a neural network.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Flat.FlatNetwork.#ctor">
             <summary>
             Default constructor.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Flat.FlatNetwork.#ctor(Encog.Neural.Flat.FlatLayer[])">
             <summary>
             Create a flat network from an array of layers.
             </summary>
            
             <param name="layers">The layers.</param>
        </member>
        <member name="M:Encog.Neural.Flat.FlatNetwork.#ctor(System.Int32,System.Int32,System.Int32,System.Int32,System.Boolean)">
             <summary>
             Construct a flat neural network.
             </summary>
            
             <param name="input">Neurons in the input layer.</param>
             <param name="hidden1"></param>
             <param name="hidden2"></param>
             <param name="output">Neurons in the output layer.</param>
             <param name="tanh">True if this is a tanh activation, false for sigmoid.</param>
        </member>
        <member name="P:Encog.Neural.Flat.FlatNetwork.ActivationFunctions">
            <summary>
            Set the activation functions.
            </summary>
        </member>
        <member name="P:Encog.Neural.Flat.FlatNetwork.BeginTraining">
            <value>the beginTraining to set</value>
        </member>
        <member name="P:Encog.Neural.Flat.FlatNetwork.BiasActivation">
            <summary>
            Set the bias activation.
            </summary>
        </member>
        <member name="P:Encog.Neural.Flat.FlatNetwork.ConnectionLimit">
            <value>the connectionLimit to set</value>
        </member>
        <member name="P:Encog.Neural.Flat.FlatNetwork.ContextTargetOffset">
            <summary>
            Set the context target offset.
            </summary>
        </member>
        <member name="P:Encog.Neural.Flat.FlatNetwork.ContextTargetSize">
            <summary>
            Set the context target size.
            </summary>
        </member>
        <member name="P:Encog.Neural.Flat.FlatNetwork.EncodeLength">
            <value>The length of the array the network would encode to.</value>
        </member>
        <member name="P:Encog.Neural.Flat.FlatNetwork.EndTraining">
            <value>the endTraining to set</value>
        </member>
        <member name="P:Encog.Neural.Flat.FlatNetwork.HasContext">
            <summary>
            Set the hasContext property.
            </summary>
        </member>
        <member name="P:Encog.Neural.Flat.FlatNetwork.InputCount">
            <summary>
            Set the input count.
            </summary>
        </member>
        <member name="P:Encog.Neural.Flat.FlatNetwork.LayerContextCount">
            <summary>
            Set the layer context count.
            </summary>
        </member>
        <member name="P:Encog.Neural.Flat.FlatNetwork.LayerCounts">
            <summary>
            Set the layer counts.
            </summary>
        </member>
        <member name="P:Encog.Neural.Flat.FlatNetwork.LayerFeedCounts">
            <summary>
            The layer feed counts. The number of neurons in each layer that are fed by the previous
            layer.
            </summary>
        </member>
        <member name="P:Encog.Neural.Flat.FlatNetwork.LayerIndex">
            <summary>
            Set the layer index.
            </summary>
        </member>
        <member name="P:Encog.Neural.Flat.FlatNetwork.LayerOutput">
            <summary>
            Set the layer output.
            </summary>
        </member>
        <member name="P:Encog.Neural.Flat.FlatNetwork.NeuronCount">
            <value>The neuron count.</value>
        </member>
        <member name="P:Encog.Neural.Flat.FlatNetwork.OutputCount">
            <summary>
            Set the output count.
            </summary>
        </member>
        <member name="P:Encog.Neural.Flat.FlatNetwork.WeightIndex">
            <summary>
            Set the weight index.
            </summary>
        </member>
        <member name="P:Encog.Neural.Flat.FlatNetwork.Weights">
            <summary>
            Set the weights.
            </summary>
        </member>
        <member name="P:Encog.Neural.Flat.FlatNetwork.Limited">
            <value>the isLimited</value>
        </member>
        <member name="M:Encog.Neural.Flat.FlatNetwork.CalculateError(Encog.ML.Data.IMLDataSet)">
             <summary>
             Calculate the error for this neural network. The error is calculated
             using root-mean-square(RMS).
             </summary>
            
             <param name="data">The training set.</param>
             <returns>The error percentage.</returns>
        </member>
        <member name="M:Encog.Neural.Flat.FlatNetwork.ClearConnectionLimit">
             <summary>
             Clear any connection limits.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Flat.FlatNetwork.ClearContext">
             <summary>
             Clear any context neurons.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Flat.FlatNetwork.Clone">
             <summary>
             Clone the network.
             </summary>
            
             <returns>A clone of the network.</returns>
        </member>
        <member name="M:Encog.Neural.Flat.FlatNetwork.CloneFlatNetwork(Encog.Neural.Flat.FlatNetwork)">
             <summary>
             Clone into the flat network passed in.
             </summary>
            
             <param name="result">The network to copy into.</param>
        </member>
        <member name="M:Encog.Neural.Flat.FlatNetwork.Compute(System.Double[],System.Double[])">
             <summary>
             Calculate the output for the given input.
             </summary>
            
             <param name="input">The input.</param>
             <param name="output">Output will be placed here.</param>
        </member>
        <member name="M:Encog.Neural.Flat.FlatNetwork.ComputeLayer(System.Int32)">
             <summary>
             Calculate a layer.
             </summary>
            
             <param name="currentLayer">The layer to calculate.</param>
        </member>
        <member name="M:Encog.Neural.Flat.FlatNetwork.DecodeNetwork(System.Double[])">
             <summary>
             Decode the specified data into the weights of the neural network. This
             method performs the opposite of encodeNetwork.
             </summary>
            
             <param name="data">The data to be decoded.</param>
        </member>
        <member name="M:Encog.Neural.Flat.FlatNetwork.EncodeNetwork">
             <summary>
             Encode the neural network to an array of doubles. This includes the
             network weights. To read this into a neural network, use the
             decodeNetwork method.
             </summary>
            
             <returns>The encoded network.</returns>
        </member>
        <member name="M:Encog.Neural.Flat.FlatNetwork.HasSameActivationFunction">
             <summary>
             Neural networks with only one type of activation function offer certain
             optimization options. This method determines if only a single activation
             function is used.
             </summary>
            
             <returns>The number of the single activation function, or -1 if there are
             no activation functions or more than one type of activation
             function.</returns>
        </member>
        <member name="M:Encog.Neural.Flat.FlatNetwork.Init(Encog.Neural.Flat.FlatLayer[])">
             <summary>
             Construct a flat network.
             </summary>
            
             <param name="layers">The layers of the network to create.</param>
        </member>
        <member name="M:Encog.Neural.Flat.FlatNetwork.Randomize">
             <summary>
             Perform a simple randomization of the weights of the neural network
             between -1 and 1.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Flat.FlatNetwork.Randomize(System.Double,System.Double)">
             <summary>
             Perform a simple randomization of the weights of the neural network
             between the specified hi and lo.
             </summary>
            
             <param name="hi">The network high.</param>
             <param name="lo">The network low.</param>
        </member>
        <member name="P:Encog.Neural.Flat.FlatNetwork.LayerSums">
            <summary>
            The layer sums, before the activation is applied.
            </summary>
        </member>
        <member name="T:Encog.Neural.Flat.FlatNetworkRBF">
             <summary>
             A flat network designed to handle an RBF.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Flat.FlatNetworkRBF._rbf">
             <summary>
             The RBF's used.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Flat.FlatNetworkRBF.#ctor">
             <summary>
             Default constructor.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Flat.FlatNetworkRBF.#ctor(System.Int32,System.Int32,System.Int32,Encog.MathUtil.RBF.IRadialBasisFunction[])">
             <summary>
             Construct an RBF flat network.
             </summary>
            
             <param name="inputCount">The number of input neurons. (also the number of dimensions)</param>
             <param name="hiddenCount">The number of hidden neurons.</param>
             <param name="outputCount">The number of output neurons.</param>
             <param name="rbf"></param>
        </member>
        <member name="P:Encog.Neural.Flat.FlatNetworkRBF.RBF">
            <summary>
            Set the RBF's used.
            </summary>
        </member>
        <member name="M:Encog.Neural.Flat.FlatNetworkRBF.Clone">
             <summary>
             Clone the network.
             </summary>
            
             <returns>A clone of the network.</returns>
        </member>
        <member name="M:Encog.Neural.Flat.FlatNetworkRBF.Compute(System.Double[],System.Double[])">
             <summary>
             Calculate the output for the given input.
             </summary>
            
             <param name="x">The input.</param>
             <param name="output">Output will be placed here.</param>
        </member>
        <member name="T:Encog.Neural.NEAT.NEATLink">
             <summary>
             Implements a link between two NEAT neurons.
             NeuroEvolution of Augmenting Topologies (NEAT) is a genetic algorithm for the
             generation of evolving artificial neural networks. It was developed by Ken
             Stanley while at The University of Texas at Austin.
             http://www.cs.ucf.edu/~kstanley/
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATLink._fromNeuron">
             <summary>
             The source neuron.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATLink._recurrent">
             <summary>
             Is this link recurrent.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATLink._toNeuron">
             <summary>
             The target neuron.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATLink._weight">
             <summary>
             The weight between the two neurons.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.NEAT.NEATLink.#ctor">
             <summary>
             Default constructor, used mainly for persistance.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.NEAT.NEATLink.#ctor(System.Double,Encog.Neural.NEAT.NEATNeuron,Encog.Neural.NEAT.NEATNeuron,System.Boolean)">
             <summary>
             Construct a NEAT link.
             </summary>
            
             <param name="weight">The weight between the two neurons.</param>
             <param name="fromNeuron">The source neuron.</param>
             <param name="toNeuron">The target neuron.</param>
             <param name="recurrent">Is this a recurrent link.</param>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATLink.FromNeuron">
            <value>The source neuron.</value>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATLink.ToNeuron">
            <value>The target neuron.</value>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATLink.Weight">
            <value>The weight of the link.</value>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATLink.Recurrent">
            <value>True if this is a recurrent link.</value>
        </member>
        <member name="M:Encog.Neural.NEAT.NEATLink.ToString">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.NEAT.NEATNetwork">
            <summary>
            Implements a NEAT network as a synapse between two layers. In Encog, a NEAT
            network is created by using a NEATSynapse between an input and output layer.
            NEAT networks only have an input and an output layer. There are no actual
            hidden layers. Rather this synapse will evolve many hidden neurons that have
            connections that are not easily defined by layers. Connections can be
            feedforward, recurrent, or self-connected.
            NEAT networks relieve the programmer of the need to define the hidden layer
            structure of the neural network.
            The output from the neural network can be calculated normally or using a
            snapshot. The snapshot mode is slower, but it can be more accurate. The
            snapshot handles recurrent layers better, as it takes the time to loop
            through the network multiple times to "flush out" the recurrent links.
            NeuroEvolution of Augmenting Topologies (NEAT) is a genetic algorithm for the
            generation of evolving artificial neural networks. It was developed by Ken
            Stanley while at The University of Texas at Austin.
            http://www.cs.ucf.edu/~kstanley/
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNetwork.PropertyNetworkDepth">
            <summary>
            The depth property.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNetwork.PropertyLinks">
            <summary>
            The links property.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNetwork.PropertySnapshot">
            <summary>
            The snapshot property.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNetwork._neurons">
             <summary>
             The neurons that make up this network.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNetwork._activationFunction">
             <summary>
             The activation function.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNetwork._inputCount">
            <summary>
            The input count.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNetwork._networkDepth">
             <summary>
             The depth of the network.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNetwork._outputActivationFunction">
            <summary>
            The output activation function.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNetwork._outputCount">
            <summary>
            The output count.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNetwork._snapshot">
             <summary>
             Should snapshot be used to calculate the output of the neural network.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.NEAT.NEATNetwork.#ctor">
             <summary>
             Default constructor.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.NEAT.NEATNetwork.#ctor(System.Int32,System.Int32,System.Collections.Generic.IEnumerable{Encog.Neural.NEAT.NEATNeuron},Encog.Engine.Network.Activation.IActivationFunction,Encog.Engine.Network.Activation.IActivationFunction,System.Int32)">
             <summary>
             Construct a NEAT synapse.
             </summary>
            
             <param name="inputCount">The number of input neurons.</param>
             <param name="outputCount">The number of output neurons.</param>
             <param name="neurons">The neurons in this synapse.</param>
             <param name="activationFunction">The activation function to use.</param>
             <param name="outputActivationFunction">The output activation function.</param>
             <param name="networkDepth">The depth of the network.</param>
        </member>
        <member name="M:Encog.Neural.NEAT.NEATNetwork.#ctor(System.Int32,System.Int32)">
             <summary>
             Construct a NEAT network.
             </summary>
            
             <param name="inputCount">The input count.</param>
             <param name="outputCount">The output count.</param>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATNetwork.ActivationFunction">
            <summary>
            Set the activation function.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATNetwork.NetworkDepth">
            <summary>
            The network depth.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATNetwork.Neurons">
            <value>The NEAT neurons.</value>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATNetwork.Snapshot">
            <summary>
            Sets if snapshot is used.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATNetwork.OutputActivationFunction">
            <value>the outputActivationFunction to set</value>
        </member>
        <member name="M:Encog.Neural.NEAT.NEATNetwork.ClearContext">
             <summary>
             Clear any context from previous runs. This sets the activation of all
             neurons to zero.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.NEAT.NEATNetwork.CalculateError(Encog.ML.Data.IMLDataSet)">
             <summary>
             Calculate the error for this neural network. 
             </summary>
            
             <param name="data">The training set.</param>
             <returns>The error percentage.</returns>
        </member>
        <member name="M:Encog.Neural.NEAT.NEATNetwork.Compute(Encog.ML.Data.IMLData)">
             <summary>
             Compute the output from this synapse.
             </summary>
            
             <param name="input">The input to this synapse.</param>
             <returns>The output from this synapse.</returns>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATNetwork.InputCount">
            <summary>
            The input count.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATNetwork.OutputCount">
            <summary>
            The output count.
            </summary>
        </member>
        <member name="M:Encog.Neural.NEAT.NEATNetwork.UpdateProperties">
            <summary>
            Not needed.
            </summary>
        </member>
        <member name="T:Encog.Neural.NEAT.NEATNeuron">
             <summary>
             Implements a NEAT neuron. Neat neurons are of a specific type, defined by the
             NEATNeuronType enum. Usually NEAT uses a sigmoid activation function. The
             activation response is used to allow the slope of the sigmoid to be evolved.
             NeuroEvolution of Augmenting Topologies (NEAT) is a genetic algorithm for the
             generation of evolving artificial neural networks. It was developed by Ken
             Stanley while at The University of Texas at Austin.
             http://www.cs.ucf.edu/~kstanley/
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNeuron._activationResponse">
             <summary>
             The activation response. This is evolved to allow NEAT to scale the slope
             of the activation function.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNeuron._inboundLinks">
             <summary>
             Inbound links to this neuron.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNeuron._neuronID">
             <summary>
             The neuron id.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNeuron._neuronType">
             <summary>
             The type of neuron this is.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNeuron._outputboundLinks">
             <summary>
             The outbound links for this neuron.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNeuron._posX">
             <summary>
             The x-position of this neuron. Used to split links, as well as display.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNeuron._posY">
             <summary>
             The y-position of this neuron. Used to split links, as well as display.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNeuron._splitX">
             <summary>
             The split value for X. Used to track splits.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNeuron._splitY">
             <summary>
             The split value for Y. Used to track splits.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNeuron._sumActivation">
             <summary>
             The sum activation.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNeuron._output">
             <summary>
             The output from the neuron.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.NEAT.NEATNeuron.#ctor">
             <summary>
             Default constructor, used for persistance.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.NEAT.NEATNeuron.#ctor(Encog.Neural.NEAT.NEATNeuronType,System.Int64,System.Double,System.Double,System.Double)">
             <summary>
             Construct a NEAT neuron.
             </summary>
            
             <param name="neuronType_0">The type of neuron.</param>
             <param name="neuronID_1">The id of the neuron.</param>
             <param name="splitY_2">The split for y.</param>
             <param name="splitX_3">THe split for x.</param>
             <param name="activationResponse_4">The activation response.</param>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATNeuron.ActivationResponse">
            <value>the activation response.</value>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATNeuron.InboundLinks">
            <value>the inbound links.</value>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATNeuron.NeuronID">
            <value>The neuron id.</value>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATNeuron.NeuronType">
            <value>the neuron type.</value>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATNeuron.Output">
            <value>The output of the neuron.</value>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATNeuron.OutputboundLinks">
            <value>The outbound links.</value>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATNeuron.PosX">
            <value>The x position.</value>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATNeuron.PosY">
            <value>The y position.</value>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATNeuron.SplitX">
            <value>The split x.</value>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATNeuron.SplitY">
            <value>The split y.</value>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATNeuron.SumActivation">
            <value>The sum activation.</value>
        </member>
        <member name="M:Encog.Neural.NEAT.NEATNeuron.ToString">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.NEAT.NEATNeuron.String2NeuronType(System.String)">
            <summary>
            Convert a string to a NEAT neuron type.
            </summary>
            <param name="t">The string.</param>
            <returns>The NEAT neuron type.</returns>
        </member>
        <member name="M:Encog.Neural.NEAT.NEATNeuron.NeuronType2String(Encog.Neural.NEAT.NEATNeuronType)">
            <summary>
            Convert NEAT neuron type to string.
            </summary>
            <param name="t">The neuron type.</param>
            <returns>The string of the specified neuron type.</returns>
        </member>
        <member name="T:Encog.Neural.NEAT.NEATNeuronType">
             <summary>
             The types of neurons supported by NEAT.
             NeuroEvolution of Augmenting Topologies (NEAT) is a genetic algorithm for the
             generation of evolving artificial neural networks. It was developed by Ken
             Stanley while at The University of Texas at Austin.
             http://www.cs.ucf.edu/~kstanley/
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNeuronType.Bias">
             <summary>
             Each NEAT network has one bias neuron.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNeuronType.Hidden">
             <summary>
             Hidden neurons are between the input and output.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNeuronType.Input">
             <summary>
             Input neurons receive input, they are never altered during evolution.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNeuronType.None">
             <summary>
             Not really a neuron type, as you will never see one of these in the
             network. However, it is used to mark an innovation as not affecting a
             neuron type, but rather a link.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATNeuronType.Output">
             <summary>
             Output neurons provide output, they are never altered during evolution.
             </summary>
            
        </member>
        <member name="T:Encog.Neural.NEAT.NEATPopulation">
            <summary>
            A population that is designed to be used with NEAT.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.NEATPopulation.PropertyNEATActivation">
            <summary>
            NEAT activation function tag.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.NEATPopulation.PropertyOutputActivation">
            <summary>
            NEAT output activation function.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.NEATPopulation._neatActivationFunction">
             <summary>
             The activation function for neat to use.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATPopulation._outputActivationFunction">
             <summary>
             The activation function to use on the output layer of Encog.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.NEATPopulation._snapshot">
            <summary>
            Are we using snapshot?
            </summary>
        </member>
        <member name="M:Encog.Neural.NEAT.NEATPopulation.#ctor(System.Int32,System.Int32,System.Int32)">
             <summary>
             Construct a starting NEAT population.
             </summary>
            
             <param name="inputCount">The input neuron count.</param>
             <param name="outputCount">The output neuron count.</param>
             <param name="populationSize">The population size.</param>
        </member>
        <member name="M:Encog.Neural.NEAT.NEATPopulation.#ctor">
            <summary>
            Construct the object.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATPopulation.InputCount">
            <value>the inputCount to set</value>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATPopulation.OutputCount">
            <value>the outputCount to set</value>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATPopulation.NeatActivationFunction">
            <value>the neatActivationFunction to set</value>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATPopulation.OutputActivationFunction">
            <value>the outputActivationFunction to set</value>
        </member>
        <member name="P:Encog.Neural.NEAT.NEATPopulation.Snapshot">
            <value>the snapshot to set</value>
        </member>
        <member name="T:Encog.Neural.NEAT.PersistNEATNetwork">
            <summary>
            Persist a NEAT network.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.PersistNEATNetwork.FileVersion">
            <summary>
            The file version.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.PersistNEATNetwork.PersistClassString">
            <summary>
            The persist class string.
            </summary>
        </member>
        <member name="M:Encog.Neural.NEAT.PersistNEATNetwork.Read(System.IO.Stream)">
            <summary>
            Read the object.
            </summary>
            <param name="mask0">The stream to read from.</param>
            <returns>The loaded object.</returns>
        </member>
        <member name="M:Encog.Neural.NEAT.PersistNEATNetwork.Save(System.IO.Stream,System.Object)">
            <summary>
            Save the object.
            </summary>
            <param name="os">The output stream.</param>
            <param name="obj">The object to save.</param>
        </member>
        <member name="M:Encog.Neural.NEAT.PersistNEATNetwork.WriteLink(Encog.Persist.EncogWriteHelper,Encog.Neural.NEAT.NEATLink)">
            <summary>
            Write a link.
            </summary>
            <param name="xout">The output file.</param>
            <param name="link">The link.</param>
        </member>
        <member name="P:Encog.Neural.NEAT.PersistNEATNetwork.NativeType">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.NEAT.Training.NEATGenome">
             <summary>
             Implements a NEAT genome. This is a "blueprint" for creating a neural
             network.
             NeuroEvolution of Augmenting Topologies (NEAT) is a genetic algorithm for the
             generation of evolving artificial neural networks. It was developed by Ken
             Stanley while at The University of Texas at Austin.
             http://www.cs.ucf.edu/~kstanley/
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATGenome.PROPERTY_NEURONS">
            <summary>
            The neurons property.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATGenome.PROPERTY_LINKS">
            <summary>
            The links property.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATGenome.TWEAK_DISJOINT">
             <summary>
             The adjustment factor for disjoint genes.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATGenome.TWEAK_EXCESS">
             <summary>
             The adjustment factor for excess genes.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATGenome.TWEAK_MATCHED">
             <summary>
             The adjustment factor for matched genes.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATGenome.inputCount">
             <summary>
             The number of inputs.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATGenome.linksChromosome">
             <summary>
             The chromsome that holds the links.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATGenome.networkDepth">
             <summary>
             THe network depth.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATGenome.neuronsChromosome">
             <summary>
             The chromosome that holds the neurons.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATGenome.outputCount">
             <summary>
             The number of outputs.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATGenome.speciesID">
             <summary>
             The species id.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATGenome.#ctor(Encog.Neural.NEAT.Training.NEATGenome)">
             <summary>
             Construct a genome by copying another.
             </summary>
            
             <param name="other">The other genome.</param>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATGenome.#ctor(System.Int64,Encog.ML.Genetic.Genome.Chromosome,Encog.ML.Genetic.Genome.Chromosome,System.Int32,System.Int32)">
             <summary>
             Create a NEAT gnome.
             </summary>
            
             <param name="genomeID">The genome id.</param>
             <param name="neurons">The neurons.</param>
             <param name="links">The links.</param>
             <param name="inputCount_0">The input count.</param>
             <param name="outputCount_1">The output count.</param>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATGenome.#ctor(System.Int64,System.Int32,System.Int32)">
             <summary>
             Construct a genome, do not provide links and neurons.
             </summary>
            
             <param name="id">The genome id.</param>
             <param name="inputCount_0">The input count.</param>
             <param name="outputCount_1">The output count.</param>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATGenome.#ctor">
            <summary>
            Construct the object.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATGenome.InputCount">
            <value>the inputCount to set</value>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATGenome.Links">
            <value>THe links chromosome.</value>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATGenome.NetworkDepth">
            <value>the networkDepth to set</value>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATGenome.Neurons">
            <value>The neurons chromosome.</value>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATGenome.NumGenes">
            <value>The number of genes in the links chromosome.</value>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATGenome.OutputCount">
            <value>the outputCount to set</value>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATGenome.SpeciesID">
             <summary>
             Set the species id.
             </summary>
            
             <value>The species id.</value>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATGenome.LinksChromosome">
            <value>the linksChromosome to set</value>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATGenome.NeuronsChromosome">
            <value>the neuronsChromosome to set</value>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATGenome.Clone">
            <summary>
            Clone the object. Not currently supported.
            </summary>
            <returns>The cloned object.</returns>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATGenome.AddLink(System.Double,System.Double,System.Int32,System.Int32)">
             <summary>
             Mutate the genome by adding a link to this genome.
             </summary>
            
             <param name="mutationRate">The mutation rate.</param>
             <param name="chanceOfLooped">The chance of a self-connected neuron.</param>
             <param name="numTrysToFindLoop">The number of tries to find a loop.</param>
             <param name="numTrysToAddLink">The number of tries to add a link.</param>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATGenome.AddNeuron(System.Double,System.Int32)">
             <summary>
             Mutate the genome by adding a neuron.
             </summary>
            
             <param name="mutationRate">The mutation rate.</param>
             <param name="numTrysToFindOldLink">The number of tries to find a link to split.</param>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATGenome.AlreadyHaveThisNeuronID(System.Int64)">
             <summary>
             Do we already have this neuron id?
             </summary>
            
             <param name="id">The id to check for.</param>
             <returns>True if we already have this neuron id.</returns>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATGenome.ChooseRandomNeuron(System.Boolean)">
             <summary>
             Choose a random neuron.
             </summary>
            
             <param name="includeInput">Should the input neurons be included.</param>
             <returns>The random neuron.</returns>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATGenome.Decode">
             <summary>
             Convert the genes to an actual network.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATGenome.Encode">
             <summary>
             Convert the network to genes. Not currently supported.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATGenome.GetCompatibilityScore(Encog.Neural.NEAT.Training.NEATGenome)">
             <summary>
             Get the compatibility score with another genome. Used to determine
             species.
             </summary>
            
             <param name="genome">The other genome.</param>
             <returns>The score.</returns>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATGenome.GetElementPos(System.Int64)">
             <summary>
             Get the specified neuron's index.
             </summary>
            
             <param name="neuronID">The neuron id to check for.</param>
             <returns>The index.</returns>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATGenome.GetSplitY(System.Int32)">
             <summary>
             Get the specified split y.
             </summary>
            
             <param name="nd">The neuron.</param>
             <returns>The split y.</returns>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATGenome.IsDuplicateLink(System.Int64,System.Int64)">
             <summary>
             Determine if this is a duplicate link.
             </summary>
            
             <param name="fromNeuronID">The from neuron id.</param>
             <param name="toNeuronID">The to neuron id.</param>
             <returns>True if this is a duplicate link.</returns>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATGenome.MutateActivationResponse(System.Double,System.Double)">
             <summary>
             Mutate the activation response.
             </summary>
            
             <param name="mutateRate">The mutation rate.</param>
             <param name="maxPertubation">The maximum to perturb it by.</param>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATGenome.MutateWeights(System.Double,System.Double,System.Double)">
             <summary>
             Mutate the weights.
             </summary>
            
             <param name="mutateRate">The mutation rate.</param>
             <param name="probNewMutate">The probability of a whole new weight.</param>
             <param name="maxPertubation">The max perturbation.</param>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATGenome.SortGenes">
             <summary>
             Sort the genes.
             </summary>
            
        </member>
        <member name="T:Encog.Neural.NEAT.Training.NEATInnovation">
             <summary>
             Implements a NEAT innovation. This lets NEAT track what changes it has
             previously tried with a neural network.
             NeuroEvolution of Augmenting Topologies (NEAT) is a genetic algorithm for the
             generation of evolving artificial neural networks. It was developed by Ken
             Stanley while at The University of Texas at Austin.
             http://www.cs.ucf.edu/~kstanley/
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATInnovation.fromNeuronID">
             <summary>
             The from neuron id.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATInnovation.innovationType">
             <summary>
             The type of innovation.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATInnovation.neuronID">
             <summary>
             The neuron id.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATInnovation.neuronType">
             <summary>
             The type of neuron, or none, if this is a link innovation.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATInnovation.splitX">
             <summary>
             The split x property.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATInnovation.splitY">
             <summary>
             The split y property.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATInnovation.toNeuronID">
             <summary>
             The to neuron's id.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATInnovation.#ctor">
             <summary>
             Default constructor, used mainly for persistence.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATInnovation.#ctor(System.Int64,System.Int64,Encog.Neural.NEAT.Training.NEATInnovationType,System.Int64)">
             <summary>
             Construct an innovation.
             </summary>
            
             <param name="fromNeuronID_0">The from neuron.</param>
             <param name="toNeuronID_1">The two neuron.</param>
             <param name="innovationType_2">The innovation type.</param>
             <param name="innovationID">The innovation id.</param>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATInnovation.#ctor(System.Int64,System.Int64,Encog.Neural.NEAT.Training.NEATInnovationType,System.Int64,Encog.Neural.NEAT.NEATNeuronType,System.Double,System.Double)">
             <summary>
             Construct an innovation.
             </summary>
            
             <param name="fromNeuronID_0">The from neuron.</param>
             <param name="toNeuronID_1">The to neuron.</param>
             <param name="innovationType_2">The innovation type.</param>
             <param name="innovationID">The innovation id.</param>
             <param name="neuronType_3">The neuron type.</param>
             <param name="x">The x coordinate.</param>
             <param name="y">THe y coordinate.</param>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATInnovation.#ctor(Encog.Neural.Neat.Training.NEATNeuronGene,System.Int64,System.Int64)">
             <summary>
             Construct an innovation.
             </summary>
            
             <param name="neuronGene">The neuron gene.</param>
             <param name="innovationID">The innovation id.</param>
             <param name="neuronID_0">The neuron id.</param>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATInnovation.FromNeuronID">
            <value>the fromNeuronID to set</value>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATInnovation.InnovationType">
            <summary>
            The innovation type.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATInnovation.NeuronID">
            <summary>
            Set the neuron id.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATInnovation.NeuronType">
            <summary>
            The neuron type.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATInnovation.SplitX">
            <summary>
            The split X, useful for display, also used during training, max is 1.0.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATInnovation.SplitY">
            <summary>
            The split Y, useful for display, also used during training, max is 1.0.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATInnovation.ToNeuronID">
            <value>the toNeuronID to set</value>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATInnovation.ToString">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.NEAT.Training.NEATInnovationList">
             <summary>
             Implements a NEAT innovation list.
             NeuroEvolution of Augmenting Topologies (NEAT) is a genetic algorithm for the
             generation of evolving artificial neural networks. It was developed by Ken
             Stanley while at The University of Texas at Austin.
             http://www.cs.ucf.edu/~kstanley/
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATInnovationList.nextNeuronID">
             <summary>
             The next neuron id.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATInnovationList.population">
             <summary>
             The population.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATInnovationList.#ctor">
             <summary>
             The default constructor, used mainly for persistance.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATInnovationList.#ctor(Encog.ML.Genetic.Population.IPopulation,Encog.ML.Genetic.Genome.Chromosome,Encog.ML.Genetic.Genome.Chromosome)">
             <summary>
             Construct an innovation list.
             </summary>
            
             <param name="population_0">The population.</param>
             <param name="links">The links.</param>
             <param name="neurons">THe neurons.</param>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATInnovationList.Population">
            <summary>
            The population.
            </summary>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATInnovationList.AssignNeuronID">
             <summary>
             Assign a neuron ID.
             </summary>
            
             <returns>The neuron id.</returns>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATInnovationList.CheckInnovation(System.Int64,System.Int64,Encog.Neural.NEAT.Training.NEATInnovationType)">
             <summary>
             Check to see if we already have an innovation.
             </summary>
            
             <param name="ins0">The input neuron.</param>
             <param name="xout">THe output neuron.</param>
             <param name="type">The type.</param>
             <returns>The innovation, either new or existing if found.</returns>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATInnovationList.CreateNeuronFromID(System.Int64)">
             <summary>
             Create a new neuron gene from an id.
             </summary>
            
             <param name="neuronID">The neuron id.</param>
             <returns>The neuron gene.</returns>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATInnovationList.CreateNewInnovation(System.Int64,System.Int64,Encog.Neural.NEAT.Training.NEATInnovationType)">
             <summary>
             Create a new innovation.
             </summary>
            
             <param name="ins0">The input neuron.</param>
             <param name="xout">The output neuron.</param>
             <param name="type">The type.</param>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATInnovationList.CreateNewInnovation(System.Int64,System.Int64,Encog.Neural.NEAT.Training.NEATInnovationType,Encog.Neural.NEAT.NEATNeuronType,System.Double,System.Double)">
             <summary>
             Create a new innovation.
             </summary>
            
             <param name="from">The from neuron.</param>
             <param name="to">The to neuron.</param>
             <param name="innovationType">THe innovation type.</param>
             <param name="neuronType">The neuron type.</param>
             <param name="x">The x-coordinate.</param>
             <param name="y">The y-coordinate.</param>
             <returns>The new innovation.</returns>
        </member>
        <member name="T:Encog.Neural.NEAT.Training.NEATInnovationType">
             <summary>
             The type of NEAT innovation.
             NeuroEvolution of Augmenting Topologies (NEAT) is a genetic algorithm for the
             generation of evolving artificial neural networks. It was developed by Ken
             Stanley while at The University of Texas at Austin.
             http://www.cs.ucf.edu/~kstanley/
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATInnovationType.NewLink">
             <summary>
             A new link.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATInnovationType.NewNeuron">
             <summary>
             A new neuron.
             </summary>
            
        </member>
        <member name="T:Encog.Neural.NEAT.Training.NEATLinkGene">
             <summary>
             Implements a NEAT link gene. This describes a way in which two neurons are
             linked.
             NeuroEvolution of Augmenting Topologies (NEAT) is a genetic algorithm for the
             generation of evolving artificial neural networks. It was developed by Ken
             Stanley while at The University of Texas at Austin.
             http://www.cs.ucf.edu/~kstanley/
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATLinkGene.fromNeuronID">
             <summary>
             The from neuron id.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATLinkGene.recurrent">
             <summary>
             Is this a recurrent connection.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATLinkGene.toNeuronID">
             <summary>
             The to neuron id.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATLinkGene.weight">
             <summary>
             The weight of this link.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATLinkGene.#ctor">
             <summary>
             Default constructor, used mainly for persistence.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATLinkGene.#ctor(System.Int64,System.Int64,System.Boolean,System.Int64,System.Double,System.Boolean)">
             <summary>
             Construct a NEAT link gene.
             </summary>
            
             <param name="fromNeuronID_0">The source neuron.</param>
             <param name="toNeuronID_1">The target neuron.</param>
             <param name="enabled">Is this link enabled.</param>
             <param name="innovationID">The innovation id.</param>
             <param name="weight_2">The weight.</param>
             <param name="recurrent_3">Is this a recurrent link?</param>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATLinkGene.Weight">
            <summary>
            Set the weight of this connection.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATLinkGene.Recurrent">
            <summary>
            True if this is a recurrent link.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATLinkGene.FromNeuronID">
            <summary>
            The from neuron id.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATLinkGene.ToNeuronID">
            <summary>
            The to neuron id.
            </summary>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATLinkGene.Copy(Encog.ML.Genetic.Genes.IGene)">
            <summary>
            Copy from another gene.
            </summary>
            <param name="gene">The other gene.</param>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATLinkGene.ToString">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.NEAT.Training.NEATParent">
             <summary>
             The two parents.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATParent.Dad">
             <summary>
             The father.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATParent.Mom">
             <summary>
             The mother.
             </summary>
            
        </member>
        <member name="T:Encog.Neural.NEAT.Training.NEATTraining">
             <summary>
             Implements NEAT genetic training.
             NeuroEvolution of Augmenting Topologies (NEAT) is a genetic algorithm for the
             generation of evolving artificial neural networks. It was developed by Ken
             Stanley while at The University of Texas at Austin.
             http://www.cs.ucf.edu/~kstanley/
             </summary>
            
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.inputCount">
            <summary>
            The number of inputs.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.outputCount">
            <summary>
            The number of output neurons.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.averageFitAdjustment">
            <summary>
            The average fit adjustment.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.bestEverNetwork">
            <summary>
            The best ever network.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.bestEverScore">
            <summary>
            The best ever score.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.iteration">
            <summary>
            The iteration number.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.paramActivationMutationRate">
            <summary>
            The activation mutation rate.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.paramChanceAddLink">
            <summary>
            The likelyhood of adding a link.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.paramChanceAddNode">
            <summary>
            The likelyhood of adding a node.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.paramChanceAddRecurrentLink">
            <summary>
            The likelyhood of adding a recurrent link.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.paramCompatibilityThreshold">
            <summary>
            The compatibility threshold for a species.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.paramCrossoverRate">
            <summary>
            The crossover rate.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.paramMaxActivationPerturbation">
            <summary>
            The max activation perturbation.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.paramMaxNumberOfSpecies">
            <summary>
            The maximum number of species.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.paramMaxPermittedNeurons">
            <summary>
            The maximum number of neurons.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.paramMaxWeightPerturbation">
            <summary>
            The maximum weight perturbation.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.paramMutationRate">
            <summary>
            The mutation rate.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.paramNumAddLinkAttempts">
            <summary>
            The number of link add attempts.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.paramNumGensAllowedNoImprovement">
            <summary>
            The number of generations allowed with no improvement.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.paramNumTrysToFindLoopedLink">
            <summary>
            The number of tries to find a looped link.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.paramNumTrysToFindOldLink">
            <summary>
            The number of tries to find an old link.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.paramProbabilityWeightReplaced">
            <summary>
            The probability that the weight will be totally replaced.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.snapshot">
            <summary>
            Determines if we are using snapshot mode.
            </summary>
        </member>
        <member name="F:Encog.Neural.NEAT.Training.NEATTraining.totalFitAdjustment">
            <summary>
            The total fit adjustment.
            </summary>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATTraining.#ctor(Encog.Neural.Networks.Training.ICalculateScore,System.Int32,System.Int32,System.Int32)">
            <summary>
            Construct a neat trainer with a new population. The new population is
            created from the specified parameters.
            </summary>
            <param name="calculateScore">The score calculation object.</param>
            <param name="inputCount">The input neuron count.</param>
            <param name="outputCount">The output neuron count.</param>
            <param name="populationSize">The population size.</param>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATTraining.#ctor(Encog.Neural.Networks.Training.ICalculateScore,Encog.ML.Genetic.Population.IPopulation)">
            <summary>
            Construct neat training with an existing population.
            </summary>
            <param name="calculateScore">The score object to use.</param>
            <param name="population">The population to use.</param>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.Innovations">
            <summary>
            The innovations.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.InputCount">
            <summary>
            The input count.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.OutputCount">
            <summary>
            The number of output neurons.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.ParamActivationMutationRate">
            <summary>
            Set the activation mutation rate.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.ParamChanceAddLink">
            <summary>
            Set the chance to add a link.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.ParamChanceAddNode">
            <summary>
            Set the chance to add a node.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.ParamChanceAddRecurrentLink">
            <summary>
            Set the chance to add a recurrent link.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.ParamCompatibilityThreshold">
            <summary>
            Set the compatibility threshold for species.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.ParamCrossoverRate">
            <summary>
            Set the cross over rate.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.ParamMaxActivationPerturbation">
            <summary>
            Set the max activation perturbation.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.ParamMaxNumberOfSpecies">
            <summary>
            Set the maximum number of species.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.ParamMaxPermittedNeurons">
            <summary>
            Set the max permitted neurons.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.ParamMaxWeightPerturbation">
            <summary>
            Set the max weight perturbation.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.ParamMutationRate">
            <summary>
            Set the mutation rate.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.ParamNumAddLinkAttempts">
            <summary>
            Set the number of attempts to add a link.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.ParamNumGensAllowedNoImprovement">
            <summary>
            Set the number of no-improvement generations allowed.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.ParamNumTrysToFindLoopedLink">
            <summary>
            Set the number of tries to create a looped link.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.ParamNumTrysToFindOldLink">
            <summary>
            Set the number of tries to try an old link.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.ParamProbabilityWeightReplaced">
            <summary>
            Set the probability to replace a weight.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.Snapshot">
            <summary>
            Set if we are using snapshot mode.
            </summary>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATTraining.AddStrategy(Encog.ML.Train.Strategy.IStrategy)">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.CanContinue">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATTraining.FinishTraining">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.Error">
            <summary>
            The error for the best genome.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.ImplementationType">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.IterationNumber">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.Method">
            <summary>
            A network created for the best genome.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.Strategies">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.Training">
            <summary>
            Returns null, does not use a training set, rather uses a score function.
            </summary>
        </member>
        <member name="P:Encog.Neural.NEAT.Training.NEATTraining.TrainingDone">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATTraining.Iteration">
            <summary>
            Perform one training iteration.
            </summary>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATTraining.Iteration(System.Int32)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATTraining.Pause">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATTraining.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATTraining.AddNeuronID(System.Int64,System.Collections.Generic.IList{System.Int64})">
            <summary>
            Add the specified neuron id.
            </summary>
            <param name="nodeID">The neuron to add.</param>
            <param name="vec">The list to add to.</param>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATTraining.AdjustCompatibilityThreshold">
            <summary>
            Adjust the compatibility threshold.
            </summary>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATTraining.AdjustSpeciesScore">
            <summary>
            Adjust each species score.
            </summary>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATTraining.Crossover(Encog.Neural.NEAT.Training.NEATGenome,Encog.Neural.NEAT.Training.NEATGenome)">
            <summary>
            Perform a cross over.  
            </summary>
            <param name="mom">The mother genome.</param>
            <param name="dad">The father genome.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATTraining.Init">
            <summary>
            Init the training.
            </summary>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATTraining.ResetAndKill">
            <summary>
            Reset counts and kill genomes with worse scores.
            </summary>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATTraining.SortAndRecord">
            <summary>
            Sort the genomes.
            </summary>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATTraining.SpeciateAndCalculateSpawnLevels">
            <summary>
            Determine the species.
            </summary>
        </member>
        <member name="M:Encog.Neural.NEAT.Training.NEATTraining.TournamentSelection(System.Int32)">
            <summary>
            Select a gene using a tournament.
            </summary>
            <param name="numComparisons">The number of compares to do.</param>
            <returns>The chosen genome.</returns>
        </member>
        <member name="T:Encog.Neural.Neat.PersistNEATPopulation">
            <summary>
            Persist the NEAT population.
            </summary>
        </member>
        <member name="P:Encog.Neural.Neat.PersistNEATPopulation.PersistClassString">
            <summary>
            The persistence class string.
            </summary>
        </member>
        <member name="M:Encog.Neural.Neat.PersistNEATPopulation.Read(System.IO.Stream)">
            <summary>
            Read the object.
            </summary>
            <param name="mask0">The stream to read the object from.</param>
            <returns>The object that was loaded.</returns>
        </member>
        <member name="M:Encog.Neural.Neat.PersistNEATPopulation.Save(System.IO.Stream,System.Object)">
            <summary>
            Save the object.
            </summary>
            <param name="os">The stream to write to.</param>
            <param name="obj">The object to save.</param>
        </member>
        <member name="P:Encog.Neural.Neat.PersistNEATPopulation.FileVersion">
            <summary>
            The file version.
            </summary>
        </member>
        <member name="M:Encog.Neural.Neat.PersistNEATPopulation.NeuronTypeToString(Encog.Neural.NEAT.NEATNeuronType)">
            <summary>
            Convert the neuron type to a string.
            </summary>
            <param name="t">The neuron type.</param>
            <returns>The string.</returns>
        </member>
        <member name="M:Encog.Neural.Neat.PersistNEATPopulation.InnovationTypeToString(Encog.Neural.NEAT.Training.NEATInnovationType)">
            <summary>
            Convert the innovation type to a string.
            </summary>
            <param name="t">The innovation type.</param>
            <returns>The string.</returns>
        </member>
        <member name="M:Encog.Neural.Neat.PersistNEATPopulation.StringToInnovationType(System.String)">
            <summary>
            Convert a string to an innovation type.
            </summary>
            <param name="t">The string to convert.</param>
            <returns>The innovation type.</returns>
        </member>
        <member name="M:Encog.Neural.Neat.PersistNEATPopulation.StringToNeuronType(System.String)">
            <summary>
            Convert a string to a neuron type.
            </summary>
            <param name="t">The string.</param>
            <returns>The resulting neuron type.</returns>
        </member>
        <member name="P:Encog.Neural.Neat.PersistNEATPopulation.NativeType">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.Neat.Training.NEATNeuronGene">
             <summary>
             Implements a NEAT neuron gene.
             NeuroEvolution of Augmenting Topologies (NEAT) is a genetic algorithm for the
             generation of evolving artificial neural networks. It was developed by Ken
             Stanley while at The University of Texas at Austin.
             http://www.cs.ucf.edu/~kstanley/
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Neat.Training.NEATNeuronGene.PROPERTY_ACT_RESPONSE">
            <summary>
            The activation response tag.
            </summary>
        </member>
        <member name="F:Encog.Neural.Neat.Training.NEATNeuronGene.PROPERTY_RECURRENT">
            <summary>
            The recurrent tag.
            </summary>
        </member>
        <member name="F:Encog.Neural.Neat.Training.NEATNeuronGene.PROPERTY_SPLIT_X">
            <summary>
            The split-x tag.
            </summary>
        </member>
        <member name="F:Encog.Neural.Neat.Training.NEATNeuronGene.PROPERTY_SPLIT_Y">
            <summary>
            The split-y tag.
            </summary>
        </member>
        <member name="F:Encog.Neural.Neat.Training.NEATNeuronGene.activationResponse">
             <summary>
             The activation response, the slope of the activation function.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Neat.Training.NEATNeuronGene.neuronType">
             <summary>
             The neuron type.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Neat.Training.NEATNeuronGene.recurrent">
             <summary>
             True if this is recurrent.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Neat.Training.NEATNeuronGene.splitX">
             <summary>
             The x-split.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Neat.Training.NEATNeuronGene.splitY">
             <summary>
             The y-split.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Neat.Training.NEATNeuronGene.#ctor">
             <summary>
             The default constructor.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Neat.Training.NEATNeuronGene.#ctor(Encog.Neural.NEAT.NEATNeuronType,System.Int64,System.Double,System.Double)">
             <summary>
             Construct a gene.
             </summary>
            
             <param name="type">The type of neuron.</param>
             <param name="id">The id of this gene.</param>
             <param name="splitY_0">The split y.</param>
             <param name="splitX_1">The split x.</param>
        </member>
        <member name="M:Encog.Neural.Neat.Training.NEATNeuronGene.#ctor(Encog.Neural.NEAT.NEATNeuronType,System.Int64,System.Double,System.Double,System.Boolean,System.Double)">
             <summary>
             Construct a neuron gene.
             </summary>
            
             <param name="type">The type of neuron.</param>
             <param name="id">The id of this gene.</param>
             <param name="splitY_0">The split y.</param>
             <param name="splitX_1">The split x.</param>
             <param name="recurrent_2">True if this is a recurrent link.</param>
             <param name="act">The activation response.</param>
        </member>
        <member name="P:Encog.Neural.Neat.Training.NEATNeuronGene.ActivationResponse">
            <summary>
            Set the activation response.
            </summary>
        </member>
        <member name="P:Encog.Neural.Neat.Training.NEATNeuronGene.NeuronType">
            <summary>
            Set the neuron type.
            </summary>
        </member>
        <member name="P:Encog.Neural.Neat.Training.NEATNeuronGene.SplitX">
            <summary>
            Set the split x.
            </summary>
        </member>
        <member name="P:Encog.Neural.Neat.Training.NEATNeuronGene.SplitY">
            <summary>
            Set the split y.
            </summary>
        </member>
        <member name="P:Encog.Neural.Neat.Training.NEATNeuronGene.Recurrent">
            <summary>
            Set if this is a recurrent neuron.
            </summary>
        </member>
        <member name="M:Encog.Neural.Neat.Training.NEATNeuronGene.Copy(Encog.ML.Genetic.Genes.IGene)">
             <summary>
             Copy another gene to this one.
             </summary>
            
             <param name="gene">The other gene.</param>
        </member>
        <member name="M:Encog.Neural.Neat.Training.NEATNeuronGene.ToString">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.Networks.BasicNetwork">
             <summary>
             This class implements a neural network. This class works in conjunction the
             Layer classes. Layers are added to the BasicNetwork to specify the structure
             of the neural network.
             The first layer added is the input layer, the final layer added is the output
             layer. Any layers added between these two layers are the hidden layers.
             The network structure is stored in the structure member. It is important to
             call:
             network.getStructure().finalizeStructure();
             Once the neural network has been completely constructed.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.BasicNetwork.TagLimit">
             <summary>
             Tag used for the connection limit.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.BasicNetwork.DefaultConnectionLimit">
             <summary>
             The default connection limit.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.BasicNetwork.TagConnectionLimit">
             <summary>
             The property for connection limit.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.BasicNetwork.TagBeginTraining">
             <summary>
             The property for begin training.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.BasicNetwork.TagContextTargetOffset">
             <summary>
             The property for context target offset.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.BasicNetwork.TagContextTargetSize">
             <summary>
             The property for context target size.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.BasicNetwork.TagEndTraining">
             <summary>
             The property for end training.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.BasicNetwork.TagHasContext">
             <summary>
             The property for has context.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.BasicNetwork.TagLayerCounts">
             <summary>
             The property for layer counts.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.BasicNetwork.TagLayerFeedCounts">
             <summary>
             The property for layer feed counts.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.BasicNetwork.TagLayerIndex">
             <summary>
             The property for layer index.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.BasicNetwork.TagWeightIndex">
             <summary>
             The property for weight index.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.BasicNetwork.TagBiasActivation">
             <summary>
             The property for bias activation.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.BasicNetwork.TagLayerContextCount">
             <summary>
             The property for layer context count.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.BasicNetwork._structure">
             <summary>
             Holds the structure of the network. This keeps the network from having to
             constantly lookup layers and synapses.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.#ctor">
             <summary>
             Construct an empty neural network.
             </summary>
            
        </member>
        <member name="P:Encog.Neural.Networks.BasicNetwork.LayerCount">
            <value>The layer count.</value>
        </member>
        <member name="P:Encog.Neural.Networks.BasicNetwork.Structure">
            <value>Get the structure of the neural network. The structure allows you
            to quickly obtain synapses and layers without traversing the
            network.</value>
        </member>
        <member name="P:Encog.Neural.Networks.BasicNetwork.BiasActivation">
            <summary>
            Sets the bias activation for every layer that supports bias. Make sure
            that the network structure has been finalized before calling this method.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.BasicNetwork.Flat">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.Classify(Encog.ML.Data.IMLData)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.ClearContext">
             <summary>
             Clear any data from any context layers.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.DecodeFromArray(System.Double[])">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.EncodedArrayLength">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.EncodeToArray(System.Double[])">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.CalculateError(Encog.ML.Data.IMLDataSet)">
             <summary>
             Calculate the error for this neural network.
             </summary>
            
             <param name="data">The training set.</param>
             <returns>The error percentage.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.Compute(Encog.ML.Data.IMLData)">
             <summary>
             Compute the output for a given input to the neural network.
             </summary>
            
             <param name="input">The input to the neural network.</param>
             <returns>The output from the neural network.</returns>
        </member>
        <member name="P:Encog.Neural.Networks.BasicNetwork.InputCount">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.Networks.BasicNetwork.OutputCount">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.Reset">
             <summary>
             Reset the weight matrix and the bias values. This will use a
             Nguyen-Widrow randomizer with a range between -1 and 1. If the network
             does not have an input, output or hidden layers, then Nguyen-Widrow
             cannot be used and a simple range randomize between -1 and 1 will be
             used.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.Reset(System.Int32)">
             <summary>
             Reset the weight matrix and the bias values. This will use a
             Nguyen-Widrow randomizer with a range between -1 and 1. If the network
             does not have an input, output or hidden layers, then Nguyen-Widrow
             cannot be used and a simple range randomize between -1 and 1 will be
             used.
             Use the specified seed.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.AddLayer(Encog.Neural.Networks.Layers.ILayer)">
             <summary>
             Add a layer to the neural network. If there are no layers added this
             layer will become the input layer. This function automatically updates
             both the input and output layer references.
             </summary>
            
             <param name="layer">The layer to be added to the network.</param>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.AddWeight(System.Int32,System.Int32,System.Int32,System.Double)">
             <summary>
             Add to a weight.
             </summary>
            
             <param name="fromLayer">The from layer.</param>
             <param name="fromNeuron">The from neuron.</param>
             <param name="toNeuron">The to neuron.</param>
             <param name="v">The value to add.</param>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.CalculateNeuronCount">
             <summary>
             Calculate the total number of neurons in the network across all layers.
             </summary>
            
             <returns>The neuron count.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.Clone">
             <summary>
             Return a clone of this neural network. Including structure, weights and
             bias values. This is a deep copy.
             </summary>
            
             <returns>A cloned copy of the neural network.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.Compute(System.Double[],System.Double[])">
             <summary>
             Compute the output for this network.
             </summary>
            
             <param name="input">The input.</param>
             <param name="output">The output.</param>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.DumpWeights">
            <returns>The weights as a comma separated list.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.EnableConnection(System.Int32,System.Int32,System.Int32,System.Boolean)">
             <summary>
             Enable, or disable, a connection.
             </summary>
            
             <param name="fromLayer">The layer that contains the from neuron.</param>
             <param name="fromNeuron">The source neuron.</param>
             <param name="toNeuron">The target connection.</param>
             <param name="enable">True to enable, false to disable.</param>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.Equals(Encog.Neural.Networks.BasicNetwork)">
             <summary>
             Compare the two neural networks. For them to be equal they must be of the
             same structure, and have the same matrix values.
             </summary>
            
             <param name="other">The other neural network.</param>
             <returns>True if the two networks are equal.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.Equals(Encog.Neural.Networks.BasicNetwork,System.Int32)">
             <summary>
             Determine if this neural network is equal to another. Equal neural
             networks have the same weight matrix and bias values, within a specified
             precision.
             </summary>
            
             <param name="other">The other neural network.</param>
             <param name="precision">The number of decimal places to compare to.</param>
             <returns>True if the two neural networks are equal.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.GetActivation(System.Int32)">
             <summary>
             Get the activation function for the specified layer.
             </summary>
            
             <param name="layer">The layer.</param>
             <returns>The activation function.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.GetLayerBiasActivation(System.Int32)">
             <summary>
             Get the bias activation for the specified layer.
             </summary>
            
             <param name="l">The layer.</param>
             <returns>The bias activation.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.GetLayerNeuronCount(System.Int32)">
             <summary>
             Get the neuron count.
             </summary>
            
             <param name="l">The layer.</param>
             <returns>The neuron count.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.GetLayerOutput(System.Int32,System.Int32)">
             <summary>
             Get the layer output for the specified neuron.
             </summary>
            
             <param name="layer">The layer.</param>
             <param name="neuronNumber">The neuron number.</param>
             <returns>The output from the last call to compute.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.GetLayerTotalNeuronCount(System.Int32)">
             <summary>
             Get the total (including bias and context) neuron cont for a layer.
             </summary>
            
             <param name="l">The layer.</param>
             <returns>The count.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.GetWeight(System.Int32,System.Int32,System.Int32)">
             <summary>
             Get the weight between the two layers.
             </summary>
            
             <param name="fromLayer">The from layer.</param>
             <param name="fromNeuron">The from neuron.</param>
             <param name="toNeuron">The to neuron.</param>
             <returns>The weight value.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.GetHashCode">
             <summary>
             Generate a hash code.
             </summary>
            
             <returns>THe hash code.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.IsConnected(System.Int32,System.Int32,System.Int32)">
             <summary>
             Determine if the specified connection is enabled.
             </summary>
            
             <param name="layer">The layer to check.</param>
             <param name="fromNeuron">The source neuron.</param>
             <param name="toNeuron">THe target neuron.</param>
             <returns>True, if the connection is enabled, false otherwise.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.IsLayerBiased(System.Int32)">
             <summary>
             Determine if the specified layer is biased.
             </summary>
            
             <param name="l">The layer number.</param>
             <returns>True, if the layer is biased.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.SetLayerBiasActivation(System.Int32,System.Double)">
             <summary>
             Set the bias activation for the specified layer.
             </summary>
            
             <param name="l">The layer to use.</param>
             <param name="value_ren">The bias activation.</param>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.SetWeight(System.Int32,System.Int32,System.Int32,System.Double)">
             <summary>
             Set the weight between the two specified neurons.
             </summary>
            
             <param name="fromLayer">The from layer.</param>
             <param name="fromNeuron">The from neuron.</param>
             <param name="toNeuron">The to neuron.</param>
             <param name="v">The to value.</param>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.ToString">
             <summary>
             
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.UpdateProperties">
             <summary>
             
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.ValidateNeuron(System.Int32,System.Int32)">
             <summary>
             Validate the the specified targetLayer and neuron are valid.
             </summary>
            
             <param name="targetLayer">The target layer.</param>
             <param name="neuron">The target neuron.</param>
        </member>
        <member name="M:Encog.Neural.Networks.BasicNetwork.Winner(Encog.ML.Data.IMLData)">
             <summary>
             Determine the winner for the specified input. This is the number of the
             winning neuron.
             </summary>
            
             <param name="input">The input patter to present to the neural network.</param>
             <returns>The winning neuron.</returns>
        </member>
        <member name="T:Encog.Neural.Networks.IContainsFlat">
             <summary>
             Interface that specifies that a machine learning method contains a 
             flat network.
             </summary>
            
        </member>
        <member name="P:Encog.Neural.Networks.IContainsFlat.Flat">
            <value>The flat network associated with this neural network.</value>
        </member>
        <member name="T:Encog.Neural.Networks.Layers.BasicLayer">
             <summary>
             Basic functionality that most of the neural layers require. The basic layer
             is often used by itself to implement forward or recurrent layers. Other layer
             types are based on the basic layer as well.
             The following summarizes how basic layers calculate the output for a neural
             network.
             Example of a simple XOR network.
             Input: BasicLayer: 2 Neurons, null biasWeights, null biasActivation
             Hidden: BasicLayer: 2 Neurons, 2 biasWeights, 1 biasActivation
             Output: BasicLayer: 1 Neuron, 1 biasWeights, 1 biasActivation
             Input1Output and Input2Output are both provided.
             Synapse 1: Input to Hidden Hidden1Activation = (Input1Output 
             Input1->Hidden1Weight) + (Input2Output/// Input2->Hidden1Weight) +
             (HiddenBiasActivation/// Hidden1BiasWeight)
             Hidden1Output = calculate(Hidden1Activation, HiddenActivationFunction)
             Hidden2Activation = (Input1Output/// Input1->Hidden2Weight) + (Input2Output 
             Input2->Hidden2Weight) + (HiddenBiasActivation/// Hidden2BiasWeight)
             Hidden2Output = calculate(Hidden2Activation, HiddenActivationFunction)
             Synapse 2: Hidden to Output
             Output1Activation = (Hidden1Output/// Hidden1->Output1Weight)
             + (Hidden2Output 
             Hidden2->Output1Weight) + (OutputBiasActivation/// Output1BiasWeight)
             Output1Output = calculate(Output1Activation, OutputActivationFunction)
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Layers.BasicLayer._network">
             <summary>
             The network that this layer belongs to.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Layers.BasicLayer.#ctor(Encog.Engine.Network.Activation.IActivationFunction,System.Boolean,System.Int32)">
             <summary>
             Construct this layer with a non-default activation function, also
             determine if a bias is desired or not.
             </summary>
            
             <param name="activationFunction">The activation function to use.</param>
             <param name="neuronCount">How many neurons in this layer.</param>
             <param name="hasBias">True if this layer has a bias.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Layers.BasicLayer.#ctor(System.Int32)">
            <summary>
            Construct this layer with a sigmoid activation function.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Layers.BasicLayer.Network">
            <summary>
            Set the network for this layer.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Layers.BasicLayer.NeuronCount">
            <summary>
            THe neuron count.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Layers.BasicLayer.ActivationFunction">
            <summary>
            The activation function.
            </summary>
        </member>
        <member name="T:Encog.Neural.Networks.Layers.ILayer">
             <summary>
             This interface defines all necessary methods for a neural network layer.
             </summary>
            
        </member>
        <member name="P:Encog.Neural.Networks.Layers.ILayer.ActivationFunction">
            <value>The activation function used for this layer.</value>
        </member>
        <member name="P:Encog.Neural.Networks.Layers.ILayer.Network">
            <summary>
            Set the network that this layer belongs to.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Layers.ILayer.NeuronCount">
            <value>The neuron count.</value>
        </member>
        <member name="P:Encog.Neural.Networks.Layers.ILayer.BiasActivation">
            <summary>
            Most layer types will default this value to one. However, it is possible
            to use other values. This is the activation that will be passed over the
            bias weights to the inputs of this layer. See the Layer interface
            documentation for more information on how Encog handles bias values.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Layers.ILayer.Activation">
             <summary>
             Set the activation function.
             </summary>
            
             <value>The activation function.</value>
        </member>
        <member name="M:Encog.Neural.Networks.Layers.ILayer.HasBias">
            <returns>True if this layer has a bias.</returns>
        </member>
        <member name="T:Encog.Neural.Networks.NeuralDataMapping">
             <summary>
             Used to map one neural data object to another. Useful for a BAM network.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.NeuralDataMapping.#ctor">
             <summary>
             Construct the neural data mapping class, with null values.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.NeuralDataMapping.#ctor(Encog.ML.Data.IMLData,Encog.ML.Data.IMLData)">
             <summary>
             Construct the neural data mapping class with the specified values.
             </summary>
            
             <param name="f">The source data.</param>
             <param name="t">The target data.</param>
        </member>
        <member name="P:Encog.Neural.Networks.NeuralDataMapping.From">
             <summary>
             Set the from data.
             </summary>
            
             <value>The from data.</value>
        </member>
        <member name="P:Encog.Neural.Networks.NeuralDataMapping.To">
             <summary>
             Set the target data.
             </summary>
            
             <value>The target data.</value>
        </member>
        <member name="M:Encog.Neural.Networks.NeuralDataMapping.Copy(Encog.Neural.Networks.NeuralDataMapping,Encog.Neural.Networks.NeuralDataMapping)">
             <summary>
             Copy from one object to the other.
             </summary>
            
             <param name="source">The source object.</param>
             <param name="target">The target object.</param>
        </member>
        <member name="T:Encog.Neural.Networks.PersistBasicNetwork">
             <summary>
             Persist a basic network.
             </summary>
            
        </member>
        <member name="P:Encog.Neural.Networks.PersistBasicNetwork.FileVersion">
            <summary>
            The file version.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.PersistBasicNetwork.PersistClassString">
            <summary>
            The persist class string.
            </summary>
        </member>
        <member name="M:Encog.Neural.Networks.PersistBasicNetwork.Read(System.IO.Stream)">
             <summary>
             Read an object.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.PersistBasicNetwork.Save(System.IO.Stream,System.Object)">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.Networks.PersistBasicNetwork.NativeType">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.Networks.Structure.AnalyzeNetwork">
             <summary>
             Allows the weights and bias values of the neural network to be analyzed.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Structure.AnalyzeNetwork._allValues">
             <summary>
             All of the values in the neural network.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Structure.AnalyzeNetwork._bias">
             <summary>
             The ranges of the bias values.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Structure.AnalyzeNetwork._biasValues">
             <summary>
             The bias values in the neural network.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Structure.AnalyzeNetwork._disabledConnections">
             <summary>
             The number of disabled connections.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Structure.AnalyzeNetwork._totalConnections">
             <summary>
             The total number of connections.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Structure.AnalyzeNetwork._weightValues">
             <summary>
             The weight values in the neural network.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Structure.AnalyzeNetwork._weights">
             <summary>
             The ranges of the weights.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Structure.AnalyzeNetwork._weightsAndBias">
             <summary>
             The ranges of both the weights and biases.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Structure.AnalyzeNetwork.#ctor(Encog.Neural.Networks.BasicNetwork)">
             <summary>
             Construct a network analyze class. Analyze the specified network.
             </summary>
            
             <param name="network">The network to analyze.</param>
        </member>
        <member name="P:Encog.Neural.Networks.Structure.AnalyzeNetwork.AllValues">
            <value>All of the values in the neural network.</value>
        </member>
        <member name="P:Encog.Neural.Networks.Structure.AnalyzeNetwork.Bias">
            <value>The numeric range of the bias values.</value>
        </member>
        <member name="P:Encog.Neural.Networks.Structure.AnalyzeNetwork.BiasValues">
            <value>The bias values in the neural network.</value>
        </member>
        <member name="P:Encog.Neural.Networks.Structure.AnalyzeNetwork.DisabledConnections">
            <value>The number of disabled connections in the network.</value>
        </member>
        <member name="P:Encog.Neural.Networks.Structure.AnalyzeNetwork.TotalConnections">
            <value>The total number of connections in the network.</value>
        </member>
        <member name="P:Encog.Neural.Networks.Structure.AnalyzeNetwork.Weights">
            <value>The numeric range of the weights values.</value>
        </member>
        <member name="P:Encog.Neural.Networks.Structure.AnalyzeNetwork.WeightsAndBias">
            <value>The numeric range of the weights and bias values.</value>
        </member>
        <member name="P:Encog.Neural.Networks.Structure.AnalyzeNetwork.WeightValues">
            <value>The weight values in the neural network.</value>
        </member>
        <member name="M:Encog.Neural.Networks.Structure.AnalyzeNetwork.ToString">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.Networks.Structure.NetworkCODEC">
             <summary>
             This class will extract the "long term memory" of a neural network, that is
             the weights and bias values into an array. This array can be used to view the
             neural network as a linear array of doubles. These values can then be
             modified and copied back into the neural network. This is very useful for
             simulated annealing, as well as genetic algorithms.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Structure.NetworkCODEC.Error">
             <summary>
             Error message.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Structure.NetworkCODEC.ArrayToNetwork(System.Double[],Encog.ML.IMLMethod)">
             <summary>
             Use an array to populate the memory of the neural network.
             </summary>
            
             <param name="array">An array of doubles.</param>
             <param name="network">The network to encode.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Structure.NetworkCODEC.Equals(Encog.Neural.Networks.BasicNetwork,Encog.Neural.Networks.BasicNetwork)">
             <summary>
             Determine if the two neural networks are equal. Uses exact precision
             required by Arrays.equals.
             </summary>
            
             <param name="network1">The first network.</param>
             <param name="network2">The second network.</param>
             <returns>True if the two networks are equal.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Structure.NetworkCODEC.Equals(Encog.Neural.Networks.BasicNetwork,Encog.Neural.Networks.BasicNetwork,System.Int32)">
             <summary>
             Determine if the two neural networks are equal.
             </summary>
            
             <param name="network1">The first network.</param>
             <param name="network2">The second network.</param>
             <param name="precision">How many decimal places to check.</param>
             <returns>True if the two networks are equal.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Structure.NetworkCODEC.NetworkSize(Encog.ML.IMLMethod)">
             <summary>
             Determine the network size.
             </summary>
            
             <param name="network">The network.</param>
             <returns>The size.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Structure.NetworkCODEC.NetworkToArray(Encog.ML.IMLMethod)">
             <summary>
             Convert to an array. This is used with some training algorithms that
             require that the "memory" of the neuron(the weight and bias values) be
             expressed as a linear array.
             </summary>
            
             <param name="network">The network to encode.</param>
             <returns>The memory of the neuron.</returns>
        </member>
        <member name="T:Encog.Neural.Networks.Structure.NeuralStructure">
             <summary>
             Holds "cached" information about the structure of the neural network. This is
             a very good performance boost since the neural network does not need to
             traverse itself each time a complete collection of layers or synapses is
             needed.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Structure.NeuralStructure._layers">
             <summary>
             The layers in this neural network.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Structure.NeuralStructure._network">
             <summary>
             The neural network this class belongs to.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Structure.NeuralStructure._connectionLimit">
             <summary>
             The limit, below which a connection is treated as zero.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Structure.NeuralStructure._connectionLimited">
             <summary>
             Are connections limited?
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Structure.NeuralStructure._flat">
             <summary>
             The flattened form of the network.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Structure.NeuralStructure.#ctor(Encog.Neural.Networks.BasicNetwork)">
            <summary>
            Construct a structure object for the specified network.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Structure.NeuralStructure.ConnectionLimit">
            <value>The connection limit.</value>
        </member>
        <member name="P:Encog.Neural.Networks.Structure.NeuralStructure.Flat">
            <summary>
            Set the flat network.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Structure.NeuralStructure.Layers">
            <value>The layers in this neural network.</value>
        </member>
        <member name="P:Encog.Neural.Networks.Structure.NeuralStructure.Network">
            <value>The network this structure belongs to.</value>
        </member>
        <member name="P:Encog.Neural.Networks.Structure.NeuralStructure.ConnectionLimited">
            <value>True if this is not a fully connected feedforward network.</value>
        </member>
        <member name="M:Encog.Neural.Networks.Structure.NeuralStructure.CalculateSize">
             <summary>
             Calculate the size that an array should be to hold all of the weights and
             bias values.
             </summary>
            
             <returns>The size of the calculated array.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Structure.NeuralStructure.EnforceLimit">
             <summary>
             Enforce that all connections are above the connection limit. Any
             connections below this limit will be severed.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Structure.NeuralStructure.FinalizeLimit">
             <summary>
             Parse/finalize the limit value for connections.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Structure.NeuralStructure.FinalizeStructure">
             <summary>
             Build the synapse and layer structure. This method should be called after
             you are done adding layers to a network, or change the network's logic
             property.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Structure.NeuralStructure.RequireFlat">
             <summary>
             Throw an error if there is no flat network.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Structure.NeuralStructure.UpdateProperties">
             <summary>
             Update any properties from the property map.
             </summary>
            
        </member>
        <member name="T:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealing">
             <summary>
             This class implements a simulated annealing training algorithm for neural
             networks. It is based on the generic SimulatedAnnealing class. It is used in
             the same manner as any other training class that implements the Train
             interface. There are essentially two ways you can make use of this class.
             Either way, you will need a score object. The score object tells the
             simulated annealing algorithm how well suited a neural network is.
             If you would like to use simulated annealing with a training set you should
             make use TrainingSetScore class. This score object uses a training set to
             score your neural network.
             If you would like to be more abstract, and not use a training set, you can
             create your own implementation of the CalculateScore method. This class can
             then score the networks any way that you like.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealing.Cut">
             <summary>
             The cutoff for random data.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealing._anneal">
             <summary>
             This class actually performs the training.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealing._calculateScore">
             <summary>
             Used to calculate the score.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealing._network">
             <summary>
             The neural network that is to be trained.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealing.#ctor(Encog.Neural.Networks.BasicNetwork,Encog.Neural.Networks.Training.ICalculateScore,System.Double,System.Double,System.Int32)">
             <summary>
             Construct a simulated annleaing trainer for a feedforward neural network.
             </summary>
            
             <param name="network">The neural network to be trained.</param>
             <param name="calculateScore">Used to calculate the score for a neural network.</param>
             <param name="startTemp">The starting temperature.</param>
             <param name="stopTemp">The ending temperature.</param>
             <param name="cycles">The number of cycles in a training iteration.</param>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealing.CanContinue">
            <inheritdoc />
        </member>
        <member name="P:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealing.Array">
            <summary>
            Get the network as an array of doubles.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealing.ArrayCopy">
            <value>A copy of the annealing array.</value>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealing.CalculateScore">
            <value>The object used to calculate the score.</value>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealing.Method">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealing.Iteration">
             <summary>
             Perform one iteration of simulated annealing.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealing.Pause">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealing.PutArray(System.Double[])">
             <summary>
             Convert an array of doubles to the current best network.
             </summary>
            
             <param name="array">An array.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealing.Randomize">
             <summary>
             Randomize the weights and bias values. This function does most of the
             work of the class. Each call to this class will randomize the data
             according to the current temperature. The higher the temperature the more
             randomness.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealing.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealingHelper">
             <summary>
             Simple class used by the neural simulated annealing. This class is a subclass
             of the basic SimulatedAnnealing class. The It is used by the actual
             NeuralSimulatedAnnealing class, which subclasses BasicTraining. This class is
             mostly necessary due to the fact that NeuralSimulatedAnnealing can't subclass
             BOTH SimulatedAnnealing and Train, because multiple inheritance is not
             supported.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealingHelper._owner">
             <summary>
             The class that this class should report to.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealingHelper.#ctor(Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealing)">
             <summary>
             Constructs this object.
             </summary>
            
             <param name="owner">The owner of this class, that recieves all messages.</param>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealingHelper.Array">
            <summary>
            Used to pass the getArray call on to the parent object.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealingHelper.ArrayCopy">
             <summary>
             Used to pass the getArrayCopy call on to the parent object.
             </summary>
            
             <value>The array copy created by the owner.</value>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealingHelper.PerformCalculateScore">
             <summary>
             Used to pass the determineError call on to the parent object.
             </summary>
            
             <returns>The error returned by the owner.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealingHelper.PutArray(System.Double[])">
             <summary>
             Used to pass the putArray call on to the parent object.
             </summary>
            
             <param name="array">The array.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Anneal.NeuralSimulatedAnnealingHelper.Randomize">
             <summary>
             Call the owner's randomize method.
             </summary>
            
        </member>
        <member name="T:Encog.Neural.Networks.Training.ICalculateScore">
             <summary>
             Used by simulated annealing and genetic algorithms to calculate the score
             for a neural network.  This allows networks to be ranked.  We may be seeking
             a high or a low score, depending on the value the shouldMinimize
             method returns.
             </summary>
            
        </member>
        <member name="P:Encog.Neural.Networks.Training.ICalculateScore.ShouldMinimize">
            <returns>True if the goal is to minimize the score.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.ICalculateScore.CalculateScore(Encog.ML.IMLRegression)">
             <summary>
             Calculate this network's score.
             </summary>
            
             <param name="network">The network.</param>
             <returns>The score.</returns>
        </member>
        <member name="T:Encog.Neural.Networks.Training.Cross.CrossTraining">
             <summary>
             Base class for cross training trainers. Must use a folded dataset.  
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Cross.CrossTraining._folded">
             <summary>
             The folded dataset.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Cross.CrossTraining._network">
             <summary>
             The network to train.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Cross.CrossTraining.#ctor(Encog.ML.IMLMethod,Encog.ML.Data.Folded.FoldedDataSet)">
             <summary>
             Construct a cross trainer.
             </summary>
            
             <param name="network">The network.</param>
             <param name="training">The training data.</param>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Cross.CrossTraining.Folded">
            <value>The folded training data.</value>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Cross.CrossTraining.Method">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.Networks.Training.Cross.CrossValidationKFold">
             <summary>
             Train using K-Fold cross validation. Each iteration will train a number of
             times equal to the number of folds - 1. Each of these sub iterations will
             train all of the data minus the fold. The fold is used to validate.
             Therefore, you are seeing an error that reflects data that was not always
             used as part of training. This should give you a better error result based on
             how the network will perform on non-trained data.(validation).
             The cross validation trainer must be provided with some other sort of
             trainer, perhaps RPROP, to actually perform the training. The training data
             must be the FoldedDataSet. The folded dataset can wrap most other training
             sets.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Cross.CrossValidationKFold._flatNetwork">
             <summary>
             The flat network to train.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Cross.CrossValidationKFold._networks">
             <summary>
             The network folds.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Cross.CrossValidationKFold._train">
             <summary>
             The underlying trainer to use. This trainer does the actual training.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Cross.CrossValidationKFold.#ctor(Encog.ML.Train.IMLTrain,System.Int32)">
             <summary>
             Construct a cross validation trainer.
             </summary>
            
             <param name="train">The training</param>
             <param name="k">The number of folds.</param>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Cross.CrossValidationKFold.CanContinue">
            <inheritdoc />
        </member>
        <member name="M:Encog.Neural.Networks.Training.Cross.CrossValidationKFold.Iteration">
             <summary>
             Perform one iteration.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Cross.CrossValidationKFold.Pause">
             <summary>
             
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Cross.CrossValidationKFold.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
             <summary>
             
             </summary>
            
        </member>
        <member name="T:Encog.Neural.Networks.Training.Cross.NetworkFold">
             <summary>
             The network for one fold of a cross validation.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Cross.NetworkFold._output">
             <summary>
             The output for this fold.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Cross.NetworkFold._weights">
             <summary>
             The weights for this fold.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Cross.NetworkFold.#ctor(Encog.Neural.Flat.FlatNetwork)">
             <summary>
             Construct a fold from the specified flat network.
             </summary>
            
             <param name="flat">THe flat network.</param>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Cross.NetworkFold.Weights">
            <value>The network weights.</value>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Cross.NetworkFold.Output">
            <value>The network output.</value>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Cross.NetworkFold.CopyToNetwork(Encog.Neural.Flat.FlatNetwork)">
             <summary>
             Copy weights and output to the network.
             </summary>
            
             <param name="target">The network to copy to.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Cross.NetworkFold.CopyFromNetwork(Encog.Neural.Flat.FlatNetwork)">
             <summary>
             Copy the weights and output from the network.
             </summary>
            
             <param name="source">The network to copy from.</param>
        </member>
        <member name="T:Encog.Neural.Networks.Training.Genetic.GeneticScoreAdapter">
             <summary>
             This adapter allows a CalculateScore object to be used to calculate a
             Genome's score, where a CalculateGenomeScore object would be called for.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Genetic.GeneticScoreAdapter._calculateScore">
             <summary>
             The calculate score object to use.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Genetic.GeneticScoreAdapter.#ctor(Encog.Neural.Networks.Training.ICalculateScore)">
             <summary>
             Construct the adapter.
             </summary>
            
             <param name="calculateScore">The CalculateScore object to use.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Genetic.GeneticScoreAdapter.CalculateScore(Encog.ML.Genetic.Genome.IGenome)">
             <summary>
             Calculate the genome's score.
             </summary>
            
             <param name="genome">The genome to calculate for.</param>
             <returns>The calculated score.</returns>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Genetic.GeneticScoreAdapter.ShouldMinimize">
            <returns>True, if the score should be minimized.</returns>
        </member>
        <member name="T:Encog.Neural.Networks.Training.Genetic.NeuralGeneticAlgorithm">
             <summary>
             Implements a genetic algorithm that allows a feedforward or simple recurrent
             neural network to be trained using a genetic algorithm.
             There are essentially two ways you can make use of this class.
             Either way, you will need a score object. The score object tells the genetic
             algorithm how well suited a neural network is.
             If you would like to use genetic algorithms with a training set you should
             make use TrainingSetScore class. This score object uses a training set to
             score your neural network.
             If you would like to be more abstract, and not use a training set, you can
             create your own implementation of the CalculateScore method. This class can
             then score the networks any way that you like.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Genetic.NeuralGeneticAlgorithm.#ctor(Encog.Neural.Networks.BasicNetwork,Encog.MathUtil.Randomize.IRandomizer,Encog.Neural.Networks.Training.ICalculateScore,System.Int32,System.Double,System.Double)">
             <summary>
             Construct a neural genetic algorithm.
             </summary>
            
             <param name="network">The network to base this on.</param>
             <param name="randomizer">The randomizer used to create this initial population.</param>
             <param name="calculateScore">The score calculation object.</param>
             <param name="populationSize">The population size.</param>
             <param name="mutationPercent">The percent of offspring to mutate.</param>
             <param name="percentToMate">The percent of the population allowed to mate.</param>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Genetic.NeuralGeneticAlgorithm.CanContinue">
            <inheritdoc />
        </member>
        <member name="P:Encog.Neural.Networks.Training.Genetic.NeuralGeneticAlgorithm.Genetic">
            <summary>
            Set the genetic helper class.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Genetic.NeuralGeneticAlgorithm.Method">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Genetic.NeuralGeneticAlgorithm.Iteration">
             <summary>
             Perform one training iteration.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Genetic.NeuralGeneticAlgorithm.Pause">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Genetic.NeuralGeneticAlgorithm.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.Networks.Training.Genetic.NeuralGeneticAlgorithm.NeuralGeneticAlgorithmHelper">
             <summary>
             Very simple class that implements a genetic algorithm.
             </summary>
            
        </member>
        <member name="P:Encog.Neural.Networks.Training.Genetic.NeuralGeneticAlgorithm.NeuralGeneticAlgorithmHelper.Error">
            <value>The error from the last iteration.</value>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Genetic.NeuralGeneticAlgorithm.NeuralGeneticAlgorithmHelper.Method">
            <summary>
            Get the current best neural network.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Genetic.NeuralGeneticAlgorithm.ThreadCount">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.Networks.Training.Genetic.NeuralGenome">
             <summary>
             Implements a genome that allows a feedforward neural network to be trained
             using a genetic algorithm. The chromosome for a feed forward neural network
             is the weight and bias matrix.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Genetic.NeuralGenome._networkChromosome">
             <summary>
             The chromosome.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Genetic.NeuralGenome.#ctor(Encog.Neural.Networks.BasicNetwork)">
             <summary>
             Construct a neural genome.
             </summary>
            
             <param name="network">The network to use.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Genetic.NeuralGenome.Decode">
             <summary>
             Decode the genomes into a neural network.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Genetic.NeuralGenome.Encode">
             <summary>
             Encode the neural network into genes.
             </summary>
            
        </member>
        <member name="T:Encog.Neural.Networks.Training.ILearningRate">
             <summary>
             Specifies that a training algorithm has the concept of a learning rate.
             This allows it to be used with strategies that automatically adjust the
             learning rate.
             </summary>
            
        </member>
        <member name="P:Encog.Neural.Networks.Training.ILearningRate.LearningRate">
            <summary>
            Set the learning rate.
            </summary>
        </member>
        <member name="T:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining">
             <summary>
             Trains a neural network using a Levenberg Marquardt algorithm (LMA). This
             training technique is based on the mathematical technique of the same name.
             
             The LMA interpolates between the Gauss-Newton algorithm (GNA) and the 
             method of gradient descent (similar to what is used by backpropagation. 
             The lambda parameter determines the degree to which GNA and Gradient 
             Descent are used.  A lower lambda results in heavier use of GNA, 
             whereas a higher lambda results in a heavier use of gradient descent.
             
             Each iteration starts with a low lambda that  builds if the improvement 
             to the neural network is not desirable.  At some point the lambda is
             high enough that the training method reverts totally to gradient descent.
             
             This allows the neural network to be trained effectively in cases where GNA
             provides the optimal training time, but has the ability to fall back to the
             more primitive gradient descent method
            
             LMA finds only a local minimum, not a global minimum.
              
             References:
             
             C. R. Souza. (2009). Neural Network Learning by the Levenberg-Marquardt Algorithm 
             with Bayesian Regularization. Website, available from: 
             http://crsouza.blogspot.com/2009/11/neural-network-learning-by-levenberg_18.html
             
             http://www.heatonresearch.com/wiki/LMA
             http://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm
             http://en.wikipedia.org/wiki/Finite_difference_method
             http://mathworld.wolfram.com/FiniteDifference.html 
             http://www-alg.ist.hokudai.ac.jp/~jan/alpha.pdf -
             http://www.inference.phy.cam.ac.uk/mackay/Bayes_FAQ.html
             </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining.ScaleLambda">
            <summary>
            The amount to scale the lambda by.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining.LambdaMax">
            <summary>
            The max amount for the LAMBDA.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining._diagonal">
            <summary>
            The diagonal of the hessian.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining._hessian">
            <summary>
            Utility class to compute the Hessian.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining._indexableTraining">
            <summary>
            The training set that we are using to train.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining._network">
            <summary>
            The network that is to be trained.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining._pair">
            <summary>
            The training elements.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining._trainingLength">
            <summary>
            The training set length.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining._weightCount">
            <summary>
            How many weights are we dealing with?
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining._deltas">
            <summary>
            The amount to change the weights by.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining._lambda">
            <summary>
            The lambda, or damping factor. This is increased until a desirable
            adjustment is found.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining._weights">
            <summary>
            The neural network weights and bias values.
            </summary>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining.#ctor(Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet)">
            <summary>
            Construct the LMA object. Use the chain rule for Hessian calc.
            </summary>
            <param name="network">The network to train. Must have a single output neuron.</param>
            <param name="training">The training data to use. Must be indexable.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining.#ctor(Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet,Encog.MathUtil.Matrices.Hessian.IComputeHessian)">
            <summary>
            Construct the LMA object. 
            </summary>
            <param name="network">The network to train. Must have a single output neuron.</param>
            <param name="training">The training data to use. Must be indexable.</param>
            <param name="h">The Hessian calculator to use.</param>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining.CanContinue">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining.Method">
            <summary>
            The trained neural network.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining.Hessian">
            <summary>
            The Hessian calculation method used.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining.ThreadCount">
            <summary>
            The thread count, specify 0 for Encog to automatically select (default).  
            If the underlying Hessian calculator does not support multithreading, an error 
            will be thrown.  The default chain rule calc does support multithreading.
            </summary>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining.SaveDiagonal">
            <summary>
            Save the diagonal of the Hessian.  Will be used to apply the lambda.
            </summary>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining.CalculateError">
            <summary>
            Calculate the SSE error.
            </summary>
            <returns>The SSE error with the current weights.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining.ApplyLambda">
            <summary>
            Apply the lambda, this will dampen the GNA.
            </summary>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining.Iteration">
            <summary>
            Perform one iteration.
            </summary>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining.Pause">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Lma.LevenbergMarquardtTraining.UpdateWeights">
            <summary>
            Update the weights in the neural network.
            </summary>
        </member>
        <member name="T:Encog.Neural.Networks.Training.IMomentum">
             <summary>
             Specifies that a training algorithm has the concept of a momentum.
             This allows it to be used with strategies that automatically adjust the
             momentum.
             </summary>
            
        </member>
        <member name="P:Encog.Neural.Networks.Training.IMomentum.Momentum">
            <summary>
            Set the momentum.
            </summary>
        </member>
        <member name="T:Encog.Neural.Networks.Training.NM.NelderMeadTraining">
            <summary>
            The Nelder-Mead method is a commonly used parameter optimization method that
            can be used for neural network training. It typically provides a good error
            rate and is relatively fast.
            
            Nelder-Mead must build a simplex, which is an n*(n+1) matrix of weights. If
            you have a large number of weights, this matrix can quickly overflow memory.
            
            The biggest enhancement that is needed for this trainer is to make use of
            multi-threaded code to evaluate the speed evaluations when training on a
            multi-core.
            
            This implementation is based on the source code provided by John Burkardt
            (http://people.sc.fsu.edu/~jburkardt/)
            
            http://people.sc.fsu.edu/~jburkardt/c_src/asa047/asa047.c
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.NM.NelderMeadTraining._network">
            <summary>
            The network to be trained.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.NM.NelderMeadTraining.ccoeff">
            <summary>
            Used to calculate the centroid.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.NM.NelderMeadTraining._converged">
            <summary>
            True if the network has converged, and no further training is needed.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.NM.NelderMeadTraining._ynewlo">
            <summary>
            The best error rate.
            </summary>
        </member>
        <member name="M:Encog.Neural.Networks.Training.NM.NelderMeadTraining.#ctor(Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet)">
            <summary>
            Construct a Nelder Mead trainer with a step size of 100.
            </summary>
            <param name="network">The network to train.</param>
            <param name="training">The training set to use.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.NM.NelderMeadTraining.#ctor(Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet,System.Double)">
            <summary>
            Construct a Nelder Mead trainer with a definable step. 
            </summary>
            <param name="network">The network to train.</param>
            <param name="training">The training data to use.</param>
            <param name="stepValue">The step value. This value defines, to some degree the range
            of different weights that will be tried.</param>
        </member>
        <member name="P:Encog.Neural.Networks.Training.NM.NelderMeadTraining.CanContinue">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.Networks.Training.NM.NelderMeadTraining.Method">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.Networks.Training.NM.NelderMeadTraining.TrainingDone">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Networks.Training.NM.NelderMeadTraining.Fn(System.Double[])">
            <summary>
            Calculate the error for the neural network with a given set of weights. 
            </summary>
            <param name="weights">The weights to use.</param>
            <returns>The current error.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.NM.NelderMeadTraining.Iteration">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Networks.Training.NM.NelderMeadTraining.Pause">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Networks.Training.NM.NelderMeadTraining.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.Networks.Training.PNN.ICalculationCriteria">
             <summary>
             Calculate criteria.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.PNN.ICalculationCriteria.CalcErrorWithSingleSigma(System.Double)">
             <summary>
             Calculate the error with a single sigma.
             </summary>
            
             <param name="sigma">The sigma.</param>
             <returns>The error.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PNN.ICalculationCriteria.CalcErrorWithMultipleSigma(System.Double[],System.Double[],System.Double[],System.Boolean)">
             <summary>
             Calculate the error with multiple sigmas.
             </summary>
            
             <param name="x">The data.</param>
             <param name="direc">The first derivative.</param>
             <param name="deriv2">The 2nd derivatives.</param>
             <param name="b">Calculate the derivative.</param>
             <returns>The error.</returns>
        </member>
        <member name="T:Encog.Neural.Networks.Training.PNN.DeriveMinimum">
             <summary>
             This class determines optimal values for multiple sigmas in a PNN kernel.
             This is done using a CJ (conjugate gradient) method.
             Some of the algorithms in this class are based on C++ code from:
             Advanced Algorithms for Neural Networks: A C++ Sourcebook by Timothy Masters
             John Wiley Sons Inc (Computers); April 3, 1995 ISBN: 0471105880
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.PNN.DeriveMinimum.Calculate(System.Int32,System.Double,System.Double,System.Double,Encog.Neural.Networks.Training.PNN.ICalculationCriteria,System.Int32,System.Double[],System.Double,System.Double[],System.Double[],System.Double[],System.Double[],System.Double[])">
             <summary>
             Derive the minimum, using a conjugate gradient method.
             </summary>
            
             <param name="maxIterations">The max iterations.</param>
             <param name="maxError">Stop at this error rate.</param>
             <param name="eps">The machine's precision.</param>
             <param name="tol">The convergence tolerance.</param>
             <param name="network">The network to get the error from.</param>
             <param name="n">The number of variables.</param>
             <param name="x">The independent variable.</param>
             <param name="ystart">The start for y.</param>
             <param name="bs">Work vector, must have n elements.</param>
             <param name="direc">Work vector, must have n elements.</param>
             <param name="g">Work vector, must have n elements.</param>
             <param name="h">Work vector, must have n elements.</param>
             <param name="deriv2">Work vector, must have n elements.</param>
             <returns>The best error.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PNN.DeriveMinimum.FindNewDir(System.Int32,System.Double,System.Double[],System.Double[],System.Double[])">
             <summary>
             Find gamma.
             </summary>
            
             <param name="n">The number of variables.</param>
             <param name="gam">The gamma value.</param>
             <param name="g">The "g" value, used for CJ algorithm.</param>
             <param name="h">The "h" value, used for CJ algorithm.</param>
             <param name="grad">The gradients.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PNN.DeriveMinimum.Gamma(System.Int32,System.Double[],System.Double[])">
             <summary>
             Find correction for next iteration.
             </summary>
            
             <param name="n">The number of variables.</param>
             <param name="g">The "g" value, used for CJ algorithm.</param>
             <param name="grad">The gradients.</param>
             <returns>The correction for the next iteration.</returns>
        </member>
        <member name="T:Encog.Neural.Networks.Training.PNN.GlobalMinimumSearch">
             <summary>
             Search sigma's for a global minimum. First do a rough search, and then use
             the "Brent Method" to refine the search for an optimal sigma. This class uses
             the same sigma for each kernel. Multiple sigmas will be introduced in a later
             step.
             Some of the algorithms in this class are based on C++ code from:
             Advanced Algorithms for Neural Networks: A C++ Sourcebook by Timothy Masters
             John Wiley Sons Inc (Computers); April 3, 1995 ISBN: 0471105880
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.PNN.GlobalMinimumSearch.Cgold">
             <summary>
             The golden section.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.PNN.GlobalMinimumSearch._x1">
             <summary>
             A gamma to the left(lower) of the best(middle) gamma.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.PNN.GlobalMinimumSearch._x2">
             <summary>
             The middle(best) gamma.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.PNN.GlobalMinimumSearch._x3">
             <summary>
             A gamma to the right(higher) of the middle(best) gamma.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.PNN.GlobalMinimumSearch._y1">
             <summary>
             The value y1 is the error for x1.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.PNN.GlobalMinimumSearch._y2">
             <summary>
             The value y2 is the error for x2. This is the best(middle) error.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.PNN.GlobalMinimumSearch._y3">
             <summary>
             The value y3 is the error for x3.
             </summary>
            
        </member>
        <member name="P:Encog.Neural.Networks.Training.PNN.GlobalMinimumSearch.X1">
            <value></value>
        </member>
        <member name="P:Encog.Neural.Networks.Training.PNN.GlobalMinimumSearch.X2">
            <value>Set X2, which is the middle(best) gamma.</value>
        </member>
        <member name="P:Encog.Neural.Networks.Training.PNN.GlobalMinimumSearch.X3">
            <value>X3, which is a gamma to the right(higher) of the middle(best)
            gamma.</value>
        </member>
        <member name="P:Encog.Neural.Networks.Training.PNN.GlobalMinimumSearch.Y1">
            <value>Set Y1, which is the value y1 is the error for x1.</value>
        </member>
        <member name="P:Encog.Neural.Networks.Training.PNN.GlobalMinimumSearch.Y2">
            <value>Y2, which is the value y2 is the error for x2. This is the
            best(middle) error.</value>
        </member>
        <member name="P:Encog.Neural.Networks.Training.PNN.GlobalMinimumSearch.Y3">
            <value>Set Y3, which is the value y3 is the error for x3.</value>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PNN.GlobalMinimumSearch.Brentmin(System.Int32,System.Double,System.Double,System.Double,Encog.Neural.Networks.Training.PNN.ICalculationCriteria,System.Double)">
             <summary>
             Use the "Brent Method" to find a better minimum.
             </summary>
            
             <param name="maxIterations">THe maximum number of iterations.</param>
             <param name="maxError">We can stop if we reach this error.</param>
             <param name="eps">The approximate machine precision.</param>
             <param name="tol">Brent's tolerance, must be >= sqrt( eps )</param>
             <param name="network">The network to obtain the error from.</param>
             <param name="y">The error at x2.</param>
             <returns>The best error.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PNN.GlobalMinimumSearch.FindBestRange(System.Double,System.Double,System.Int32,System.Boolean,System.Double,Encog.Neural.Networks.Training.PNN.ICalculationCriteria)">
             <summary>
             Find the best common gamma. Use the same gamma for all kernels. This is a
             crude brute-force search. The range found should be refined using the
             "Brent Method", also provided in this class.
             </summary>
            
             <param name="low">The low gamma to begin the search with.</param>
             <param name="high">The high gamma to end the search with.</param>
             <param name="numberOfPoints">If you do set this to negative, set x2 and y2 to the correct values.</param>
             <param name="useLog">Should we progress "logarithmically" from low to high.</param>
             <param name="minError">We are done if the error is below this.</param>
             <param name="network">The network to evaluate.</param>
        </member>
        <member name="T:Encog.Neural.Networks.Training.PNN.TrainBasicPNN">
             <summary>
             Train a PNN.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.PNN.TrainBasicPNN.DefaultMaxError">
             <summary>
             The default max error.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.PNN.TrainBasicPNN.DefaultMinImprovement">
             <summary>
             The default minimum improvement before stop.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.PNN.TrainBasicPNN.DefaultSigmaLow">
             <summary>
             THe default sigma low value.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.PNN.TrainBasicPNN.DefaultSigmaHigh">
             <summary>
             The default sigma high value.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.PNN.TrainBasicPNN.DefaultNumSigmas">
             <summary>
             The default number of sigmas to evaluate between the low and high.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.PNN.TrainBasicPNN._network">
             <summary>
             The network to train.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.PNN.TrainBasicPNN._training">
             <summary>
             The training data.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.PNN.TrainBasicPNN._dsqr">
             <summary>
             Temp storage for derivative computation.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.PNN.TrainBasicPNN._maxError">
             <summary>
             The maximum error to allow.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.PNN.TrainBasicPNN._minImprovement">
             <summary>
             The minimum improvement allowed.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.PNN.TrainBasicPNN._numSigmas">
             <summary>
             The number of sigmas to evaluate between the low and high.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.PNN.TrainBasicPNN._samplesLoaded">
             <summary>
             Have the samples been loaded.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.PNN.TrainBasicPNN._sigmaHigh">
             <summary>
             The high value for the sigma search.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.PNN.TrainBasicPNN._sigmaLow">
             <summary>
             The low value for the sigma search.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.PNN.TrainBasicPNN._v">
             <summary>
             Temp storage for derivative computation.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.PNN.TrainBasicPNN._w">
             <summary>
             Temp storage for derivative computation.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.PNN.TrainBasicPNN.#ctor(Encog.Neural.PNN.BasicPNN,Encog.ML.Data.IMLDataSet)">
             <summary>
             Train a BasicPNN.
             </summary>
            
             <param name="network">The network to train.</param>
             <param name="training">The training data.</param>
        </member>
        <member name="P:Encog.Neural.Networks.Training.PNN.TrainBasicPNN.CanContinue">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.Networks.Training.PNN.TrainBasicPNN.MaxError">
            <value>the maxError to set</value>
        </member>
        <member name="P:Encog.Neural.Networks.Training.PNN.TrainBasicPNN.Method">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.Networks.Training.PNN.TrainBasicPNN.MinImprovement">
            <value>the minImprovement to set</value>
        </member>
        <member name="P:Encog.Neural.Networks.Training.PNN.TrainBasicPNN.NumSigmas">
            <value>the numSigmas to set</value>
        </member>
        <member name="P:Encog.Neural.Networks.Training.PNN.TrainBasicPNN.SigmaHigh">
            <value>the sigmaHigh to set</value>
        </member>
        <member name="P:Encog.Neural.Networks.Training.PNN.TrainBasicPNN.SigmaLow">
            <value>the sigmaLow to set</value>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PNN.TrainBasicPNN.CalcErrorWithMultipleSigma(System.Double[],System.Double[],System.Double[],System.Boolean)">
             <summary>
             Calculate the error with multiple sigmas.
             </summary>
            
             <param name="x">The data.</param>
             <param name="der1">The first derivative.</param>
             <param name="der2">The 2nd derivatives.</param>
             <param name="der">Calculate the derivative.</param>
             <returns>The error.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PNN.TrainBasicPNN.CalcErrorWithSingleSigma(System.Double)">
             <summary>
             Calculate the error using a common sigma.
             </summary>
            
             <param name="sig">The sigma to use.</param>
             <returns>The training error.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PNN.TrainBasicPNN.CalculateError(Encog.ML.Data.IMLDataSet,System.Boolean)">
             <summary>
             Calculate the error for the entire training set.
             </summary>
            
             <param name="training">Training set to use.</param>
             <param name="deriv">Should we find the derivative.</param>
             <returns>The error.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PNN.TrainBasicPNN.ComputeDeriv(Encog.ML.Data.IMLData,Encog.ML.Data.IMLData)">
             <summary>
             Compute the derivative for target data.
             </summary>
            
             <param name="input">The input.</param>
             <param name="target">The target data.</param>
             <returns>The output.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PNN.TrainBasicPNN.Iteration">
             <summary>
             
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.PNN.TrainBasicPNN.Pause">
             <summary>
             
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.PNN.TrainBasicPNN.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
             <summary>
             
             </summary>
            
        </member>
        <member name="T:Encog.Neural.Networks.Training.Propagation.Back.Backpropagation">
             <summary>
             This class implements a backpropagation training algorithm for feed forward
             neural networks. It is used in the same manner as any other training class
             that implements the Train interface.
             Backpropagation is a common neural network training algorithm. It works by
             analyzing the error of the output of the neural network. Each neuron in the
             output layer's contribution, according to weight, to this error is
             determined. These weights are then adjusted to minimize this error. This
             process continues working its way backwards through the layers of the neural
             network.
             This implementation of the backpropagation algorithm uses both momentum and a
             learning rate. The learning rate specifies the degree to which the weight
             matrixes will be modified through each iteration. The momentum specifies how
             much the previous learning iteration affects the current. To use no momentum
             at all specify zero.
             One primary problem with backpropagation is that the magnitude of the partial
             derivative is often detrimental to the training of the neural network. The
             other propagation methods of Manhatten and Resilient address this issue in
             different ways. In general, it is suggested that you use the resilient
             propagation technique for most Encog training tasks over back propagation.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Back.Backpropagation.PropertyLastDelta">
             <summary>
             The resume key for backpropagation.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Back.Backpropagation._lastDelta">
             <summary>
             The last delta values.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Back.Backpropagation._learningRate">
             <summary>
             The learning rate.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Back.Backpropagation._momentum">
             <summary>
             The momentum.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Back.Backpropagation.#ctor(Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet)">
             <summary>
             Create a class to train using backpropagation. Use auto learn rate and
             momentum. Use the CPU to train.
             </summary>
            
             <param name="network">The network that is to be trained.</param>
             <param name="training">The training data to be used for backpropagation.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Back.Backpropagation.#ctor(Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet,System.Double,System.Double)">
            <param name="network">The network that is to be trained</param>
            <param name="training">The training set</param>
            <param name="learnRate"></param>
            <param name="momentum"></param>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Back.Backpropagation.CanContinue">
            <inheritdoc />
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Back.Backpropagation.LastDelta">
            <value>Ther last delta values.</value>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Back.Backpropagation.LearningRate">
            <summary>
            Set the learning rate, this is value is essentially a percent. It is the
            degree to which the gradients are applied to the weight matrix to allow
            learning.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Back.Backpropagation.Momentum">
            <summary>
            Set the momentum for training. This is the degree to which changes from
            which the previous training iteration will affect this training
            iteration. This can be useful to overcome local minima.
            </summary>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Back.Backpropagation.IsValidResume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
             <summary>
             Determine if the specified continuation object is valid to resume with.
             </summary>
            
             <param name="state">The continuation object to check.</param>
             <returns>True if the specified continuation object is valid for this
             training method and network.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Back.Backpropagation.Pause">
             <summary>
             Pause the training.
             </summary>
            
             <returns>A training continuation object to continue with.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Back.Backpropagation.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
             <summary>
             Resume training.
             </summary>
            
             <param name="state">The training state to return to.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Back.Backpropagation.UpdateWeight(System.Double[],System.Double[],System.Int32)">
             <summary>
             Update a weight.
             </summary>
            
             <param name="gradients">The gradients.</param>
             <param name="lastGradient">The last gradients.</param>
             <param name="index">The index.</param>
             <returns>The weight delta.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Back.Backpropagation.InitOthers">
            <summary>
            Not needed for this training type.
            </summary>
        </member>
        <member name="T:Encog.Neural.Networks.Training.Propagation.GradientWorker">
             <summary>
             Worker class for the mulithreaded training of flat networks.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.GradientWorker._actual">
             <summary>
             The actual values from the neural network.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.GradientWorker._errorCalculation">
             <summary>
             The error calculation method.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.GradientWorker._gradients">
             <summary>
             The gradients.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.GradientWorker._high">
             <summary>
             The low end of the training.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.GradientWorker._layerCounts">
             <summary>
             The neuron counts, per layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.GradientWorker._layerDelta">
             <summary>
             The deltas for each layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.GradientWorker._layerFeedCounts">
             <summary>
             The feed counts, per layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.GradientWorker._layerIndex">
             <summary>
             The layer indexes.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.GradientWorker._layerOutput">
             <summary>
             The output from each layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.GradientWorker._layerSums">
             <summary>
             The sum from each layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.GradientWorker._low">
             <summary>
             The high end of the training data.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.GradientWorker._network">
             <summary>
             The network to train.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.GradientWorker._owner">
             <summary>
             The owner.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.GradientWorker._pair">
             <summary>
             The pair to use for training.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.GradientWorker._training">
             <summary>
             The training data.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.GradientWorker._weightIndex">
             <summary>
             The index to each layer's weights and thresholds.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.GradientWorker._weights">
             <summary>
             The weights and thresholds.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.GradientWorker._flatSpot">
            <summary>
            Derivative add constant.  Used to combat flat spot.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.GradientWorker._ef">
            <summary>
            The error function.
            </summary>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.GradientWorker.#ctor(Encog.Neural.Flat.FlatNetwork,Encog.Neural.Networks.Training.Propagation.Propagation,Encog.ML.Data.IMLDataSet,System.Int32,System.Int32,System.Double[],Encog.Neural.Error.IErrorFunction)">
             <summary>
             Construct a gradient worker.
             </summary>
            
             <param name="theNetwork">The network to train.</param>
             <param name="theOwner">The owner that is doing the training.</param>
             <param name="theTraining">The training data.</param>
             <param name="theLow">The low index to use in the training data.</param>
             <param name="theHigh">The high index to use in the training data.</param>
             <param name="theFlatSpots">Holds an array of flat spot constants.</param>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.GradientWorker.Network">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.GradientWorker.Weights">
            <value>The weights for this network.</value>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.GradientWorker.Run">
             <summary>
             Perform the gradient calculation for the specified index range.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.GradientWorker.Process(System.Double[],System.Double[],System.Double)">
             <summary>
             Process one training set element.
             </summary>
            
             <param name="input">The network input.</param>
             <param name="ideal">The ideal values.</param>
             <param name="s">The significance of this error.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.GradientWorker.ProcessLevel(System.Int32)">
             <summary>
             Process one level.
             </summary>
            
             <param name="currentLevel">The level.</param>
        </member>
        <member name="T:Encog.Neural.Networks.Training.Propagation.Manhattan.ManhattanPropagation">
             <summary>
             One problem that the backpropagation technique has is that the magnitude of
             the partial derivative may be calculated too large or too small. The
             Manhattan update algorithm attempts to solve this by using the partial
             derivative to only indicate the sign of the update to the weight matrix. The
             actual amount added or subtracted from the weight matrix is obtained from a
             simple constant. This constant must be adjusted based on the type of neural
             network being trained. In general, start with a higher constant and decrease
             it as needed.
             The Manhattan update algorithm can be thought of as a simplified version of
             the resilient algorithm. The resilient algorithm uses more complex techniques
             to determine the update value.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Manhattan.ManhattanPropagation.DefaultZeroTolerance">
             <summary>
             The default tolerance to determine of a number is close to zero.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Manhattan.ManhattanPropagation._zeroTolerance">
             <summary>
             The zero tolerance to use.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Manhattan.ManhattanPropagation._learningRate">
             <summary>
             The learning rate.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Manhattan.ManhattanPropagation.#ctor(Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet,System.Double)">
             <summary>
             Construct a Manhattan propagation training object.
             </summary>
            
             <param name="network">The network to train.</param>
             <param name="training">The training data to use.</param>
             <param name="learnRate">The learning rate.</param>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Manhattan.ManhattanPropagation.CanContinue">
            <inheritdoc />
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Manhattan.ManhattanPropagation.LearningRate">
            <summary>
            Set the learning rate.
            </summary>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Manhattan.ManhattanPropagation.Pause">
             <summary>
             This training type does not support training continue.
             </summary>
            
             <returns>Always returns null.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Manhattan.ManhattanPropagation.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
             <summary>
             This training type does not support training continue.
             </summary>
            
             <param name="state">Not used.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Manhattan.ManhattanPropagation.UpdateWeight(System.Double[],System.Double[],System.Int32)">
             <summary>
             Calculate the amount to change the weight by.
             </summary>
            
             <param name="gradients">The gradients.</param>
             <param name="lastGradient">The last gradients.</param>
             <param name="index">The index to update.</param>
             <returns>The amount to change the weight by.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Manhattan.ManhattanPropagation.InitOthers">
            <summary>
            Not needed for this training type.
            </summary>
        </member>
        <member name="T:Encog.Neural.Networks.Training.Propagation.PersistTrainingContinuation">
             <summary>
             Persist the training continuation.
             </summary>
            
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.PersistTrainingContinuation.FileVersion">
             <summary>
             
             </summary>
            
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.PersistTrainingContinuation.NativeType">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.PersistTrainingContinuation.PersistClassString">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.PersistTrainingContinuation.Read(System.IO.Stream)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.PersistTrainingContinuation.Save(System.IO.Stream,System.Object)">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.Networks.Training.Propagation.Propagation">
             <summary>
             Implements basic functionality that is needed by each of the propagation
             methods. The specifics of each of the propagation methods is implemented
             inside of the PropagationMethod interface implementors.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Propagation._indexable">
             <summary>
             The network in indexable form.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Propagation._lastGradient">
             <summary>
             The last gradients, from the last training iteration.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Propagation._network">
            <summary>
            The network to train.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Propagation._flat">
             <summary>
             The network to train.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Propagation._training">
             <summary>
             The training data.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Propagation.CurrentError">
             <summary>
             The current error is the average error over all of the threads.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Propagation.Gradients">
             <summary>
             The gradients.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Propagation._iteration">
             <summary>
             The iteration.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Propagation._numThreads">
             <summary>
             The number of threads to use.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Propagation._reportedException">
             <summary>
             Reported exception from the threads.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Propagation._totalError">
             <summary>
             The total error. Used to take the average of.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Propagation._workers">
             <summary>
             The workers.
             </summary>
            
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Propagation.FixFlatSpot">
            <summary>
            True (default) if we should fix flatspots on supported activation functions.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Propagation._flatSpot">
            <summary>
            The flat spot constants.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Propagation.ErrorFunction">
            <summary>
            The error function.
            </summary>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Propagation.#ctor(Encog.Neural.Networks.IContainsFlat,Encog.ML.Data.IMLDataSet)">
             <summary>
             Construct a propagation object.
             </summary>
            
             <param name="network">The network.</param>
             <param name="training">The training set.</param>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Propagation.ThreadCount">
            <summary>
            Set the number of threads. Specify zero to tell Encog to automatically
            determine the best number of threads for the processor. If OpenCL is used
            as the target device, then this value is not used.
            </summary>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Propagation.RollIteration">
            <summary>
            Increase the iteration count by one.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Propagation.Method">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Propagation.Iteration">
            <summary>
            Perform the specified number of training iterations. This can be more
            efficient than single training iterations. This is particularly true if
            you are training with a GPU.
            </summary>        
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Propagation.LastGradient">
            <value>The gradients from the last iteration;</value>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Propagation.FinishTraining">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Propagation.Error">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Propagation.IterationNumber">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Propagation.Network">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Propagation.NumThreads">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Propagation.Training">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Propagation.CalculateGradients">
             <summary>
             Calculate the gradients.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Propagation.CopyContexts">
             <summary>
             Copy the contexts to keep them consistent with multithreaded training.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Propagation.Init">
             <summary>
             Init the process.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Propagation.Learn">
             <summary>
             Apply and learn.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Propagation.LearnLimited">
             <summary>
             Apply and learn. This is the same as learn, but it checks to see if any
             of the weights are below the limit threshold. In this case, these weights
             are zeroed out. Having two methods allows the regular learn method, which
             is what is usually use, to be as fast as possible.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Propagation.Report(System.Double[],System.Double,System.Exception)">
             <summary>
             Called by the worker threads to report the progress at each step.
             </summary>
            
             <param name="gradients">The gradients from that worker.</param>
             <param name="error">The error for that worker.</param>
             <param name="ex">The exception.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Propagation.UpdateWeight(System.Double[],System.Double[],System.Int32)">
             <summary>
             Update a weight, the means by which weights are updated vary depending on
             the training.
             </summary>
            
             <param name="gradients">The gradients.</param>
             <param name="lastGradient">The last gradients.</param>
             <param name="index">The index.</param>
             <returns>The update value.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Propagation.InitOthers">
            <summary>
            Allow other training methods to init.
            </summary>
        </member>
        <member name="T:Encog.Neural.Networks.Training.Propagation.Quick.QuickPropagation">
            <summary>
            QPROP is an efficient training method that is based on Newton's Method.  
            QPROP was introduced in a paper:
            
            An Empirical Study of Learning Speed in Back-Propagation Networks" (Scott E. Fahlman, 1988)
            
             
            http://www.heatonresearch.com/wiki/Quickprop
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Quick.QuickPropagation.Decay">
            <summary>
            This factor times the current weight is added to the slope 
            at the start of each output epoch. Keeps weights from growing 
            too big.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Quick.QuickPropagation.EPS">
            <summary>
            Used to scale for the size of the training set.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Quick.QuickPropagation.LastDelta">
            <summary>
            The last deltas.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Quick.QuickPropagation.LearningRate">
            <summary>
            The learning rate.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Quick.QuickPropagation.OutputEpsilon">
            <summary>
            Controls the amount of linear gradient descent 
            to use in updating output weights.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Quick.QuickPropagation.Shrink">
            <summary>
            Used in computing whether the proposed step is 
            too large.  Related to learningRate.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Quick.QuickPropagation.LastGradients">
            <summary>
            Continuation tag for the last gradients.
            </summary>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Quick.QuickPropagation.#ctor(Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet)">
            <summary>
            Construct a QPROP trainer for flat networks.  Uses a learning rate of 2.
            </summary>
            <param name="network">The network to train.</param>
            <param name="training">The training data.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Quick.QuickPropagation.#ctor(Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet,System.Double)">
            <summary>
            Construct a QPROP trainer for flat networks.
            </summary>
            <param name="network">The network to train.</param>
            <param name="training">The training data.</param>
            <param name="learnRate">The learning rate.  2 is a good suggestion as 
                       a learning rate to start with.  If it fails to converge, 
                       then drop it.  Just like backprop, except QPROP can 
                       take higher learning rates.</param>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Quick.QuickPropagation.CanContinue">
            <inheritdoc />
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Quick.QuickPropagation.IsValidResume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
            <summary>
            Determine if the specified continuation object is valid to resume with.
            </summary>
            <param name="state">The continuation object to check.</param>
            <returns>True if the specified continuation object is valid for this
            training method and network.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Quick.QuickPropagation.Pause">
            <summary>
            Pause the training.
            </summary>
            <returns>A training continuation object to continue with.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Quick.QuickPropagation.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
            <summary>
            Resume training.
            </summary>
            <param name="state">The training state to return to.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Quick.QuickPropagation.InitOthers">
            <summary>
            Called to init the QPROP.
            </summary>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Quick.QuickPropagation.UpdateWeight(System.Double[],System.Double[],System.Int32)">
            <summary>
            Update a weight.
            </summary>
            <param name="gradients">The gradients.</param>
            <param name="lastGradient">The last gradients.</param>
            <param name="index">The index.</param>
            <returns>The weight delta.</returns>
        </member>
        <member name="T:Encog.Neural.Networks.Training.Propagation.Resilient.ResilientPropagation">
             <summary>
             One problem with the backpropagation algorithm is that the magnitude of the
             partial derivative is usually too large or too small. Further, the learning
             rate is a single value for the entire neural network. The resilient
             propagation learning algorithm uses a special update value(similar to the
             learning rate) for every neuron connection. Further these update values are
             automatically determined, unlike the learning rate of the backpropagation
             algorithm.
             For most training situations, we suggest that the resilient propagation
             algorithm (this class) be used for training.
             There are a total of three parameters that must be provided to the resilient
             training algorithm. Defaults are provided for each, and in nearly all cases,
             these defaults are acceptable. This makes the resilient propagation algorithm
             one of the easiest and most efficient training algorithms available.
             The optional parameters are:
             zeroTolerance - How close to zero can a number be to be considered zero. The
             default is 0.00000000000000001.
             initialUpdate - What are the initial update values for each matrix value. The
             default is 0.1.
             maxStep - What is the largest amount that the update values can step. The
             default is 50.
             Usually you will not need to use these, and you should use the constructor
             that does not require them.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Resilient.ResilientPropagation.LastGradientsConst">
             <summary>
             Continuation tag for the last gradients.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Resilient.ResilientPropagation.UpdateValuesConst">
             <summary>
             Continuation tag for the last values.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Resilient.ResilientPropagation._lastDelta">
            <summary>
            The last deltas.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Resilient.ResilientPropagation._lastWeightChanged">
            <summary>
            The last weight changed.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Resilient.ResilientPropagation._maxStep">
             <summary>
             The maximum step value for rprop.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Resilient.ResilientPropagation._updateValues">
             <summary>
             The update values, for the weights and thresholds.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Resilient.ResilientPropagation._zeroTolerance">
             <summary>
             The zero tolerance.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Resilient.ResilientPropagation._lastError">
            <summary>
            The last error.
            </summary>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Resilient.ResilientPropagation.#ctor(Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet)">
             <summary>
             Construct an RPROP trainer, allows an OpenCL device to be specified. Use
             the defaults for all training parameters. Usually this is the constructor
             to use as the resilient training algorithm is designed for the default
             parameters to be acceptable for nearly all problems.
             </summary>
            
             <param name="network">The network to train.</param>
             <param name="training">The training data to use.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Resilient.ResilientPropagation.#ctor(Encog.Neural.Networks.IContainsFlat,Encog.ML.Data.IMLDataSet,System.Double,System.Double)">
             <summary>
             Construct a resilient training object, allow the training parameters to
             be specified. Usually the default parameters are acceptable for the
             resilient training algorithm. Therefore you should usually use the other
             constructor, that makes use of the default values.
             </summary>
            
             <param name="network">The network to train.</param>
             <param name="training">The training set to use.</param>
             <param name="initialUpdate"></param>
             <param name="maxStep">The maximum that a delta can reach.</param>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Resilient.ResilientPropagation.CanContinue">
            <inheritdoc />
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Resilient.ResilientPropagation.IsValidResume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
             <summary>
             Determine if the specified continuation object is valid to resume with.
             </summary>
            
             <param name="state">The continuation object to check.</param>
             <returns>True if the specified continuation object is valid for this
             training method and network.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Resilient.ResilientPropagation.Pause">
             <summary>
             Pause the training.
             </summary>
            
             <returns>A training continuation object to continue with.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Resilient.ResilientPropagation.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
             <summary>
             Resume training.
             </summary>
            
             <param name="state">The training state to return to.</param>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Resilient.ResilientPropagation.RType">
            <summary>
            The type of RPROP to use.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.Resilient.ResilientPropagation.UpdateValues">
            <value>The RPROP update values.</value>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Resilient.ResilientPropagation.Sign(System.Double)">
             <summary>
             Determine the sign of the value.
             </summary>
            
             <param name="v">The value to check.</param>
             <returns>-1 if less than zero, 1 if greater, or 0 if zero.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Resilient.ResilientPropagation.UpdateWeight(System.Double[],System.Double[],System.Int32)">
             <summary>
             Calculate the amount to change the weight by.
             </summary>
            
             <param name="gradients">The gradients.</param>
             <param name="lastGradient">The last gradients.</param>
             <param name="index">The index to update.</param>
             <returns>The amount to change the weight by.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.Resilient.ResilientPropagation.InitOthers">
            <summary>
            Not needed for this training type.
            </summary>
        </member>
        <member name="T:Encog.Neural.Networks.Training.Propagation.Resilient.RPROPConst">
             <summary>
             Constants used for Resilient Propagation (RPROP) training.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Resilient.RPROPConst.DefaultZeroTolerance">
             <summary>
             The default zero tolerance.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Resilient.RPROPConst.PositiveEta">
             <summary>
             The POSITIVE ETA value. This is specified by the resilient propagation
             algorithm. This is the percentage by which the deltas are increased by if
             the partial derivative is greater than zero.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Resilient.RPROPConst.NegativeEta">
             <summary>
             The NEGATIVE ETA value. This is specified by the resilient propagation
             algorithm. This is the percentage by which the deltas are increased by if
             the partial derivative is less than zero.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Resilient.RPROPConst.DeltaMin">
             <summary>
             The minimum delta value for a weight matrix value.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Resilient.RPROPConst.DefaultInitialUpdate">
             <summary>
             The starting update for a delta.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Resilient.RPROPConst.DefaultMaxStep">
             <summary>
             The maximum amount a delta can reach.
             </summary>
            
        </member>
        <member name="T:Encog.Neural.Networks.Training.Propagation.Resilient.RPROPType">
            <summary>
            Allows the type of RPROP to be defined.  RPROPp is the classic RPROP.
            
            For more information, visit:
            
            http://www.heatonresearch.com/wiki/RPROP
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Resilient.RPROPType.RPROPp">
            <summary>
            RPROP+ : The classic RPROP algorithm.  Uses weight back tracking.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Resilient.RPROPType.RPROPm">
            <summary>
            RPROP- : No weight back tracking.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Resilient.RPROPType.iRPROPp">
            <summary>
            iRPROP+ : New weight back tracking method, some consider this to be
            the most advanced RPROP.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.Resilient.RPROPType.iRPROPm">
            <summary>
            iRPROP- : New RPROP without weight back tracking. 
            </summary>
        </member>
        <member name="T:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient">
             <summary>
             This is a training class that makes use of scaled conjugate gradient methods.
             It is a very fast and efficient training algorithm.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient.FirstSigma">
             <summary>
             The starting value for sigma.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient.FirstLambda">
             <summary>
             The starting value for lambda.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient._oldGradient">
             <summary>
             The old gradients, used to compare.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient._oldWeights">
             <summary>
             The old weight values, used to restore the neural network.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient._p">
             <summary>
             Step direction vector.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient._r">
             <summary>
             Step direction vector.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient._weights">
             <summary>
             The neural network weights.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient._delta">
             <summary>
             The current delta.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient._k">
             <summary>
             The number of iterations. The network will reset when this value
             increases over the number of weights in the network.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient._lambda">
             <summary>
             The first lambda value.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient._lambda2">
             <summary>
             The second lambda value.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient._magP">
             <summary>
             The magnitude of p.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient._mustInit">
             <summary>
             Should the initial gradients be calculated.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient._oldError">
             <summary>
             The old error value, used to make sure an improvement happened.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient._restart">
             <summary>
             Should we restart?
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient._success">
             <summary>
             Tracks if the latest training cycle was successful.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient.#ctor(Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet)">
             <summary>
             Construct a training class.
             </summary>
            
             <param name="network">The network to train.</param>
             <param name="training">The training data.</param>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient.CanContinue">
             <summary>
             This training type does not support training continue.
             </summary>
            
             <returns>Always returns false.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient.Pause">
             <summary>
             This training type does not support training continue.
             </summary>
            
             <returns>Always returns null.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
             <summary>
             This training type does not support training continue.
             </summary>
            
             <param name="state">Not used.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient.CalculateGradients">
             <summary>
             Calculate the gradients. They are normalized as well.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient.Init">
             <summary>
             Calculate the starting set of gradients.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient.Iteration">
             <summary>
             Perform one iteration.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient.UpdateWeight(System.Double[],System.Double[],System.Int32)">
             <summary>
             Update the weights.
             </summary>
            
             <param name="gradients">The current gradients.</param>
             <param name="lastGradient">The last gradients.</param>
             <param name="index">The weight index being updated.</param>
             <returns>The new weight value.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.SCG.ScaledConjugateGradient.InitOthers">
            <summary>
            Not needed for this training type.
            </summary>
        </member>
        <member name="T:Encog.Neural.Networks.Training.Propagation.TrainingContinuation">
            <summary>
            Allows training to be continued.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.Propagation.TrainingContinuation._contents">
             <summary>
             The contents of this object.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.TrainingContinuation.#ctor">
            <summary>
            Construct the object.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.TrainingContinuation.Contents">
            <value>The contents.</value>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Propagation.TrainingContinuation.TrainingType">
            <value>the trainingType to set</value>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.TrainingContinuation.Get(System.String)">
             <summary>
             Get an object by name.
             </summary>
            
             <param name="name">The name of the object.</param>
             <returns>The object requested.</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.TrainingContinuation.Put(System.String,System.Double[])">
             <summary>
             Save a list of doubles.
             </summary>
            
             <param name="key">The key to save them under.</param>
             <param name="list">The list of doubles.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Propagation.TrainingContinuation.Set(System.String,System.Object)">
             <summary>
             Set a value to a string.
             </summary>
            
             <param name="name">The value to set.</param>
             <param name="v">The value.</param>
        </member>
        <member name="T:Encog.Neural.Networks.Training.PSO.NeuralPSO">
            <summary>
            Iteratively trains a population of neural networks by applying   
            particle swarm optimisation (PSO).
            
            Contributed by:
            Geoffroy Noel
            https://github.com/goffer-looney 
            
            References: 
             James Kennedy and Russell C. Eberhart, Particle swarm optimization, 
            Proceedings of the IEEE International Conference on Neural Networks, 
            1995, pp. 1942-1948
            
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.PSO.NeuralPSO.m_networks">
            <summary>
            Swarm state and memories.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.PSO.NeuralPSO.m_bestVector">
            <summary>
            Although this is redundant with m_bestVectors[m_bestVectorIndex],
            m_bestVectors[m_bestVectorIndex] is not thread safe.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.PSO.NeuralPSO.m_populationSize">
            <summary>
            Typical range is 20 - 40 for many problems. 
            More difficult problems may need much higher value. 
            Must be low enough to keep the training process 
            computationally efficient.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.PSO.NeuralPSO.m_maxPosition">
            <summary>
            Determines the size of the search space. 
            The position components of particle will be bounded to 
            [-maxPos, maxPos]
            A well chosen range can improve the performance. 
            -1 is a special value that represents boundless search space.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.PSO.NeuralPSO.m_maxVelocity">
            <summary>
            Maximum change one particle can take during one iteration.
            Imposes a limit on the maximum absolute value of the velocity 
            components of a particle. 
            Affects the granularity of the search.
            If too high, particle can fly past optimum solution.
            If too low, particle can get stuck in local minima.
            Usually set to a fraction of the dynamic range of the search
            space (10% was shown to be good for high dimensional problems).
            -1 is a special value that represents boundless velocities. 
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.PSO.NeuralPSO.m_c1">
            <summary>
            c1, cognitive learning rate >= 0
            tendency to return to personal best position
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.PSO.NeuralPSO.m_c2">
            <summary>
            c2, social learning rate >= 0
            tendency to move towards the swarm best position
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.PSO.NeuralPSO.m_inertiaWeight">
            <summary>
            w, inertia weight.
            Controls global (higher value) vs local exploration 
            of the search space. 
            Analogous to temperature in simulated annealing.
            Must be chosen carefully or gradually decreased over time.
            Value usually between 0 and 1.
            </summary>
        </member>
        <member name="F:Encog.Neural.Networks.Training.PSO.NeuralPSO.m_pseudoAsynchronousUpdate">
            <summary>
            If true, the position of the previous global best position 
            can be updated *before* the other particles have been modified.
            </summary>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PSO.NeuralPSO.#ctor(Encog.Neural.Networks.BasicNetwork,Encog.MathUtil.Randomize.IRandomizer,Encog.Neural.Networks.Training.ICalculateScore,System.Int32)">
            <summary>
            Constructor. 
            </summary>
            <param name="network">an initialised Encog network. 
                                     The networks in the swarm will be created with 
                                     the same topology as this network.</param>
            <param name="randomizer">any type of Encog network weight initialisation
                                     object.</param>
            <param name="calculateScore">any type of Encog network scoring/fitness object.</param>
            <param name="populationSize">the swarm size.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PSO.NeuralPSO.InitPopulation">
            <summary>
            Initialise the particle positions and velocities, 
            personal and global bests.
            Only does this if they have not yet been initialised.
            </summary>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PSO.NeuralPSO.Iteration">
            <summary>
            Runs one PSO iteration over the whole population of networks.
            </summary>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PSO.NeuralPSO.IterationPSO(System.Boolean)">
            <summary>
            Internal method for the iteration of the swarm. 
            </summary>
            <param name="init">true if this is an initialisation iteration.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PSO.NeuralPSO.UpdateParticle(System.Int32,System.Boolean)">
            <summary>
            Update the velocity, position and personal 
            best position of a particle.
            </summary>
            <param name="particleIndex">index of the particle in the swarm</param>
            <param name="init">if true, the position and velocity
                                     will be initialised. </param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PSO.NeuralPSO.UpdateVelocity(System.Int32,System.Double[])">
            <summary>
            Update the velocity of a particle  
            </summary>
            <param name="particleIndex">index of the particle in the swarm</param>
            <param name="particlePosition">the particle current position vector</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PSO.NeuralPSO.UpdatePersonalBestPosition(System.Int32,System.Double[])">
            <summary>
            Update the personal best position of a particle. 
            </summary>
            <param name="particleIndex">index of the particle in the swarm</param>
            <param name="particlePosition">the particle current position vector</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PSO.NeuralPSO.UpdateGlobalBestPosition">
            <summary>
            Update the swarm's best position
            </summary>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PSO.NeuralPSO.IsScoreBetter(System.Double,System.Double)">
            <summary>
            Compares two scores. 
            </summary>
            <param name="score1">a score</param>
            <param name="score2">a score</param>
            <returns>true if score1 is better than score2</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PSO.NeuralPSO.GetNetworkState(System.Int32)">
            <summary>
            Returns the state of a network in the swarm  
            </summary>
            <param name="particleIndex">index of the network in the swarm</param>
            <returns>an array of weights and biases for the given network</returns>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PSO.NeuralPSO.SetNetworkState(System.Int32,System.Double[])">
            <summary>
            Sets the state of the networks in the swarm
            </summary>
            <param name="particleIndex">index of the network in the swarm</param>
            <param name="state">an array of weights and biases</param>
        </member>
        <member name="P:Encog.Neural.Networks.Training.PSO.NeuralPSO.PopulationSize">
            <summary>
            Set the swarm size.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Training.PSO.NeuralPSO.MaxVelocity">
            <summary>
            Sets the maximum velocity.
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Training.PSO.NeuralPSO.MaxPosition">
            <summary>
            Set the boundary of the search space (Xmax)
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Training.PSO.NeuralPSO.C1">
            <summary>
            Sets the cognition coefficient (c1).
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Training.PSO.NeuralPSO.C2">
            <summary>
            Set the social coefficient (c2).
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Training.PSO.NeuralPSO.InertiaWeight">
            <summary>
            Get the inertia weight (w) 
            </summary>
        </member>
        <member name="P:Encog.Neural.Networks.Training.PSO.NeuralPSO.Description">
            <summary>
            Get a description of all the current settings.
            </summary>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PSO.NeuralPSO.SetInitialPopulation(Encog.Neural.Networks.BasicNetwork[])">
            <summary>
            Keep a reference to the passed population of networks.
            This population is not copied, it will evolve during training.   
            </summary>
            <param name="initialPopulation"></param>
        </member>
        <member name="T:Encog.Neural.Networks.Training.PSO.NeuralPSOWorker">
            <summary>
            PSO multi-treaded worker.
            It allows PSO to offload all of the individual 
            particle calculations to a separate thread.
            
            Contributed by:
            Geoffroy Noel
            https://github.com/goffer-looney 
            
            </summary>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PSO.NeuralPSOWorker.#ctor(Encog.Neural.Networks.Training.PSO.NeuralPSO,System.Int32,System.Boolean)">
            <summary>
            Constructor. 
            </summary>
            <param name="neuralPSO">the training algorithm</param>
            <param name="particleIndex">the index of the particle in the swarm</param>
            <param name="init">true for an initialisation iteration </param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.PSO.NeuralPSOWorker.Run">
            <summary>
            Update the particle velocity, position and personal best.
            </summary>
        </member>
        <member name="T:Encog.Neural.Networks.Training.Simple.TrainAdaline">
             <summary>
             Train an ADALINE neural network.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Simple.TrainAdaline._network">
             <summary>
             The network to train.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Simple.TrainAdaline._training">
             <summary>
             The training data to use.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Simple.TrainAdaline._learningRate">
             <summary>
             The learning rate.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Simple.TrainAdaline.#ctor(Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet,System.Double)">
             <summary>
             Construct an ADALINE trainer.
             </summary>
            
             <param name="network">The network to train.</param>
             <param name="training">The training data.</param>
             <param name="learningRate">The learning rate.</param>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Simple.TrainAdaline.CanContinue">
            <inheritdoc />
        </member>
        <member name="P:Encog.Neural.Networks.Training.Simple.TrainAdaline.Method">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.Networks.Training.Simple.TrainAdaline.LearningRate">
            <summary>
            Set the learning rate.
            </summary>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Simple.TrainAdaline.Iteration">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Simple.TrainAdaline.Pause">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Simple.TrainAdaline.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.Networks.Training.Strategy.SmartLearningRate">
             <summary>
             Attempt to automatically set the learning rate in a learning method that
             supports a learning rate.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Strategy.SmartLearningRate.LearningDecay">
             <summary>
             Learning decay rate.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Strategy.SmartLearningRate._currentLearningRate">
             <summary>
             The current learning rate.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Strategy.SmartLearningRate._lastError">
             <summary>
             The error rate from the previous iteration.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Strategy.SmartLearningRate._ready">
             <summary>
             Has one iteration passed, and we are now ready to start evaluation.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Strategy.SmartLearningRate._setter">
             <summary>
             The class that is to have the learning rate set for.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Strategy.SmartLearningRate._train">
             <summary>
             The training algorithm that is using this strategy.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Strategy.SmartLearningRate._trainingSize">
             <summary>
             The training set size, this is used to pick an initial learning rate.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Strategy.SmartLearningRate.Init(Encog.ML.Train.IMLTrain)">
             <summary>
             Initialize this strategy.
             </summary>
            
             <param name="train">The training algorithm.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Strategy.SmartLearningRate.PostIteration">
             <summary>
             Called just after a training iteration.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Strategy.SmartLearningRate.PreIteration">
             <summary>
             Called just before a training iteration.
             </summary>
            
        </member>
        <member name="T:Encog.Neural.Networks.Training.Strategy.SmartMomentum">
             <summary>
             Attempt to automatically set a momentum in a training algorithm that supports
             momentum.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Strategy.SmartMomentum.MinImprovement">
             <summary>
             The minimum improvement to adjust momentum.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Strategy.SmartMomentum.MaxMomentum">
             <summary>
             The maximum value that momentum can go to.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Strategy.SmartMomentum.StartMomentum">
             <summary>
             The starting momentum.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Strategy.SmartMomentum.MomentumIncrease">
             <summary>
             How much to increase momentum by.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Strategy.SmartMomentum.MomentumCycles">
             <summary>
             How many cycles to accept before adjusting momentum.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Strategy.SmartMomentum._currentMomentum">
             <summary>
             The current momentum.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Strategy.SmartMomentum._lastError">
             <summary>
             The error rate from the previous iteration.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Strategy.SmartMomentum._lastImprovement">
             <summary>
             The last improvement in error rate.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Strategy.SmartMomentum._lastMomentum">
             <summary>
             The last momentum.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Strategy.SmartMomentum._ready">
             <summary>
             Has one iteration passed, and we are now ready to start evaluation.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Strategy.SmartMomentum._setter">
             <summary>
             The setter used to change momentum.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.Strategy.SmartMomentum._train">
             <summary>
             The training algorithm that is using this strategy.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Strategy.SmartMomentum.Init(Encog.ML.Train.IMLTrain)">
             <summary>
             Initialize this strategy.
             </summary>
            
             <param name="train_0">The training algorithm.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.Strategy.SmartMomentum.PostIteration">
             <summary>
             Called just after a training iteration.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.Strategy.SmartMomentum.PreIteration">
             <summary>
             Called just before a training iteration.
             </summary>
            
        </member>
        <member name="T:Encog.Neural.Networks.Training.ITrain">
             <summary>
             This is an alias class for Encog 2.5 compatibility.  This class aliases 
             MLTrain.  Newer code should use MLTrain in place of this class.
             </summary>
            
        </member>
        <member name="T:Encog.Neural.Networks.Training.TrainingError">
             <summary>
             Thrown when a training error occurs.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.TrainingError.#ctor(System.String)">
             <summary>
             Construct a message exception.
             </summary>
            
             <param name="msg">The exception message.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.TrainingError.#ctor(System.Exception)">
             <summary>
             Construct an exception that holds another exception.
             </summary>
            
             <param name="t">The other exception.</param>
        </member>
        <member name="T:Encog.Neural.Networks.Training.TrainingSetScore">
             <summary>
             Calculate a score based on a training set. This class allows simulated
             annealing or genetic algorithms just as you would any other training set
             based training method.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Networks.Training.TrainingSetScore._training">
             <summary>
             The training set.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Networks.Training.TrainingSetScore.#ctor(Encog.ML.Data.IMLDataSet)">
             <summary>
             Construct a training set score calculation.
             </summary>
            
             <param name="training">The training data to use.</param>
        </member>
        <member name="M:Encog.Neural.Networks.Training.TrainingSetScore.CalculateScore(Encog.ML.IMLRegression)">
             <summary>
             Calculate the score for the network.
             </summary>
            
             <param name="method">The network to calculate for.</param>
             <returns>The score.</returns>
        </member>
        <member name="P:Encog.Neural.Networks.Training.TrainingSetScore.ShouldMinimize">
             <summary>
             A training set based score should always seek to lower the error,
             as a result, this method always returns true.
             </summary>
            
             <returns>Returns true.</returns>
        </member>
        <member name="T:Encog.Neural.NeuralData.INeuralData">
            <summary>
            This is an alias class for Encog 2.5 compatibility.  This class aliases 
            IMLData.  Newer code should use IMLData in place of this class.
            </summary>
        </member>
        <member name="T:Encog.Neural.NeuralData.INeuralDataPair">
            <summary>
            This is an alias class for Encog 2.5 compatibility.  This class aliases 
            IMLDataPair.  Newer code should use IMLDataPair in place of this class.
            </summary>
        </member>
        <member name="T:Encog.Neural.NeuralData.INeuralDataSet">
            <summary>
            This is an alias class for Encog 2.5 compatibility.  This class aliases 
            IMLDataSet.  Newer code should use IMLDataSet in place of this class.
            </summary>
        </member>
        <member name="T:Encog.Neural.Pattern.ADALINEPattern">
             <summary>
             Construct an ADALINE neural network.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.ADALINEPattern._inputNeurons">
             <summary>
             The number of neurons in the input layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.ADALINEPattern._outputNeurons">
             <summary>
             The number of neurons in the output layer.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.ADALINEPattern.AddHiddenLayer(System.Int32)">
             <summary>
             Not used, the ADALINE has no hidden layers, this will throw an error.
             </summary>
            
             <param name="count">The neuron count.</param>
        </member>
        <member name="M:Encog.Neural.Pattern.ADALINEPattern.Clear">
             <summary>
             Clear out any parameters.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.ADALINEPattern.Generate">
            <summary>
            Generate the network.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.ADALINEPattern.ActivationFunction">
            <summary>
            Not used, ADALINE does not use custom activation functions.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.ADALINEPattern.InputNeurons">
            <summary>
            Set the input neurons.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.ADALINEPattern.OutputNeurons">
            <summary>
            Set the output neurons.
            </summary>
        </member>
        <member name="T:Encog.Neural.Pattern.ART1Pattern">
             <summary>
             Pattern to create an ART-1 neural network.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.ART1Pattern._a1">
             <summary>
             A parameter for F1 layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.ART1Pattern._b1">
             <summary>
             B parameter for F1 layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.ART1Pattern._c1">
             <summary>
             C parameter for F1 layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.ART1Pattern._d1">
             <summary>
             D parameter for F1 layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.ART1Pattern._inputNeurons">
             <summary>
             The number of input neurons.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.ART1Pattern._l">
             <summary>
             L parameter for net.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.ART1Pattern._outputNeurons">
             <summary>
             The number of output neurons.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.ART1Pattern._vigilance">
             <summary>
             The vigilance parameter.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.ART1Pattern.#ctor">
            <summary>
            Construct the object.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.ART1Pattern.A1">
            <summary>
            Set the A1 parameter.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.ART1Pattern.B1">
            <summary>
            Set the B1 parameter.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.ART1Pattern.C1">
            <summary>
            Set the C1 parameter.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.ART1Pattern.D1">
            <summary>
            Set the D1 parameter.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.ART1Pattern.L">
             <summary>
             Set the L parameter.
             </summary>
            
             <value>The new value.</value>
        </member>
        <member name="P:Encog.Neural.Pattern.ART1Pattern.Vigilance">
            <summary>
            Set the vigilance for the network.
            </summary>
        </member>
        <member name="M:Encog.Neural.Pattern.ART1Pattern.AddHiddenLayer(System.Int32)">
             <summary>
             This will fail, hidden layers are not supported for this type of network.
             </summary>
            
             <param name="count">Not used.</param>
        </member>
        <member name="M:Encog.Neural.Pattern.ART1Pattern.Clear">
             <summary>
             Clear any properties set for this network.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.ART1Pattern.Generate">
             <summary>
             Generate the neural network.
             </summary>
            
             <returns>The generated neural network.</returns>
        </member>
        <member name="P:Encog.Neural.Pattern.ART1Pattern.ActivationFunction">
            <summary>
            This method will throw an error, you can't set the activation function
            for an ART1. type network.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.ART1Pattern.InputNeurons">
            <summary>
            Set the input neuron (F1 layer) count.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.ART1Pattern.OutputNeurons">
            <summary>
            Set the output neuron (F2 layer) count.
            </summary>
        </member>
        <member name="T:Encog.Neural.Pattern.BAMPattern">
             <summary>
             Construct a Bidirectional Access Memory (BAM) neural network. This neural
             network type learns to associate one pattern with another. The two patterns
             do not need to be of the same length. This network has two that are connected
             to each other. Though they are labeled as input and output layers to Encog,
             they are both equal, and should simply be thought of as the two layers that
             make up the net.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.BAMPattern._f1Neurons">
             <summary>
             The number of neurons in the first layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.BAMPattern._f2Neurons">
             <summary>
             The number of neurons in the second layer.
             </summary>
            
        </member>
        <member name="P:Encog.Neural.Pattern.BAMPattern.F1Neurons">
             <summary>
             Set the F1 neurons. The BAM really does not have an input and output
             layer, so this is simply setting the number of neurons that are in the
             first layer.
             </summary>
            
             <value>The number of neurons in the first layer.</value>
        </member>
        <member name="P:Encog.Neural.Pattern.BAMPattern.F2Neurons">
            <summary>
            Set the output neurons. The BAM really does not have an input and output
            layer, so this is simply setting the number of neurons that are in the
            second layer.
            </summary>
        </member>
        <member name="M:Encog.Neural.Pattern.BAMPattern.AddHiddenLayer(System.Int32)">
             <summary>
             Unused, a BAM has no hidden layers.
             </summary>
            
             <param name="count">Not used.</param>
        </member>
        <member name="M:Encog.Neural.Pattern.BAMPattern.Clear">
            <summary>
            Clear any settings on the pattern.
            </summary>
        </member>
        <member name="M:Encog.Neural.Pattern.BAMPattern.Generate">
            <returns>The generated network.</returns>
        </member>
        <member name="P:Encog.Neural.Pattern.BAMPattern.ActivationFunction">
            <summary>
            Not used, the BAM uses a bipoloar activation function.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.BAMPattern.InputNeurons">
            <summary>
            Set the number of input neurons.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.BAMPattern.OutputNeurons">
            <summary>
            Set the number of output neurons.
            </summary>
        </member>
        <member name="T:Encog.Neural.Pattern.BoltzmannPattern">
             <summary>
             Pattern to create a Boltzmann machine.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.BoltzmannPattern._annealCycles">
             <summary>
             The number of annealing cycles per run.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.BoltzmannPattern._neuronCount">
             <summary>
             The number of neurons in the Boltzmann network.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.BoltzmannPattern._runCycles">
             <summary>
             The number of cycles per run.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.BoltzmannPattern._temperature">
             <summary>
             The current temperature.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.BoltzmannPattern.#ctor">
            <summary>
            Construct the object.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.BoltzmannPattern.AnnealCycles">
            <summary>
            Set the number of annealing cycles per run.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.BoltzmannPattern.RunCycles">
            <summary>
            Set the number of cycles per run.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.BoltzmannPattern.Temperature">
            <summary>
            Set the temperature.
            </summary>
        </member>
        <member name="M:Encog.Neural.Pattern.BoltzmannPattern.AddHiddenLayer(System.Int32)">
             <summary>
             Not supported, will throw an exception, Boltzmann networks have no hidden
             layers.
             </summary>
            
             <param name="count">Not used.</param>
        </member>
        <member name="M:Encog.Neural.Pattern.BoltzmannPattern.Clear">
             <summary>
             Clear any properties set on this network.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.BoltzmannPattern.Generate">
            <summary>
            Generate the network.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.BoltzmannPattern.ActivationFunction">
             <summary>
             Not used, will throw an exception.
             </summary>
            
             <value>Not used.</value>
        </member>
        <member name="P:Encog.Neural.Pattern.BoltzmannPattern.InputNeurons">
             <summary>
             Set the number of input neurons. This is the same as the number of output
             neurons.
             </summary>
            
             <value>The number of input neurons.</value>
        </member>
        <member name="P:Encog.Neural.Pattern.BoltzmannPattern.OutputNeurons">
            <summary>
            Set the number of output neurons. This is the same as the number of input
            neurons.
            </summary>
        </member>
        <member name="T:Encog.Neural.Pattern.CPNPattern">
             <summary>
             Pattern that creates a CPN neural network.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.CPNPattern.TagInstar">
             <summary>
             The tag for the INSTAR layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.CPNPattern.TagOutstar">
             <summary>
             The tag for the OUTSTAR layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.CPNPattern._inputCount">
             <summary>
             The number of neurons in the hidden layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.CPNPattern._instarCount">
             <summary>
             The number of neurons in the instar layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.CPNPattern._outstarCount">
             <summary>
             The number of neurons in the outstar layer.
             </summary>
            
        </member>
        <member name="P:Encog.Neural.Pattern.CPNPattern.InstarCount">
            <summary>
            Set the number of neurons in the instar layer. This level is essentially
            a hidden layer.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.CPNPattern.OutstarCount">
            <summary>
            Set the number of neurons in the outstar level, this level is mapped to
            the "output" level.
            </summary>
        </member>
        <member name="M:Encog.Neural.Pattern.CPNPattern.AddHiddenLayer(System.Int32)">
             <summary>
             Not used, will throw an error. CPN networks already have a predefined
             hidden layer called the instar layer.
             </summary>
            
             <param name="count">NOT USED</param>
        </member>
        <member name="M:Encog.Neural.Pattern.CPNPattern.Clear">
             <summary>
             Clear any parameters that were set.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.CPNPattern.Generate">
             <summary>
             Generate the network.
             </summary>
            
             <returns>The generated network.</returns>
        </member>
        <member name="P:Encog.Neural.Pattern.CPNPattern.ActivationFunction">
            <summary>
            This method will throw an error. The CPN network uses predefined
            activation functions.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.CPNPattern.InputNeurons">
            <summary>
            Set the number of input neurons.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.CPNPattern.OutputNeurons">
            <summary>
            Set the number of output neurons. Calling this method maps to setting the
            number of neurons in the outstar layer.
            </summary>
        </member>
        <member name="T:Encog.Neural.Pattern.ElmanPattern">
             <summary>
             This class is used to generate an Elman style recurrent neural network. This
             network type consists of three regular layers, an input output and hidden
             layer. There is also a context layer which accepts output from the hidden
             layer and outputs back to the hidden layer. This makes it a recurrent neural
             network.
             The Elman neural network is useful for temporal input data. The specified
             activation function will be used on all layers. The Elman neural network is
             similar to the Jordan neural network.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.ElmanPattern._activation">
             <summary>
             The activation function.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.ElmanPattern._hiddenNeurons">
             <summary>
             The number of hidden neurons.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.ElmanPattern._inputNeurons">
             <summary>
             The number of input neurons.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.ElmanPattern._outputNeurons">
             <summary>
             The number of output neurons.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.ElmanPattern.#ctor">
             <summary>
             Create an object to generate Elman neural networks.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.ElmanPattern.AddHiddenLayer(System.Int32)">
             <summary>
             Add a hidden layer with the specified number of neurons.
             </summary>
            
             <param name="count">The number of neurons in this hidden layer.</param>
        </member>
        <member name="M:Encog.Neural.Pattern.ElmanPattern.Clear">
             <summary>
             Clear out any hidden neurons.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.ElmanPattern.Generate">
             <summary>
             Generate the Elman neural network.
             </summary>
            
             <returns>The Elman neural network.</returns>
        </member>
        <member name="P:Encog.Neural.Pattern.ElmanPattern.ActivationFunction">
            <summary>
            Set the activation function to use on each of the layers.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.ElmanPattern.InputNeurons">
            <summary>
            Set the number of input neurons.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.ElmanPattern.OutputNeurons">
            <summary>
            Set the number of output neurons.
            </summary>
        </member>
        <member name="T:Encog.Neural.Pattern.FeedForwardPattern">
             <summary>
             Used to create feedforward neural networks. A feedforward network has an
             input and output layers separated by zero or more hidden layers. The
             feedforward neural network is one of the most common neural network patterns.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.FeedForwardPattern._hidden">
             <summary>
             The number of hidden neurons.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.FeedForwardPattern._activationHidden">
             <summary>
             The activation function.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.FeedForwardPattern._activationOutput">
             <summary>
             The activation function.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.FeedForwardPattern._inputNeurons">
             <summary>
             The number of input neurons.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.FeedForwardPattern._outputNeurons">
             <summary>
             The number of output neurons.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.FeedForwardPattern.#ctor">
            <summary>
            Construct the object.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.FeedForwardPattern.ActivationOutput">
            <value>the activationOutput to set</value>
        </member>
        <member name="M:Encog.Neural.Pattern.FeedForwardPattern.AddHiddenLayer(System.Int32)">
            <summary>
            Add a hidden layer, with the specified number of neurons.
            </summary>
        </member>
        <member name="M:Encog.Neural.Pattern.FeedForwardPattern.Clear">
             <summary>
             Clear out any hidden neurons.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.FeedForwardPattern.Generate">
            <summary>
            Generate the feedforward neural network.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.FeedForwardPattern.ActivationFunction">
            <summary>
            Set the activation function to use on each of the layers.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.FeedForwardPattern.InputNeurons">
            <summary>
            Set the number of input neurons.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.FeedForwardPattern.OutputNeurons">
            <summary>
            Set the number of output neurons.
            </summary>
        </member>
        <member name="T:Encog.Neural.Pattern.HopfieldPattern">
             <summary>
             Create a Hopfield pattern. A Hopfield neural network has a single layer that
             functions both as the input and output layers. There are no hidden layers.
             Hopfield networks are used for basic pattern recognition. When a Hopfield
             network recognizes a pattern, it "echos" that pattern on the output.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.HopfieldPattern._neuronCount">
             <summary>
             How many neurons in the Hopfield network. Default to -1, which is
             invalid. Therefore this value must be set.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.HopfieldPattern.#ctor">
            <summary>
            Construct the object.
            </summary>
        </member>
        <member name="M:Encog.Neural.Pattern.HopfieldPattern.AddHiddenLayer(System.Int32)">
             <summary>
             Add a hidden layer. This will throw an error, because the Hopfield neural
             network has no hidden layers.
             </summary>
            
             <param name="count">The number of neurons.</param>
        </member>
        <member name="M:Encog.Neural.Pattern.HopfieldPattern.Clear">
             <summary>
             Nothing to clear.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.HopfieldPattern.Generate">
             <summary>
             Generate the Hopfield neural network.
             </summary>
            
             <returns>The generated network.</returns>
        </member>
        <member name="P:Encog.Neural.Pattern.HopfieldPattern.ActivationFunction">
            <summary>
            Set the activation function to use. This function will throw an error,
            because the Hopfield network must use the BiPolar activation function.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.HopfieldPattern.InputNeurons">
            <summary>
            Set the number of input neurons, this must match the output neurons.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.HopfieldPattern.OutputNeurons">
            <summary>
            Set the number of output neurons, should not be used with a hopfield
            neural network, because the number of input neurons defines the number of
            output neurons.
            </summary>
        </member>
        <member name="T:Encog.Neural.Pattern.JordanPattern">
             <summary>
             This class is used to generate an Jordan style recurrent neural network. This
             network type consists of three regular layers, an input output and hidden
             layer. There is also a context layer which accepts output from the output
             layer and outputs back to the hidden layer. This makes it a recurrent neural
             network.
             The Jordan neural network is useful for temporal input data. The specified
             activation function will be used on all layers. The Jordan neural network is
             similar to the Elman neural network.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.JordanPattern._activation">
             <summary>
             The activation function.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.JordanPattern._hiddenNeurons">
             <summary>
             The number of hidden neurons.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.JordanPattern._inputNeurons">
             <summary>
             The number of input neurons.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.JordanPattern._outputNeurons">
             <summary>
             The number of output neurons.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.JordanPattern.#ctor">
             <summary>
             Construct an object to create a Jordan type neural network.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.JordanPattern.AddHiddenLayer(System.Int32)">
             <summary>
             Add a hidden layer, there should be only one.
             </summary>
            
             <param name="count">The number of neurons in this hidden layer.</param>
        </member>
        <member name="M:Encog.Neural.Pattern.JordanPattern.Clear">
             <summary>
             Clear out any hidden neurons.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.JordanPattern.Generate">
             <summary>
             Generate a Jordan neural network.
             </summary>
            
             <returns>A Jordan neural network.</returns>
        </member>
        <member name="P:Encog.Neural.Pattern.JordanPattern.ActivationFunction">
            <summary>
            Set the activation function to use on each of the layers.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.JordanPattern.InputNeurons">
            <summary>
            Set the number of input neurons.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.JordanPattern.OutputNeurons">
            <summary>
            Set the number of output neurons.
            </summary>
        </member>
        <member name="T:Encog.Neural.Pattern.INeuralNetworkPattern">
             <summary>
             Patterns are used to create common sorts of neural networks. Information
             about the structure of the neural network is communicated to the pattern, and
             then generate is called to produce a neural network of this type.
             </summary>
            
        </member>
        <member name="P:Encog.Neural.Pattern.INeuralNetworkPattern.ActivationFunction">
             <summary>
             Set the activation function to be used for all created layers that allow
             an activation function to be specified. Not all patterns allow the
             activation function to be specified.
             </summary>
            
             <value>The activation function.</value>
        </member>
        <member name="P:Encog.Neural.Pattern.INeuralNetworkPattern.InputNeurons">
             <summary>
             Set the number of input neurons.
             </summary>
            
             <value>The number of input neurons.</value>
        </member>
        <member name="P:Encog.Neural.Pattern.INeuralNetworkPattern.OutputNeurons">
             <summary>
             Set the number of output neurons.
             </summary>
            
             <value>The output neuron count.</value>
        </member>
        <member name="M:Encog.Neural.Pattern.INeuralNetworkPattern.AddHiddenLayer(System.Int32)">
             <summary>
             Add the specified hidden layer.
             </summary>
            
             <param name="count">The number of neurons in the hidden layer.</param>
        </member>
        <member name="M:Encog.Neural.Pattern.INeuralNetworkPattern.Clear">
             <summary>
             Clear the hidden layers so that they can be redefined.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.INeuralNetworkPattern.Generate">
             <summary>
             Generate the specified neural network.
             </summary>
            
             <returns>The resulting neural network.</returns>
        </member>
        <member name="T:Encog.Neural.Pattern.PatternError">
             <summary>
             This class is thrown when an error occurs while using one of the neural
             network pattern classes.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.PatternError.#ctor(System.String)">
             <summary>
             Construct a message exception.
             </summary>
            
             <param name="msg">The exception message.</param>
        </member>
        <member name="M:Encog.Neural.Pattern.PatternError.#ctor(System.Exception)">
             <summary>
             Construct an exception that holds another exception.
             </summary>
            
             <param name="t">The other exception.</param>
        </member>
        <member name="T:Encog.Neural.Pattern.PNNPattern">
             <summary>
             Pattern to create a PNN.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.PNNPattern._inputNeurons">
             <summary>
             The number of input neurons.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.PNNPattern._kernel">
             <summary>
             The kernel type.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.PNNPattern._outmodel">
             <summary>
             The output model.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.PNNPattern._outputNeurons">
             <summary>
             The number of output neurons.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.PNNPattern.#ctor">
            <summary>
            Construct the object.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.PNNPattern.Kernel">
            <summary>
            Set the kernel type.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.PNNPattern.Outmodel">
            <summary>
            Set the output model.
            </summary>
        </member>
        <member name="M:Encog.Neural.Pattern.PNNPattern.AddHiddenLayer(System.Int32)">
             <summary>
             Add a hidden layer. PNN networks do not have hidden layers, so this will
             throw an error.
             </summary>
            
             <param name="count">The number of hidden neurons.</param>
        </member>
        <member name="M:Encog.Neural.Pattern.PNNPattern.Clear">
             <summary>
             Clear out any hidden neurons.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.PNNPattern.Generate">
             <summary>
             Generate the RSOM network.
             </summary>
            
             <returns>The neural network.</returns>
        </member>
        <member name="P:Encog.Neural.Pattern.PNNPattern.InputNeurons">
            <summary>
            Set the input neuron count.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.PNNPattern.OutputNeurons">
             <summary>
             Set the output neuron count.
             </summary>
            
             <value>The number of neurons.</value>
        </member>
        <member name="P:Encog.Neural.Pattern.PNNPattern.ActivationFunction">
            <summary>
            Set the activation function. A PNN uses a linear activation function, so
            this method throws an error.
            </summary>
        </member>
        <member name="T:Encog.Neural.Pattern.RadialBasisPattern">
             <summary>
             A radial basis function (RBF) network uses several radial basis functions to
             provide a more dynamic hidden layer activation function than many other types
             of neural network. It consists of a input, output and hidden layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.RadialBasisPattern._hiddenNeurons">
             <summary>
             The number of hidden neurons to use. Must be set, default to invalid -1
             value.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.RadialBasisPattern._inputNeurons">
             <summary>
             The number of input neurons to use. Must be set, default to invalid -1
             value.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.RadialBasisPattern._outputNeurons">
             <summary>
             The number of hidden neurons to use. Must be set, default to invalid -1
             value.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.RadialBasisPattern._rbfType">
            <summary>
            The RBF type.
            </summary>
        </member>
        <member name="M:Encog.Neural.Pattern.RadialBasisPattern.#ctor">
            <summary>
            Construct the object.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.RadialBasisPattern.RBF">
            <summary>
            The RBF type.
            </summary>
        </member>
        <member name="M:Encog.Neural.Pattern.RadialBasisPattern.AddHiddenLayer(System.Int32)">
             <summary>
             Add the hidden layer, this should be called once, as a RBF has a single
             hidden layer.
             </summary>
            
             <param name="count">The number of neurons in the hidden layer.</param>
        </member>
        <member name="M:Encog.Neural.Pattern.RadialBasisPattern.Clear">
             <summary>
             Clear out any hidden neurons.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.RadialBasisPattern.Generate">
             <summary>
             Generate the RBF network.
             </summary>
            
             <returns>The neural network.</returns>
        </member>
        <member name="P:Encog.Neural.Pattern.RadialBasisPattern.ActivationFunction">
            <summary>
            Set the activation function, this is an error. The activation function
            may not be set on a RBF layer.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.RadialBasisPattern.InputNeurons">
            <summary>
            Set the number of input neurons.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.RadialBasisPattern.OutputNeurons">
            <summary>
            Set the number of output neurons.
            </summary>
        </member>
        <member name="T:Encog.Neural.Pattern.SOMPattern">
             <summary>
             A self organizing map is a neural network pattern with an input and output
             layer. There is no hidden layer. The winning neuron, which is that neuron
             with the higest output is the winner, this winning neuron is often used to
             classify the input into a group.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.SOMPattern._inputNeurons">
             <summary>
             The number of input neurons.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.SOMPattern._outputNeurons">
             <summary>
             The number of output neurons.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.SOMPattern.AddHiddenLayer(System.Int32)">
            <summary>
            Add a hidden layer. SOM networks do not have hidden layers, so this will
            throw an error.
            </summary>
        </member>
        <member name="M:Encog.Neural.Pattern.SOMPattern.Clear">
             <summary>
             Clear out any hidden neurons.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.SOMPattern.Generate">
            <summary>
            Generate the RSOM network.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.SOMPattern.ActivationFunction">
            <summary>
            Set the activation function. A SOM uses a linear activation function, so
            this method throws an error.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.SOMPattern.InputNeurons">
            <summary>
            Set the input neuron count.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.SOMPattern.OutputNeurons">
            <summary>
            Set the output neuron count.
            </summary>
        </member>
        <member name="T:Encog.Neural.Pattern.SVMPattern">
             <summary>
             A pattern to create support vector machines.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.SVMPattern._inputNeurons">
             <summary>
             The number of neurons in the first layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.SVMPattern._kernelType">
             <summary>
             The kernel type.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.SVMPattern._outputNeurons">
             <summary>
             The number of neurons in the second layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pattern.SVMPattern._svmType">
             <summary>
             The SVM type.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.SVMPattern.#ctor">
            <summary>
            Construct the object.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.SVMPattern.Regression">
            <summary>
            Set if regression is used.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.SVMPattern.KernelType">
            <summary>
            Set the kernel type.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.SVMPattern.SVMType">
            <summary>
            Set the SVM type.
            </summary>
        </member>
        <member name="M:Encog.Neural.Pattern.SVMPattern.AddHiddenLayer(System.Int32)">
             <summary>
             Unused, a BAM has no hidden layers.
             </summary>
            
             <param name="count">Not used.</param>
        </member>
        <member name="M:Encog.Neural.Pattern.SVMPattern.Clear">
             <summary>
             Clear any settings on the pattern.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pattern.SVMPattern.Generate">
            <returns>The generated network.</returns>
        </member>
        <member name="P:Encog.Neural.Pattern.SVMPattern.InputNeurons">
            <summary>
            Set the number of input neurons.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.SVMPattern.OutputNeurons">
            <summary>
            Set the number of output neurons.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pattern.SVMPattern.ActivationFunction">
            <summary>
            Not used, the BAM uses a bipoloar activation function.
            </summary>
        </member>
        <member name="T:Encog.Neural.PNN.AbstractPNN">
            <summary>
            Abstract class to build PNN networks upon.
            </summary>
        </member>
        <member name="F:Encog.Neural.PNN.AbstractPNN._deriv">
             <summary>
             First derivative. 
             </summary>
            
        </member>
        <member name="F:Encog.Neural.PNN.AbstractPNN._deriv2">
             <summary>
             Second derivative.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.PNN.AbstractPNN._inputCount">
             <summary>
             Input neuron count.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.PNN.AbstractPNN._kernel">
             <summary>
             Kernel type. 
             </summary>
            
        </member>
        <member name="F:Encog.Neural.PNN.AbstractPNN._outputCount">
             <summary>
             Output neuron count. 
             </summary>
            
        </member>
        <member name="F:Encog.Neural.PNN.AbstractPNN._outputMode">
             <summary>
             Output mode.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.PNN.AbstractPNN._confusion">
             <summary>
             Confusion work area.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.PNN.AbstractPNN.#ctor(Encog.Neural.PNN.PNNKernelType,Encog.Neural.PNN.PNNOutputMode,System.Int32,System.Int32)">
             <summary>
             Constructor.
             </summary>
            
             <param name="kernel">The kernel type to use.</param>
             <param name="outputMode">The output mode to use.</param>
             <param name="inputCount">The input count.</param>
             <param name="outputCount">The output count.</param>
        </member>
        <member name="P:Encog.Neural.PNN.AbstractPNN.Deriv">
            <value>the deriv</value>
        </member>
        <member name="P:Encog.Neural.PNN.AbstractPNN.Deriv2">
            <value>the deriv2</value>
        </member>
        <member name="P:Encog.Neural.PNN.AbstractPNN.Error">
            <value>the error to set</value>
        </member>
        <member name="P:Encog.Neural.PNN.AbstractPNN.Exclude">
            <value>the exclude to set</value>
        </member>
        <member name="P:Encog.Neural.PNN.AbstractPNN.InputCount">
            <value>the inputCount</value>
        </member>
        <member name="P:Encog.Neural.PNN.AbstractPNN.Kernel">
            <value>the kernel</value>
        </member>
        <member name="P:Encog.Neural.PNN.AbstractPNN.OutputCount">
            <value>the outputCount</value>
        </member>
        <member name="P:Encog.Neural.PNN.AbstractPNN.OutputMode">
            <value>the outputMode</value>
        </member>
        <member name="P:Encog.Neural.PNN.AbstractPNN.Trained">
            <value>the trained to set</value>
        </member>
        <member name="P:Encog.Neural.PNN.AbstractPNN.SeparateClass">
            <value>the separateClass to set</value>
        </member>
        <member name="M:Encog.Neural.PNN.AbstractPNN.Compute(Encog.ML.Data.IMLData)">
             <summary>
             Compute the output from the network.
             </summary>
            
             <param name="input">The input to the network.</param>
             <returns>The output from the network.</returns>
        </member>
        <member name="M:Encog.Neural.PNN.AbstractPNN.ResetConfusion">
             <summary>
             Reset the confusion.
             </summary>
            
        </member>
        <member name="T:Encog.Neural.PNN.BasicPNN">
            <summary>
            This class implements either a:
            Probabilistic Neural Network (PNN)
            General Regression Neural Network (GRNN)
            To use a PNN specify an output mode of classification, to make use of a GRNN
            specify either an output mode of regression or un-supervised autoassociation.
            The PNN/GRNN networks are potentially very useful. They share some
            similarities with RBF-neural networks and also the Support Vector Machine
            (SVM). These network types directly support the use of classification.
            The following book was very helpful in implementing PNN/GRNN's in Encog.
            Advanced Algorithms for Neural Networks: A C++ Sourcebook
            by Timothy Masters, PhD (http://www.timothymasters.info/) John Wiley Sons
            Inc (Computers); April 3, 1995, ISBN: 0471105880
            </summary>
        </member>
        <member name="F:Encog.Neural.PNN.BasicPNN._sigma">
             <summary>
             The sigma's specify the widths of each kernel used.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.PNN.BasicPNN._countPer">
             <summary>
             Used for classification, the number of cases in each class.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.PNN.BasicPNN._priors">
             <summary>
             The prior probability weights.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.PNN.BasicPNN._samples">
             <summary>
             The training samples that form the memory of this network.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.PNN.BasicPNN.#ctor(Encog.Neural.PNN.PNNKernelType,Encog.Neural.PNN.PNNOutputMode,System.Int32,System.Int32)">
             <summary>
             Construct a BasicPNN network.
             </summary>
            
             <param name="kernel">The kernel to use.</param>
             <param name="outmodel">The output model for this network.</param>
             <param name="inputCount">The number of inputs in this network.</param>
             <param name="outputCount">The number of outputs in this network.</param>
        </member>
        <member name="P:Encog.Neural.PNN.BasicPNN.CountPer">
            <value>the countPer</value>
        </member>
        <member name="P:Encog.Neural.PNN.BasicPNN.Priors">
            <value>the priors</value>
        </member>
        <member name="P:Encog.Neural.PNN.BasicPNN.Samples">
            <value>the samples to set</value>
        </member>
        <member name="P:Encog.Neural.PNN.BasicPNN.Sigma">
            <value>the sigma</value>
        </member>
        <member name="M:Encog.Neural.PNN.BasicPNN.Compute(Encog.ML.Data.IMLData)">
             <summary>
             Compute the output from this network.
             </summary>
            
             <param name="input">The input to the network.</param>
             <returns>The output from the network.</returns>
        </member>
        <member name="M:Encog.Neural.PNN.BasicPNN.UpdateProperties">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.PNN.BasicPNN.CalculateError(Encog.ML.Data.IMLDataSet)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.PNN.BasicPNN.Classify(Encog.ML.Data.IMLData)">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.PNN.PNNKernelType">
             <summary>
             Specifies the kernel type for the PNN.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.PNN.PNNKernelType.Gaussian">
             <summary>
             A Gaussian curved kernel. The usual choice.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.PNN.PNNKernelType.Reciprocal">
             <summary>
             A steep kernel.
             </summary>
            
        </member>
        <member name="T:Encog.Neural.PNN.PNNOutputMode">
             <summary>
             The output mode that will be used by the PNN.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.PNN.PNNOutputMode.Unsupervised">
             <summary>
             Unsupervised training will make use of autoassociation. No "ideal" values
             should be provided for training. Input and output neuron counts must
             match.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.PNN.PNNOutputMode.Regression">
             <summary>
             Regression is where the neural network performs as a function. Input is
             supplied, and output is returned. The output is a numeric value.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.PNN.PNNOutputMode.Classification">
             <summary>
             Classification attempts to classify the input into a number of predefined
             classes. The class is stored in the ideal as a single "double" value,
             though it is really treated as an integer that represents class
             membership. The number of output neurons should match the number of
             classes. Classes are indexed beginning at 0.
             </summary>
            
        </member>
        <member name="T:Encog.Neural.Pnn.PersistBasicPNN">
             <summary>
             Persist a PNN.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Pnn.PersistBasicPNN.PropertyOutputMode">
             <summary>
             The output mode property.
             </summary>
            
        </member>
        <member name="P:Encog.Neural.Pnn.PersistBasicPNN.FileVersion">
            <summary>
            File version.
            </summary>
        </member>
        <member name="P:Encog.Neural.Pnn.PersistBasicPNN.PersistClassString">
            <summary>
            File version.
            </summary>
        </member>
        <member name="M:Encog.Neural.Pnn.PersistBasicPNN.Read(System.IO.Stream)">
            <summary>
            Read an object.
            </summary>
        </member>
        <member name="M:Encog.Neural.Pnn.PersistBasicPNN.Save(System.IO.Stream,System.Object)">
             <summary>
             
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Pnn.PersistBasicPNN.KernelToString(Encog.Neural.PNN.PNNKernelType)">
             <summary>
             Convert a kernel type to a string.
             </summary>
            
             <param name="k">The kernel type.</param>
             <returns>The string.</returns>
        </member>
        <member name="M:Encog.Neural.Pnn.PersistBasicPNN.OutputModeToString(Encog.Neural.PNN.PNNOutputMode)">
             <summary>
             Convert output mode to string.
             </summary>
            
             <param name="mode">The output mode.</param>
             <returns>The string.</returns>
        </member>
        <member name="M:Encog.Neural.Pnn.PersistBasicPNN.StringToKernel(System.String)">
             <summary>
             Convert a string to a PNN kernel.
             </summary>
            
             <param name="k">The string.</param>
             <returns>The kernel.</returns>
        </member>
        <member name="M:Encog.Neural.Pnn.PersistBasicPNN.StringToOutputMode(System.String)">
             <summary>
             Convert a string to a PNN output mode.
             </summary>
            
             <param name="mode">The string.</param>
             <returns>The output ndoe.</returns>
        </member>
        <member name="P:Encog.Neural.Pnn.PersistBasicPNN.NativeType">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.Prune.HiddenLayerParams">
             <summary>
             Specifies the minimum and maximum neuron counts for a layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Prune.HiddenLayerParams._max">
             <summary>
             The maximum number of neurons on this layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Prune.HiddenLayerParams._min">
             <summary>
             The minimum number of neurons on this layer.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Prune.HiddenLayerParams.#ctor(System.Int32,System.Int32)">
             <summary>
             Construct a hidden layer param object with the specified min and max
             values.
             </summary>
            
             <param name="min">The minimum number of neurons.</param>
             <param name="max">The maximum number of neurons.</param>
        </member>
        <member name="P:Encog.Neural.Prune.HiddenLayerParams.Max">
            <value>The maximum number of neurons.</value>
        </member>
        <member name="P:Encog.Neural.Prune.HiddenLayerParams.Min">
            <value>The minimum number of neurons.</value>
        </member>
        <member name="T:Encog.Neural.Prune.NetworkPattern">
             <summary>
             Specify which network pattern to use.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Prune.NetworkPattern.MultiLayerFeedforward">
             <summary>
             Multilayer feedforward.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Prune.NetworkPattern.Elman">
             <summary>
             Elman.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Prune.NetworkPattern.Jordan">
             <summary>
             Jordan.
             </summary>
            
        </member>
        <member name="T:Encog.Neural.Prune.PruneIncremental">
             <summary>
             This class is used to help determine the optimal configuration for the hidden
             layers of a neural network. It can accept a pattern, which specifies the type
             of neural network to create, and a list of the maximum and minimum hidden
             layer neurons. It will then attempt to train the neural network at all
             configurations and see which hidden neuron counts work the best.
             This method does not simply choose the network with the lowest error rate. A
             specifiable number of best networks are kept, which represent the networks
             with the lowest error rates. From this collection of networks, the best
             network is defined to be the one with the fewest number of connections.
             Not all starting random weights are created equal. Because of this, an option
             is provided to allow you to choose how many attempts you want the process to
             make, with different weights. All random weights are created using the
             default Nguyen-Widrow method normally used by Encog.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Prune.PruneIncremental._hidden">
             <summary>
             The ranges for the hidden layers.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Prune.PruneIncremental._iterations">
             <summary>
             The number if training iterations that should be tried for each network.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Prune.PruneIncremental._pattern">
             <summary>
             The pattern for which type of neural network we would like to create.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Prune.PruneIncremental._report">
             <summary>
             The object that status should be reported to.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Prune.PruneIncremental._topErrors">
             <summary>
             An array of the top errors.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Prune.PruneIncremental._topNetworks">
             <summary>
             An array of the top networks.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Prune.PruneIncremental._training">
             <summary>
             The training set to use as different neural networks are evaluated.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Prune.PruneIncremental._weightTries">
             <summary>
             The number of tries with random weights.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Prune.PruneIncremental._bestNetwork">
             <summary>
             The best network found so far.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Prune.PruneIncremental._currentTry">
             <summary>
             How many networks have been tried so far?
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Prune.PruneIncremental._done">
             <summary>
             Are we done?
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Prune.PruneIncremental._hidden1Size">
             <summary>
             The size of the first hidden layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Prune.PruneIncremental._hidden2Size">
             <summary>
             The size of the second hidden layer.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Prune.PruneIncremental._hiddenCounts">
             <summary>
             Keeps track of how many neurons in each hidden layer as training the
             evaluation progresses.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Prune.PruneIncremental._high">
             <summary>
             The current highest error.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Prune.PruneIncremental._low">
             <summary>
             The current lowest error.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Prune.PruneIncremental._results">
             <summary>
             The results in a 2d array.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Prune.PruneIncremental.#ctor(Encog.ML.Data.IMLDataSet,Encog.Neural.Pattern.INeuralNetworkPattern,System.Int32,System.Int32,System.Int32,Encog.IStatusReportable)">
             <summary>
             Construct an object to determine the optimal number of hidden layers and
             neurons for the specified training data and pattern.
             </summary>
            
             <param name="training">The training data to use.</param>
             <param name="pattern">The network pattern to use to solve this data.</param>
             <param name="iterations">How many iterations to try per network.</param>
             <param name="weightTries">The number of random weights to use.</param>
             <param name="numTopResults"></param>
             <param name="report">Object used to report status to.</param>
        </member>
        <member name="P:Encog.Neural.Prune.PruneIncremental.BestNetwork">
            <value>The network being processed.</value>
        </member>
        <member name="P:Encog.Neural.Prune.PruneIncremental.Hidden">
            <value>The hidden layer max and min.</value>
        </member>
        <member name="P:Encog.Neural.Prune.PruneIncremental.Hidden1Size">
            <value>The size of the first hidden layer.</value>
        </member>
        <member name="P:Encog.Neural.Prune.PruneIncremental.Hidden2Size">
            <value>The size of the second hidden layer.</value>
        </member>
        <member name="P:Encog.Neural.Prune.PruneIncremental.High">
            <value>The higest error so far.</value>
        </member>
        <member name="P:Encog.Neural.Prune.PruneIncremental.Iterations">
            <value>The number of training iterations to try for each network.</value>
        </member>
        <member name="P:Encog.Neural.Prune.PruneIncremental.Low">
            <value>The lowest error so far.</value>
        </member>
        <member name="P:Encog.Neural.Prune.PruneIncremental.Pattern">
            <value>The network pattern to use.</value>
        </member>
        <member name="P:Encog.Neural.Prune.PruneIncremental.Results">
            <value>The error results.</value>
        </member>
        <member name="P:Encog.Neural.Prune.PruneIncremental.TopErrors">
            <value>the topErrors</value>
        </member>
        <member name="P:Encog.Neural.Prune.PruneIncremental.TopNetworks">
            <value>the topNetworks</value>
        </member>
        <member name="P:Encog.Neural.Prune.PruneIncremental.Training">
            <value>The training set to use.</value>
        </member>
        <member name="M:Encog.Neural.Prune.PruneIncremental.NetworkToString(Encog.Neural.Networks.BasicNetwork)">
             <summary>
             Format the network as a human readable string that lists the hidden
             layers.
             </summary>
            
             <param name="network">The network to format.</param>
             <returns>A human readable string.</returns>
        </member>
        <member name="M:Encog.Neural.Prune.PruneIncremental.AddHiddenLayer(System.Int32,System.Int32)">
             <summary>
             Add a hidden layer's min and max. Call this once per hidden layer.
             Specify a zero min if it is possible to remove this hidden layer.
             </summary>
            
             <param name="min">The minimum number of neurons for this layer.</param>
             <param name="max">The maximum number of neurons for this layer.</param>
        </member>
        <member name="M:Encog.Neural.Prune.PruneIncremental.GenerateNetwork">
             <summary>
             Generate a network according to the current hidden layer counts.
             </summary>
            
             <returns>The network based on current hidden layer counts.</returns>
        </member>
        <member name="M:Encog.Neural.Prune.PruneIncremental.IncreaseHiddenCounts">
             <summary>
             Increase the hidden layer counts according to the hidden layer
             parameters. Increase the first hidden layer count by one, if it is maxed
             out, then set it to zero and increase the next hidden layer.
             </summary>
            
             <returns>False if no more increases can be done, true otherwise.</returns>
        </member>
        <member name="M:Encog.Neural.Prune.PruneIncremental.Init">
             <summary>
             Init for prune.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Prune.PruneIncremental.LoadWorkload">
             <summary>
             Get the next workload. This is the number of hidden neurons. This is the
             total amount of work to be processed.
             </summary>
            
             <returns>The amount of work to be processed by this.</returns>
        </member>
        <member name="M:Encog.Neural.Prune.PruneIncremental.PerformJobUnit(Encog.Util.Concurrency.Job.JobUnitContext)">
             <summary>
             Perform an individual job unit, which is a single network to train and
             evaluate.
             </summary>
            
             <param name="context">Contains information about the job unit.</param>
        </member>
        <member name="M:Encog.Neural.Prune.PruneIncremental.Process">
             <summary>
             Begin the prune process.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Prune.PruneIncremental.RequestNextTask">
             <summary>
             Request the next task. This is the next network to attempt to train.
             </summary>
            
             <returns>The next network to train.</returns>
        </member>
        <member name="M:Encog.Neural.Prune.PruneIncremental.UpdateBest(Encog.Neural.Networks.BasicNetwork,System.Double)">
             <summary>
             Update the best network.
             </summary>
            
             <param name="network">The network to consider.</param>
             <param name="error">The error for this network.</param>
        </member>
        <member name="T:Encog.Neural.Prune.PruneSelective">
             <summary>
             Prune a neural network selectively. This class allows you to either add or
             remove neurons from layers of a neural network. You can also randomize or
             stimulate neurons.
             No provision is given for removing an entire layer. Removing a layer requires
             a totally new set of weights between the layers before and after the removed
             one. This essentially makes any remaining weights useless. At this point you
             are better off just creating a new network of the desired dimensions.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Prune.PruneSelective._network">
             <summary>
             The network to prune.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Prune.PruneSelective.#ctor(Encog.Neural.Networks.BasicNetwork)">
             <summary>
             Construct an object prune the neural network.
             </summary>
            
             <param name="network">The network to prune.</param>
        </member>
        <member name="P:Encog.Neural.Prune.PruneSelective.Network">
            <value>The network that is being processed.</value>
        </member>
        <member name="M:Encog.Neural.Prune.PruneSelective.ChangeNeuronCount(System.Int32,System.Int32)">
             <summary>
             Change the neuron count for the network. If the count is increased then a
             zero-weighted neuron is added, which will not affect the output of the
             neural network. If the neuron count is decreased, then the weakest neuron
             will be removed.
             This method cannot be used to remove a bias neuron.
             </summary>
            
             <param name="layer">The layer to adjust.</param>
             <param name="neuronCount">The new neuron count for this layer.</param>
        </member>
        <member name="M:Encog.Neural.Prune.PruneSelective.DecreaseNeuronCount(System.Int32,System.Int32)">
             <summary>
             Internal function to decrease the neuron count of a layer.
             </summary>
            
             <param name="layer">The layer to affect.</param>
             <param name="neuronCount">The new neuron count.</param>
        </member>
        <member name="M:Encog.Neural.Prune.PruneSelective.DetermineNeuronSignificance(System.Int32,System.Int32)">
             <summary>
             Determine the significance of the neuron. The higher the return value,
             the more significant the neuron is.
             </summary>
            
             <param name="layer">The layer to query.</param>
             <param name="neuron">The neuron to query.</param>
             <returns>How significant is this neuron.</returns>
        </member>
        <member name="M:Encog.Neural.Prune.PruneSelective.FindWeakestNeurons(System.Int32,System.Int32)">
             <summary>
             Find the weakest neurons on a layer. Considers both weight and bias.
             </summary>
            
             <param name="layer">The layer to search.</param>
             <param name="count">The number of neurons to find.</param>
             <returns>An array of the indexes of the weakest neurons.</returns>
        </member>
        <member name="M:Encog.Neural.Prune.PruneSelective.IncreaseNeuronCount(System.Int32,System.Int32)">
             <summary>
             Internal function to increase the neuron count. This will add a
             zero-weight neuron to this layer.
             </summary>
            
             <param name="targetLayer">The layer to increase.</param>
             <param name="neuronCount">The new neuron count.</param>
        </member>
        <member name="M:Encog.Neural.Prune.PruneSelective.Prune(System.Int32,System.Int32)">
             <summary>
             Prune one of the neurons from this layer. Remove all entries in this
             weight matrix and other layers. This method cannot be used to remove a
             bias neuron.
             </summary>
            
             <param name="targetLayer">The neuron to prune. Zero specifies the first neuron.</param>
             <param name="neuron">The neuron to prune.</param>
        </member>
        <member name="M:Encog.Neural.Prune.PruneSelective.RandomizeNeuron(System.Double,System.Double,System.Int32,System.Int32)">
            <param name="low">The low-end of the range.</param>
            <param name="high">The high-end of the range.</param>
            <param name="targetLayer">The target layer.</param>
            <param name="neuron">The target neuron.</param>
        </member>
        <member name="M:Encog.Neural.Prune.PruneSelective.RandomizeNeuron(System.Int32,System.Int32)">
             <summary>
             Assign random values to the network. The range will be the min/max of
             existing neurons.
             </summary>
            
             <param name="targetLayer">The target layer.</param>
             <param name="neuron">The target neuron.</param>
        </member>
        <member name="M:Encog.Neural.Prune.PruneSelective.RandomizeNeuron(System.Int32,System.Int32,System.Boolean,System.Double,System.Double,System.Boolean,System.Double)">
             <summary>
             Used internally to randomize a neuron. Usually called from
             randomizeNeuron or stimulateNeuron.
             </summary>
            
             <param name="targetLayer">The target layer.</param>
             <param name="neuron">The target neuron.</param>
             <param name="useRange">True if range randomization should be used.</param>
             <param name="low">The low-end of the range.</param>
             <param name="high">The high-end of the range.</param>
             <param name="usePercent">True if percent stimulation should be used.</param>
             <param name="percent">The percent to stimulate by.</param>
        </member>
        <member name="M:Encog.Neural.Prune.PruneSelective.ReindexNetwork">
             <summary>
             Creat new index values for the network.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Prune.PruneSelective.StimulateNeuron(System.Double,System.Int32,System.Int32)">
             <summary>
             Stimulate the specified neuron by the specified percent. This is used to
             randomize the weights and bias values for weak neurons.
             </summary>
            
             <param name="percent">The percent to randomize by.</param>
             <param name="targetLayer">The layer that the neuron is on.</param>
             <param name="neuron">The neuron to randomize.</param>
        </member>
        <member name="M:Encog.Neural.Prune.PruneSelective.StimulateWeakNeurons(System.Int32,System.Int32,System.Double)">
             <summary>
             Stimulate weaker neurons on a layer. Find the weakest neurons and then
             randomize them by the specified percent.
             </summary>
            
             <param name="layer">The layer to stimulate.</param>
             <param name="count">The number of weak neurons to stimulate.</param>
             <param name="percent">The percent to stimulate by.</param>
        </member>
        <member name="T:Encog.Neural.Rbf.PersistRBFNetwork">
             <summary>
             Persist a RBF network.
             </summary>
            
        </member>
        <member name="P:Encog.Neural.Rbf.PersistRBFNetwork.FileVersion">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.Rbf.PersistRBFNetwork.PersistClassString">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Rbf.PersistRBFNetwork.Read(System.IO.Stream)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Rbf.PersistRBFNetwork.Save(System.IO.Stream,System.Object)">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.Rbf.PersistRBFNetwork.NativeType">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.Rbf.Training.SVDTraining">
             <summary>
             Train a RBF neural network using a SVD.
             Contributed to Encog By M.Fletcher and M.Dean University of Cambridge, Dept.
             of Physics, UK
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Rbf.Training.SVDTraining.network">
             <summary>
             The network that is to be trained.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Rbf.Training.SVDTraining.#ctor(Encog.Neural.RBF.RBFNetwork,Encog.ML.Data.IMLDataSet)">
             <summary>
             Construct the training object.
             </summary>
            
             <param name="network_0">The network to train. Must have a single output neuron.</param>
             <param name="training">The training data to use. Must be indexable.</param>
        </member>
        <member name="P:Encog.Neural.Rbf.Training.SVDTraining.CanContinue">
            <inheritdoc />
        </member>
        <member name="P:Encog.Neural.Rbf.Training.SVDTraining.Method">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Rbf.Training.SVDTraining.FlatToMatrix(System.Double[],System.Int32,System.Double[][])">
            <summary>
            Convert a flat network to a matrix.
            </summary>
            <param name="flat">The flat network to convert.</param>
            <param name="start">The starting point.</param>
            <param name="matrix">The matrix to convert to.</param>
        </member>
        <member name="M:Encog.Neural.Rbf.Training.SVDTraining.Iteration">
             <summary>
             Perform one iteration.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Rbf.Training.SVDTraining.MatrixToFlat(System.Double[][],System.Double[],System.Int32)">
             <summary>
             Convert the matrix to flat.
             </summary>
            
             <param name="matrix">The matrix.</param>
             <param name="flat">Flat array.</param>
             <param name="start">WHere to start.</param>
        </member>
        <member name="M:Encog.Neural.Rbf.Training.SVDTraining.Pause">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Rbf.Training.SVDTraining.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.RBF.RBFNetwork">
            <summary>
            RBF neural network.
            </summary>
        </member>
        <member name="F:Encog.Neural.RBF.RBFNetwork._flat">
             <summary>
             The underlying flat network.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.RBF.RBFNetwork.#ctor">
             <summary>
             Construct RBF network.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.RBF.RBFNetwork.#ctor(System.Int32,System.Int32,System.Int32,Encog.MathUtil.RBF.RBFEnum)">
             <summary>
             Construct RBF network.
             </summary>
            
             <param name="inputCount">The input count.</param>
             <param name="hiddenCount">The hidden count.</param>
             <param name="outputCount">The output count.</param>
             <param name="t">The RBF type.</param>
        </member>
        <member name="M:Encog.Neural.RBF.RBFNetwork.#ctor(System.Int32,System.Int32,Encog.MathUtil.RBF.IRadialBasisFunction[])">
             <summary>
             Construct RBF network.
             </summary>
            
             <param name="inputCount">The input count.</param>
             <param name="outputCount">The output count.</param>
             <param name="rbf">The RBF type.</param>
        </member>
        <member name="P:Encog.Neural.RBF.RBFNetwork.RBF">
            <summary>
            Set the RBF's.
            </summary>
        </member>
        <member name="P:Encog.Neural.RBF.RBFNetwork.Flat">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.RBF.RBFNetwork.CalculateError(Encog.ML.Data.IMLDataSet)">
             <summary>
             Calculate the error for this neural network.
             </summary>
            
             <param name="data">The training set.</param>
             <returns>The error percentage.</returns>
        </member>
        <member name="M:Encog.Neural.RBF.RBFNetwork.Compute(Encog.ML.Data.IMLData)">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.RBF.RBFNetwork.InputCount">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.RBF.RBFNetwork.OutputCount">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.RBF.RBFNetwork.RandomizeRBFCentersAndWidths(System.Double,System.Double,Encog.MathUtil.RBF.RBFEnum)">
             <summary>
             Set the RBF components to random values.
             </summary>
            
             <param name="min">Minimum random value.</param>
             <param name="max">Max random value.</param>
             <param name="t">The type of RBF to use.</param>
        </member>
        <member name="M:Encog.Neural.RBF.RBFNetwork.SetRBFCentersAndWidths(System.Double[][],System.Double[],Encog.MathUtil.RBF.RBFEnum)">
             <summary>
             Array containing center position. Row n contains centers for neuron n.
             Row n contains x elements for x number of dimensions.
             </summary>
            
             <param name="centers">The centers.</param>
             <param name="widths"></param>
             <param name="t">The RBF Function to use for this layer.</param>
        </member>
        <member name="M:Encog.Neural.RBF.RBFNetwork.SetRBFCentersAndWidthsEqualSpacing(System.Double,System.Double,Encog.MathUtil.RBF.RBFEnum,System.Double,System.Boolean)">
             <summary>
             Equally spaces all hidden neurons within the n dimensional variable
             space.
             </summary>
            
             <param name="minPosition">The minimum position neurons should be centered. Typically 0.</param>
             <param name="maxPosition">The maximum position neurons should be centered. Typically 1</param>
             <param name="t">The RBF type.</param>
             <param name="volumeNeuronRBFWidth">The neuron width of neurons within the mesh.</param>
             <param name="useWideEdgeRBFs">Enables wider RBF's around the boundary of the neuron mesh.</param>
        </member>
        <member name="M:Encog.Neural.RBF.RBFNetwork.SetRBFFunction(System.Int32,Encog.MathUtil.RBF.RBFEnum,System.Double[],System.Double)">
             <summary>
             Set an RBF function.
             </summary>
            
             <param name="index">The index to set.</param>
             <param name="t">The function type.</param>
             <param name="centers">The centers.</param>
             <param name="width">The width.</param>
        </member>
        <member name="M:Encog.Neural.RBF.RBFNetwork.UpdateProperties">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.RBF.Training.SVD">
             <summary>
             Perform a SVD decomp on a matrix.
             Contributed to Encog By M.Fletcher and M.Dean University of Cambridge, Dept.
             of Physics, UK
             </summary>
            
        </member>
        <member name="M:Encog.Neural.RBF.Training.SVD.Svdfit(System.Double[][],System.Double[][],System.Double[][],Encog.MathUtil.RBF.IRadialBasisFunction[])">
            <summary>
            Perform a SVD fit.
            </summary>
            <param name="x">The X matrix.</param>
            <param name="y">The Y matrix.</param>
            <param name="a">The A matrix.</param>
            <param name="funcs">The RBF functions.</param>
            <returns>The fit.</returns>
        </member>
        <member name="M:Encog.Neural.RBF.Training.SVD.Svdcmp(System.Double[][],System.Double[],System.Double[][])">
            <summary>
            Given a matrix a[1..m][1..n], this routine computes its singular value
            decomposition, A = U.W.VT.  The matrix U replaces a on output.  The diagonal
            matrix of singular values W is output as a vector w[1..n].  The matrix V (not
            the transpose VT) is output as v[1..n][1..n].
            </summary>
            <param name="a"></param>
            <param name="w"></param>
            <param name="v"></param>
        </member>
        <member name="M:Encog.Neural.RBF.Training.SVD.MIN(System.Int32,System.Int32)">
            <summary>
            Take the min of two numbers.
            </summary>
            <param name="m">First number.</param>
            <param name="n">Second number.</param>
            <returns>The min.</returns>
        </member>
        <member name="M:Encog.Neural.RBF.Training.SVD.MAX(System.Double,System.Double)">
            <summary>
            Take the max of two numbers.
            </summary>
            <param name="a">The first number.</param>
            <param name="b">The second number.</param>
            <returns>The max.</returns>
        </member>
        <member name="M:Encog.Neural.RBF.Training.SVD.SIGN(System.Double,System.Double)">
            <summary>
            Take the sign of two numbers.
            </summary>
            <param name="a">The first number.</param>
            <param name="b">The second number.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Neural.RBF.Training.SVD.Pythag(System.Double,System.Double)">
            <summary>
            Compute the pythag distance of two numbers.
            </summary>
            <param name="a">The first number.</param>
            <param name="b">The second number.</param>
            <returns>The result.</returns>
        </member>
        <member name="T:Encog.Neural.SOM.PersistSOM">
             <summary>
             Persist the SOM.
             </summary>
            
        </member>
        <member name="P:Encog.Neural.SOM.PersistSOM.FileVersion">
            {@inheritDoc}
        </member>
        <member name="P:Encog.Neural.SOM.PersistSOM.PersistClassString">
            {@inheritDoc}
        </member>
        <member name="M:Encog.Neural.SOM.PersistSOM.Read(System.IO.Stream)">
            {@inheritDoc}
        </member>
        <member name="M:Encog.Neural.SOM.PersistSOM.Save(System.IO.Stream,System.Object)">
            {@inheritDoc}
        </member>
        <member name="T:Encog.Neural.SOM.SOMNetwork">
            <summary>
            A self organizing map neural network.
            </summary>
        </member>
        <member name="F:Encog.Neural.SOM.SOMNetwork._weights">
            <summary>
            The weights of the output neurons base on the input from the input
            neurons.
            </summary>
        </member>
        <member name="M:Encog.Neural.SOM.SOMNetwork.#ctor">
            <summary>
            Default constructor.
            </summary>
        </member>
        <member name="M:Encog.Neural.SOM.SOMNetwork.#ctor(System.Int32,System.Int32)">
            <summary>
            The constructor.
            </summary>
            <param name="inputCount">Number of input neurons</param>
            <param name="outputCount">Number of output neurons</param>
        </member>
        <member name="P:Encog.Neural.SOM.SOMNetwork.Weights">
            <summary>
            The weights.
            </summary>
        </member>
        <member name="M:Encog.Neural.SOM.SOMNetwork.Classify(Encog.ML.Data.IMLData)">
            <summary>
            Classify the input into one of the output clusters.
            </summary>
            <param name="input">The input.</param>
            <returns>The cluster it was clasified into.</returns>
        </member>
        <member name="P:Encog.Neural.SOM.SOMNetwork.InputCount">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.SOM.SOMNetwork.OutputCount">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.SOM.SOMNetwork.CalculateError(Encog.ML.Data.IMLDataSet)">
            <summary>
            Calculate the error for the specified data set. The error is the largest distance.
            </summary>
            <param name="data">The data set to check.</param>
            <returns>The error.</returns>
        </member>
        <member name="M:Encog.Neural.SOM.SOMNetwork.Reset">
            <summary>
            Randomize the network.
            </summary>
        </member>
        <member name="M:Encog.Neural.SOM.SOMNetwork.Reset(System.Int32)">
            <summary>
            Randomize the network.
            </summary>
            <param name="seed">Not used.</param>
        </member>
        <member name="M:Encog.Neural.SOM.SOMNetwork.UpdateProperties">
            <summary>
            Not used.
            </summary>
        </member>
        <member name="M:Encog.Neural.SOM.SOMNetwork.Winner(Encog.ML.Data.IMLData)">
            <summary>
            An alias for the classify method, kept for compatibility 
            with earlier versions of Encog.
            </summary>
            <param name="input">The input pattern.</param>
            <returns>The winning neuron.</returns>
        </member>
        <member name="T:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM">
             <summary>
             This class implements competitive training, which would be used in a
             winner-take-all neural network, such as the self organizing map (SOM). This
             is an unsupervised training method, no ideal data is needed on the training
             set. If ideal data is provided, it will be ignored.
             Training is done by looping over all of the training elements and calculating
             a "best matching unit" (BMU). This BMU output neuron is then adjusted to
             better "learn" this pattern. Additionally, this training may be applied to
             other "nearby" output neurons. The degree to which nearby neurons are update
             is defined by the neighborhood function.
             A neighborhood function is required to determine the degree to which
             neighboring neurons (to the winning neuron) are updated by each training
             iteration.
             Because this is unsupervised training, calculating an error to measure
             progress by is difficult. The error is defined to be the "worst", or longest,
             Euclidean distance of any of the BMU's. This value should be minimized, as
             learning progresses.
             Because only the BMU neuron and its close neighbors are updated, you can end
             up with some output neurons that learn nothing. By default these neurons are
             not forced to win patterns that are not represented well. This spreads out
             the workload among all output neurons. This feature is not used by default,
             but can be enabled by setting the "forceWinner" property.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM._bmuUtil">
            <summary>
            Utility class used to determine the BMU.
            </summary>
        </member>
        <member name="F:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM._correctionMatrix">
            <summary>
            Holds the corrections for any matrix being trained.
            </summary>
        </member>
        <member name="F:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM._inputNeuronCount">
            <summary>
            How many neurons in the input layer.
            </summary>
        </member>
        <member name="F:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM._neighborhood">
            <summary>
            The neighborhood function to use to determine to what degree a neuron
            should be "trained".
            </summary>
        </member>
        <member name="F:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM._network">
            <summary>
            The network being trained.
            </summary>
        </member>
        <member name="F:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM._outputNeuronCount">
            <summary>
            How many neurons in the output layer.
            </summary>
        </member>
        <member name="F:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM._autoDecayRadius">
            <summary>
            This is the current autodecay radius.
            </summary>
        </member>
        <member name="F:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM._autoDecayRate">
            <summary>
            This is the current autodecay learning rate.
            </summary>
        </member>
        <member name="F:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM._endRadius">
            <summary>
            When used with autodecay, this is the ending radius.
            </summary>
        </member>
        <member name="F:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM._endRate">
            <summary>
            When used with autodecay, this is the ending learning rate.
            </summary>
        </member>
        <member name="F:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM._radius">
            <summary>
            The current radius.
            </summary>
        </member>
        <member name="F:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM._startRadius">
            <summary>
            When used with autodecay, this is the starting radius.
            </summary>
        </member>
        <member name="F:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM._startRate">
            <summary>
            When used with autodecay, this is the starting learning rate.
            </summary>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.#ctor(Encog.Neural.SOM.SOMNetwork,System.Double,Encog.ML.Data.IMLDataSet,Encog.Neural.SOM.Training.Neighborhood.INeighborhoodFunction)">
            <summary>
            Create an instance of competitive training.
            </summary>
            <param name="network">The network to train.</param>
            <param name="learningRate">The learning rate, how much to apply per iteration.</param>
            <param name="training">The training set (unsupervised).</param>
            <param name="neighborhood">The neighborhood function to use.</param>
        </member>
        <member name="P:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.ForceWinner">
            <summary>
            True is a winner is to be forced, see class description, or forceWinners
            method. By default, this is true.
            </summary>
        </member>
        <member name="P:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.CanContinue">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.InputNeuronCount">
            <summary>
            The input neuron count.
            </summary>
        </member>
        <member name="P:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.Method">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.Neighborhood">
            <summary>
            The network neighborhood function.
            </summary>
        </member>
        <member name="P:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.OutputNeuronCount">
            <summary>
            The output neuron count.
            </summary>
        </member>
        <member name="P:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.LearningRate">
            <summary>
            The learning rate. To what degree should changes be applied.
            </summary>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.ApplyCorrection">
            <summary>
            Loop over the synapses to be trained and apply any corrections that were
            determined by this training iteration.
            </summary>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.AutoDecay">
            <summary>
            Should be called each iteration if autodecay is desired.
            </summary>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.CopyInputPattern(Encog.MathUtil.Matrices.Matrix,System.Int32,Encog.ML.Data.IMLData)">
            <summary>
            Copy the specified input pattern to the weight matrix. This causes an
            output neuron to learn this pattern "exactly". This is useful when a
            winner is to be forced.
            </summary>
            <param name="matrix">The matrix that is the target of the copy.</param>
            <param name="outputNeuron">The output neuron to set.</param>
            <param name="input">The input pattern to copy.</param>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.Decay(System.Double)">
            <summary>
            Called to decay the learning rate and radius by the specified amount.
            </summary>
            <param name="d">The percent to decay by.</param>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.Decay(System.Double,System.Double)">
            <summary>
            Decay the learning rate and radius by the specified amount.
            </summary>
            <param name="decayRate">The percent to decay the learning rate by.</param>
            <param name="decayRadius">The percent to decay the radius by.</param>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.DetermineNewWeight(System.Double,System.Double,System.Int32,System.Int32)">
            <summary>
            Determine the weight adjustment for a single neuron during a training
            iteration.
            </summary>
            <param name="weight">The starting weight.</param>
            <param name="input">The input to this neuron.</param>
            <param name="currentNeuron">The neuron who's weight is being updated.</param>
            <param name="bmu">The neuron that "won", the best matching unit.</param>
            <returns>The new weight value.</returns>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.ForceWinners(Encog.MathUtil.Matrices.Matrix,System.Int32[],Encog.ML.Data.IMLData)">
            <summary>
            Force any neurons that did not win to off-load patterns from overworked
            neurons.
            </summary>
            <param name="matrix">The synapse to modify.</param>
            <param name="won">An array that specifies how many times each output neuron has "won".</param>
            <param name="leastRepresented">The training pattern that is the least represented by this neural network.</param>
            <returns>True if a winner was forced.</returns>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.Iteration">
            <summary>
            Perform one training iteration.
            </summary>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.Pause">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.SetAutoDecay(System.Int32,System.Double,System.Double,System.Double,System.Double)">
            <summary>
            Setup autodecay. This will decrease the radius and learning rate from the
            start values to the end values.
            </summary>
            <param name="plannedIterations">The number of iterations that are planned. This allows the
            decay rate to be determined.</param>
            <param name="startRate">The starting learning rate.</param>
            <param name="endRate">The ending learning rate.</param>
            <param name="startRadius">The starting radius.</param>
            <param name="endRadius">The ending radius.</param>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.SetParams(System.Double,System.Double)">
            <summary>
            Set the learning rate and radius.
            </summary>
            <param name="rate">The new learning rate.</param>
            <param name="radius">The new radius.</param>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.ToString">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.Train(System.Int32,Encog.MathUtil.Matrices.Matrix,Encog.ML.Data.IMLData)">
            <summary>
            Train for the specified synapse and BMU.
            </summary>
            <param name="bmu">The best matching unit for this input.</param>
            <param name="matrix">The synapse to train.</param>
            <param name="input">The input to train for.</param>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.TrainPattern(Encog.MathUtil.Matrices.Matrix,Encog.ML.Data.IMLData,System.Int32,System.Int32)">
            <summary>
            Train for the specified pattern.
            </summary>
            <param name="matrix">The synapse to train.</param>
            <param name="input">The input pattern to train for.</param>
            <param name="current">The current output neuron being trained.</param>
            <param name="bmu">The best matching unit, or winning output neuron.</param>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.TrainPattern(Encog.ML.Data.IMLData)">
            <summary>
            Train the specified pattern. Find a winning neuron and adjust all neurons
            according to the neighborhood function.
            </summary>
            <param name="pattern">The pattern to train.</param>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.BasicTrainSOM.Compute(Encog.Neural.SOM.SOMNetwork,Encog.ML.Data.IMLData)">
            <summary>
            Calculate the output of the SOM, for each output neuron.  Typically,
            you will use the classify method instead of calling this method.
            </summary>
            <param name="som">The SOM to use.</param>
            <param name="input">The input.</param>
            <returns>The output.</returns>
        </member>
        <member name="T:Encog.Neural.SOM.Training.Neighborhood.BestMatchingUnit">
             <summary>
             The "Best Matching Unit" or BMU is a very important concept in the training
             for a SOM. The BMU is the output neuron that has weight connections to the
             input neurons that most closely match the current input vector. This neuron
             (and its "neighborhood") are the neurons that will receive training.
             This class also tracks the worst distance (of all BMU's). This gives some
             indication of how well the network is trained, and thus becomes the "error"
             of the entire network.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.SOM.Training.Neighborhood.BestMatchingUnit._som">
             <summary>
             The owner of this class.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.SOM.Training.Neighborhood.BestMatchingUnit._worstDistance">
             <summary>
             What is the worst BMU distance so far, this becomes the error for the
             entire SOM.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.BestMatchingUnit.#ctor(Encog.Neural.SOM.SOMNetwork)">
             <summary>
             Construct a BestMatchingUnit class.  The training class must be provided.
             </summary>
            
             <param name="som">The SOM to evaluate.</param>
        </member>
        <member name="P:Encog.Neural.SOM.Training.Neighborhood.BestMatchingUnit.WorstDistance">
            <value>What is the worst BMU distance so far, this becomes the error 
            for the entire SOM.</value>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.BestMatchingUnit.CalculateBMU(Encog.ML.Data.IMLData)">
             <summary>
             Calculate the best matching unit (BMU). This is the output neuron that
             has the lowest Euclidean distance to the input vector.
             </summary>
            
             <param name="input">The input vector.</param>
             <returns>The output neuron number that is the BMU.</returns>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.BestMatchingUnit.CalculateEuclideanDistance(Encog.MathUtil.Matrices.Matrix,Encog.ML.Data.IMLData,System.Int32)">
             <summary>
             Calculate the Euclidean distance for the specified output neuron and the
             input vector.  This is the square root of the squares of the differences
             between the weight and input vectors.
             </summary>
            
             <param name="matrix">The matrix to get the weights from.</param>
             <param name="input">The input vector.</param>
             <param name="outputNeuron">The neuron we are calculating the distance for.</param>
             <returns>The Euclidean distance.</returns>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.BestMatchingUnit.Reset">
             <summary>
             Reset the "worst distance" back to a minimum value.  This should be
             called for each training iteration.
             </summary>
            
        </member>
        <member name="T:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodBubble">
             <summary>
             A neighborhood function that uses a simple bubble. A radius is defined, and
             any neuron that is plus or minus that width from the winning neuron will be
             updated as a result of training.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodBubble._radius">
             <summary>
             The radius of the bubble.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodBubble.#ctor(System.Int32)">
             <summary>
             Create a bubble neighborhood function that will return 1.0 (full update)
             for any neuron that is plus or minus the width distance from the winning
             neuron.
             </summary>
            
             <param name="radius">bubble, is actually two times this parameter.</param>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodBubble.Function(System.Int32,System.Int32)">
             <summary>
             Determine how much the current neuron should be affected by training
             based on its proximity to the winning neuron.
             </summary>
            
             <param name="currentNeuron">THe current neuron being evaluated.</param>
             <param name="bestNeuron">The winning neuron.</param>
             <returns>The ratio for this neuron's adjustment.</returns>
        </member>
        <member name="P:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodBubble.Radius">
            <summary>
            Set the radius.
            </summary>
        </member>
        <member name="T:Encog.Neural.SOM.Training.Neighborhood.INeighborhoodFunction">
             <summary>
             Defines how a neighborhood function should work in competitive training. This
             is most often used in the training process for a self-organizing map. This
             function determines to what degree the training should take place on a
             neuron, based on its proximity to the "winning" neuron.
             </summary>
            
        </member>
        <member name="P:Encog.Neural.SOM.Training.Neighborhood.INeighborhoodFunction.Radius">
            <summary>
            Set the radius.
            </summary>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.INeighborhoodFunction.Function(System.Int32,System.Int32)">
             <summary>
             Determine how much the current neuron should be affected by training
             based on its proximity to the winning neuron.
             </summary>
            
             <param name="currentNeuron">THe current neuron being evaluated.</param>
             <param name="bestNeuron">The winning neuron.</param>
             <returns>The ratio for this neuron's adjustment.</returns>
        </member>
        <member name="T:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodRBF">
             <summary>
             Implements a multi-dimensional RBF neighborhood function.  
             </summary>
            
        </member>
        <member name="F:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodRBF._rbf">
             <summary>
             The radial basis function to use.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodRBF._size">
             <summary>
             The size of each dimension.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodRBF._displacement">
             <summary>
             The displacement of each dimension, when mapping the dimensions
             to a 1d array.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodRBF.#ctor(Encog.MathUtil.RBF.RBFEnum,System.Int32,System.Int32)">
             <summary>
             Construct a 2d neighborhood function based on the sizes for the
             x and y dimensions.
             </summary>
            
             <param name="type">The RBF type to use.</param>
             <param name="x">The size of the x-dimension.</param>
             <param name="y">The size of the y-dimension.</param>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodRBF.#ctor(System.Int32[],Encog.MathUtil.RBF.RBFEnum)">
             <summary>
             Construct a multi-dimensional neighborhood function.
             </summary>
            
             <param name="size">The sizes of each dimension.</param>
             <param name="type">The RBF type to use.</param>
        </member>
        <member name="P:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodRBF.RBF">
            <value>The RBF to use.</value>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodRBF.Function(System.Int32,System.Int32)">
             <summary>
             Calculate the value for the multi RBF function.
             </summary>
            
             <param name="currentNeuron">The current neuron.</param>
             <param name="bestNeuron">The best neuron.</param>
             <returns>A percent that determines the amount of training the current
             neuron should get.  Usually 100% when it is the bestNeuron.</returns>
        </member>
        <member name="P:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodRBF.Radius">
            <summary>
            Set the radius.
            </summary>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodRBF.CalculateDisplacement">
             <summary>
             Calculate all of the displacement values.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodRBF.TranslateCoordinates(System.Int32)">
             <summary>
             Translate the specified index into a set of multi-dimensional
             coordinates that represent the same index.  This is how the
             multi-dimensional coordinates are translated into a one dimensional
             index for the input neurons.
             </summary>
            
             <param name="index">The index to translate.</param>
             <returns>The multi-dimensional coordinates.</returns>
        </member>
        <member name="T:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodRBF1D">
             <summary>
             A neighborhood function based on an RBF function.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodRBF1D._radial">
             <summary>
             The radial basis function (RBF) to use to calculate the training falloff
             from the best neuron.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodRBF1D.#ctor(Encog.MathUtil.RBF.IRadialBasisFunction)">
             <summary>
             Construct the neighborhood function with the specified radial function.
             Generally this will be a Gaussian function but any RBF should do.
             </summary>
            
             <param name="radial">The radial basis function to use.</param>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodRBF1D.#ctor(Encog.MathUtil.RBF.RBFEnum)">
             <summary>
             Construct a 1d neighborhood function.
             </summary>
            
             <param name="type">The RBF type to use.</param>
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodRBF1D.Function(System.Int32,System.Int32)">
            <summary>
            Compute the RBF function.
            </summary>
            <param name="currentNeuron">The current neuron.</param>
            <param name="bestNeuron">The best neuron.</param>
            <returns>The distance.</returns>
        </member>
        <member name="P:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodRBF1D.Radius">
             <summary>
             Set the radius.
             </summary>
            
             <value>The new radius.</value>
        </member>
        <member name="T:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodSingle">
             <summary>
             A very simple neighborhood function that will return 1.0 (full effect) for
             the winning neuron, and 0.0 (no change) for everything else.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodSingle.Function(System.Int32,System.Int32)">
             <summary>
             Determine how much the current neuron should be affected by training
             based on its proximity to the winning neuron.
             </summary>
            
             <param name="currentNeuron">THe current neuron being evaluated.</param>
             <param name="bestNeuron">The winning neuron.</param>
             <returns>The ratio for this neuron's adjustment.</returns>
        </member>
        <member name="P:Encog.Neural.SOM.Training.Neighborhood.NeighborhoodSingle.Radius">
             <summary>
             Set the radius.  This type does not use a radius, so this has no effect.
             </summary>
            
             <value>The radius.</value>
        </member>
        <member name="T:Encog.Neural.Som.Training.Clustercopy.SOMClusterCopyTraining">
             <summary>
             SOM cluster copy is a very simple trainer for SOM's. Using this triner all of
             the training data is copied to the SOM weights. This can provide a functional
             SOM, or can be used as a starting point for training.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Som.Training.Clustercopy.SOMClusterCopyTraining._network">
             <summary>
             The SOM to train.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Som.Training.Clustercopy.SOMClusterCopyTraining.#ctor(Encog.Neural.SOM.SOMNetwork,Encog.ML.Data.IMLDataSet)">
             <summary>
             Construct the object.
             </summary>
            
             <param name="network">The network to train.</param>
             <param name="training">The training data.</param>
        </member>
        <member name="P:Encog.Neural.Som.Training.Clustercopy.SOMClusterCopyTraining.CanContinue">
            <inheritdoc />
        </member>
        <member name="P:Encog.Neural.Som.Training.Clustercopy.SOMClusterCopyTraining.Method">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Som.Training.Clustercopy.SOMClusterCopyTraining.CopyInputPattern(System.Int32,Encog.ML.Data.IMLData)">
             <summary>
             Copy the specified input pattern to the weight matrix. This causes an
             output neuron to learn this pattern "exactly". This is useful when a
             winner is to be forced.
             </summary>
            
             <param name="outputNeuron">The output neuron to set.</param>
             <param name="input">The input pattern to copy.</param>
        </member>
        <member name="M:Encog.Neural.Som.Training.Clustercopy.SOMClusterCopyTraining.Iteration">
             <summary>
             
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Som.Training.Clustercopy.SOMClusterCopyTraining.Pause">
             <summary>
             
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Som.Training.Clustercopy.SOMClusterCopyTraining.Resume(Encog.Neural.Networks.Training.Propagation.TrainingContinuation)">
             <summary>
             
             </summary>
            
        </member>
        <member name="T:Encog.Neural.Thermal.BoltzmannMachine">
            <summary>
            Implements a Boltzmann machine.
            </summary>
        </member>
        <member name="F:Encog.Neural.Thermal.BoltzmannMachine.ParamRunCycles">
             <summary>
             The property for run cycles.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Thermal.BoltzmannMachine.ParamAnnealCycles">
             <summary>
             The property for anneal cycles.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Thermal.BoltzmannMachine._annealCycles">
             <summary>
             The number of cycles to anneal for.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Thermal.BoltzmannMachine._off">
            <summary>
            Count used to internally determine if a neuron is "off".
            </summary>
        </member>
        <member name="F:Encog.Neural.Thermal.BoltzmannMachine._on">
            <summary>
            Count used to internally determine if a neuron is "on".
            </summary>
        </member>
        <member name="F:Encog.Neural.Thermal.BoltzmannMachine._runCycles">
             <summary>
             The number of cycles to run the network through before annealing.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Thermal.BoltzmannMachine._temperature">
             <summary>
             The current temperature of the neural network. The higher the
             temperature, the more random the network will behave.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Thermal.BoltzmannMachine._threshold">
             <summary>
             The thresholds.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Thermal.BoltzmannMachine.#ctor">
             <summary>
             Default constructors.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Thermal.BoltzmannMachine.#ctor(System.Int32)">
            <summary>
            Construct a Boltzmann machine with the specified number of neurons.
            </summary>
        </member>
        <member name="P:Encog.Neural.Thermal.BoltzmannMachine.AnnealCycles">
            <value>the annealCycles to set</value>
        </member>
        <member name="P:Encog.Neural.Thermal.BoltzmannMachine.InputCount">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.Thermal.BoltzmannMachine.OutputCount">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.Thermal.BoltzmannMachine.RunCycles">
            <value>the runCycles to set</value>
        </member>
        <member name="P:Encog.Neural.Thermal.BoltzmannMachine.Temperature">
            <summary>
            Set the network temperature.
            </summary>
        </member>
        <member name="P:Encog.Neural.Thermal.BoltzmannMachine.Threshold">
            <summary>
            Set the thresholds.
            </summary>
        </member>
        <member name="M:Encog.Neural.Thermal.BoltzmannMachine.Compute(Encog.ML.Data.IMLData)">
             <summary>
             Note: for Boltzmann networks, you will usually want to call the "run"
             method to compute the output.
             This method can be used to copy the input data to the current state. A
             single iteration is then run, and the new current state is returned.
             </summary>
            
             <param name="input">The input pattern.</param>
             <returns>The new current state.</returns>
        </member>
        <member name="M:Encog.Neural.Thermal.BoltzmannMachine.DecreaseTemperature(System.Double)">
             <summary>
             Decrease the temperature by the specified amount.
             </summary>
            
             <param name="d">The amount to decrease by.</param>
        </member>
        <member name="M:Encog.Neural.Thermal.BoltzmannMachine.EstablishEquilibrium">
             <summary>
             Run the network until thermal equilibrium is established.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Thermal.BoltzmannMachine.Run">
             <summary>
             Run the network for all neurons present.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Thermal.BoltzmannMachine.Run(System.Int32)">
             <summary>
             Run the network for the specified neuron.
             </summary>
            
             <param name="i">The neuron to run for.</param>
        </member>
        <member name="M:Encog.Neural.Thermal.BoltzmannMachine.UpdateProperties">
             <summary>
             
             </summary>
            
        </member>
        <member name="T:Encog.Neural.Thermal.HopfieldNetwork">
            <summary>
            Implements a Hopfield network.
            </summary>
        </member>
        <member name="M:Encog.Neural.Thermal.HopfieldNetwork.#ctor">
             <summary>
             Default constructor.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Thermal.HopfieldNetwork.#ctor(System.Int32)">
             <summary>
             Construct a Hopfield with the specified neuron count.
             </summary>
            
             <param name="neuronCount">The neuron count.</param>
        </member>
        <member name="P:Encog.Neural.Thermal.HopfieldNetwork.InputCount">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.Thermal.HopfieldNetwork.OutputCount">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Thermal.HopfieldNetwork.AddPattern(Encog.ML.Data.IMLData)">
             <summary>
             Train the neural network for the specified pattern. The neural network
             can be trained for more than one pattern. To do this simply call the
             train method more than once.
             </summary>
            
             <param name="pattern">The pattern to train for.</param>
        </member>
        <member name="M:Encog.Neural.Thermal.HopfieldNetwork.Compute(Encog.ML.Data.IMLData)">
             <summary>
             Note: for Hopfield networks, you will usually want to call the "run"
             method to compute the output.
             This method can be used to copy the input data to the current state. A
             single iteration is then run, and the new current state is returned.
             </summary>
            
             <param name="input">The input pattern.</param>
             <returns>The new current state.</returns>
        </member>
        <member name="M:Encog.Neural.Thermal.HopfieldNetwork.ConvertHopfieldMatrix(Encog.MathUtil.Matrices.Matrix)">
             <summary>
             Update the Hopfield weights after training.
             </summary>
            
             <param name="delta">The amount to change the weights by.</param>
        </member>
        <member name="M:Encog.Neural.Thermal.HopfieldNetwork.Run">
             <summary>
             Perform one Hopfield iteration.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Thermal.HopfieldNetwork.RunUntilStable(System.Int32)">
             <summary>
             Run the network until it becomes stable and does not change from more
             runs.
             </summary>
            
             <param name="max">The maximum number of cycles to run before giving up.</param>
             <returns>The number of cycles that were run.</returns>
        </member>
        <member name="M:Encog.Neural.Thermal.HopfieldNetwork.UpdateProperties">
             <summary>
             
             </summary>
            
        </member>
        <member name="T:Encog.Neural.Thermal.PersistBoltzmann">
             <summary>
             Persist the Boltzmann machine.
             </summary>
            
        </member>
        <member name="P:Encog.Neural.Thermal.PersistBoltzmann.FileVersion">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.Thermal.PersistBoltzmann.PersistClassString">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Thermal.PersistBoltzmann.Read(System.IO.Stream)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Neural.Thermal.PersistBoltzmann.Save(System.IO.Stream,System.Object)">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Neural.Thermal.PersistBoltzmann.NativeType">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.Thermal.PersistHopfield">
             <summary>
             Persist the Hopfield network.
             </summary>
            
        </member>
        <member name="P:Encog.Neural.Thermal.PersistHopfield.FileVersion">
            <summary>
            The file version.
            </summary>
        </member>
        <member name="P:Encog.Neural.Thermal.PersistHopfield.PersistClassString">
             <summary>
             The class string.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Thermal.PersistHopfield.Read(System.IO.Stream)">
            <summary>
            Read a an object.
            </summary>
        </member>
        <member name="M:Encog.Neural.Thermal.PersistHopfield.Save(System.IO.Stream,System.Object)">
             <summary>
             
             </summary>
            
        </member>
        <member name="P:Encog.Neural.Thermal.PersistHopfield.NativeType">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Neural.Thermal.ThermalNetwork">
            <summary>
            The thermal network forms the base class for Hopfield and Boltzmann machines.
            </summary>
        </member>
        <member name="F:Encog.Neural.Thermal.ThermalNetwork._currentState">
             <summary>
             The current state of the thermal network.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Thermal.ThermalNetwork._neuronCount">
             <summary>
             The neuron count.
             </summary>
            
        </member>
        <member name="F:Encog.Neural.Thermal.ThermalNetwork._weights">
             <summary>
             The weights.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Thermal.ThermalNetwork.#ctor">
             <summary>
             Default constructor.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Thermal.ThermalNetwork.#ctor(System.Int32)">
             <summary>
             Construct the network with the specicified neuron count.
             </summary>
            
             <param name="neuronCount">The number of neurons.</param>
        </member>
        <member name="P:Encog.Neural.Thermal.ThermalNetwork.NeuronCount">
            <summary>
            Set the neuron count.
            </summary>
        </member>
        <member name="P:Encog.Neural.Thermal.ThermalNetwork.Weights">
             <summary>
             Set the weight array.
             </summary>
            
             <value>The weight array.</value>
        </member>
        <member name="P:Encog.Neural.Thermal.ThermalNetwork.CurrentState">
            <summary>
            Set the current state.
            </summary>
        </member>
        <member name="P:Encog.Neural.Thermal.ThermalNetwork.InputCount">
            <summary>
            from Encog.ml.MLInput
            </summary>
        </member>
        <member name="P:Encog.Neural.Thermal.ThermalNetwork.OutputCount">
             <summary>
             from Encog.ml.MLOutput
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Thermal.ThermalNetwork.Compute(Encog.ML.Data.IMLData)">
             <summary>
             from Encog.ml.MLRegression
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Thermal.ThermalNetwork.Reset">
             <summary>
             
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Thermal.ThermalNetwork.Reset(System.Int32)">
             <summary>
             
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Thermal.ThermalNetwork.AddWeight(System.Int32,System.Int32,System.Double)">
             <summary>
             Add to the specified weight.
             </summary>
            
             <param name="fromNeuron">The from neuron.</param>
             <param name="toNeuron">The to neuron.</param>
             <param name="v">The value to add.</param>
        </member>
        <member name="M:Encog.Neural.Thermal.ThermalNetwork.CalculateEnergy">
            <returns>Calculate the current energy for the network. The network will
            seek to lower this value.</returns>
        </member>
        <member name="M:Encog.Neural.Thermal.ThermalNetwork.Clear">
             <summary>
             Clear any connection weights.
             </summary>
            
        </member>
        <member name="M:Encog.Neural.Thermal.ThermalNetwork.GetWeight(System.Int32,System.Int32)">
             <summary>
             Get a weight.
             </summary>
            
             <param name="fromNeuron">The from neuron.</param>
             <param name="toNeuron">The to neuron.</param>
             <returns>The weight.</returns>
        </member>
        <member name="M:Encog.Neural.Thermal.ThermalNetwork.Init(System.Int32,System.Double[],System.Double[])">
             <summary>
             Init the network.
             </summary>
            
             <param name="neuronCount">The neuron count.</param>
             <param name="weights">The weights.</param>
             <param name="output">The toutpu</param>
        </member>
        <member name="M:Encog.Neural.Thermal.ThermalNetwork.SetCurrentState(System.Double[])">
            <summary>
            Set the current state.
            </summary>
            <param name="s">The new current state.</param>
        </member>
        <member name="M:Encog.Neural.Thermal.ThermalNetwork.SetWeight(System.Int32,System.Int32,System.Double)">
             <summary>
             Set the weight.
             </summary>
            
             <param name="fromNeuron">The from neuron.</param>
             <param name="toNeuron">The to neuron.</param>
             <param name="v">The value.</param>
        </member>
        <member name="T:Encog.Neural.NeuralNetworkError">
            <summary>
            Indicates an error has occurred in the Neural Network classes..
            </summary>
        </member>
        <member name="M:Encog.Neural.NeuralNetworkError.#ctor(System.String)">
            <summary>
            Construct a message exception.
            </summary>
            <param name="str">The message.</param>
        </member>
        <member name="M:Encog.Neural.NeuralNetworkError.#ctor(System.Exception)">
            <summary>
            Pass on an exception.
            </summary>
            <param name="e">The other exception.</param>
        </member>
        <member name="M:Encog.Neural.NeuralNetworkError.#ctor(System.String,System.Exception)">
            <summary>
            Pass on an exception.
            </summary>
            <param name="msg">The message.</param>
            <param name="e">The exception.</param>
        </member>
        <member name="T:Encog.Persist.EncogDirectoryPersistence">
             <summary>
             Handles Encog persistence for a directory. This is the usual mode where each
             resource is stored in a separate EG file.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.EncogDirectoryPersistence._parent">
             <summary>
             The directory that holds the EG files.
             </summary>
            
        </member>
        <member name="M:Encog.Persist.EncogDirectoryPersistence.#ctor(System.IO.FileInfo)">
             <summary>
             Construct the object.
             </summary>
            
             <param name="parent">The directory to use.</param>
        </member>
        <member name="P:Encog.Persist.EncogDirectoryPersistence.Parent">
            <value>The directory.</value>
        </member>
        <member name="M:Encog.Persist.EncogDirectoryPersistence.LoadObject(System.IO.FileInfo)">
             <summary>
             Load the specified object.
             </summary>
            
             <param name="file">The file to load.</param>
             <returns>The loaded object.</returns>
        </member>
        <member name="M:Encog.Persist.EncogDirectoryPersistence.LoadResourceObject(System.String)">
            <summary>
            Load an EG object as a reousrce.
            </summary>
            <param name="res">The resource to load.</param>
            <returns>The loaded object.</returns>
        </member>
        <member name="M:Encog.Persist.EncogDirectoryPersistence.LoadObject(System.IO.Stream)">
             <summary>
             Load an object from an input stream.
             </summary>
            
             <param name="mask0">The input stream to read from.</param>
             <returns>The loaded object.</returns>
        </member>
        <member name="M:Encog.Persist.EncogDirectoryPersistence.ReadLine(System.IO.Stream)">
             <summary>
             Read a line from the input stream.
             </summary>
            
             <param name="mask0">The input stream.</param>
             <returns>The line read.</returns>
        </member>
        <member name="M:Encog.Persist.EncogDirectoryPersistence.SaveObject(System.IO.FileInfo,System.Object)">
             <summary>
             Save the specified object.
             </summary>
            
             <param name="filename">The filename to save to.</param>
             <param name="obj">The Object to save.</param>
        </member>
        <member name="M:Encog.Persist.EncogDirectoryPersistence.SaveObject(System.IO.Stream,System.Object)">
             <summary>
             Save the specified object.
             </summary>
            
             <param name="os">The output stream to write to.</param>
             <param name="obj">The object to save.</param>
        </member>
        <member name="M:Encog.Persist.EncogDirectoryPersistence.GetEncogType(System.String)">
             <summary>
             Get the type of an Encog object in an EG file, without the 
             need to read the entire file.
             </summary>
            
             <param name="name">The filename to read.</param>
             <returns>The type.</returns>
        </member>
        <member name="M:Encog.Persist.EncogDirectoryPersistence.LoadFromDirectory(System.String)">
             <summary>
             Load a file from the directory that this object refers to.
             </summary>
            
             <param name="name">The name to load.</param>
             <returns>The object.</returns>
        </member>
        <member name="M:Encog.Persist.EncogDirectoryPersistence.SaveToDirectory(System.String,System.Object)">
             <summary>
             Save a file to the directory that this object refers to.
             </summary>
            
             <param name="name">The name to load.</param>
             <param name="obj">The object.</param>
        </member>
        <member name="T:Encog.Persist.EncogFileSection">
             <summary>
             This class is used internally to parse Encog files. A file section is part of
             a name-value pair file.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.EncogFileSection._largeArrays">
            <summary>
            Any large arrays that were read.
            </summary>
        </member>
        <member name="F:Encog.Persist.EncogFileSection._lines">
             <summary>
             The lines in this section/subsection.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.EncogFileSection._sectionName">
             <summary>
             The name of this section.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.EncogFileSection._subSectionName">
             <summary>
             The name of this subsection.
             </summary>
            
        </member>
        <member name="M:Encog.Persist.EncogFileSection.#ctor(System.String,System.String)">
             <summary>
             Construct the object.
             </summary>
            
             <param name="theSectionName">The section name.</param>
             <param name="theSubSectionName">The sub section name.</param>
        </member>
        <member name="P:Encog.Persist.EncogFileSection.Lines">
            <value>The lines.</value>
        </member>
        <member name="P:Encog.Persist.EncogFileSection.LinesAsString">
            <value>All lines separated by a delimiter.</value>
        </member>
        <member name="P:Encog.Persist.EncogFileSection.SectionName">
            <value>The section name.</value>
        </member>
        <member name="P:Encog.Persist.EncogFileSection.SubSectionName">
            <value>The section name.</value>
        </member>
        <member name="M:Encog.Persist.EncogFileSection.ParseActivationFunction(System.Collections.Generic.IDictionary{System.String,System.String},System.String)">
             <summary>
             Parse an activation function from a string.
             </summary>
            
             <param name="paras">The params.</param>
             <param name="name">The name of the param to parse.</param>
             <returns>The parsed activation function.</returns>
        </member>
        <member name="M:Encog.Persist.EncogFileSection.ParseBoolean(System.Collections.Generic.IDictionary{System.String,System.String},System.String)">
             <summary>
             Parse a boolean from a name-value collection of params.
             </summary>
            
             <param name="paras">The name-value pairs.</param>
             <param name="name">The name to parse.</param>
             <returns>The parsed boolean value.</returns>
        </member>
        <member name="M:Encog.Persist.EncogFileSection.ParseDouble(System.Collections.Generic.IDictionary{System.String,System.String},System.String)">
             <summary>
             Parse a double from a name-value collection of params.
             </summary>
            
             <param name="paras">The name-value pairs.</param>
             <param name="name">The name to parse.</param>
             <returns>The parsed double value.</returns>
        </member>
        <member name="M:Encog.Persist.EncogFileSection.ParseDoubleArray(System.Collections.Generic.IDictionary{System.String,System.String},System.String)">
             <summary>
             Parse a double array from a name-value collection of params.
             </summary>
            
             <param name="paras">The name-value pairs.</param>
             <param name="name">The name to parse.</param>
             <returns>The parsed double array value.</returns>
        </member>
        <member name="M:Encog.Persist.EncogFileSection.ParseInt(System.Collections.Generic.IDictionary{System.String,System.String},System.String)">
             <summary>
             Parse an int from a name-value collection of params.
             </summary>
            
             <param name="paras">The name-value pairs.</param>
             <param name="name">The name to parse.</param>
             <returns>The parsed int value.</returns>
        </member>
        <member name="M:Encog.Persist.EncogFileSection.ParseIntArray(System.Collections.Generic.IDictionary{System.String,System.String},System.String)">
             <summary>
             Parse an int array from a name-value collection of params.
             </summary>
            
             <param name="paras">The name-value pairs.</param>
             <param name="name">The name to parse.</param>
             <returns>The parsed int array value.</returns>
        </member>
        <member name="M:Encog.Persist.EncogFileSection.ParseMatrix(System.Collections.Generic.IDictionary{System.String,System.String},System.String)">
             <summary>
             Parse a matrix from a name-value collection of params.
             </summary>
            
             <param name="paras">The name-value pairs.</param>
             <param name="name">The name to parse.</param>
             <returns>The parsed matrix value.</returns>
        </member>
        <member name="M:Encog.Persist.EncogFileSection.SplitColumns(System.String)">
             <summary>
             Split a delimited string into columns.
             </summary>
            
             <param name="line">THe string to split.</param>
             <returns>The string split.</returns>
        </member>
        <member name="M:Encog.Persist.EncogFileSection.ParseParams">
            <returns>The params.</returns>
        </member>
        <member name="P:Encog.Persist.EncogFileSection.LargeArrays">
            <summary>
            Large arrays.
            </summary>
        </member>
        <member name="M:Encog.Persist.EncogFileSection.ToString">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Persist.IEncogPersistor">
             <summary>
             This interface defines an Encog Persistor. An Encog persistor will write an
             Encog object to an EG file.
             </summary>
            
        </member>
        <member name="P:Encog.Persist.IEncogPersistor.NativeType">
            <summary>
            The native type.
            </summary>
        </member>
        <member name="P:Encog.Persist.IEncogPersistor.PersistClassString">
            <value>Get the class string for the object.</value>
        </member>
        <member name="P:Encog.Persist.IEncogPersistor.FileVersion">
            <value>Get the file version used by this persistor.</value>
        </member>
        <member name="M:Encog.Persist.IEncogPersistor.Read(System.IO.Stream)">
             <summary>
             Read the object from an input stream.
             </summary>
            
             <param name="mask0">The input stream.</param>
             <returns>The object.</returns>
        </member>
        <member name="M:Encog.Persist.IEncogPersistor.Save(System.IO.Stream,System.Object)">
             <summary>
             Save the object.
             </summary>
            
             <param name="os">The output stream to save to.</param>
             <param name="obj">The object to save.</param>
        </member>
        <member name="T:Encog.Persist.EncogReadHelper">
             <summary>
             Used to read an Encog EG/EGA file. EG files are used to hold Encog objects.
             EGA files are used to hold Encog Analyst scripts.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.EncogReadHelper.lines">
             <summary>
             The lines read from the file.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.EncogReadHelper.reader">
             <summary>
             The file being read.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.EncogReadHelper.currentSectionName">
             <summary>
             The current section name.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.EncogReadHelper.currentSubSectionName">
             <summary>
             The current subsection name.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.EncogReadHelper.section">
             <summary>
             The current section name.
             </summary>
            
        </member>
        <member name="M:Encog.Persist.EncogReadHelper.#ctor(System.IO.Stream)">
             <summary>
             Construct the object.
             </summary>
            
             <param name="mask0">The input stream.</param>
        </member>
        <member name="M:Encog.Persist.EncogReadHelper.Close">
             <summary>
             Close the file.
             </summary>
            
        </member>
        <member name="M:Encog.Persist.EncogReadHelper.ReadNextSection">
             <summary>
             Read the next section.
             </summary>
            
             <returns>The next section.</returns>
        </member>
        <member name="M:Encog.Persist.EncogReadHelper.ReadLargeArray(System.String)">
            <summary>
            Called internally to read a large array.
            </summary>
            <param name="line">The line containing the beginning of a large array.</param>
            <returns>The array read.</returns>
        </member>
        <member name="T:Encog.Persist.EncogWriteHelper">
             <summary>
             Used to write an Encog EG/EGA file. EG files are used to hold Encog objects.
             EGA files are used to hold Encog Analyst scripts.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.EncogWriteHelper._largeArrayNumber">
            <summary>
            The current large array that we are on.
            </summary>
        </member>
        <member name="F:Encog.Persist.EncogWriteHelper.QUOTE">
             <summary>
             A quote char.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.EncogWriteHelper.COMMA">
             <summary>
             A comma char.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.EncogWriteHelper.line">
             <summary>
             The current line.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.EncogWriteHelper.xout">
             <summary>
             The file to write to.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.EncogWriteHelper.currentSection">
             <summary>
             The current section.
             </summary>
            
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.#ctor(System.IO.Stream)">
             <summary>
             Construct the object.
             </summary>
            
             <param name="stream">The stream to write to.</param>
        </member>
        <member name="P:Encog.Persist.EncogWriteHelper.CurrentSection">
            <value>The current section.</value>
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.AddColumn(System.Boolean)">
             <summary>
             Add a boolean value as a column.  
             </summary>
            
             <param name="b">The boolean value.</param>
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.AddColumn(System.Double)">
             <summary>
             Add a column as a double.
             </summary>
            
             <param name="d">The double to add.</param>
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.AddColumn(System.Int64)">
             <summary>
             Add a column as a long.
             </summary>
            
             <param name="v">The long to add.</param>
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.AddColumn(System.Int32)">
             <summary>
             Add a column as an integer.
             </summary>
            
             <param name="i">The integer to add.</param>
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.AddColumn(System.String)">
             <summary>
             Add a column as a string.
             </summary>
            
             <param name="str">The string to add.</param>
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.AddColumns(System.Collections.Generic.IList{System.String})">
             <summary>
             Add a list of string columns.
             </summary>
            
             <param name="cols">The columns to add.</param>
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.AddLine(System.String)">
             <summary>
             Add a line.
             </summary>
            
             <param name="l">The line to add.</param>
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.AddProperties(System.Collections.Generic.IDictionary{System.String,System.String})">
             <summary>
             Add the specified properties.
             </summary>
            
             <param name="properties">The properties.</param>
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.AddSection(System.String)">
             <summary>
             Add a new section.
             </summary>
            
             <param name="str">The section to add.</param>
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.AddSubSection(System.String)">
             <summary>
             Add a new subsection.
             </summary>
            
             <param name="str">The subsection.</param>
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.Flush">
             <summary>
             Flush the file.
             </summary>
            
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.Write(System.String)">
             <summary>
             Write the specified string.
             </summary>
            
             <param name="str">The string to write.</param>
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.WriteLine">
             <summary>
             Write the line.
             </summary>
            
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.WriteProperty(System.String,Encog.Engine.Network.Activation.IActivationFunction)">
             <summary>
             Write a property as an activation function.
             </summary>
            
             <param name="name">The name of the property.</param>
             <param name="act">The activation function.</param>
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.WriteProperty(System.String,System.Boolean)">
             <summary>
             Write the property as a boolean.
             </summary>
            
             <param name="name">The name of the property.</param>
             <param name="value_ren">The boolean value.</param>
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.WriteProperty(System.String,Encog.Util.CSV.CSVFormat)">
             <summary>
             Write a property as a CSV format.
             </summary>
            
             <param name="name">The name of the property.</param>
             <param name="csvFormat">The format.</param>
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.WriteProperty(System.String,System.Double)">
             <summary>
             Write the property as a double.
             </summary>
            
             <param name="name">The name of the property.</param>
             <param name="value_ren">The value.</param>
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.WriteProperty(System.String,System.Int64)">
             <summary>
             Write the property as a long.
             </summary>
            
             <param name="name">The name of the property.</param>
             <param name="v">The value.</param>
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.WriteProperty(System.String,System.Double[])">
             <summary>
             Write the property as a double array.
             </summary>
            
             <param name="name">The name of the property.</param>
             <param name="d">The double value.</param>
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.WriteProperty(System.String,System.Int32)">
             <summary>
             Write a property as an int value.
             </summary>
            
             <param name="name">The name of the property.</param>
             <param name="value_ren">The int value.</param>
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.WriteProperty(System.String,System.Int32[])">
             <summary>
             Write a property as an int array.
             </summary>
            
             <param name="name">The name of the property.</param>
             <param name="array">The array.</param>
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.WriteProperty(System.String,Encog.MathUtil.Matrices.Matrix)">
             <summary>
             Write a matrix as a property.
             </summary>
            
             <param name="name">The property name.</param>
             <param name="matrix">The matrix.</param>
        </member>
        <member name="M:Encog.Persist.EncogWriteHelper.WriteProperty(System.String,System.String)">
             <summary>
             Write the property a s string.
             </summary>
            
             <param name="name">The name of the property.</param>
             <param name="value_ren">The value.</param>
        </member>
        <member name="T:Encog.Persist.PersistConst">
             <summary>
             Some common persistance constants.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.TypeHopfield">
             <summary>
             A Hopfield neural network.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.TypeBoltzmann">
             <summary>
             A Boltzmann machine.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.TypeART1">
             <summary>
             An ART1 neural network.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.TypeBAM">
             <summary>
             A BAM neural network.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.TypeSOM">
             <summary>
             A SOM neural network.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.TypeNEAT">
             <summary>
             A NEAT neural network.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.TypeNEATPopulation">
             <summary>
             A NEAT population.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.TypeBasicSpecies">
             <summary>
             A species.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.TypeNEATNeuronGene">
             <summary>
             A neuron gene.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.TypeSVM">
             <summary>
             A support vector machine.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.TypeBasicNetwork">
             <summary>
             A neural network.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.TypeRBFNetwork">
             <summary>
             A RBF network.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Name">
             <summary>
             A name.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Description">
             <summary>
             A description.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.NeuronCount">
             <summary>
             Neurons.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Thresholds">
             <summary>
             Thresholds.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Weights">
             <summary>
             Weights.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Output">
             <summary>
             Output.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Native">
             <summary>
             Native.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Temperature">
             <summary>
             Temperature.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.InputCount">
             <summary>
             The input count.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.OutputCount">
             <summary>
             The output count.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.List">
             <summary>
             List.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Data">
             <summary>
             Data.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Matrix">
             <summary>
             matrix.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.ActivationType">
             <summary>
             An activation function.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.PropertyF1Count">
             <summary>
             The F1 count.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.PropertyF2Count">
             <summary>
             The F2 count.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.PropertyWeightsF1F2">
             <summary>
             The weights from F1 to F2.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.PropertyWeightsF2F1">
             <summary>
             The weights from F2 to F1.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.ActivationFunction">
             <summary>
             Activation function.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Neurons">
             <summary>
             Neuron count.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Type">
             <summary>
             Type.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Recurrent">
             <summary>
             Recurrent.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Weight">
             <summary>
             Weight.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Links">
             <summary>
             Links.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.TypeNEATInnovation">
             <summary>
             NEAT innovation.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.PropertyID">
             <summary>
             Property id.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.TypeNEATGenome">
             <summary>
             NEAT genome.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Enabled">
             <summary>
             Enabled.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Idata">
             <summary>
             idata.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Properties">
             <summary>
             Properties.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Version">
             <summary>
             Version.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Depth">
             <summary>
             Depth.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Snapshot">
             <summary>
             Snapshot.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Error">
             <summary>
             Error.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Sigma">
             <summary>
             Sigma.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Kernel">
             <summary>
             Kernel.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistConst.Instar">
             <summary>
             Instar.
             </summary>
            
        </member>
        <member name="T:Encog.Persist.PersistError">
             <summary>
             General error class for Encog persistence.
             </summary>
            
        </member>
        <member name="M:Encog.Persist.PersistError.#ctor(System.String)">
             <summary>
             Construct a message exception.
             </summary>
            
             <param name="msg">The exception message.</param>
        </member>
        <member name="M:Encog.Persist.PersistError.#ctor(System.String,System.Exception)">
             <summary>
             Construct an exception that holds another exception.
             </summary>
            
             <param name="msg">The message.</param>
             <param name="t">The other exception.</param>
        </member>
        <member name="M:Encog.Persist.PersistError.#ctor(System.Exception)">
             <summary>
             Construct an exception that holds another exception.
             </summary>
            
             <param name="t">The other exception.</param>
        </member>
        <member name="T:Encog.Persist.PersistorRegistry">
             <summary>
             Registry to hold persistors.  This is a singleton.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistorRegistry._instance">
             <summary>
             The instance.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistorRegistry._map">
             <summary>
             The mapping between name and persistor.
             </summary>
            
        </member>
        <member name="F:Encog.Persist.PersistorRegistry._classMap">
            <summary>
            The class map, used to lookup native classes to their persistor.
            </summary>
        </member>
        <member name="M:Encog.Persist.PersistorRegistry.#ctor">
             <summary>
             Construct the object.
             </summary>
            
        </member>
        <member name="P:Encog.Persist.PersistorRegistry.Instance">
            <value>The singleton instance.</value>
        </member>
        <member name="M:Encog.Persist.PersistorRegistry.Add(Encog.Persist.IEncogPersistor)">
             <summary>
             Add a persistor.
             </summary>
            
             <param name="persistor">The persistor to add.</param>
        </member>
        <member name="M:Encog.Persist.PersistorRegistry.GetPersistor(System.Type)">
             <summary>
             Get a persistor.
             </summary>
            
             <param name="clazz">The class to get the persistor for.</param>
             <returns>Return the persistor.</returns>
        </member>
        <member name="M:Encog.Persist.PersistorRegistry.GetPersistor(System.String)">
             <summary>
             Get the persistor by name.
             </summary>
            
             <param name="name">The name of the persistor.</param>
             <returns>The persistor.</returns>
        </member>
        <member name="T:Encog.Plugin.EncogPluginBase">
             <summary>
             The base plugin for Encog.
             </summary>
            
        </member>
        <member name="P:Encog.Plugin.EncogPluginBase.PluginType">
            <value>The type number for this plugin.</value>
        </member>
        <member name="P:Encog.Plugin.EncogPluginBase.PluginServiceType">
            <value>The service type provided by this plugin.</value>
        </member>
        <member name="P:Encog.Plugin.EncogPluginBase.PluginName">
            <value>The name of the plugin.</value>
        </member>
        <member name="P:Encog.Plugin.EncogPluginBase.PluginDescription">
            <value>The plugin description.</value>
        </member>
        <member name="T:Encog.Plugin.IEncogPluginLogging1">
            <summary>
            A plugin that supports logging.  This is a version 1 plugin.
            </summary>
        </member>
        <member name="P:Encog.Plugin.IEncogPluginLogging1.LogLevel">
            <summary>
            The current log level.
            </summary>
        </member>
        <member name="M:Encog.Plugin.IEncogPluginLogging1.Log(System.Int32,System.String)">
            <summary>
            Log a message at the specified level. 
            </summary>
            <param name="level">The level to log at.</param>
            <param name="message">The message to log.</param>
        </member>
        <member name="M:Encog.Plugin.IEncogPluginLogging1.Log(System.Int32,System.Exception)">
            <summary>
            Log a throwable at the specified level.
            </summary>
            <param name="level">The level to log at.</param>
            <param name="t">The error to log.</param>
        </member>
        <member name="M:Encog.Plugin.IEncogPluginService1.CreateActivationFunction(System.String)">
            <summary>
            Create an activation function.
            </summary>
            <param name="name">The name of the activation function.</param>
            <returns>The newly created activation function.</returns>
        </member>
        <member name="M:Encog.Plugin.IEncogPluginService1.CreateMethod(System.String,System.String,System.Int32,System.Int32)">
            <summary>
            Create a new machine learning method. 
            </summary>
            <param name="methodType">The method to create.</param>
            <param name="architecture">The architecture string.</param>
            <param name="input">The input count.</param>
            <param name="output">The output count.</param>
            <returns>The newly created machine learning method.</returns>
        </member>
        <member name="M:Encog.Plugin.IEncogPluginService1.CreateTraining(Encog.ML.IMLMethod,Encog.ML.Data.IMLDataSet,System.String,System.String)">
            <summary>
            Create a trainer. 
            </summary>
            <param name="method">The method to train.</param>
            <param name="training">The training data.</param>
            <param name="type">Type type of trainer.</param>
            <param name="args">The training args.</param>
            <returns>The new training method.</returns>
        </member>
        <member name="T:Encog.Plugin.EncogPluginBaseConst">
            <summary>
            A type-1 Encog plugin.
            </summary>
        </member>
        <member name="F:Encog.Plugin.EncogPluginBaseConst.SERVICE_TYPE_GENERAL">
             <summary>
             A general plugin, you can have multiple plugins installed that provide
             general services.
             </summary>
            
        </member>
        <member name="F:Encog.Plugin.EncogPluginBaseConst.SERVICE_TYPE_LOGGING">
             <summary>
             A special plugin that provides logging. You may only have one logging
             plugin installed.
             </summary>
            
        </member>
        <member name="P:Encog.Plugin.SystemPlugin.SystemActivationPlugin.PluginDescription">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Plugin.SystemPlugin.SystemActivationPlugin.PluginName">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Plugin.SystemPlugin.SystemActivationPlugin.PluginType">
            <summary>
            This is a type-1 plugin.
            </summary>
        </member>
        <member name="M:Encog.Plugin.SystemPlugin.SystemActivationPlugin.AllocateAF(System.String)">
            <summary>
            Allocate an activation function.
            </summary>
            <param name="name">The name of the activation function.</param>
            <returns>The activation function.</returns>
        </member>
        <member name="M:Encog.Plugin.SystemPlugin.SystemActivationPlugin.CreateActivationFunction(System.String)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Plugin.SystemPlugin.SystemActivationPlugin.CreateMethod(System.String,System.String,System.Int32,System.Int32)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Plugin.SystemPlugin.SystemActivationPlugin.CreateTraining(Encog.ML.IMLMethod,Encog.ML.Data.IMLDataSet,System.String,System.String)">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Plugin.SystemPlugin.SystemActivationPlugin.PluginServiceType">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Plugin.SystemPlugin.SystemLoggingPlugin">
             <summary>
             This is the built-in logging plugin for Encog. This plugin provides simple
             file and console logging.
             </summary>
            
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemLoggingPlugin.currentLevel">
             <summary>
             The current level.
             </summary>
            
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemLoggingPlugin.logConsole">
             <summary>
             True if we are logging to the console.
             </summary>
            
        </member>
        <member name="M:Encog.Plugin.SystemPlugin.SystemLoggingPlugin.#ctor">
            <summary>
            Construct the object.
            </summary>
        </member>
        <member name="M:Encog.Plugin.SystemPlugin.SystemLoggingPlugin.CalculateGradient(System.Double[],System.Double[],System.Double[],System.Double[],Encog.Engine.Network.Activation.IActivationFunction,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32)">
             <summary>
             Not used for this type of plugin.
             </summary>
            
             <param name="gradients">Not used.</param>
             <param name="layerOutput">Not used.</param>
             <param name="weights">Not used.</param>
             <param name="layerDelta">Not used.</param>
             <param name="af">Not used.</param>
             <param name="index">Not used.</param>
             <param name="fromLayerIndex">Not used.</param>
             <param name="fromLayerSize">Not used.</param>
             <param name="toLayerIndex">Not used.</param>
             <param name="toLayerSize">Not used.</param>
        </member>
        <member name="M:Encog.Plugin.SystemPlugin.SystemLoggingPlugin.CalculateLayer(System.Double[],System.Double[],System.Int32,System.Int32,System.Int32,System.Int32,System.Int32)">
             <summary>
             Not used for this type of plugin.
             </summary>
            
             <param name="weights">Not used.</param>
             <param name="layerOutput">Not used.</param>
             <param name="startIndex">Not used.</param>
             <param name="outputIndex">Not used.</param>
             <param name="outputSize">Not used.</param>
             <param name="inputIndex">Not used.</param>
             <param name="inputSize">Not used.</param>
             <returns>Not used.</returns>
        </member>
        <member name="P:Encog.Plugin.SystemPlugin.SystemLoggingPlugin.LogLevel">
            <summary>
            Set the logging level.
            </summary>
        </member>
        <member name="P:Encog.Plugin.SystemPlugin.SystemLoggingPlugin.PluginDescription">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Plugin.SystemPlugin.SystemLoggingPlugin.PluginName">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Plugin.SystemPlugin.SystemLoggingPlugin.PluginServiceType">
            <value>Returns the service type for this plugin. This plugin provides
            the system calculation for layers and gradients. Therefore, this
            plugin returns SERVICE_TYPE_CALCULATION.</value>
        </member>
        <member name="P:Encog.Plugin.SystemPlugin.SystemLoggingPlugin.PluginType">
            <value>This is a type-1 plugin.</value>
        </member>
        <member name="M:Encog.Plugin.SystemPlugin.SystemLoggingPlugin.Log(System.Int32,System.String)">
             <summary>
             Log the message.
             </summary>
            
             <param name="level">The logging level.</param>
             <param name="message">The logging message.</param>
        </member>
        <member name="M:Encog.Plugin.SystemPlugin.SystemLoggingPlugin.Log(System.Int32,System.Exception)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Plugin.SystemPlugin.SystemLoggingPlugin.StartConsoleLogging">
             <summary>
             Start logging to the console.
             </summary>
            
        </member>
        <member name="M:Encog.Plugin.SystemPlugin.SystemLoggingPlugin.StopLogging">
             <summary>
             Stop any console or file logging.
             </summary>
            
        </member>
        <member name="T:Encog.Plugin.SystemPlugin.SystemMethodsPlugin">
            <summary>
            System plugin for core ML Methods.
            </summary>
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemMethodsPlugin._bayesianFactory">
            <summary>
            A factory used to create Bayesian networks
            </summary>
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemMethodsPlugin._feedforwardFactory">
            <summary>
            A factory used to create feedforward neural networks.
            </summary>
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemMethodsPlugin._pnnFactory">
            <summary>
            The factory for PNN's.
            </summary>
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemMethodsPlugin._rbfFactory">
            <summary>
            A factory used to create RBF networks.
            </summary>
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemMethodsPlugin._somFactory">
            <summary>
            A factory used to create SOM's.
            </summary>
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemMethodsPlugin._svmFactory">
            <summary>
            A factory used to create support vector machines.
            </summary>
        </member>
        <member name="P:Encog.Plugin.SystemPlugin.SystemMethodsPlugin.PluginDescription">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Plugin.SystemPlugin.SystemMethodsPlugin.PluginName">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Plugin.SystemPlugin.SystemMethodsPlugin.PluginType">
            <summary>
            This is a type-1 plugin.
            </summary>
        </member>
        <member name="M:Encog.Plugin.SystemPlugin.SystemMethodsPlugin.CreateActivationFunction(System.String)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Plugin.SystemPlugin.SystemMethodsPlugin.CreateMethod(System.String,System.String,System.Int32,System.Int32)">
            <inheritdoc/>
        </member>
        <member name="M:Encog.Plugin.SystemPlugin.SystemMethodsPlugin.CreateTraining(Encog.ML.IMLMethod,Encog.ML.Data.IMLDataSet,System.String,System.String)">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Plugin.SystemPlugin.SystemMethodsPlugin.PluginServiceType">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Plugin.SystemPlugin.SystemTrainingPlugin">
            <summary>
            Create the system training methods.
            </summary>
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemTrainingPlugin.annealFactory">
            <summary>
            The factory for simulated annealing.
            </summary>
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemTrainingPlugin.backpropFactory">
            <summary>
            The factory for backprop.
            </summary>
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemTrainingPlugin.bayesianFactory">
            <summary>
            The factory for K2
            </summary>
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemTrainingPlugin.geneticFactory">
            <summary>
            The factory for genetic.
            </summary>
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemTrainingPlugin.lmaFactory">
            <summary>
            The factory for LMA.
            </summary>
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemTrainingPlugin.manhattanFactory">
            <summary>
            The factory for Manhattan networks.
            </summary>
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemTrainingPlugin.neighborhoodFactory">
            <summary>
            The factory for neighborhood SOM.
            </summary>
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemTrainingPlugin.nmFactory">
            <summary>
            Nelder Mead Factory.
            </summary>
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemTrainingPlugin.pnnFactory">
            <summary>
            Factory for PNN.
            </summary>
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemTrainingPlugin.psoFactory">
            <summary>
            PSO training factory.
            </summary>
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemTrainingPlugin.qpropFactory">
            <summary>
            Factory for quick prop.
            </summary>
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemTrainingPlugin.rpropFactory">
            <summary>
            The factory for RPROP.
            </summary>
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemTrainingPlugin.scgFactory">
            <summary>
            The factory for SCG.
            </summary>
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemTrainingPlugin.somClusterFactory">
            <summary>
            The factory for SOM cluster.
            </summary>
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemTrainingPlugin.svdFactory">
            <summary>
            Factory for SVD.
            </summary>
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemTrainingPlugin.svmFactory">
            <summary>
            The factory for basic SVM.
            </summary>
        </member>
        <member name="F:Encog.Plugin.SystemPlugin.SystemTrainingPlugin.svmSearchFactory">
            <summary>
            The factory for SVM-Search.
            </summary>
        </member>
        <member name="P:Encog.Plugin.SystemPlugin.SystemTrainingPlugin.PluginDescription">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Plugin.SystemPlugin.SystemTrainingPlugin.PluginName">
            <inheritdoc/>
        </member>
        <member name="P:Encog.Plugin.SystemPlugin.SystemTrainingPlugin.PluginType">
            <summary>
            This is a type-1 plugin.
            </summary>
        </member>
        <member name="M:Encog.Plugin.SystemPlugin.SystemTrainingPlugin.CreateActivationFunction(System.String)">
            <summary>
            This plugin does not support activation functions, so it will 
            always return null. 
            </summary>
            <param name="name">Not used.</param>
            <returns>The activation function.</returns>
        </member>
        <member name="P:Encog.Plugin.SystemPlugin.SystemTrainingPlugin.PluginServiceType">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Util.Arrayutil.ClassItem">
             <summary>
             A class item.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Arrayutil.ClassItem._index">
             <summary>
             The index of the class.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Arrayutil.ClassItem._name">
             <summary>
             The name of the class.
             </summary>
            
        </member>
        <member name="M:Encog.Util.Arrayutil.ClassItem.#ctor(System.String,System.Int32)">
             <summary>
             Construct the object.
             </summary>
            
             <param name="theName">The name of the class.</param>
             <param name="theIndex">The index of the class.</param>
        </member>
        <member name="P:Encog.Util.Arrayutil.ClassItem.Index">
            <summary>
            Set the index of the class.
            </summary>
        </member>
        <member name="P:Encog.Util.Arrayutil.ClassItem.Name">
            <summary>
            Set the name of the class.
            </summary>
        </member>
        <member name="M:Encog.Util.Arrayutil.ClassItem.ToString">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Util.Arrayutil.NormalizationAction">
             <summary>
             Normalization actions desired.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Arrayutil.NormalizationAction.PassThrough">
             <summary>
             Do not normalize the column, just allow it to pass through. This allows
             string fields to pass through as well.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Arrayutil.NormalizationAction.Normalize">
             <summary>
             Normalize this column.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Arrayutil.NormalizationAction.Ignore">
             <summary>
             Ignore this column, do not include in the output.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Arrayutil.NormalizationAction.OneOf">
             <summary>
             Use the "one-of" classification method.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Arrayutil.NormalizationAction.Equilateral">
             <summary>
             Use the equilateral classification method.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Arrayutil.NormalizationAction.SingleField">
             <summary>
             Use a single-field classification method.
             </summary>
            
        </member>
        <member name="T:Encog.Util.Arrayutil.NormalizationActionExtension">
            <summary>
            Determine the normalization action.  Is it a classify?
            </summary>
        </member>
        <member name="M:Encog.Util.Arrayutil.NormalizationActionExtension.IsClassify(Encog.Util.Arrayutil.NormalizationAction)">
            <returns>True, if this is a classify.</returns>
        </member>
        <member name="T:Encog.Util.Arrayutil.TemporalType">
             <summary>
             Operations that the temporal class may perform on fields.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Arrayutil.TemporalType.Input">
             <summary>
             This field is used as part of the input. However, if you wish to use the
             field for prediction as well, specify InputAndPredict.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Arrayutil.TemporalType.Predict">
             <summary>
             This field is used as part of the prediction. However, if you wish to use
             the field for input as well, specify InputAndPredict.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Arrayutil.TemporalType.InputAndPredict">
             <summary>
             This field is used for both input and prediction.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Arrayutil.TemporalType.Ignore">
             <summary>
             This field should be ignored.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Arrayutil.TemporalType.PassThrough">
             <summary>
             This field should pass through, to the output file, without modification.
             </summary>
            
        </member>
        <member name="T:Encog.Util.Arrayutil.TemporalWindowArray">
             <summary>
             Produce a time-series from an array.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Arrayutil.TemporalWindowArray._fields">
             <summary>
             The fields that are to be processed.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Arrayutil.TemporalWindowArray._inputWindow">
             <summary>
             The size of the input window.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Arrayutil.TemporalWindowArray._predictWindow">
             <summary>
             The size of the prediction window.
             </summary>
            
        </member>
        <member name="M:Encog.Util.Arrayutil.TemporalWindowArray.#ctor(System.Int32,System.Int32)">
             <summary>
             Construct a time-series from an array.
             </summary>
            
             <param name="theInputWindow">The size of the input window.</param>
             <param name="thePredictWindow">The size of the predict window.</param>
        </member>
        <member name="P:Encog.Util.Arrayutil.TemporalWindowArray.Fields">
            <value>The fields that are to be processed.</value>
        </member>
        <member name="P:Encog.Util.Arrayutil.TemporalWindowArray.InputWindow">
            <value>the inputWindow to set</value>
        </member>
        <member name="P:Encog.Util.Arrayutil.TemporalWindowArray.PredictWindow">
            <value>the predictWindow to set</value>
        </member>
        <member name="M:Encog.Util.Arrayutil.TemporalWindowArray.Analyze(System.Double[])">
             <summary>
             Analyze the 1D array.
             </summary>
            
             <param name="array">The array to analyze.</param>
        </member>
        <member name="M:Encog.Util.Arrayutil.TemporalWindowArray.Analyze(System.Double[][])">
             <summary>
             Analyze the 2D array.
             </summary>
            
             <param name="array">The 2D array to analyze.</param>
        </member>
        <member name="M:Encog.Util.Arrayutil.TemporalWindowArray.CountInputFields">
             <summary>
             Count the number of input fields, or fields used to predict.
             </summary>
            
             <returns>The number of input fields.</returns>
        </member>
        <member name="M:Encog.Util.Arrayutil.TemporalWindowArray.CountPredictFields">
             <summary>
             Count the number of fields that are that are in the prediction.
             </summary>
            
             <returns>The number of fields predicted.</returns>
        </member>
        <member name="M:Encog.Util.Arrayutil.TemporalWindowArray.Process(System.Double[])">
             <summary>
             Process the array.
             </summary>
            
             <param name="data">The array to process.</param>
             <returns>A neural data set that contains the time-series.</returns>
        </member>
        <member name="M:Encog.Util.Arrayutil.TemporalWindowArray.Process(System.Double[][])">
            <summary>
            Processes the specified data array in an IMLDataset.
            You can send a [][] array directly with this method.
            </summary>
            <param name="data">The data.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.Arrayutil.TemporalWindowArray.ProcessToPair(System.Double[])">
             <summary>
             Process the data array and returns an IMLdatapair.
             </summary>
            
             <param name="data">The array to process.</param>
             <returns>An IMLDatapair containing data.</returns>
        </member>
        <member name="T:Encog.Util.Arrayutil.TemporalWindowField">
             <summary>
             This class specifies how fields are to be used by the TemporalWindowCSV
             class.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Arrayutil.TemporalWindowField._action">
             <summary>
             The action that is to be taken on this field.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Arrayutil.TemporalWindowField._name">
             <summary>
             The name of this field.
             </summary>
            
        </member>
        <member name="M:Encog.Util.Arrayutil.TemporalWindowField.#ctor(System.String)">
             <summary>
             Construct the object.
             </summary>
            
             <param name="theName">The name of the field to be considered.</param>
        </member>
        <member name="P:Encog.Util.Arrayutil.TemporalWindowField.Action">
            <value>the action to set</value>
        </member>
        <member name="P:Encog.Util.Arrayutil.TemporalWindowField.Input">
            <value>Returns true, if this field is to be used as part of the input
            for a prediction.</value>
        </member>
        <member name="P:Encog.Util.Arrayutil.TemporalWindowField.LastValue">
            <value>the lastValue to set</value>
        </member>
        <member name="P:Encog.Util.Arrayutil.TemporalWindowField.Name">
            <value>the name to set</value>
        </member>
        <member name="P:Encog.Util.Arrayutil.TemporalWindowField.Predict">
            <value>Returns true, if this field is part of what is being predicted.</value>
        </member>
        <member name="M:Encog.Util.Arrayutil.TemporalWindowField.ToString">
            <inheritdoc/>
        </member>
        <member name="T:Encog.Util.Banchmark.EncoderTrainingFactory">
            <summary>
             * This benchmark implements a Fahlman Encoder.  Though probably not invented by Scott 
            Fahlman, such encoders were used in many of his papers, particularly:
            
            "An Empirical Study of Learning Speed in Backpropagation Networks" 
            (Fahlman,1988)
            
            It provides a very simple way of evaluating classification neural networks.
              Basically, the input and output neurons are the same in count.  However, 
              there is a smaller number of hidden neurons.  This forces the neural 
              network to learn to encode the patterns from the input neurons to a 
              smaller vector size, only to be expanded again to the outputs.
            
            The training data is exactly the size of the input/output neuron count.  
            Each training element will have a single column set to 1 and all other 
            columns set to zero.  You can also perform in "complement mode", where 
            the opposite is true.  In "complement mode" all columns are set to 1, 
            except for one column that is 0.  The data produced in "complement mode" 
            is more difficult to train.
            
            Fahlman used this simple training data to benchmark neural networks when 
            he introduced the Quickprop algorithm in the above paper.
            </summary>
        </member>
        <member name="M:Encog.Util.Banchmark.EncoderTrainingFactory.generateTraining(System.Int32,System.Boolean)">
            <summary>
            Generate an encoder training set over the range [0.0,1.0].  This is the range used by
            Fahlman.
            </summary>
            <param name="inputCount">The number of inputs and outputs.</param>
            <param name="compl">True if the complement mode should be use.</param>
            <returns>The training set.</returns>
        </member>
        <member name="M:Encog.Util.Banchmark.EncoderTrainingFactory.GenerateTraining(System.Int32,System.Boolean,System.Double,System.Double)">
            <summary>
            Generate an encoder over the specified range. 
            </summary>
            <param name="inputCount">The number of inputs and outputs.</param>
            <param name="compl">True if the complement mode should be use. </param>
            <param name="min">The minimum value to use(i.e. 0 or -1)</param>
            <param name="max">The maximum value to use(i.e. 1 or 0)</param>
            <returns>The training set.</returns>
        </member>
        <member name="T:Encog.Util.Banchmark.EncogBenchmark">
            <summary>
            Benchmark Encog with several network types.
            </summary>
        </member>
        <member name="F:Encog.Util.Banchmark.EncogBenchmark.Steps">
            <summary>
            Number of steps in all.
            </summary>
        </member>
        <member name="F:Encog.Util.Banchmark.EncogBenchmark.Step1">
            <summary>
            The first step.
            </summary>
        </member>
        <member name="F:Encog.Util.Banchmark.EncogBenchmark.Step2">
            <summary>
            The third step.
            </summary>
        </member>
        <member name="F:Encog.Util.Banchmark.EncogBenchmark.Step3">
            <summary>
            The fourth step.
            </summary>
        </member>
        <member name="F:Encog.Util.Banchmark.EncogBenchmark._report">
            <summary>
            Report progress.
            </summary>
        </member>
        <member name="F:Encog.Util.Banchmark.EncogBenchmark._binaryScore">
            <summary>
            The binary score.
            </summary>
        </member>
        <member name="F:Encog.Util.Banchmark.EncogBenchmark._cpuScore">
            <summary>
            The CPU score.
            </summary>
        </member>
        <member name="F:Encog.Util.Banchmark.EncogBenchmark._memoryScore">
            <summary>
            The memory score.
            </summary>
        </member>
        <member name="M:Encog.Util.Banchmark.EncogBenchmark.#ctor(Encog.IStatusReportable)">
            <summary>
            Construct a benchmark object.
            </summary>
            <param name="report">The object to report progress to.</param>
        </member>
        <member name="P:Encog.Util.Banchmark.EncogBenchmark.CpuScore">
            <summary>
            The CPU score.
            </summary>
        </member>
        <member name="P:Encog.Util.Banchmark.EncogBenchmark.MemoryScore">
            <summary>
            The memory score.
            </summary>
        </member>
        <member name="P:Encog.Util.Banchmark.EncogBenchmark.BinaryScore">
            <summary>
            The binary score.
            </summary>
        </member>
        <member name="M:Encog.Util.Banchmark.EncogBenchmark.Process">
            <summary>
            Perform the benchmark. Returns the total amount of time for all of the
            benchmarks. Returns the final score. The lower the better for a score.
            </summary>
            <returns>The total time, which is the final Encog benchmark score.</returns>
        </member>
        <member name="M:Encog.Util.Banchmark.EncogBenchmark.EvalCpu">
            <summary>
            Evaluate the CPU.
            </summary>
        </member>
        <member name="M:Encog.Util.Banchmark.EncogBenchmark.EvalMemory">
            <summary>
            Evaluate memory.
            </summary>
        </member>
        <member name="M:Encog.Util.Banchmark.EncogBenchmark.EvalBinary">
            <summary>
            Evaluate disk.
            </summary>
        </member>
        <member name="T:Encog.Util.Banchmark.Evaluate">
            <summary>
            Used to evaluate the training time for a network.
            </summary>
        </member>
        <member name="F:Encog.Util.Banchmark.Evaluate.Milis">
            <summary>
            Mili-seconds in a second.
            </summary>
        </member>
        <member name="M:Encog.Util.Banchmark.Evaluate.EvaluateTrain(System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            Evaluate training.
            </summary>
            <param name="input">Input neurons.</param>
            <param name="hidden1">Hidden 1 neurons.</param>
            <param name="hidden2">Hidden 2 neurons.</param>
            <param name="output">Output neurons.</param>
            <returns>The result of the evaluation.</returns>
        </member>
        <member name="M:Encog.Util.Banchmark.Evaluate.EvaluateTrain(Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet)">
            <summary>
            Evaluate how long it takes to calculate the error for the network. This
            causes each of the training pairs to be run through the network. The
            network is evaluated 10 times and the lowest time is reported. 
            </summary>
            <param name="network">The training data to use.</param>
            <param name="training">The number of seconds that it took.</param>
            <returns></returns>
        </member>
        <member name="T:Encog.Util.Banchmark.RandomTrainingFactory">
            <summary>
            Class used to generate random training sets.
            </summary>
        </member>
        <member name="M:Encog.Util.Banchmark.RandomTrainingFactory.#ctor">
            <summary>
            Private constructor.
            </summary>
        </member>
        <member name="M:Encog.Util.Banchmark.RandomTrainingFactory.Generate(System.Int64,System.Int32,System.Int32,System.Int32,System.Double,System.Double)">
            <summary>
            Generate a random training set. 
            </summary>
            <param name="seed">The seed value to use, the same seed value will always produce
            the same results.</param>
            <param name="count">How many training items to generate.</param>
            <param name="inputCount">How many input numbers.</param>
            <param name="idealCount">How many ideal numbers.</param>
            <param name="min">The minimum random number.</param>
            <param name="max">The maximum random number.</param>
            <returns>The random training set.</returns>
        </member>
        <member name="M:Encog.Util.Banchmark.RandomTrainingFactory.Generate(Encog.ML.Data.IMLDataSet,System.Int64,System.Int32,System.Double,System.Double)">
            <summary>
            Generate random training into a training set.
            </summary>
            <param name="training">The training set to generate into.</param>
            <param name="seed">The seed to use.</param>
            <param name="count">How much data to generate.</param>
            <param name="min">The low random value.</param>
            <param name="max">The high random value.</param>
        </member>
        <member name="T:Encog.Util.Concurrency.DetermineWorkload">
             <summary>
             Used by several Encog training methods to break up a workload. Can also be
             used to determine the number of threads to use. If zero threads are
             specified, Encog will query the processor count and determine the best number
             of threads to use.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Concurrency.DetermineWorkload.MinWorthwhile">
             <summary>
             What is the minimum number of workload entries for a thread to be
             worthwhile.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Concurrency.DetermineWorkload._threadCount">
             <summary>
             How many threads to use.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Concurrency.DetermineWorkload._workloadSize">
             <summary>
             What is the total workload size?
             </summary>
            
        </member>
        <member name="M:Encog.Util.Concurrency.DetermineWorkload.#ctor(System.Int32,System.Int32)">
             <summary>
             Determine the workload.
             </summary>
            
             <param name="threads">Threads to use, or zero to allow Encog to pick.</param>
             <param name="workloadSize">Total workload size.</param>
        </member>
        <member name="P:Encog.Util.Concurrency.DetermineWorkload.ThreadCount">
            <summary>
            The thread count.
            </summary>
        </member>
        <member name="M:Encog.Util.Concurrency.DetermineWorkload.CalculateWorkers">
            <summary>
            Calculate the high and low ranges for each worker.
            </summary>
            <returns>A list of IntRange objects.</returns>
        </member>
        <member name="T:Encog.Util.Concurrency.EngineConcurrency">
            <summary>
            This class abstracts thread pools, and potentially grids and other types of
            concurrency. It is used by other classes inside of Encog to allow tasks to be
            executed efficiently on multicore machines.
            </summary>
        </member>
        <member name="F:Encog.Util.Concurrency.EngineConcurrency._instance">
            <summary>
            Singleton instance.
            </summary>
        </member>
        <member name="F:Encog.Util.Concurrency.EngineConcurrency._activeTasks">
            <summary>
            The number of active tasks.
            </summary>
        </member>
        <member name="P:Encog.Util.Concurrency.EngineConcurrency.Instance">
            <summary>
            The instance to the singleton.
            </summary>
        </member>
        <member name="M:Encog.Util.Concurrency.EngineConcurrency.#ctor">
            <summary>
            Construct a concurrency object.
            </summary>
        </member>
        <member name="M:Encog.Util.Concurrency.EngineConcurrency.ProcessTask(Encog.Util.Concurrency.IEngineTask)">
            <summary>
            Process the specified task.  It will be processed either now,
            or queued to process on the thread pool.  No group is assigned.
            </summary>
            <param name="task">The task to process.</param>
        </member>
        <member name="M:Encog.Util.Concurrency.EngineConcurrency.ProcessTask(Encog.Util.Concurrency.IEngineTask,Encog.Util.Concurrency.TaskGroup)">
            <summary>
            Process the specified task.  It will be processed either now,
            or queued to process on the thread pool.
            </summary>
            <param name="task">The task to process.</param>
            <param name="group">The group this task belongs to.</param>
        </member>
        <member name="P:Encog.Util.Concurrency.EngineConcurrency.MaxThreads">
            <summary>
            How many threads should be used?
            </summary>
        </member>
        <member name="M:Encog.Util.Concurrency.EngineConcurrency.SetMaxThreadsToCoreCount">
            <summary>
            Set the max threads to the number of processors.
            </summary>
        </member>
        <member name="M:Encog.Util.Concurrency.EngineConcurrency.CreateTaskGroup">
            <summary>
            Create a new task group.
            </summary>
            <returns>The new task group.</returns>
        </member>
        <member name="T:Encog.Util.Concurrency.IEngineTask">
            <summary>
            A task for Encog concurrency.
            </summary>
        </member>
        <member name="M:Encog.Util.Concurrency.IEngineTask.Run">
            <summary>
            Run the specified task.
            </summary>
        </member>
        <member name="T:Encog.Util.Concurrency.IMultiThreadable">
            <summary>
            Defines a class that is multithreadable.
            </summary>
        </member>
        <member name="P:Encog.Util.Concurrency.IMultiThreadable.ThreadCount">
            <summary>
            The thread count.  Set to zero to automatically determine the 
            thread count based on cores.  Set to 1 to specify single threaded.
            </summary>
        </member>
        <member name="T:Encog.Util.Concurrency.Job.ConcurrentJob">
            <summary>
            A concurrent JOB, works well for multicore machines.  Provides
            the low-level tools to create a concurrent job.
            </summary>
        </member>
        <member name="F:Encog.Util.Concurrency.Job.ConcurrentJob._report">
            <summary>
            Where to report progress to.
            </summary>
        </member>
        <member name="F:Encog.Util.Concurrency.Job.ConcurrentJob._totalTasks">
            <summary>
            Total number of tasks.
            </summary>
        </member>
        <member name="M:Encog.Util.Concurrency.Job.ConcurrentJob.#ctor(Encog.IStatusReportable)">
            <summary>
            
            </summary>
            <param name="report"></param>
        </member>
        <member name="P:Encog.Util.Concurrency.Job.ConcurrentJob.ShouldStop">
            <summary>
            Has a stop been requested?
            </summary>
        </member>
        <member name="M:Encog.Util.Concurrency.Job.ConcurrentJob.RequestNextTask">
            <summary>
            Called by a thread to get the next task.
            </summary>
            <returns>Config info for the next task.</returns>
        </member>
        <member name="M:Encog.Util.Concurrency.Job.ConcurrentJob.LoadWorkload">
            <summary>
            Load the workload that this job must process.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.Concurrency.Job.ConcurrentJob.PerformJobUnit(Encog.Util.Concurrency.Job.JobUnitContext)">
            <summary>
            Perform the actual workload.
            </summary>
            <param name="context">The workload to execute.</param>
        </member>
        <member name="M:Encog.Util.Concurrency.Job.ConcurrentJob.Process">
            <summary>
            Start the job, block until its done.
            </summary>
        </member>
        <member name="M:Encog.Util.Concurrency.Job.ConcurrentJob.ReportStatus(Encog.Util.Concurrency.Job.JobUnitContext,System.String)">
            <summary>
            Recieve status reports.
            </summary>
            <param name="context">The context for this job.</param>
            <param name="status">The current status for this job.</param>
        </member>
        <member name="P:Encog.Util.Concurrency.Job.ConcurrentJob.ThreadCount">
            <summary>
            Set the thread count, 0 for auto, 1 for single-threaded, 
            otherwise the number of threads.
            </summary>
        </member>
        <member name="T:Encog.Util.Concurrency.Job.JobUnitContext">
            <summary>
            Holds basic configuration information for an Encog job.
            </summary>
        </member>
        <member name="P:Encog.Util.Concurrency.Job.JobUnitContext.JobUnit">
            <summary>
            The JobUnit that this context will execute.
            </summary>
        </member>
        <member name="P:Encog.Util.Concurrency.Job.JobUnitContext.Owner">
            <summary>
            The owner of this job.
            </summary>
        </member>
        <member name="P:Encog.Util.Concurrency.Job.JobUnitContext.TaskNumber">
            <summary>
            The task number.
            </summary>
        </member>
        <member name="T:Encog.Util.Concurrency.Job.JobUnitWorker">
            <summary>
            A worker job for Encog concurrency
            </summary>
        </member>
        <member name="F:Encog.Util.Concurrency.Job.JobUnitWorker._context">
            <summary>
            The context for this job unit.
            </summary>
        </member>
        <member name="M:Encog.Util.Concurrency.Job.JobUnitWorker.#ctor(Encog.Util.Concurrency.Job.JobUnitContext)">
            <summary>
            Construct a job unit worker to execute the specified job.
            </summary>
            <param name="context">The context of the job to execute.</param>
        </member>
        <member name="M:Encog.Util.Concurrency.Job.JobUnitWorker.Run">
            <summary>
            Run this job.
            </summary>
        </member>
        <member name="T:Encog.Util.Concurrency.PoolItem">
            <summary>
            An item in the thread pool.
            </summary>
        </member>
        <member name="F:Encog.Util.Concurrency.PoolItem._group">
            <summary>
            The task group that this item is a part of.
            </summary>
        </member>
        <member name="F:Encog.Util.Concurrency.PoolItem._owner">
            <summary>
            The concurrency object that started this.
            </summary>
        </member>
        <member name="F:Encog.Util.Concurrency.PoolItem._task">
            <summary>
            The task that was executed.
            </summary>
        </member>
        <member name="M:Encog.Util.Concurrency.PoolItem.#ctor(Encog.Util.Concurrency.EngineConcurrency,Encog.Util.Concurrency.IEngineTask,Encog.Util.Concurrency.TaskGroup)">
            <summary>
            Construct a pool item.
            </summary>
            <param name="owner">The owner of this task.</param>
            <param name="task">The task to execute.</param>
            <param name="group">The group that this task belongs to.</param>
        </member>
        <member name="M:Encog.Util.Concurrency.PoolItem.ThreadPoolCallback(System.Object)">
            <summary>
            The thread callback.  This actually executes the task.
            </summary>
            <param name="threadContext">The thread context, not used.</param>
        </member>
        <member name="T:Encog.Util.Concurrency.TaskGroup">
            <summary>
            A task group is a group of tasks that you would like to execute at once.  
            You can wait for all tasks in a task group to exit before your program
            continues.
            </summary>
        </member>
        <member name="F:Encog.Util.Concurrency.TaskGroup._completeEvent">
            <summary>
            The event used to sync waiting for tasks to stop.
            </summary>
        </member>
        <member name="F:Encog.Util.Concurrency.TaskGroup._id">
            <summary>
            The ID for this task group.
            </summary>
        </member>
        <member name="F:Encog.Util.Concurrency.TaskGroup._completedTasks">
            <summary>
            The number of tasks that have completed.
            </summary>
        </member>
        <member name="F:Encog.Util.Concurrency.TaskGroup._totalTasks">
            <summary>
            The total number of tasks in this group.
            </summary>
        </member>
        <member name="M:Encog.Util.Concurrency.TaskGroup.#ctor(System.Int32)">
            <summary>
            Create a task group with the specified id.
            </summary>
            <param name="id">The ID of the task group.</param>
        </member>
        <member name="P:Encog.Util.Concurrency.TaskGroup.ID">
            <summary>
            The ID of the task group.
            </summary>
        </member>
        <member name="P:Encog.Util.Concurrency.TaskGroup.NoTasks">
            <summary>
            Returns true if there are no more tasks.
            </summary>
        </member>
        <member name="M:Encog.Util.Concurrency.TaskGroup.TaskStarting">
            <summary>
            Notify that a task is starting.
            </summary>
        </member>
        <member name="M:Encog.Util.Concurrency.TaskGroup.TaskStopping">
            <summary>
            Notify that a task is stopping.
            </summary>
        </member>
        <member name="M:Encog.Util.Concurrency.TaskGroup.WaitForComplete">
            <summary>
            Wait for all tasks to complete in this group.
            </summary>
        </member>
        <member name="T:Encog.Util.EncogValidate">
             <summary>
             Used to validate if training is valid.
             </summary>
            
        </member>
        <member name="M:Encog.Util.EncogValidate.#ctor">
             <summary>
             Private constructor.
             </summary>
            
        </member>
        <member name="M:Encog.Util.EncogValidate.ValidateNetworkForTraining(Encog.Neural.Networks.IContainsFlat,Encog.ML.Data.IMLDataSet)">
             <summary>
             Validate a network for training.
             </summary>
            
             <param name="network">The network to validate.</param>
             <param name="training">The training set to validate.</param>
        </member>
        <member name="T:Encog.Util.EngineArray">
            <summary>
            Simple array utilities for Encog.
            </summary>
        </member>
        <member name="M:Encog.Util.EngineArray.ArrayCopy(System.Double[])">
            <summary>
            Copy a double array.
            </summary>
            <param name="input">The array to copy.</param>
            <returns>The result of the copy.</returns>
        </member>
        <member name="M:Encog.Util.EngineArray.ArrayCopy(System.Int32[])">
            <summary>
            Copy an int array.
            </summary>
            <param name="input">The array to copy.</param>
            <returns>The result of the copy.</returns>
        </member>
        <member name="M:Encog.Util.EngineArray.ArrayCopy(System.Double[],System.Double[])">
            <summary>
            Completely copy one array into another. 
            </summary>
            <param name="src">Source array.</param>
            <param name="dst">Destination array.</param>
        </member>
        <member name="M:Encog.Util.EngineArray.ArrayCopy(System.Int32[],System.Int32[])">
            <summary>
            Completely copy one array into another. 
            </summary>
            <param name="src">Source array.</param>
            <param name="dst">Destination array.</param>
        </member>
        <member name="M:Encog.Util.EngineArray.VectorProduct(System.Double[],System.Double[])">
            <summary>
            Calculate the product of two vectors (a scalar value).
            </summary>
            <param name="a">First vector to multiply.</param>
            <param name="b">Second vector to multiply.</param>
            <returns>The product of the two vectors (a scalar value).</returns>
        </member>
        <member name="M:Encog.Util.EngineArray.AllocateDouble2D(System.Int32,System.Int32)">
            <summary>
            Allocate a 2D array of doubles.
            </summary>
            <param name="rows">The number of rows.</param>
            <param name="cols">The number of columns.</param>
            <returns>The array.</returns>
        </member>
        <member name="M:Encog.Util.EngineArray.AllocateBool2D(System.Int32,System.Int32)">
            <summary>
            Allocate a 2D array of bools.
            </summary>
            <param name="rows">The number of rows.</param>
            <param name="cols">The number of columns.</param>
            <returns>The array.</returns>
        </member>
        <member name="M:Encog.Util.EngineArray.ArrayCopy(System.Double[],System.Int32,System.Double[],System.Int32,System.Int32)">
            <summary>
            Copy an array of doubles.
            </summary>
            <param name="source">The source array.</param>
            <param name="sourceIndex">The source index.</param>
            <param name="output">The output array.</param>
            <param name="targetIndex">The output index.</param>
            <param name="size">The size to copy.</param>
        </member>
        <member name="M:Encog.Util.EngineArray.ListToDouble(System.Collections.Generic.IList{System.Double})">
            <summary>
            Convert the collection to an array list of doubles.
            </summary>
            <param name="list">The list to convert.</param>
            <returns>The array of doubles.</returns>
        </member>
        <member name="M:Encog.Util.EngineArray.Fill(System.Double[],System.Double)">
            <summary>
            Fill the specified array with the specified value.
            </summary>
            <param name="p">The array to fill.</param>
            <param name="v">The value to fill.</param>
        </member>
        <member name="M:Encog.Util.EngineArray.FindStringInArray(System.String[],System.String)">
            <summary>
            Search for a string in an array. 
            </summary>
            <param name="search">Where to search.</param>
            <param name="searchFor">What we are looking for.</param>
            <returns>The index that the string occurs at.</returns>
        </member>
        <member name="M:Encog.Util.EngineArray.TransferNvaluesOfSerie(System.Int32,System.Double[])">
            <summary>
            Gets the last N closing values of a double serie;
            copied in a new double serie.
            </summary>
            <param name="lenth">The lenth to get.</param>
            <param name="closes"></param>
            <returns>a double serie with the last n requested values.</returns>
        </member>
        <member name="M:Encog.Util.EngineArray.ArrayCopy(System.Double[][])">
            <summary>
            Copy a 2d array.
            </summary>
            <param name="source">The source.</param>
            <returns>The result.</returns>
        </member>
        <member name="M:Encog.Util.EngineArray.ArrayCopy(System.Single[],System.Double[])">
            <summary>
            Copy a float array to a double array.
            </summary>
            <param name="source">The double array.</param>
            <param name="target">The float array.</param>
        </member>
        <member name="M:Encog.Util.EngineArray.ArrayCopy(System.Double[],System.Single[])">
            <summary>
            Copy a double array to a float array.
            </summary>
            <param name="source">The double array.</param>
            <param name="target">The float array.</param>
        </member>
        <member name="M:Encog.Util.EngineArray.Fill(System.Double[],System.Int32)">
            <summary>
            Fill the array with the specified value.
            </summary>
            <param name="target">The array to fill.</param>
            <param name="v">The value to fill.</param>
        </member>
        <member name="M:Encog.Util.EngineArray.Fill(System.Single[],System.Int32)">
            <summary>
            Fill the array with the specified value.
            </summary>
            <param name="target">The array to fill.</param>
            <param name="v">The value to fill.</param>
        </member>
        <member name="M:Encog.Util.EngineArray.IndexOfLargest(System.Double[])">
            <summary>
            Get the index of the largest value in the array.
            </summary>
            <param name="data">The array to search.</param>
            <returns>The index.</returns>
        </member>
        <member name="M:Encog.Util.EngineArray.Min(System.Double[])">
            <summary>
            Get the min value in an array.
            </summary>
            <param name="weights">The array to search.</param>
            <returns>The result.</returns>
        </member>
        <member name="M:Encog.Util.EngineArray.Max(System.Double[])">
            <summary>
            Get the max value from an array.
            </summary>
            <param name="weights">The array to search.</param>
            <returns>The value.</returns>
        </member>
        <member name="M:Encog.Util.EngineArray.PutAll``2(System.Collections.Generic.IDictionary{``0,``1},System.Collections.Generic.IDictionary{``0,``1})">
            <summary>
            Put all elements from one dictionary to another.
            </summary>
            <typeparam name="TK">The key type.</typeparam>
            <typeparam name="TV">The value type.</typeparam>
            <param name="source">The source dictionary.</param>
            <param name="target">The target dictionary.</param>
        </member>
        <member name="M:Encog.Util.EngineArray.Contains(System.Int32[],System.Int32)">
            <summary>
            Determine if the array contains the specified number.
            </summary>
            <param name="array">The array to search.</param>
            <param name="target">The number being searched for.</param>
            <returns>True, if the number was found.</returns>
        </member>
        <member name="M:Encog.Util.EngineArray.MaxIndex(System.Double[])">
            <summary>
            Get the index of the max value in the array.
            </summary>
            <param name="data">The array to search.</param>
            <returns>The result</returns>
        </member>
        <member name="M:Encog.Util.EngineArray.MaxIndex(System.Int32[])">
            <summary>
            Get the index of the max value in the array.
            </summary>
            <param name="data">The array to search.</param>
            <returns>The result</returns>
        </member>
        <!-- Проигнорирован некорректный комментарий XML для члена "M:Encog.Util.EngineArray.CreateArray``1(System.Int32,System.Func{``0})" -->
        <member name="M:Encog.Util.EngineArray.Fill(System.Boolean[],System.Boolean)">
            <summary>
            Fill the array with the specified value.
            </summary>
            <param name="array">The array.</param>
            <param name="v">The value.</param>
        </member>
        <member name="M:Encog.Util.EngineArray.Add(System.Double[],System.Double[])">
            <summary>
            Add two vectors.
            </summary>
            <param name="d">First vector.</param>
            <param name="m">Second vector.</param>
            <returns>Result vector.</returns>
        </member>
        <member name="M:Encog.Util.EngineArray.Subtract(System.Double[],System.Double[])">
            <summary>
            Subtract two vectors.
            </summary>
            <param name="a">First vector.</param>
            <param name="b">Second vector.</param>
            <returns>Result vector.</returns>
        </member>
        <member name="M:Encog.Util.EngineArray.ArrayCopy(System.Double[][],System.Double[][])">
            <summary>
            Copy one double 2d array to another.
            </summary>
            <param name="source">The source array.</param>
            <param name="target">The target array.</param>
        </member>
        <member name="M:Encog.Util.EngineArray.EuclideanDistance(System.Double[],System.Double[])">
            <summary>
            Calculate the Euclidean distance between two vectors.
            </summary>
            <param name="p1">The first vector.</param>
            <param name="p2">The second vector.</param>
            <returns>The distance.</returns>
        </member>
        <member name="T:Encog.Util.Error.CalculateRegressionError">
            <summary>
            Calculate the error for regression based Machine Learning Methods.
            </summary>
        </member>
        <member name="M:Encog.Util.Error.CalculateRegressionError.CalculateError(Encog.ML.IMLRegression,Encog.ML.Data.IMLDataSet)">
            <summary>
            Calculate an error for a method that uses regression.
            </summary>
            <param name="method">The method to evaluate.</param>
            <param name="data">The training data to evaluate with.</param>
            <returns>The error.</returns>
        </member>
        <member name="T:Encog.Util.File.Directory">
             <summary>
             Directory utilities.
             </summary>
            
        </member>
        <member name="F:Encog.Util.File.Directory.BufferSize">
             <summary>
             Default buffer size for read/write operations.
             </summary>
            
        </member>
        <member name="M:Encog.Util.File.Directory.CopyFile(System.IO.FileInfo,System.IO.FileInfo)">
             <summary>
             Copy the specified file.
             </summary>
            
             <param name="source">The file to copy.</param>
             <param name="target">The target of the copy.</param>
        </member>
        <member name="M:Encog.Util.File.Directory.DeleteDirectory(System.IO.FileInfo)">
             <summary>
             Delete a directory and all children.
             </summary>
            
             <param name="path">The path to delete.</param>
             <returns>True if successful.</returns>
        </member>
        <member name="M:Encog.Util.File.Directory.ReadStream(System.IO.Stream)">
             <summary>
             Read the entire contents of a stream into a string.
             </summary>
            
             <param name="mask0">The input stream to read from.</param>
             <returns>The string that was read in.</returns>
        </member>
        <member name="M:Encog.Util.File.Directory.ReadTextFile(System.String)">
             <summary>
             Read the entire contents of a stream into a string.
             </summary>
            
             <param name="filename">The input stream to read from.</param>
             <returns>The string that was read in.</returns>
        </member>
        <member name="T:Encog.Util.File.FileUtil">
            <summary>
            Contains several utilities for working with files.
            </summary>
        </member>
        <member name="M:Encog.Util.File.FileUtil.AddFilenameBase(System.IO.FileInfo,System.String)">
            <summary>
            Add, or replace a filename base.  A filename base is between an underbar
            and the . for the extension.  For example: "myfile_raw.csv", the base is
            "raw".
            </summary>
            <param name="filename"></param>
            <param name="bs"></param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.File.FileUtil.GetFileName(System.IO.FileInfo)">
            <summary>
            Get the filename, without extension.
            </summary>
            <param name="file">The file to parse.</param>
            <returns>The file name.</returns>
        </member>
        <member name="M:Encog.Util.File.FileUtil.GetFileExt(System.IO.FileInfo)">
            <summary>
            Get the file extension.
            </summary>
            <param name="file">The base file.</param>
            <returns>The extension.</returns>
        </member>
        <member name="M:Encog.Util.File.FileUtil.ReadFileAsString(System.IO.FileInfo)">
            <summary>
            Read a file into a string.
            </summary>
            <param name="filePath">The file to read.</param>
            <returns>The contents of the file.</returns>
        </member>
        <member name="M:Encog.Util.File.FileUtil.ForceExtension(System.String,System.String)">
            <summary>
            Change a file's extension.
            </summary>
            <param name="name">The filename to change.</param>
            <param name="ext">The new extension.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.File.FileUtil.WriteFileAsString(System.IO.FileInfo,System.String)">
            <summary>
            Write a string to a file.
            </summary>
            <param name="path"></param>
            <param name="str"></param>
        </member>
        <member name="M:Encog.Util.File.FileUtil.Copy(System.IO.FileInfo,System.IO.FileInfo)">
            <summary>
            Copy from one file to another.
            </summary>
            <param name="source">The source file.</param>
            <param name="target">The target file.</param>
        </member>
        <member name="M:Encog.Util.File.FileUtil.Copy(System.IO.Stream,System.IO.Stream)">
            <summary>
            Copy from one stream to another.
            </summary>
            <param name="mask0">The source.</param>
            <param name="os">The target.</param>
        </member>
        <member name="M:Encog.Util.File.FileUtil.CopyResource(System.String,System.IO.FileInfo)">
            <summary>
            Copy a resource to the file system.
            </summary>
            <param name="resource">The resource to copy.</param>
            <param name="targetFile">There to copy the resource to.</param>
        </member>
        <member name="M:Encog.Util.File.FileUtil.CombinePath(System.IO.FileInfo,System.String)">
            <summary>
            Combine a path with a filename.
            </summary>
            <param name="dir">The path to combine.</param>
            <param name="f">The filename to combine.</param>
            <returns>The resulting path.</returns>
        </member>
        <member name="M:Encog.Util.File.FileUtil.CopyStream(System.IO.Stream,System.IO.Stream)">
            <summary>
            Copy a stream from one 
            </summary>
            <param name="input"></param>
            <param name="output"></param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.File.FileUtil.MoveFileOrDirectory(System.String,System.String)">
             <summary>
            Move a file or directory to a destination path.
             </summary>
             <param name="fromPath">From path.</param>
             <param name="toPath">To path.</param>
             <returns>true if we were able to move the file or directory.</returns>
        </member>
        <member name="T:Encog.Util.File.ResourceLoader">
            <summary>
            Used to load data from resources.
            </summary>
        </member>
        <member name="M:Encog.Util.File.ResourceLoader.#ctor">
            <summary>
            Private constructor.
            </summary>
        </member>
        <member name="M:Encog.Util.File.ResourceLoader.CreateStream(System.String)">
            <summary>
            Create a stream to read the resource.
            </summary>
            <param name="resource">The resource to load.  This should be in the form Encog.Resources.classes.txt</param>
            <returns>A stream.</returns>
        </member>
        <member name="M:Encog.Util.File.ResourceLoader.LoadString(System.String)">
            <summary>
            Load a string.
            </summary>
            <param name="resource">The resource to load.</param>
            <returns>The loaded string.</returns>
        </member>
        <member name="T:Encog.Util.Format">
            <summary>
            Provides the ability for Encog to format numbers and times.
            </summary>
        </member>
        <member name="F:Encog.Util.Format.HundredPercent">
            <summary>
            One hundred percent.
            </summary>
        </member>
        <member name="F:Encog.Util.Format.MemoryK">
            <summary>
            Bytes in a KB.
            </summary>
        </member>
        <member name="F:Encog.Util.Format.MemoryMeg">
            <summary>
            Bytes in a MB.
            </summary>
        </member>
        <member name="F:Encog.Util.Format.MemoryGig">
            <summary>
            Bytes in a GB.
            </summary>
        </member>
        <member name="F:Encog.Util.Format.MemoryTera">
            <summary>
            Bytes in a TB.
            </summary>
        </member>
        <member name="F:Encog.Util.Format.SecondsInaMinute">
            <summary>
            Seconds in a minute.
            </summary>
        </member>
        <member name="F:Encog.Util.Format.SecondsInaHour">
            <summary>
            Seconds in an hour.
            </summary>
        </member>
        <member name="F:Encog.Util.Format.SecondsInaDay">
            <summary>
            Seconds in a day.
            </summary>
        </member>
        <member name="F:Encog.Util.Format.MiliInSec">
            <summary>
            Miliseconds in a day.
            </summary>
        </member>
        <member name="M:Encog.Util.Format.#ctor">
            <summary>
            Private constructor.
            </summary>
        </member>
        <member name="M:Encog.Util.Format.FormatDouble(System.Double,System.Int32)">
            <summary>
            Format a double.
            </summary>
            <param name="d">The double value to format.</param>
            <param name="i">The number of decimal places.</param>
            <returns>The double as a string.</returns>
        </member>
        <member name="M:Encog.Util.Format.FormatMemory(System.Int64)">
            <summary>
            Format a memory amount, to something like 32 MB.
            </summary>
            <param name="memory">The amount of bytes.</param>
            <returns>The formatted memory size.</returns>
        </member>
        <member name="M:Encog.Util.Format.FormatInteger(System.Int32)">
            <summary>
            Format an integer.
            </summary>
            <param name="i">The integer.</param>
            <returns>The string.</returns>
        </member>
        <member name="M:Encog.Util.Format.FormatPercent(System.Double)">
            <summary>
            Format a percent.  Using 6 decimal places.
            </summary>
            <param name="e">The percent to format.</param>
            <returns>The formatted percent.</returns>
        </member>
        <member name="M:Encog.Util.Format.FormatPercentWhole(System.Double)">
            <summary>
            Format a percent with no decimal places.
            </summary>
            <param name="e">The format to percent.</param>
            <returns>The formatted percent.</returns>
        </member>
        <member name="M:Encog.Util.Format.FormatTimeSpan(System.Int32)">
            <summary>
            Format a time span as seconds, minutes, hours and days.
            </summary>
            <param name="seconds">The number of seconds in the timespan.</param>
            <returns>The formatted timespan.</returns>
        </member>
        <member name="M:Encog.Util.Format.FormatYesNo(System.Boolean)">
            <summary>
            Format a boolean to yes/no.
            </summary>
            <param name="p">The default answer.</param>
            <returns>A string form of the boolean.</returns>
        </member>
        <member name="T:Encog.Util.HTMLReport">
            <summary>
            A utility for generating HTML reports.
            </summary>
        </member>
        <member name="F:Encog.Util.HTMLReport._text">
            <summary>
            Text.
            </summary>
        </member>
        <member name="M:Encog.Util.HTMLReport.#ctor">
            <summary>
            Construct the object.
            </summary>
        </member>
        <member name="M:Encog.Util.HTMLReport.BeginHTML">
            <summary>
            Begin an HTML tag.
            </summary>
        </member>
        <member name="M:Encog.Util.HTMLReport.EndHTML">
            <summary>
            End an HTML tag.
            </summary>
        </member>
        <member name="M:Encog.Util.HTMLReport.Title(System.String)">
            <summary>
            Set the title.
            </summary>
            <param name="str">The title.</param>
        </member>
        <member name="M:Encog.Util.HTMLReport.BeginPara">
            <summary>
            Begin an HTML para.
            </summary>
        </member>
        <member name="M:Encog.Util.HTMLReport.EndPara">
            <summary>
            End an HTML para.
            </summary>
        </member>
        <member name="M:Encog.Util.HTMLReport.Bold(System.String)">
            <summary>
            Display in bold.
            </summary>
            <param name="str"></param>
        </member>
        <member name="M:Encog.Util.HTMLReport.Para(System.String)">
            <summary>
            Display a para.
            </summary>
            <param name="str">The para to display.</param>
        </member>
        <member name="M:Encog.Util.HTMLReport.Clear">
            <summary>
            Clear the report.
            </summary>
        </member>
        <member name="M:Encog.Util.HTMLReport.ToString">
            <summary>
            Convert the report to a string.
            </summary>
            <returns>The report text.</returns>
        </member>
        <member name="M:Encog.Util.HTMLReport.BeginBody">
            <summary>
            Begin the HTML body.
            </summary>
        </member>
        <member name="M:Encog.Util.HTMLReport.EndBody">
            <summary>
            End the HTML body.
            </summary>
        </member>
        <member name="M:Encog.Util.HTMLReport.H1(System.String)">
            <summary>
            Create a H1.
            </summary>
            <param name="title"></param>
        </member>
        <member name="M:Encog.Util.HTMLReport.BeginTable">
            <summary>
            Begin a table.
            </summary>
        </member>
        <member name="M:Encog.Util.HTMLReport.EndTable">
            <summary>
            End a table.
            </summary>
        </member>
        <member name="M:Encog.Util.HTMLReport.BeginRow">
            <summary>
            Begin a row of a table.
            </summary>
        </member>
        <member name="M:Encog.Util.HTMLReport.EndRow">
            <summary>
            End a row of a table.
            </summary>
        </member>
        <member name="M:Encog.Util.HTMLReport.Header(System.String)">
            <summary>
            Add a header cell.
            </summary>
            <param name="head">The text to use.</param>
        </member>
        <member name="M:Encog.Util.HTMLReport.Cell(System.String)">
            <summary>
            Add a cell, no column span.
            </summary>
            <param name="head">The head of that call.</param>
        </member>
        <member name="M:Encog.Util.HTMLReport.Cell(System.String,System.Int32)">
            <summary>
            Add a cell to a table.
            </summary>
            <param name="head">The text for the cell.</param>
            <param name="colSpan">The col span.</param>
        </member>
        <member name="M:Encog.Util.HTMLReport.TablePair(System.String,System.String)">
            <summary>
            Add a name-value pair to a table.  This includes a row.
            </summary>
            <param name="name">The name.</param>
            <param name="v">The value.</param>
        </member>
        <member name="M:Encog.Util.HTMLReport.H2(System.String)">
            <summary>
            Add a H2.
            </summary>
            <param name="title">The title.</param>
        </member>
        <member name="M:Encog.Util.HTMLReport.H3(System.String)">
            <summary>
            Add a H3.
            </summary>
            <param name="title">The title.</param>
        </member>
        <member name="M:Encog.Util.HTMLReport.BeginList">
            <summary>
            Begin a list.
            </summary>
        </member>
        <member name="M:Encog.Util.HTMLReport.ListItem(System.String)">
            <summary>
            Add a list item.
            </summary>
            <param name="str">The item added.</param>
        </member>
        <member name="M:Encog.Util.HTMLReport.EndList">
            <summary>
            End a list.
            </summary>
        </member>
        <member name="M:Encog.Util.HTMLReport.BeginTableInCell(System.Int32)">
            <summary>
            Begin a new table in a cell.
            </summary>
            <param name="colSpan">The column span.</param>
        </member>
        <member name="M:Encog.Util.HTMLReport.EndTableInCell">
            <summary>
            End a table in a cell.
            </summary>
        </member>
        <member name="M:Encog.Util.HTMLReport.Encode(System.String)">
            <summary>
            Encode a string for HTML.
            </summary>
            <param name="str">The string to encode.</param>
            <returns>The encoded string.</returns>
        </member>
        <member name="T:Encog.Util.KMeans.Cluster`1">
            <summary>
            A cluster.
            </summary>
            <typeparam name="T">The type of data to cluster.</typeparam>
        </member>
        <member name="F:Encog.Util.KMeans.Cluster`1._contents">
            <summary>
            The contents of the cluster.
            </summary>
        </member>
        <member name="F:Encog.Util.KMeans.Cluster`1._centroid">
            <summary>
            The centroid of this cluster.
            </summary>
        </member>
        <member name="M:Encog.Util.KMeans.Cluster`1.#ctor">
            <summary>
            Create an empty cluster.
            </summary>
        </member>
        <member name="M:Encog.Util.KMeans.Cluster`1.#ctor(`0)">
            <summary>
            Create a cluster with one initial data point. 
            </summary>
            <param name="d">The initial data point.</param>
        </member>
        <member name="P:Encog.Util.KMeans.Cluster`1.Contents">
            <summary>
            The contents of this cluster.
            </summary>
        </member>
        <member name="M:Encog.Util.KMeans.Cluster`1.Add(`0)">
            <summary>
            Add a element to the cluster.
            </summary>
            <param name="e">The element to add.</param>
        </member>
        <member name="M:Encog.Util.KMeans.Cluster`1.Remove(System.Int32)">
            <summary>
            Remove the specified index from the cluster. 
            </summary>
            <param name="i">The index to remove.</param>
        </member>
        <member name="M:Encog.Util.KMeans.Cluster`1.Centroid">
            <summary>
            The centroid of this cluster.
            </summary>
            <returns>The centroid.</returns>
        </member>
        <member name="T:Encog.Util.KMeans.ICentroid`1">
            <summary>
            A centroid.
            </summary>
            <typeparam name="TO">The type.</typeparam>
        </member>
        <member name="M:Encog.Util.KMeans.ICentroid`1.Add(`0)">
            <summary>
            Add an element to the centroid.
            </summary>
            <param name="e">The element to add.</param>
        </member>
        <member name="M:Encog.Util.KMeans.ICentroid`1.Remove(`0)">
            <summary>
            Remove an element from the centroid. 
            </summary>
            <param name="o">The element to remove.</param>
        </member>
        <member name="M:Encog.Util.KMeans.ICentroid`1.Distance(`0)">
            <summary>
            The distance between this centroid and an element. 
            </summary>
            <param name="o">The element.</param>
            <returns>The distance.</returns>
        </member>
        <member name="T:Encog.Util.KMeans.ICentroidFactory`1">
            <summary>
            An object that can create centroids.
            </summary>
            <typeparam name="TO">The element type for the centroid.</typeparam>
        </member>
        <member name="M:Encog.Util.KMeans.ICentroidFactory`1.CreateCentroid">
            <summary>
            The centroid.
            </summary>
            <returns>The centroid.</returns>
        </member>
        <member name="T:Encog.Util.KMeans.KMeansUtil`1">
            <summary>
            Generic KMeans clustering object.
            </summary>
            <typeparam name="TK">The type to cluster</typeparam>
        </member>
        <member name="F:Encog.Util.KMeans.KMeansUtil`1._clusters">
            <summary>
            The clusters.
            </summary>
        </member>
        <member name="F:Encog.Util.KMeans.KMeansUtil`1._k">
            <summary>
            The number of clusters.
            </summary>
        </member>
        <member name="M:Encog.Util.KMeans.KMeansUtil`1.#ctor(System.Int32,System.Collections.IList)">
            <summary>
            Construct the clusters.  Call process to perform the cluster.
            </summary>
            <param name="theK">The number of clusters.</param>
            <param name="theElements">The elements to cluster.</param>
        </member>
        <member name="P:Encog.Util.KMeans.KMeansUtil`1.Count">
            <summary>
            The number of clusters.
            </summary>
        </member>
        <member name="M:Encog.Util.KMeans.KMeansUtil`1.InitRandomClusters(System.Collections.IList)">
            <summary>
            Create random clusters. 
            </summary>
            <param name="elements">The elements to cluster.</param>
        </member>
        <member name="M:Encog.Util.KMeans.KMeansUtil`1.Process">
            <summary>
            Perform the cluster.
            </summary>
        </member>
        <member name="M:Encog.Util.KMeans.KMeansUtil`1.NearestCluster(`0)">
            <summary>
            Find the nearest cluster to the element. 
            </summary>
            <param name="element">The element.</param>
            <returns>The nearest cluster.</returns>
        </member>
        <member name="M:Encog.Util.KMeans.KMeansUtil`1.Get(System.Int32)">
            <summary>
            Get a cluster by index.
            </summary>
            <param name="index">The index to get.</param>
            <returns>The cluster.</returns>
        </member>
        <member name="M:Encog.Util.KMeans.KMeansUtil`1.GetCluster(System.Int32)">
            <summary>
            Get a cluster by index.
            </summary>
            <param name="i">The index to get.</param>
            <returns>The cluster.</returns>
        </member>
        <member name="T:Encog.Util.Logging.EncogLogging">
             <summary>
             This class provides logging for Encog. Programs using Encog can make use of
             it as well. All logging is passed on to the current logging plugin. By
             default the SystemLoggingPlugin is used.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Logging.EncogLogging.LevelDebug">
             <summary>
             The lowest level log type. Debug logging provides low-level Encog
             diagnostics that may slow performance, but allow you to peer into the
             inner workings.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Logging.EncogLogging.LevelInfo">
             <summary>
             Info logging tells you when major processes start and stop.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Logging.EncogLogging.LevelError">
             <summary>
             Error level tells you about errors, less important to critical.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Logging.EncogLogging.LevelCritical">
             <summary>
             Critical logging logs errors that cannot be recovered from.
             </summary>
            
        </member>
        <member name="F:Encog.Util.Logging.EncogLogging.LevelDisable">
             <summary>
             Logging is disabled at this level.
             </summary>
            
        </member>
        <member name="P:Encog.Util.Logging.EncogLogging.CurrentLevel">
            <value>The current logging level.</value>
        </member>
        <member name="M:Encog.Util.Logging.EncogLogging.Log(System.Int32,System.String)">
             <summary>
             Log the message.
             </summary>
            
             <param name="level">The level to log at.</param>
             <param name="message">The message to log.</param>
        </member>
        <member name="M:Encog.Util.Logging.EncogLogging.Log(System.Int32,System.Exception)">
             <summary>
             Log the error.
             </summary>
            
             <param name="level">The level to log at.</param>
             <param name="t">The exception to log.</param>
        </member>
        <member name="M:Encog.Util.Logging.EncogLogging.Log(System.Exception)">
             <summary>
             Log the error at ERROR level.
             </summary>
            
             <param name="t">The exception to log.</param>
        </member>
        <member name="T:Encog.Util.Logging.DumpMatrix">
            <summary>
            A utility for writing matrixes to the log.
            </summary>
        </member>
        <member name="F:Encog.Util.Logging.DumpMatrix.MaxPrecis">
            <summary>
            Maximum precision.
            </summary>
        </member>
        <member name="M:Encog.Util.Logging.DumpMatrix.#ctor">
            <summary>
            Private constructor.
            </summary>
        </member>
        <member name="M:Encog.Util.Logging.DumpMatrix.DumpArray(System.Double[])">
            <summary>
            Dump an array of numbers to a string.
            </summary>
            <param name="d">The array to dump.</param>
            <returns>The array as a string.</returns>
        </member>
        <member name="M:Encog.Util.Logging.DumpMatrix.DumpMatrixString(Encog.MathUtil.Matrices.Matrix)">
            <summary>
            Dump a matrix to a string.
            </summary>
            <param name="matrix">The matrix.</param>
            <returns>The matrix as a string.</returns>
        </member>
        <member name="T:Encog.Util.NetworkUtil.DateNormalize">
            <summary>
            Use this class to normalize a date with hours, days, months, year, seconds.
            This class uses the equilateral normalization.
            </summary>
        </member>
        <member name="T:Encog.Util.NetworkUtil.QuickCSVUtils">
            <summary>
            A class that reads csv columns.
            Useful if you need to read inputs from multiple CSV, or just need to read one input but not the rest..Less intensive on the memory usage.
            </summary>
        </member>
        <member name="M:Encog.Util.NetworkUtil.QuickCSVUtils.QuickParseCSV(System.String,Encog.Util.CSV.CSVFormat,System.String)">
            <summary>
            parses one column of a csv and returns an array of doubles.
            you can only return one double array with this method.
            </summary>
            <param name="file">The file.</param>
            <param name="formatused">The formatused.</param>
            <param name="Name">The name of the column to parse..</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.QuickCSVUtils.QuickParseCSV(System.String,System.String)">
            <summary>
            parses one column of a csv and returns an array of doubles.
            you can only return one double array with this method.
            We are assuming CSVFormat english in this quick parse csv method.
            </summary>
            <param name="file">The file.</param>
            <param name="Name">The name of the column to parse.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.QuickCSVUtils.QuickParseCSV(System.String,System.String,System.Int32)">
            <summary>
            parses one column of a csv and returns an array of doubles.
            you can only return one double array with this method.
            We are assuming CSVFormat english in this quick parse csv method.
            You can input the size (number of lines) to read.
            </summary>
            <param name="file">The file.</param>
            <param name="Name">The name of the column to parse.</param>
            <param name="size">The size.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.QuickCSVUtils.QuickParseCSV(System.String,System.String,System.Int32,System.Int32)">
            <summary>
            parses one column of a csv and returns an array of doubles.
            you can only return one double array with this method.
            We are assuming CSVFormat english in this quick parse csv method.
            You can input the size (number of lines) to read and the number of lines you want to skip from the start line
            </summary>
            <param name="file">The file.</param>
            <param name="Name">The name of the column to parse.</param>
            <param name="size">The size.</param>
            <param name="StartLine">The start line (how many lines you want to skip from the start of the file.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.QuickCSVUtils.QuickParseCSV(System.String,System.Int32,System.Int32)">
            <summary>
            parses one column of a csv and returns an array of doubles.
            you can only return one double array with this method.
            We are assuming CSVFormat english in this quick parse csv method.
            You can input the size (number of lines) to read.
            </summary>
            <param name="file">The file.</param>
            <param name="columnNumber">The column number to get.</param>
            <param name="size">The size.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.QuickCSVUtils.QuickParseCSVForDate(System.String,System.DateTime,System.String)">
             <summary>
             use this method to find a date in your csv , and it will return the line number..
             This is useful for evaluation purpose when you need to find the line number so you can check against the real price and the network output prices.
            You must specify the DateFormat ("yyyy-MM-dd HH:mm:ss") for example.
             </summary>
             <param name="file">The file.</param>
             <param name="datetoFind">The date to find.</param>
             <param name="DateFormat">The date format.</param>
             <returns></returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.QuickCSVUtils.QuickParseCSVForDate(System.String,System.DateTime,System.String,System.Int32)">
            <summary>
            use this method to find a date in your csv , and it will return the line number..
            This is useful for evaluation purpose when you need to find the line number so you can check against the real price and the network output prices.
            You can specifiy which column number you date are with this method.
            You must specify the DateFormat ("yyyy-MM-dd HH:mm:ss") for example.
            </summary>
            <param name="file">The file.</param>
            <param name="datetoFind">The date to find.</param>
            <param name="DateFormat">The date format.</param>
            <param name="Columnnumber">The columnnumber.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.QuickCSVUtils.QuickParseCSV(System.String,System.Int32,System.Int32,System.Int32)">
            <summary>
            parses one column of a csv and returns an array of doubles.
            you can only return one double array with this method.
            We are assuming CSVFormat english in this quick parse csv method.
            You can input the size (number of lines) to read , and the number of lines you want to skip start from the first line.
            </summary>
            <param name="file">The file.</param>
            <param name="columnNumber">The column number to get.</param>
            <param name="size">The size.</param>
            <param name="startLine">The start line (how many lines you want to skip from the first line.</param>
            <returns></returns>
        </member>
        <member name="T:Encog.Util.NetworkUtil.TrainerHelper">
            <summary>
            Use this helper class to build training inputs for neural networks (only memory based datasets).
            Mostly this class is used in financial neural networks when receiving multiple inputs (indicators, prices, etc) and 
            having to put them in neural datasets.
            
            </summary>
        </member>
        <member name="M:Encog.Util.NetworkUtil.TrainerHelper.MakeDoubleJaggedInputFromArray(System.Double[],System.Int32)">
            <summary>
            Makes the double [][] from single array.
            this is a very important method used in financial markets when you have multiple inputs (Close price, 1 indicator, 1 ATR, 1 moving average for example) , and each is already formated in an array of doubles.
            You just provide the number of inputs (4 here) , and it will create the resulting double [][]
            </summary>
            <param name="array">The array.</param>
            <param name="numberofinputs">The numberofinputs.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.TrainerHelper.DoubleInputsToArraySimple(System.Collections.Generic.List{System.Double},System.Int32)">
            <summary>
            Doubles the List of doubles into a jagged array.
            This is exactly similar as the MakeDoubleJaggedInputFromArray just it takes a List of double as parameter.
            It quite easier to Add doubles to a list than into a double [] Array (so this method is used more).
            </summary>
            <param name="inputs">The inputs.</param>
            <param name="lenght">The lenght.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.TrainerHelper.ProcessDoubleSerieIntoIMLDataset(System.Double[],System.Int32,System.Int32)">
            <summary>
            Processes the specified double serie into an IMLDataset.
            To use this method, you must provide a formated double array.
            The number of points in the input window makes the input array , and the predict window will create the array used in ideal.
            Example you have an array with 1, 2, 3 , 4 , 5.
            You can use this method to make an IMLDataset 4 inputs and 1 ideal (5).
            </summary>
            <param name="data">The data.</param>
            <param name="_inputWindow">The _input window.</param>
            <param name="_predictWindow">The _predict window.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.TrainerHelper.ProcessDoubleSerieIntoIMLDataset(System.Collections.Generic.List{System.Double},System.Collections.Generic.List{System.Double},System.Int32,System.Int32)">
            <summary>
            Processes the specified double serie into an IMLDataset.
            To use this method, you must provide a formated double array with the input data and the ideal data in another double array.
            The number of points in the input window makes the input array , and the predict window will create the array used in ideal.
            This method will use ALL the data inputs and ideals you have provided.
            </summary>
            <param name="datainput">The datainput.</param>
            <param name="ideals">The ideals.</param>
            <param name="_inputWindow">The _input window.</param>
            <param name="_predictWindow">The _predict window.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.TrainerHelper.CreateIdealFromSerie(System.Collections.Generic.List{System.Double},System.Int32)">
            <summary>
            Grabs every Predict point in a double serie.
            This is useful if you have a double series and you need to grab every 5 points for examples and make an ourput serie (like in elmhan networks).
            E.G , 1, 2, 1, 2,5 ...and you just need the 5..
            </summary>
            <param name="inputs">The inputs.</param>
            <param name="PredictSize">Size of the predict.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.TrainerHelper.GenerateTrainingWithRawSerie(System.Double[],System.Int32,System.Int32)">
            <summary>
            Generates the Temporal MLDataset with a given data array.
            You must input the "predict" size (inputs) and the windowsize (outputs).
            This is oftenly used with Ehlman networks.
            The temporal dataset will be in RAW format (no normalization used..Most of the times it means you already have normalized your inputs /ouputs.
            
            </summary>
            <param name="inputserie">The inputserie.</param>
            <param name="windowsize">The windowsize.</param>
            <param name="predictsize">The predictsize.</param>
            <returns>A temporalMLDataset</returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.TrainerHelper.GenerateTrainingWithDeltaChangeOnSerie(System.Double[],System.Int32,System.Int32)">
            <summary>
            Generates the training with delta change on serie.
            </summary>
            <param name="inputserie">The inputserie.</param>
            <param name="windowsize">The windowsize.</param>
            <param name="predictsize">The predictsize.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.TrainerHelper.GenerateTrainingWithPercentChangeOnSerie(System.Int32,System.Int32,System.Double[][])">
            <summary>
            Generates a temporal data set with a given double serie or a any number of double series , making your inputs.
            uses Type percent change.
            </summary>
            <param name="windowsize">The windowsize.</param>
            <param name="predictsize">The predictsize.</param>
            <param name="inputserie">The inputserie.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.TrainerHelper.NetworkbuilArrayByParams(System.Double[][])">
            <summary>
            This method takes ARRAYS of arrays (parametrable arrays) and places them in double [][]
            You can use this method if you have already formated arrays and you want to create a double [][] ready for network.
            Example you could use this method to input the XOR example:
            A[0,0]   B[0,1]  C[1, 0]  D[1,1] would format them directly in the double [][] in one method call.
            This could also be used in unsupersivsed learning.
            </summary>
            <param name="Inputs">The inputs.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.TrainerHelper.PrinteJaggedArray(System.Int32[][])">
            <summary>
            Prints the content of an array to the console.(Mostly used in debugging).
            </summary>
            <param name="num">The num.</param>
        </member>
        <member name="M:Encog.Util.NetworkUtil.TrainerHelper.ProcessPairs(System.Double[],System.Double[],System.Int32,System.Int32)">
            <summary>
            Processes a double array of data of input and a second array of data for ideals
            you must input the input and output size.
            this typically builds a supervised IMLDatapair, which you must add to a IMLDataset. 
            </summary>
            <param name="data">The data.</param>
            <param name="ideal">The ideal.</param>
            <param name="_inputWindow">The _input window.</param>
            <param name="_predictWindow">The _predict window.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.TrainerHelper.FromDualToJagged(System.Double[],System.Double[])">
            <summary>
            Takes 2 inputs arrays and makes a jagged array.
            this just copies the second array after the first array in a double [][]
            </summary>
            <param name="firstArray">The first array.</param>
            <param name="SecondArray">The second array.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.TrainerHelper.ReturnArrayOnSize(System.Double[],System.Int32)">
            <summary>
            Calculates and returns the copied array.
            This is used in live data , when you want have a full array of doubles but you want to cut from a starting position
            and return only from that point to the end.
            example you have 1000 doubles , but you want only the last 100.
            input size is the input you must set to 100.
            I use this method next to every day when calculating on an array of doubles which has just received a new price (A quote for example).
            As the array of quotes as all the quotes since a few days, i just need the last 100 for example , so this method is used when not training but using the neural network.
            </summary>
            <param name="inputted">The inputted.</param>
            <param name="inputsize">The input neuron size (window size).</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.TrainerHelper.QuickTrainingFromDoubleArray(System.Double[],System.Int32,System.Int32)">
            <summary>
            Quickly an IMLDataset from a double array using the TemporalWindow array.
            </summary>
            <param name="array">The array.</param>
            <param name="inputsize">The inputsize.</param>
            <param name="outputsize">The outputsize.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.TrainerHelper.GenerateInputz(System.Double[][])">
            <summary>
            Generates an array with as many double array inputs as wanted.
            This is useful for neural networks when you have already formated your data arrays and need to create a double []
            with all the inputs following each others.
            </summary>
            <param name="inputs">The inputs.</param>
            <returns>
            the double [] array with all inputs.
            </returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.TrainerHelper.AddInputsViaLinq(System.Int32,System.Double[][])">
            <summary>
            Prepare realtime inputs, and place them in an understandable one jagged input neuron array.
            This method uses linq.
            you can use this method if you have many inputs and need to format them as inputs with a specified "window"/input size.
            You can add as many inputs as wanted to this input layer (parametrable inputs).
            </summary>
            <param name="inputsize">The inputsize.</param>
            <param name="firstinputt">The firstinputt.</param>
            <returns>a ready to use jagged array with all the inputs setup.</returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.TrainerHelper.AddInputs(System.Int32,System.Double[][])">
            <summary>
            Prepare realtime inputs, and place them in an understandable one jagged input neuron array.
            you can use this method if you have many inputs and need to format them as inputs with a specified "window"/input size.
            You can add as many inputs as wanted to this input layer (parametrable inputs).
            </summary>
            <param name="inputsize">The inputsize.</param>
            <param name="firstinputt">The firstinputt.</param>
            <returns>a ready to use jagged array with all the inputs setup.</returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.TrainerHelper.MakeDataSet(System.Double[],System.Int32,System.Double[][])">
            <summary>
            Makes a data set with parametrable inputs and one output double array.
            you can provide as many inputs as needed and the timelapse size (input size).
            for more information on this method read the AddInputs Method.
            </summary>
            <param name="outputs">The outputs.</param>
            <param name="inputsize">The inputsize.</param>
            <param name="firstinputt">The firstinputt.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.TrainerHelper.MakeRandomIMLDataset(System.Int32,System.Int32,System.Int32)">
            <summary>
            Makes a random dataset with the number of IMLDatapairs.
            Quite useful to test networks (benchmarks).
            </summary>
            <param name="inputs">The inputs.</param>
            <param name="predictWindow">The predict window.</param>
            <param name="numberofPairs">The numberof pairs.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.NetworkUtil.TrainerHelper.MakeSetFromInputsSources(System.Int32,System.Double[][])">
            <summary>
            This is the most used method in finance.
            You send directly your double arrays and get an IMLData set ready for network training.
            You must place your ideal data as the last double data array.
            IF you have 1 data of closing prices, 1 moving average, 1 data series of interest rates , and the data you want to predict 
            This method will look the lenght of the first Data input to calculate how many points to take from each array.
            this is the method you will use to make your Dataset.
            </summary>
            <param name="number">The number.</param>
            <param name="inputs">The inputs.</param>
            <returns></returns>
        </member>
        <member name="T:Encog.Util.Normalize.DataNormalization">
            <summary>
            This class is used to normalize both input and ideal data for neural
            networks. This class can accept input from a variety of sources and output to
            a variety of targets. Normalization is a process by which input data is
            normalized so that it falls in specific ranges. Neural networks typically
            require input to be in the range of 0 to 1, or -1 to 1, depending on how the
            network is structured.
            
            The normalize class is typically given for different types of objects to tell
            it how to process data.
            
            Input Fields:
            
            Input fields specify the raw data that will be read by the Normalize class.
            Input fields are added to the Normalize class by calling addInputField
            method. Input fields must implement the InputField interface. There are a
            number of different input fields provided. Input data can be read from
            several different sources. For example, you can read the "neural network
            input" data from one CSV file and the "ideal neural network output" from
            another.
            
            
            Output Fields:
            
            The output fields are used to specify the final output from the Normalize
            class. The output fields specify both the "neural network input" and "ideal
            output". The output fields are flagged as either input our ideal. The output
            fields are not necessarily one-to-one with the input fields. For example,
            several input fields may combine to produce a single output field. Further
            some input fields may be used only to segregate data, whereas other input
            fields may be ignored all together. The type of output field that you specify
            determines the type of processing that will be done on that field. An
            OutputField is added by calling the addOutputField method.
            
            
            Segregators:
            
            Segregators are used generally for two related purposes. First, segregators
            can be used to exclude rows of data based on certain input values. Perhaps
            the data includes several classes of data, and you only want to train on one
            class. Secondly, segregators can be used to segregate data into training and
            evaluation sets. You may choose to use 80% of your data for training and 20%
            for evaluation. A segregator is added by calling the addSegregator method.
            
            
            Target Storage:
            
            The data created by the Normalization class must be stored somewhere. The
            storage targets allow this to be specified. The output can be sent to a CSV
            file, a NeuralDataSet, or any other target supported by a
            NormalizationStorage derived class. The target is specified by calling the
            setTarget method.
            
            The normalization process can take some time.  The progress can be reported
            to a StatusReportable object.
            
            The normalization is a two pass process.  The first pass counts the number
            of records and computes important statistics that will be used to 
            normalize the output.  The second pass actually performs the normalization
            and writes to the target.  Both passes are performed when the process
            method is called.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.DataNormalization._csvMap">
            <summary>
            Hold a map between the InputFieldCSV objects and the corresponding
            ReadCSV object. There will likely be many fields read from a single file.
            This allows only one ReadCSV object to need to be created per actual CSV
            file.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.DataNormalization._dataSetFieldMap">
            <summary>
            Map each of the input fields to an internally-build NeuralDataFieldHolder object.
            The NeuralDataFieldHolder object holds an Iterator, InputField and last 
            NeuralDataPair object loaded.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.DataNormalization._dataSetIteratorMap">
            <summary>
            Map each of the NeuralDataSet Iterators to an internally-build NeuralDataFieldHolder 
            object. The NeuralDataFieldHolder object holds an Iterator, InputField and last 
            NeuralDataPair object loaded.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.DataNormalization._groups">
            <summary>
            Output fields can be grouped together, if the value of one output field might 
            affect all of the others.  This collection holds a list of all of the output 
            field groups.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.DataNormalization._inputFields">
            <summary>
            The input fields.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.DataNormalization._outputFields">
            <summary>
            The output fields.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.DataNormalization._readCSV">
            <summary>
            Keep a collection of all of the ReadCSV classes to support all of the
            distinct CSV files that are to be read.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.DataNormalization._readDataSet">
            <summary>
            For each InputFieldNeuralDataSet input field an Iterator must be kept to
            actually access the data. Only one Iterator should be kept per data set
            actually used.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.DataNormalization._segregators">
            <summary>
            A list of the segregators.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.DataNormalization._csvFormat">
            <summary>
            The format to use for all CSV files.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.DataNormalization._currentIndex">
            <summary>
            The current record's index.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.DataNormalization._lastReport">
            <summary>
            How long has it been since the last report.  This filters so that
            every single record does not produce a message.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.DataNormalization._recordCount">
            <summary>
            The number of records that were found in the first pass.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.DataNormalization._report">
            <summary>
            The object to report the progress of the normalization to.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.DataNormalization._storage">
            <summary>
            Where the final output from the normalization is sent.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.DataNormalization.CSVFormatUsed">
            <summary>
            The CSV format being used.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.DataNormalization.Groups">
            <summary>
            The object groups.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.DataNormalization.InputFields">
            <summary>
            The input fields.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.DataNormalization.OutputFields">
            <summary>
            The output fields.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.DataNormalization.RecordCount">
            <summary>
            The record count.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.DataNormalization.Report">
            <summary>
            The class that progress will be reported to.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.DataNormalization.Segregators">
            <summary>
            The segregators in use.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.DataNormalization.Storage">
            <summary>
            The place that the normalization output will be stored.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.AddInputField(Encog.Util.Normalize.Input.IInputField)">
            <summary>
            Add an input field.
            </summary>
            <param name="f">The input field to add.</param>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.AddOutputField(Encog.Util.Normalize.Output.IOutputField)">
            <summary>
             Add an output field.  This output field will be added as a 
            "neural network input field", not an "ideal output field".
            </summary>
            <param name="outputField">The output field to add.</param>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.AddOutputField(Encog.Util.Normalize.Output.IOutputField,System.Boolean)">
            <summary>
            Add a field and allow it to be specified as an "ideal output field".
            An "ideal" field is the expected output that the neural network is
            training towards.
            </summary>
            <param name="outputField">The output field.</param>
            <param name="ideal">True if this is an ideal field.</param>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.AddSegregator(Encog.Util.Normalize.Segregate.ISegregator)">
            <summary>
             Add a segregator.
            </summary>
            <param name="segregator">The segregator to add.</param>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.ApplyMinMax">
            <summary>
            Called internally to allow each of the input fields to update their
            min/max values in the first pass.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.BuildForNetworkInput(System.Double[])">
            <summary>
            Build "input data for a neural network" based on the input values
            provided.  This allows  input for a neural network to be normalized.
            This is typically used when data is to be presented to a trained
            neural network.
            </summary>
            <param name="data">The input values to be normalized.</param>
            <returns>The data to be sent to the neural network.</returns>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.DetermineInputFieldValue(Encog.Util.Normalize.Input.IInputField,System.Int32)">
            <summary>
            Called internally to obtain the current value for an input field.
            </summary>
            <param name="field">The input field to determine.</param>
            <param name="index">The current index.</param>
            <returns>The value for this input field.</returns>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.DetermineInputFieldValues(System.Int32)">
            <summary>
            Called internally to determine all of the input field values.
            </summary>
            <param name="index">The current index.</param>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.DetermineInputFieldValues(System.Int32,System.Boolean)">
            <summary>
            Called internally to determine all of the input field values.
            </summary>
            <param name="index">The current index.</param>
            <param name="headers">if set to <c>true</c> [headers].</param>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.FindInputField(System.Type,System.Int32)">
            <summary>
            Find an input field by its class.
            </summary>
            <param name="clazz">The input field class type you are looking for.</param>
            <param name="count">The instance of the input field needed, 0 for the first.</param>
            <returns>The input field if found, otherwise null.</returns>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.FindOutputField(System.Type,System.Int32)">
            <summary>
            Find an output field by its class.
            </summary>
            <param name="clazz">The output field class type you are looking for.</param>
            <param name="count">The instance of the output field needed, 0 for the first.</param>
            <returns>The output field if found, otherwise null.</returns>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.FirstPass(System.Boolean)">
            <summary>
            First pass, count everything, establish min/max.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.FirstPass">
            <summary>
            First pass, count everything, establish min/max.
            This version doesn't read column names in csvinputfields.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.GetNetworkInputLayerSize">
            <summary>
            Calculate the number of output fields that are not used as ideal
            values, these will be the input to the neural network.
            This is the input layer size for the neural network.
            </summary>
            <returns>The input layer size.</returns>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.GetNetworkOutputLayerSize">
            <summary>
            The number of output fields that are used as ideal
            values, these will be the ideal output from the neural network.
            This is the output layer size for the neural network.
            </summary>
            <returns>The output layer size.</returns>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.GetOutputFieldCount">
            <summary>
            The total size of all output fields.  This takes into
            account output fields that generate more than one value.
            </summary>
            <returns>The output field count.</returns>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.InitForOutput">
            <summary>
            Setup the row for output.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.Next">
            <summary>
            Called internally to advance to the next row.
            </summary>
            <returns>True if there are more rows to reed.</returns>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.OpenCSV">
            <summary>
            Called internally to open the CSV file.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.OpenCSV(System.Boolean)">
            <summary>
            Called internally to open the CSV file with header.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.OpenDataSet">
            <summary>
            Open any datasets that were used by the input layer.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.Process">
            <summary>
            Call this method to begin the normalization process.  Any status 
            updates will be sent to the class specified in the constructor.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.Process(System.Boolean)">
            <summary>
            Call this method to begin the normalization process.  Any status 
            updates will be sent to the class specified in the constructor.
            this version uses headers.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.ReportResult(System.String,System.Int32,System.Int32)">
            <summary>
            Report on the current progress.
            </summary>
            <param name="message">The message to report.</param>
            <param name="total">The total number of records to process, 0 for unknown.</param>
            <param name="current"> The current record.</param>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.SecondPass">
            <summary>
            The second pass actually writes the data to the output files.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.SecondPass(System.Boolean)">
            <summary>
            The second pass actually writes the data to the output files.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.ShouldInclude">
            <summary>
            Should this row be included? Check the segregatprs.
            </summary>
            <returns>True if the row should be included.</returns>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.InitForPass">
            <summary>
            Setup the row for output.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.DataNormalization.TwoPassesNeeded">
            <summary>
            Determine if two passes will be needed.
            </summary>
            <returns>True if two passes will be needed.</returns>
        </member>
        <member name="T:Encog.Util.Normalize.Input.BasicInputField">
            <summary>
            Provides basic functionality, such as min/max and current value
            for other input fields.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Input.BasicInputField._max">
            <summary>
            The minimum value encountered so far for this field.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Input.BasicInputField._min">
            <summary>
            The maximum value encountered so far for this field.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Input.BasicInputField._usedForNetworkInput">
            <summary>
            True if this field is used to actually generate the input for
            the neural network.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Input.BasicInputField.ApplyMinMax(System.Double)">
            <summary>
            Given the current value, apply to the min and max values.
            </summary>
            <param name="d">The current value.</param>
        </member>
        <member name="P:Encog.Util.Normalize.Input.BasicInputField.CurrentValue">
            <summary>
            The current value of the input field.  This is only valid, 
            while the normalization is being performed.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Input.BasicInputField.Max">
            <summary>
            The maximum value for all of the input data, this is calculated
            during the first pass of normalization.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Input.BasicInputField.Min">
            <summary>
            The minimum value for all of the input data, this is calculated
            during the first pass of normalization.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Input.BasicInputField.GetValue(System.Int32)">
            <summary>
            Not supported for this sort of class, may be implemented in subclasses.
            Will throw an exception.
            </summary>
            <param name="i">The index.  Not used.</param>
            <returns>The value at the specified index.</returns>
        </member>
        <member name="P:Encog.Util.Normalize.Input.BasicInputField.UsedForNetworkInput">
            <summary>
            True, if this field is used for network input.  
            This is needed so that the buildForNetworkInput method of the 
            normalization class knows how many input fields to expect.  For instance, 
            fields used only to segregate data are not used for the actual network 
            input and may not be provided when the network is actually being queried.
            </summary>
        </member>
        <member name="T:Encog.Util.Normalize.Input.IHasFixedLength">
            <summary>
            Is this input field of a fixed length, such as an array?  Or is it
            read "iterator style" where we call "next" until there is no more 
            data.  If the length can be "known" ahead of time, then the input 
            field should support this interface.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Input.IHasFixedLength.Length">
            <summary>
            The number of records in this input field.
            </summary>
        </member>
        <member name="T:Encog.Util.Normalize.Input.IInputField">
            <summary>
             * A Normalization input field.  This field defines data that needs to be 
            normalized.  There are many different types of normalization field that can
            be used for many different purposes.
            
            To assist in normalization each input file tracks the min and max values for
            that field.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Input.IInputField.CurrentValue">
            <summary>
            The current value of the input field.  This is only valid, 
            while the normalization is being performed.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Input.IInputField.Max">
            <summary>
            The maximum value for all of the input data, this is calculated
            during the first pass of normalization.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Input.IInputField.Min">
            <summary>
            The minimum value for all of the input data, this is calculated
            during the first pass of normalization.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Input.IInputField.UsedForNetworkInput">
            <summary>
            True, if this field is used for network input.  This is needed
            so that the buildForNetworkInput method of the normalization class knows
            how many input fields to expect.  For instance, fields used only to 
            segregate data are not used for the actual network input and may
            not be provided when the network is actually being queried.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Input.IInputField.ApplyMinMax(System.Double)">
            <summary>
            Update the min and max values for this field with the specified values.
            </summary>
            <param name="d">The current value to use to update min and max.</param>
        </member>
        <member name="M:Encog.Util.Normalize.Input.IInputField.GetValue(System.Int32)">
            <summary>
            Called for input field types that require an index to get the current
            value. This is used by the InputFieldArray1D and InputFieldArray2D
            classes.
            </summary>
            <param name="i">The index to read.</param>
            <returns>The value read.</returns>
        </member>
        <member name="T:Encog.Util.Normalize.Input.InputFieldArray1D">
            <summary>
            An input field that comes from a 1D array.
            
            Note: this input field will not be persisted to an EG file.
            This is because it could point to a lengthy array, that really
            has no meaning inside of an EG file. 
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Input.InputFieldArray1D._array">
            <summary>
            A reference to the array.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Input.InputFieldArray1D.#ctor(System.Boolean,System.Double[])">
            <summary>
            Construct the 1D array field.
            </summary>
            <param name="usedForNetworkInput">True if this field is used for the actual
            input to the neural network.  See getUsedForNetworkInput for more info.</param>
            <param name="array">The array to use.</param>
        </member>
        <member name="P:Encog.Util.Normalize.Input.InputFieldArray1D.Length">
            <summary>
            The length of the array.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Input.InputFieldArray1D.GetValue(System.Int32)">
            <summary>
            Get the value from the specified index.
            </summary>
            <param name="i">The index to retrieve.</param>
            <returns>The value at the specified index.</returns>
        </member>
        <member name="T:Encog.Util.Normalize.Input.InputFieldArray2D">
            <summary>
             * An input field that comes from a 2D array. The first dimension
            of the array will be used to read each successive row.  The second
            dimension is fixed, and specified in the constructor.  You would create
            multiple InputFieldArray2D object to read each of the "columns" stored
            at each row.
            
            Note: this input field will not be persisted to an EG file.
            This is because it could point to a lengthy array, that really
            has no meaning inside of an EG file.  
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Input.InputFieldArray2D._array">
            <summary>
            The 2D array to use.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Input.InputFieldArray2D._index2">
            <summary>
            The 2nd dimension index to read the field from.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Input.InputFieldArray2D.#ctor(System.Boolean,System.Double[][],System.Int32)">
            <summary>
            Construct a 2D array input.
            </summary>
            <param name="usedForNetworkInput">Construct a 2D array input field.</param>
            <param name="array">The array to use.</param>
            <param name="index2">index2 The secondary index to read the field from.</param>
        </member>
        <member name="P:Encog.Util.Normalize.Input.InputFieldArray2D.Length">
            <summary>
            The number of rows in the array.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Input.InputFieldArray2D.GetValue(System.Int32)">
            <summary>
            Gen index.
            </summary>
            <param name="i">Read a value from the specified index.</param>
            <returns>The value read.</returns>
        </member>
        <member name="T:Encog.Util.Normalize.Input.InputFieldCSV">
            <summary>
            An input field based on a CSV file.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Input.InputFieldCSV._file">
            <summary>
            The file to read.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Input.InputFieldCSV._offset">
            <summary>
            The CSV column represented by this field.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Input.InputFieldCSV.#ctor">
            <summary>
            Construct an InputFieldCSV with the default constructor.  This is mainly
            used for reflection.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Input.InputFieldCSV.#ctor(System.Boolean,System.String,System.Int32)">
            <summary>
            Construct a input field for a CSV file.
            </summary>
            <param name="usedForNetworkInput">True if this field is used for actual 
            input to the neural network, as opposed to segregation only.</param>
            <param name="file">The tile to read.</param>
            <param name="offset">The CSV file column to read.</param>
        </member>
        <member name="M:Encog.Util.Normalize.Input.InputFieldCSV.#ctor(System.Boolean,System.String,System.String)">
            <summary>
            Construct a input field for a CSV file.
            </summary>
            <param name="usedForNetworkInput">True if this field is used for actual
            input to the neural network, as opposed to segregation only.</param>
            <param name="file">The tile to read.</param>
            <param name="columnname">The columnname you wish to read.</param>
        </member>
        <member name="P:Encog.Util.Normalize.Input.InputFieldCSV.File">
            <summary>
            The file being read.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Input.InputFieldCSV.Offset">
            <summary>
            The column in this CSV file to read.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Input.InputFieldCSV.ColumnName">
            <summary>
            Gets the name of the column we want to read.
            </summary>
            <value>
            The name of the column we want to read.
            </value>
        </member>
        <member name="T:Encog.Util.Normalize.Input.InputFieldMLDataSet">
            <summary>
            An input field based on an Encog NeuralDataSet.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Input.InputFieldMLDataSet._data">
            <summary>
            The data set.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Input.InputFieldMLDataSet._offset">
            <summary>
            The input or ideal index.  This treats the input and ideal as one
            long array, concatenated together.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Input.InputFieldMLDataSet.#ctor(System.Boolean,Encog.ML.Data.IMLDataSet,System.Int32)">
            <summary>
            Construct a input field based on a NeuralDataSet.
            </summary>
            <param name="usedForNetworkInput">Is this field used for neural input.</param>
            <param name="data">The data set to use.</param>
            <param name="offset">The input or ideal index to use. This treats the input 
            and ideal as one long array, concatenated together.</param>
        </member>
        <member name="P:Encog.Util.Normalize.Input.InputFieldMLDataSet.NeuralDataSet">
            <summary>
            The neural data set to read.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Input.InputFieldMLDataSet.Offset">
            <summary>
            The field to be accessed. This treats the input and 
            ideal as one long array, concatenated together.
            </summary>
        </member>
        <member name="T:Encog.Util.Normalize.Input.MLDataFieldHolder">
            <summary>
            Simple holder class used internally for Encog.
            Used as a holder for a:
            
             NeuralDataPair
             Enumeration
             InputFieldNeuralDataSet
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Input.MLDataFieldHolder._field">
            <summary>
            A field.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Input.MLDataFieldHolder._iterator">
            <summary>
            An iterator.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Input.MLDataFieldHolder._pair">
            <summary>
            A neural data pair.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Input.MLDataFieldHolder.#ctor(System.Collections.Generic.IEnumerator{Encog.ML.Data.IMLDataPair},Encog.Util.Normalize.Input.InputFieldMLDataSet)">
            <summary>
            Construct the class.
            </summary>
            <param name="iterator">An iterator.</param>
            <param name="field">A field.</param>
        </member>
        <member name="P:Encog.Util.Normalize.Input.MLDataFieldHolder.Field">
            <summary>
            The field.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Input.MLDataFieldHolder.Pair">
            <summary>
            The pair.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Input.MLDataFieldHolder.GetEnumerator">
            <summary>
            Get the enumerator.
            </summary>
            <returns>The enumerator.</returns>
        </member>
        <member name="M:Encog.Util.Normalize.Input.MLDataFieldHolder.ObtainPair">
            <summary>
            Obtain the next pair.
            </summary>
        </member>
        <member name="T:Encog.Util.Normalize.NormalizationError">
            <summary>
            Used for normalization errors.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.NormalizationError.#ctor(System.String)">
            <summary>
            Construct a message exception.
            </summary>
            <param name="str">The message.</param>
        </member>
        <member name="M:Encog.Util.Normalize.NormalizationError.#ctor(System.Exception)">
            <summary>
            Pass on an exception.
            </summary>
            <param name="e">The other exception.</param>
        </member>
        <member name="T:Encog.Util.Normalize.Output.BasicOutputField">
            <summary>
            Provides very basic functionality for output fields.  Primarily provides
            the ideal instance variable.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.BasicOutputField.RowInit">
            <summary>
            Init this field for a new row.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Output.BasicOutputField.SubfieldCount">
            <summary>
            The numebr of fields that will actually be generated by 
            this field. For a simple field, this value is 1.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.BasicOutputField.Calculate(System.Int32)">
            <summary>
            Calculate the value for this field.  Specify subfield of zero
            if this is a simple field.
            </summary>
            <param name="subfield"> The subfield index.</param>
            <returns>The calculated value for this field.</returns>
        </member>
        <member name="P:Encog.Util.Normalize.Output.BasicOutputField.Ideal">
            <summary>
            Is this field part of the ideal data uses to train the
            neural network.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.BasicOutputField.Calculate(System.Double,System.Double,System.Double,System.Double,System.Double)">
            <summary>
            Calculate a ranged mapped value.
            </summary>
            <param name="value">The to map.</param>
            <param name="min">The minimum that the value param can be.</param>
            <param name="max">The maximum that the value param can be.</param>
            <param name="hi">The high value to map into.</param>
            <param name="lo">The low value to map into.</param>
            <returns>The mapped value.</returns>
        </member>
        <member name="T:Encog.Util.Normalize.Output.BasicOutputFieldGroup">
            <summary>
            Provides very basic functionality that other output field groups
            will use.  Mainly provides the list of fields that are grouped.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.BasicOutputFieldGroup._fields">
            <summary>
            The fields in this group.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.BasicOutputFieldGroup.AddField(Encog.Util.Normalize.Output.OutputFieldGrouped)">
            <summary>
            Add a field to this group.
            </summary>
            <param name="field">The field to add to the group.</param>
        </member>
        <member name="P:Encog.Util.Normalize.Output.BasicOutputFieldGroup.GroupedFields">
            <summary>
            The list of grouped fields.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.BasicOutputFieldGroup.RowInit">
            <summary>
            Init for a new row.
            </summary>
        </member>
        <member name="T:Encog.Util.Normalize.Output.IOutputField">
             <summary>
             An output field, this represents the actual output from the 
             normalization.  Output from the normalization class is usually
             input to a neural network.
            
             An output field may contain several subfields that will be
             generated.  Call getSubfieldCount to determine how many fields
             will be generated.  A simple field will return 1, indicating that 
             this is a single field.
             </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Output.IOutputField.SubfieldCount">
            <summary>
            The numebr of fields that will actually be generated by 
            this field. For a simple field, this value is 1.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Output.IOutputField.Ideal">
            <summary>
            Is this field part of the ideal data uses to train the
            neural network.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.IOutputField.Calculate(System.Int32)">
            <summary>
            Calculate the value for this field.  Specify subfield of zero
            if this is a simple field.
            </summary>
            <param name="subfield"> The subfield index.</param>
            <returns>The calculated value for this field.</returns>
        </member>
        <member name="M:Encog.Util.Normalize.Output.IOutputField.RowInit">
            <summary>
            Init this field for a new row.
            </summary>
        </member>
        <member name="T:Encog.Util.Normalize.Output.IOutputFieldGroup">
            <summary>
            Output fields can be grouped together if they are calculated together.
            This interface defines how a field group works.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Output.IOutputFieldGroup.GroupedFields">
            <summary>
            All of the output fields in this group.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.IOutputFieldGroup.AddField(Encog.Util.Normalize.Output.OutputFieldGrouped)">
            <summary>
            Add an output field to the group.
            </summary>
            <param name="field">The field to add.</param>
        </member>
        <member name="M:Encog.Util.Normalize.Output.IOutputFieldGroup.RowInit">
            <summary>
            Init the group for a new row.
            </summary>
        </member>
        <member name="T:Encog.Util.Normalize.Output.IRequireTwoPass">
            <summary>
            Interface flag that indicates that a field type requires two passes.
            </summary>
        </member>
        <member name="T:Encog.Util.Normalize.Output.Mapped.MappedRange">
            <summary>
            Simple class that is used internally to hold a range mapping.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.Mapped.MappedRange._high">
            <summary>
            The high value for the range.
            </summary>       
        </member>
        <member name="F:Encog.Util.Normalize.Output.Mapped.MappedRange._low">
            <summary>
            The low value for the range.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.Mapped.MappedRange._value">
            <summary>
            The value that should be returned for this range.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Mapped.MappedRange.#ctor(System.Double,System.Double,System.Double)">
            <summary>
            Construct the range mapping.
            </summary>
            <param name="low">The low value for the range.</param>
            <param name="high">The high value for the range.</param>
            <param name="value">The value that this range represents.</param>
        </member>
        <member name="P:Encog.Util.Normalize.Output.Mapped.MappedRange.High">
            <summary>
            The high value for this range.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Output.Mapped.MappedRange.Low">
            <summary>
            The low value for this range.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Output.Mapped.MappedRange.Value">
            <summary>
            The value that this range represents.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Mapped.MappedRange.InRange(System.Double)">
            <summary>
            Determine if the specified value is in the range.
            </summary>
            <param name="d">The value to check.</param>
            <returns>True if this value is within the range.</returns>
        </member>
        <member name="T:Encog.Util.Normalize.Output.Mapped.OutputFieldEncode">
            <summary>
            An encoded output field.  This allows ranges of output values to be
            mapped to specific values.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.Mapped.OutputFieldEncode._ranges">
            <summary>
            The ranges.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.Mapped.OutputFieldEncode._sourceField">
            <summary>
            The source field.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.Mapped.OutputFieldEncode._catchAll">
            <summary>
            The catch all value, if nothing matches, then use this value.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Mapped.OutputFieldEncode.#ctor(Encog.Util.Normalize.Input.IInputField)">
            <summary>
            Construct an encoded field.
            </summary>
            <param name="sourceField">The field that this is based on.</param>
        </member>
        <member name="P:Encog.Util.Normalize.Output.Mapped.OutputFieldEncode.SourceField">
            <summary>
            The source field.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Output.Mapped.OutputFieldEncode.SubfieldCount">
            <summary>
            Return 1, no subfield supported.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Output.Mapped.OutputFieldEncode.CatchAll">
            <summary>
            The catch all value that is to be returned if none
            of the ranges match.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Mapped.OutputFieldEncode.AddRange(System.Double,System.Double,System.Double)">
            <summary>
            Add a ranged mapped to a value.
            </summary>
            <param name="low">The low value for the range.</param>
            <param name="high">The high value for the range.</param>
            <param name="value">The value that the field should produce for this range.</param>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Mapped.OutputFieldEncode.Calculate(System.Int32)">
            <summary>
            Calculate the value for this field.
            </summary>
            <param name="subfield">Not used.</param>
            <returns>Return the value for the range the input falls within, or return
            the catchall if nothing matches.</returns>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Mapped.OutputFieldEncode.RowInit">
            <summary>
            Not needed for this sort of output field.
            </summary>
        </member>
        <member name="T:Encog.Util.Normalize.Output.Multiplicative.MultiplicativeGroup">
            <summary>
            Used to group multiplicative fields together.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.Multiplicative.MultiplicativeGroup._length">
            <summary>
            The "length" of this field.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Output.Multiplicative.MultiplicativeGroup.Length">
            <summary>
            The length of this field.  This is the sum of the squares of
            all of the groupped fields.  The square root of this sum is the 
            length. 
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Multiplicative.MultiplicativeGroup.RowInit">
            <summary>
            Called to init this group for a new field.  This recalculates the
            "length".
            </summary>
        </member>
        <member name="T:Encog.Util.Normalize.Output.Multiplicative.OutputFieldMultiplicative">
            <summary>
             * Both the multiplicative and z-axis normalization types allow a group of 
            outputs to be adjusted so that the "vector length" is 1.  Both go about it
            in different ways.  Certain types of neural networks require a vector length 
            of 1.
            
            The multiplicative normalization is more simple than Z-Axis normalization.  
            Almost always Z=Axis normalization is a better choice.  However, 
            multiplicative can perform better than Z-Axis when all of the values
            are near zero most of the time.  This can cause the "synthetic value"
            that z-axis uses to dominate and skew the answer.
            
             Multiplicative normalization works by calculating the vector length of
             the input fields and dividing each by that value.  This also presents 
             a problem, as the magnitude of the original fields is not used.  For 
             example, multiplicative normalization would not distinguish between
             (-2,1,3) and (-10,5,15).  Both would result in the same output.   
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Multiplicative.OutputFieldMultiplicative.#ctor">
            <summary>
            The default constructor.  Used for reflection.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Multiplicative.OutputFieldMultiplicative.#ctor(Encog.Util.Normalize.Output.IOutputFieldGroup,Encog.Util.Normalize.Input.IInputField)">
            <summary>
            Construct a multiplicative output field.
            </summary>
            <param name="group">The group this field belongs to.</param>
            <param name="field">The input field that this field is based on.</param>
        </member>
        <member name="P:Encog.Util.Normalize.Output.Multiplicative.OutputFieldMultiplicative.SubfieldCount">
            <summary>
            Always returns 1, subfields are not used for this field.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Multiplicative.OutputFieldMultiplicative.Calculate(System.Int32)">
            <summary>
            Calculate the value for this output field.
            </summary>
            <param name="subfield">The subfield is not used.</param>
            <returns>The value for this field.</returns>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Multiplicative.OutputFieldMultiplicative.RowInit">
            <summary>
            Not needed for this sort of output field.
            </summary>
        </member>
        <member name="T:Encog.Util.Normalize.Output.Nominal.NominalItem">
            <summary>
            A nominal item.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.Nominal.NominalItem._high">
            <summary>
            The high value for the range.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.Nominal.NominalItem._inputField">
            <summary>
            The input field used to verify against the range.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.Nominal.NominalItem._low">
            <summary>
            The low value for the range.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Nominal.NominalItem.#ctor">
            <summary>
            Construct a empty range item.  Used mainly for reflection.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Nominal.NominalItem.#ctor(Encog.Util.Normalize.Input.IInputField,System.Double,System.Double)">
            <summary>
            Create a nominal item.
            </summary>
            <param name="inputField">The field that this item is based on.</param>
            <param name="high">The high value.</param>
            <param name="low">The low value.</param>
        </member>
        <member name="P:Encog.Util.Normalize.Output.Nominal.NominalItem.High">
            <summary>
            The high value.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Output.Nominal.NominalItem.InputField">
            <summary>
            The input field value.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Output.Nominal.NominalItem.Low">
            <summary>
            The low value.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Nominal.NominalItem.BeginRow">
            <summary>
            Begin a row.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Nominal.NominalItem.IsInRange">
            <summary>
            Determine if the specified value is in range.
            </summary>
            <returns>True if this item is within range.</returns>
        </member>
        <member name="T:Encog.Util.Normalize.Output.Nominal.OutputEquilateral">
            <summary>
            Allows nominal items to be encoded using the equilateral method. This maps
            the nominal items into an array of input or output values minus 1. This can
            sometimes provide a more accurate representation than the "one of" method.
            Based on: Guiver and Klimasauskas (1991).
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.Nominal.OutputEquilateral._high">
            <summary>
            The high value to map into.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.Nominal.OutputEquilateral._items">
            <summary>
            The nominal items.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.Nominal.OutputEquilateral._low">
            <summary>
            The low value to map into.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.Nominal.OutputEquilateral._currentValue">
            <summary>
            The current value, which nominal item is selected.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.Nominal.OutputEquilateral._equilateral">
            <summary>
            The current equilateral matrix.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Nominal.OutputEquilateral.#ctor">
            <summary>
            Prodvide a default constructor for reflection.
            Use -1 for low and +1 for high.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Nominal.OutputEquilateral.#ctor(System.Double,System.Double)">
            <summary>
            Create an equilateral output field with the specified high and low output
            values. These will often be 0 to 1 or -1 to 1.
            </summary>
            <param name="high">The high output value.</param>
            <param name="low">The low output value.</param>
        </member>
        <member name="P:Encog.Util.Normalize.Output.Nominal.OutputEquilateral.Equilateral">
            <summary>
            The equalateral table being used.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Output.Nominal.OutputEquilateral.SubfieldCount">
            <summary>
            This is the total number of nominal items minus 1.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Nominal.OutputEquilateral.AddItem(Encog.Util.Normalize.Input.IInputField,System.Double)">
            <summary>
            Add a nominal value based on a single value.  This creates a 0.1 range
            around this value.
            </summary>
            <param name="inputField">The input field this is based on.</param>
            <param name="value">The value.</param>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Nominal.OutputEquilateral.AddItem(Encog.Util.Normalize.Input.IInputField,System.Double,System.Double)">
            <summary>
            Add a nominal item based on a range.
            </summary>
            <param name="inputField">The input field to use.</param>
            <param name="low">The low value of the range.</param>
            <param name="high">The high value of the range.</param>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Nominal.OutputEquilateral.Calculate(System.Int32)">
            <summary>
            Calculate the value for the specified subfield.
            </summary>
            <param name="subfield">The subfield to calculate for.</param>
            <returns>The calculated value.</returns>
        </member>
        <member name="P:Encog.Util.Normalize.Output.Nominal.OutputEquilateral.High">
            <summary>
            The high value of the range.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Output.Nominal.OutputEquilateral.Low">
            <summary>
            The low value of the range.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Nominal.OutputEquilateral.RowInit">
            <summary>
            Determine which item's index is the value.
            </summary>
        </member>
        <member name="T:Encog.Util.Normalize.Output.Nominal.OutputOneOf">
            <summary>
            An output field that uses the "on of" technique to represent input data. For
            example, if there were five nominal items, or classes, given then each one
            would be represented by a single output neuron that would be on or off.
            
            Often the OutputEquilateral class is a better choice to represent nominal
            items.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.Nominal.OutputOneOf._falseValue">
            <summary>
            What is the true value, often just "0" or "-1".
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.Nominal.OutputOneOf._items">
            <summary>
            The nominal items to represent.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.Nominal.OutputOneOf._trueValue">
            <summary>
            What is the true value, often just "1".
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Nominal.OutputOneOf.#ctor">
            <summary>
            Default constructor for reflection.  Use 1 for true, -1 for false.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Nominal.OutputOneOf.#ctor(System.Double,System.Double)">
            <summary>
            Construct a one-of field and specify the true and false value.
            </summary>
            <param name="trueValue">The true value.</param>
            <param name="falseValue">The false value.</param>
        </member>
        <member name="P:Encog.Util.Normalize.Output.Nominal.OutputOneOf.FalseValue">
            <summary>
            The false value.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Output.Nominal.OutputOneOf.SubfieldCount">
            <summary>
            The number of subfields, or nominal classes.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Nominal.OutputOneOf.AddItem(Encog.Util.Normalize.Input.IInputField,System.Double)">
            <summary>
            Add a nominal value specifying a single value, the high and low values
            will be 0.5 below and 0.5 above.
            </summary>
            <param name="inputField">The input field to use.</param>
            <param name="value">The value to calculate the high and low values off of.</param>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Nominal.OutputOneOf.AddItem(Encog.Util.Normalize.Input.IInputField,System.Double,System.Double)">
            <summary>
            Add a nominal item, specify the low and high values.
            </summary>
            <param name="inputField">The input field to base everything from.</param>
            <param name="low">The high value for this nominal item.</param>
            <param name="high">The low value for this nominal item.</param>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Nominal.OutputOneOf.Calculate(System.Int32)">
            <summary>
            Calculate the value for the specified subfield.
            </summary>
            <param name="subfield">The subfield to calculate for.</param>
            <returns>The calculated value for this field.</returns>
        </member>
        <member name="P:Encog.Util.Normalize.Output.Nominal.OutputOneOf.TrueValue">
            <summary>
            The true value.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.Normalize.Output.Nominal.OutputOneOf.RowInit">
            <summary>
            Not needed for this sort of output field.
            </summary>
        </member>
        <member name="T:Encog.Util.Normalize.Output.OutputFieldDirect">
            <summary>
            A direct output field, will simply pass the input value to the output.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.OutputFieldDirect._sourceField">
            <summary>
            The source field.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.OutputFieldDirect.#ctor">
            <summary>
            Default constructor for reflection.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.OutputFieldDirect.#ctor(Encog.Util.Normalize.Input.IInputField)">
            <summary>
            Construct a direct output field.
            </summary>
            <param name="sourceField">The source field to pass directly on.</param>
        </member>
        <member name="P:Encog.Util.Normalize.Output.OutputFieldDirect.SubfieldCount">
            <summary>
            Always returns 1, as subfields are not used.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.OutputFieldDirect.Calculate(System.Int32)">
            <summary>
            Calculate the value for this field. This will simply be the
            value from the input field. 
            </summary>
            <param name="subfield">Not used, as this output field type does not
            support subfields.</param>
            <returns>The calculated value.</returns>
        </member>
        <member name="M:Encog.Util.Normalize.Output.OutputFieldDirect.RowInit">
            <summary>
            Not needed for this sort of output field.
            </summary>
        </member>
        <member name="T:Encog.Util.Normalize.Output.OutputFieldGrouped">
            <summary>
             Defines an output field that can be grouped.  Groupable classes
            will extend this class.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.OutputFieldGrouped._group">
            <summary>
            The group that this field is a member of.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.OutputFieldGrouped._sourceField">
            <summary>
            The source field, this is the input field that provides data
            for this output field.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.OutputFieldGrouped.#ctor">
            <summary>
            Default constructor, used mainly for reflection.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.OutputFieldGrouped.#ctor(Encog.Util.Normalize.Output.IOutputFieldGroup,Encog.Util.Normalize.Input.IInputField)">
            <summary>
            Construct a grouped output field.
            </summary>
            <param name="group">The group that this field belongs to.</param>
            <param name="sourceField">The source field for this output field.</param>
        </member>
        <member name="P:Encog.Util.Normalize.Output.OutputFieldGrouped.Group">
            <summary>
            The group that this field belongs to.
            </summary>
            <returns></returns>
        </member>
        <member name="P:Encog.Util.Normalize.Output.OutputFieldGrouped.SourceField">
            <summary>
            The source field for this output field.
            </summary>
            <returns></returns>
        </member>
        <member name="P:Encog.Util.Normalize.Output.OutputFieldGrouped.SubfieldCount">
            <summary>
            The numebr of fields that will actually be generated by 
            this field. For a simple field, this value is 1.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.OutputFieldGrouped.RowInit">
            <summary>
            Init this field for a new row.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.OutputFieldGrouped.Calculate(System.Int32)">
            <summary>
            Calculate the value for this field.  Specify subfield of zero
            if this is a simple field.
            </summary>
            <param name="subfield"> The subfield index.</param>
            <returns>The calculated value for this field.</returns>
        </member>
        <member name="T:Encog.Util.Normalize.Output.OutputFieldRangeMapped">
            <summary>
            A ranged mapped output field.  This will scale the input so that it
            is between the high and low value.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.OutputFieldRangeMapped._field">
            <summary>
            The input field to scale.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.OutputFieldRangeMapped._high">
            <summary>
            The high value of the field.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.OutputFieldRangeMapped._low">
            <summary>
            The low value of the field.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.OutputFieldRangeMapped.#ctor">
            <summary>
            Default constructor, used mainly for reflection.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.OutputFieldRangeMapped.#ctor(Encog.Util.Normalize.Input.IInputField,System.Double,System.Double)">
            <summary>
            Construct a range mapped output field.
            </summary>
            <param name="field">The input field to base this on.</param>
            <param name="low">The low value.</param>
            <param name="high">The high value.</param>
        </member>
        <member name="M:Encog.Util.Normalize.Output.OutputFieldRangeMapped.#ctor(Encog.Util.Normalize.Input.IInputField)">
            <summary>
            Construct the output field with -1 for low and +1 for high.
            </summary>
            <param name="f">The input field.</param>
        </member>
        <member name="P:Encog.Util.Normalize.Output.OutputFieldRangeMapped.Field">
            <summary>
            The field that this output is based on.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Output.OutputFieldRangeMapped.High">
            <summary>
            The high value of the range to map into.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Output.OutputFieldRangeMapped.Low">
            <summary>
            The low value of the range to map into.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Output.OutputFieldRangeMapped.SubfieldCount">
            <summary>
            This field only produces one value, so this will return 1.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.OutputFieldRangeMapped.Calculate(System.Int32)">
            <summary>
            Calculate this output field.
            </summary>
            <param name="subfield">Not used.</param>
            <returns>The calculated value.</returns>
        </member>
        <member name="M:Encog.Util.Normalize.Output.OutputFieldRangeMapped.RowInit">
            <summary>
            Not needed for this sort of output field.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.OutputFieldRangeMapped.ConvertBack(System.Double)">
            <summary>
            Convert a number back after its been normalized.
            </summary>
            <param name="data">The number to convert back.</param>
            <returns>The result.</returns>
        </member>
        <member name="T:Encog.Util.Normalize.Output.ZAxis.OutputFieldZAxis">
            <summary>
            Both the multiplicative and z-axis normalization types allow a group of 
            outputs to be adjusted so that the "vector length" is 1.  Both go about it
            in different ways.  Certain types of neural networks require a vector length 
            of 1.
            
            Z-Axis normalization is usually a better choice than multiplicative.    
            However, multiplicative can perform better than Z-Axis when all of the 
            values are near zero most of the time.  This can cause the "synthetic value"
            that z-axis uses to dominate and skew the answer.
            
             Z-Axis gets its name from 3D computer graphics, where there is a Z-Axis
             extending from the plane created by the X and Y axes.  It has nothing to 
             do with z-scores or the z-transform of signal theory.
             
             To implement Z-Axis normalization a scaling factor must be created to multiply
             each of the inputs against.  Additionally, a synthetic field must be added.
             It is very important that this synthetic field be added to any z-axis
             group that you might use.  The synthetic field is represented by the
             OutputFieldZAxisSynthetic class.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.ZAxis.OutputFieldZAxis.#ctor(Encog.Util.Normalize.Output.IOutputFieldGroup,Encog.Util.Normalize.Input.IInputField)">
            <summary>
            Construct a ZAxis output field.
            </summary>
            <param name="group">The group this field belongs to.</param>
            <param name="field">The input field this is based on.</param>
        </member>
        <member name="P:Encog.Util.Normalize.Output.ZAxis.OutputFieldZAxis.SubfieldCount">
            <summary>
            The subfield count, which is one, as this field type does not
            have subfields.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.ZAxis.OutputFieldZAxis.Calculate(System.Int32)">
            <summary>
            Calculate the current value for this field. 
            </summary>
            <param name="subfield">Ignored, this field type does not have subfields.</param>
            <returns>The current value for this field.</returns>
        </member>
        <member name="M:Encog.Util.Normalize.Output.ZAxis.OutputFieldZAxis.RowInit">
            <summary>
            Not needed for this sort of output field.
            </summary>
        </member>
        <member name="T:Encog.Util.Normalize.Output.ZAxis.OutputFieldZAxisSynthetic">
            <summary>
            This field represents the synthetic value used in Z-Axis normalization.
            For more information see the OutputFieldZAxis class.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.ZAxis.OutputFieldZAxisSynthetic.#ctor(Encog.Util.Normalize.Output.IOutputFieldGroup)">
            <summary>
            Construct a synthetic output field for Z-Axis.
            </summary>
            <param name="group">The Z-Axis group that this belongs to.</param>
        </member>
        <member name="P:Encog.Util.Normalize.Output.ZAxis.OutputFieldZAxisSynthetic.SubfieldCount">
            <summary>
            The subfield count, which is one, as this field type does not
            have subfields.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.ZAxis.OutputFieldZAxisSynthetic.Calculate(System.Int32)">
            <summary>
            Calculate the synthetic value for this Z-Axis normalization.
            </summary>
            <param name="subfield">Not used.</param>
            <returns>The calculated value.</returns>
        </member>
        <member name="M:Encog.Util.Normalize.Output.ZAxis.OutputFieldZAxisSynthetic.RowInit">
            <summary>
            Not needed for this sort of output field.
            </summary>
        </member>
        <member name="T:Encog.Util.Normalize.Output.ZAxis.ZAxisGroup">
            <summary>
            Used to group Z-Axis fields together. Both OutputFieldZAxis and
            OutputFieldZAxisSynthetic fields may belong to this group. For
            more information see the OutputFieldZAxis class.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.ZAxis.ZAxisGroup._length">
            <summary>
            The calculated length.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Output.ZAxis.ZAxisGroup._multiplier">
            <summary>
            The multiplier, which is the value that all other values will be
            multiplied to become normalized.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Output.ZAxis.ZAxisGroup.Length">
            <summary>
            The vector length.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Output.ZAxis.ZAxisGroup.Multiplier">
            <summary>
            The value to multiply the other values by to normalize them.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Output.ZAxis.ZAxisGroup.RowInit">
            <summary>
            Initialize this group for a new row.
            </summary>
        </member>
        <member name="T:Encog.Util.Normalize.Segregate.Index.IndexRangeSegregator">
            <summary>
            An index segregator is used to segregate the data according to its index.
            Nothing about the data is actually compared. This makes the index range
            segregator very useful for breaking the data into training and validation
            sets. For example, you could very easily determine that 70% of the data is
            for training, and 30% for validation.
            
            This segregator takes a starting and ending index. Everything that is between
            these two indexes will be used.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Segregate.Index.IndexRangeSegregator._endingIndex">
            <summary>
            The ending index.
            </summary>        
        </member>
        <member name="F:Encog.Util.Normalize.Segregate.Index.IndexRangeSegregator._startingIndex">
            <summary>
            The starting index.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.Index.IndexRangeSegregator.#ctor">
            <summary>
            Default constructor for reflection.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.Index.IndexRangeSegregator.#ctor(System.Int32,System.Int32)">
            <summary>
            Construct an index range segregator.
            </summary>
            <param name="startingIndex">The starting index to allow.</param>
            <param name="endingIndex">The ending index to allow.</param>
        </member>
        <member name="P:Encog.Util.Normalize.Segregate.Index.IndexRangeSegregator.EndingIndex">
            <summary>
            The ending index.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Segregate.Index.IndexRangeSegregator.StartingIndex">
            <summary>
            The starting index.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.Index.IndexRangeSegregator.ShouldInclude">
            <summary>
            Determines if the current row should be included.
            </summary>
            <returns>True if the current row should be included.</returns>
        </member>
        <member name="T:Encog.Util.Normalize.Segregate.Index.IndexSampleSegregator">
            <summary>
            An index segregator is used to segregate the data according to its index.
            Nothing about the data is actually compared. This makes the index range
            segregator very useful for breaking the data into training and validation
            sets. For example, you could very easily determine that 70% of the data is
            for training, and 30% for validation.
            
            This segregator takes a starting and ending index, as well as a smple size.
            Everything that is between these two indexes will be used.  The sample 
            repeats over and over.  For example, if you choose a sample size of 10, 
            and a beginning index of 0 and an ending index of 5, you would get
            half of the first 10 element, then half of the next ten, and so on.
            
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Segregate.Index.IndexSampleSegregator._endingIndex">
            <summary>
            The ending index (within a sample).
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Segregate.Index.IndexSampleSegregator._sampleSize">
            <summary>
            The sample size.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Segregate.Index.IndexSampleSegregator._startingIndex">
            <summary>
            The starting index (within a sample).
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.Index.IndexSampleSegregator.#ctor">
            <summary>
            The default constructor, for reflection.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.Index.IndexSampleSegregator.#ctor(System.Int32,System.Int32,System.Int32)">
            <summary>
            Construct an index sample segregator.
            </summary>
            <param name="startingIndex">The starting index.</param>
            <param name="endingIndex">The ending index.</param>
            <param name="sampleSize">The sample size.</param>
        </member>
        <member name="P:Encog.Util.Normalize.Segregate.Index.IndexSampleSegregator.EndingIndex">
            <summary>
            The ending index.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Segregate.Index.IndexSampleSegregator.SampleSize">
            <summary>
            The sample size.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Segregate.Index.IndexSampleSegregator.StartingIndex">
            <summary>
            The starting index.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.Index.IndexSampleSegregator.ShouldInclude">
            <summary>
            Should this row be included.
            </summary>
            <returns>True if this row should be included.</returns>
        </member>
        <member name="T:Encog.Util.Normalize.Segregate.Index.IndexSegregator">
            <summary>
             The index segregator. An abstract class to build index based segregators off
            of. An index segregator is used to segregate the data according to its index.
            Nothing about the data is actually compared. This makes the index range
            segregator very useful for breaking the data into training and validation
            sets. For example, you could very easily determine that 70% of the data is
            for training, and 30% for validation.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Segregate.Index.IndexSegregator._currentIndex">
            <summary>
            The current index.  Updated rows are processed.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Segregate.Index.IndexSegregator._normalization">
            <summary>
            THe normalization object this belongs to.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Segregate.Index.IndexSegregator.CurrentIndex">
            <summary>
            The current index.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Segregate.Index.IndexSegregator.Owner">
            <summary>
            The normalization object this object will use.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.Index.IndexSegregator.Init(Encog.Util.Normalize.DataNormalization)">
            <summary>
            Setup this class with the specified normalization object.
            </summary>
            <param name="normalization">Normalization object.</param>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.Index.IndexSegregator.ShouldInclude">
            <summary>
            Should this row be included, according to this segregator.
            </summary>
            <returns>True if this row should be included.</returns>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.Index.IndexSegregator.PassInit">
            <summary>
            Init for pass... nothing to do fo this class.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.Index.IndexSegregator.RollIndex">
            <summary>
            Used to increase the current index as data is processed.
            </summary>
        </member>
        <member name="T:Encog.Util.Normalize.Segregate.IntegerBalanceSegregator">
            <summary>
            Balance based on an input value. This allows you to make sure that one input
            class does not saturate the training data. To do this, you specify the input
            value to check and the number of occurrences of each integer value of this
            field to allow.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Segregate.IntegerBalanceSegregator._count">
            <summary>
            The count per each of the int values for the input field.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Segregate.IntegerBalanceSegregator._runningCounts">
            <summary>
            The running totals.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Segregate.IntegerBalanceSegregator._target">
            <summary>
            The input field.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Segregate.IntegerBalanceSegregator._normalization">
            <summary>
            The normalization object to use.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.IntegerBalanceSegregator.#ctor(Encog.Util.Normalize.Input.IInputField,System.Int32)">
            <summary>
            Construct a balanced segregator.
            </summary>
            <param name="target">The input field to base this on, should 
            be an integer value.</param>
            <param name="count">The number of rows to accept from each 
            unique value for the input.</param>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.IntegerBalanceSegregator.#ctor">
            <summary>
            Default constructor for reflection.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Segregate.IntegerBalanceSegregator.Count">
            <summary>
            The number of groups found.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Segregate.IntegerBalanceSegregator.RunningCounts">
            <summary>
            A map of the running count for each group.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Segregate.IntegerBalanceSegregator.Target">
            <summary>
            The target input field.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Segregate.IntegerBalanceSegregator.Owner">
            <summary>
            The owner of this segregator.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.IntegerBalanceSegregator.Init(Encog.Util.Normalize.DataNormalization)">
            <summary>
            Init the segregator with the owning normalization object.
            </summary>
            <param name="normalization">The data normalization object to use.</param>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.IntegerBalanceSegregator.PassInit">
            <summary>
            Init for a new pass.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.IntegerBalanceSegregator.ShouldInclude">
            <summary>
            Determine of the current row should be included.
            </summary>
            <returns>True if the current row should be included.</returns>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.IntegerBalanceSegregator.DumpCounts">
            <summary>
            Get information on how many rows fall into each group.
            </summary>
            <returns>A string that contains the counts for each group.</returns>
        </member>
        <member name="T:Encog.Util.Normalize.Segregate.ISegregator">
            <summary>
            Segregators are used to exclude certain rows. You may want to exclude rows to
            create training and validation sets. You may also simply wish to exclude some
            rows because they do not apply to what you are currently training for.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Segregate.ISegregator.Owner">
            <summary>
            The normalization object that is being used with this segregator.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.ISegregator.Init(Encog.Util.Normalize.DataNormalization)">
            <summary>
            Setup this object to use the specified normalization object.
            </summary>
            <param name="normalization">The normalization object to use.</param>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.ISegregator.ShouldInclude">
            <summary>
            Should this row be included, according to this segregator.
            </summary>
            <returns>True if this row should be included.</returns>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.ISegregator.PassInit">
            <summary>
            Init for a pass.
            </summary>
        </member>
        <member name="T:Encog.Util.Normalize.Segregate.RangeSegregator">
            <summary>
            Range segregators are used to segregate data and include or exclude if it is
            within a certain range.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Segregate.RangeSegregator._include">
            <summary>
            If none of the ranges match, should this data be included.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Segregate.RangeSegregator._ranges">
            <summary>
            The ranges.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Segregate.RangeSegregator._sourceField">
            <summary>
            The source field that this is based on.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Segregate.RangeSegregator._normalization">
            <summary>
            The normalization object.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.RangeSegregator.#ctor">
            <summary>
            Default constructor for reflection.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.RangeSegregator.#ctor(Encog.Util.Normalize.Input.IInputField,System.Boolean)">
            <summary>
            Construct a range segregator.
            </summary>
            <param name="sourceField">The source field.</param>
            <param name="include">Default action, if the data is not in any of the ranges,
            should it be included.</param>
        </member>
        <member name="P:Encog.Util.Normalize.Segregate.RangeSegregator.SourceField">
            <summary>
            The source field that the ranges are compared against.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Segregate.RangeSegregator.Owner">
            <summary>
            The normalization object used by this object.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.RangeSegregator.Init(Encog.Util.Normalize.DataNormalization)">
            <summary>
            Init the object.
            </summary>
            <param name="normalization">The normalization object that owns this range.</param>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.RangeSegregator.ShouldInclude">
            <summary>
            True if the current row should be included according to this
            segregator.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.RangeSegregator.PassInit">
            <summary>
            Init for pass... nothing to do fo this class.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.RangeSegregator.AddRange(System.Double,System.Double,System.Boolean)">
            <summary>
            Add a range.
            </summary>
            <param name="low">The low end of the range.</param>
            <param name="high">The high end of the range.</param>
            <param name="include">Should this range be included.</param>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.RangeSegregator.AddRange(Encog.Util.Normalize.Segregate.SegregationRange)">
            <summary>
            Add a range.
            </summary>
            <param name="range">The range to add.</param>
        </member>
        <member name="T:Encog.Util.Normalize.Segregate.SegregationRange">
            <summary>
            Specifies a range that might be included or excluded.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Segregate.SegregationRange._high">
            <summary>
            The high end of this range.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Segregate.SegregationRange._include">
            <summary>
            Should this range be included.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Segregate.SegregationRange._low">
            <summary>
            The low end of this range.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.SegregationRange.#ctor">
            <summary>
            Default constructor for reflection.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.SegregationRange.#ctor(System.Double,System.Double,System.Boolean)">
            <summary>
            Construct a segregation range.
            </summary>
            <param name="low">The low end of the range.</param>
            <param name="high">The high end of the range.</param>
            <param name="include">Specifies if the range should be included.</param>
        </member>
        <member name="P:Encog.Util.Normalize.Segregate.SegregationRange.High">
            <summary>
            The high end of the range.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Segregate.SegregationRange.Low">
            <summary>
            The low end of the range.
            </summary>
        </member>
        <member name="P:Encog.Util.Normalize.Segregate.SegregationRange.IsIncluded">
            <summary>
            True if this range should be included.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Segregate.SegregationRange.InRange(System.Double)">
            <summary>
            Is this value within the range. 
            </summary>
            <param name="value">The value to check.</param>
            <returns>True if the value is within the range.</returns>
        </member>
        <member name="T:Encog.Util.Normalize.Target.INormalizationStorage">
            <summary>
            Defines a means by which normalized data can be stored.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Target.INormalizationStorage.Close">
            <summary>
            Open the storage.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Target.INormalizationStorage.Open">
            <summary>
            Close the storage.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Target.INormalizationStorage.Write(System.Double[],System.Int32)">
            <summary>
            Write an array.
            </summary>
            <param name="data">The data to write.</param>
            <param name="inputCount">How much of the data is input.</param>
        </member>
        <member name="T:Encog.Util.Normalize.Target.NormalizationStorageArray1D">
            <summary>
            Output the normalized data to a 1D array.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Target.NormalizationStorageArray1D._array">
            <summary>
            The array to store to.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Target.NormalizationStorageArray1D._currentIndex">
            <summary>
            The current index.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Target.NormalizationStorageArray1D.#ctor(System.Double[])">
            <summary>
            Construct an object to store to a 2D array.
            </summary>
            <param name="array">The array to store to.</param>
        </member>
        <member name="M:Encog.Util.Normalize.Target.NormalizationStorageArray1D.Close">
            <summary>
            Not needed for this storage type.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Target.NormalizationStorageArray1D.Open">
            <summary>
            Not needed for this storage type.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Target.NormalizationStorageArray1D.Write(System.Double[],System.Int32)">
            <summary>
            Write an array.
            </summary>
            <param name="data">The data to write.</param>
            <param name="inputCount">How much of the data is input.</param>
        </member>
        <member name="T:Encog.Util.Normalize.Target.NormalizationStorageArray2D">
            <summary>
            Output the normalized data to a 2D array.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Target.NormalizationStorageArray2D._array">
            <summary>
            The array to output to.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Target.NormalizationStorageArray2D._currentIndex">
            <summary>
            The current data.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Target.NormalizationStorageArray2D.#ctor(System.Double[][])">
            <summary>
            Construct an object to store to a 2D array.
            </summary>
            <param name="array">The array to store to.</param>
        </member>
        <member name="M:Encog.Util.Normalize.Target.NormalizationStorageArray2D.Close">
            <summary>
            Not needed for this storage type.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Target.NormalizationStorageArray2D.Open">
            <summary>
            Not needed for this storage type.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Target.NormalizationStorageArray2D.Write(System.Double[],System.Int32)">
            <summary>
            Write an array.
            </summary>
            <param name="data">The data to write.</param>
            <param name="inputCount">How much of the data is input.</param>
        </member>
        <member name="M:Encog.Util.Normalize.Target.NormalizationStorageArray2D.GetArray">
            <summary>
            Get the underlying array.
            </summary>
            <returns>The underlying array.</returns>
        </member>
        <member name="T:Encog.Util.Normalize.Target.NormalizationStorageCSV">
            <summary>
            Store normalized data to a CSV file.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Target.NormalizationStorageCSV._format">
            <summary>
            The CSV format to use.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Target.NormalizationStorageCSV._outputFile">
            <summary>
            The output file.
            </summary> 
        </member>
        <member name="F:Encog.Util.Normalize.Target.NormalizationStorageCSV._output">
            <summary>
            The output writer.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Target.NormalizationStorageCSV.#ctor(Encog.Util.CSV.CSVFormat,System.String)">
            <summary>
            Construct a CSV storage object from the specified file.
            </summary>
            <param name="format">The format to use.</param>
            <param name="file">The file to write the CSV to.</param>
        </member>
        <member name="M:Encog.Util.Normalize.Target.NormalizationStorageCSV.#ctor(System.String)">
            <summary>
            Construct a CSV storage object from the specified file.
            </summary>
            <param name="file">The file to write the CSV to.</param>
        </member>
        <member name="M:Encog.Util.Normalize.Target.NormalizationStorageCSV.Close">
            <summary>
            Close the CSV file.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Target.NormalizationStorageCSV.Open">
            <summary>
            Open the CSV file.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Target.NormalizationStorageCSV.Write(System.Double[],System.Int32)">
            <summary>
            Write an array.
            </summary>
            <param name="data">The data to write.</param>
            <param name="inputCount"> How much of the data is input.</param>
        </member>
        <member name="T:Encog.Util.Normalize.Target.NormalizationStorageMLDataSet">
            <summary>
            Store the normalized data to a neural data set.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Target.NormalizationStorageMLDataSet._dataset">
            <summary>
            The data set to add to.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Target.NormalizationStorageMLDataSet._idealCount">
            <summary>
            The ideal count.
            </summary>
        </member>
        <member name="F:Encog.Util.Normalize.Target.NormalizationStorageMLDataSet._inputCount">
            <summary>
            The input count.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Target.NormalizationStorageMLDataSet.#ctor(System.Int32,System.Int32)">
            <summary>
            Construct a new NeuralDataSet based on the parameters specified.
            </summary>
            <param name="inputCount">The input count.</param>
            <param name="idealCount">The output count.</param>
        </member>
        <member name="M:Encog.Util.Normalize.Target.NormalizationStorageMLDataSet.#ctor(Encog.ML.Data.IMLDataSet)">
            <summary>
            Construct a normalized neural storage class to hold data.
            </summary>
            <param name="dataset">The data set to store to. This uses an existing data set.</param>
        </member>
        <member name="P:Encog.Util.Normalize.Target.NormalizationStorageMLDataSet.DataSet">
            <summary>
            The data set being used.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Target.NormalizationStorageMLDataSet.Close">
            <summary>
            Not needed for this storage type.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Target.NormalizationStorageMLDataSet.Open">
            <summary>
            Not needed for this storage type.
            </summary>
        </member>
        <member name="M:Encog.Util.Normalize.Target.NormalizationStorageMLDataSet.Write(System.Double[],System.Int32)">
            <summary>
            Write an array.
            </summary>
            <param name="data">The data to write.</param>
            <param name="inputCount">How much of the data is input.</param>
        </member>
        <member name="T:Encog.Util.ObjectPair`2">
            <summary>
            A pair of objects.
            </summary>
            <typeparam name="TA">The type of the first object.</typeparam>
            <typeparam name="TB">The type of the second object.</typeparam>
        </member>
        <member name="F:Encog.Util.ObjectPair`2._a">
            <summary>
            The first object.
            </summary>
        </member>
        <member name="F:Encog.Util.ObjectPair`2._b">
            <summary>
            The second object.
            </summary>
        </member>
        <member name="M:Encog.Util.ObjectPair`2.#ctor(`0,`1)">
            <summary>
            Construct an object pair. 
            </summary>
            <param name="a">The first object.</param>
            <param name="b">The second object.</param>
        </member>
        <member name="P:Encog.Util.ObjectPair`2.A">
            <summary>
            The first object.
            </summary>
        </member>
        <member name="P:Encog.Util.ObjectPair`2.B">
            <summary>
            The second object.
            </summary>
        </member>
        <member name="T:Encog.Util.ParamsHolder">
             <summary>
             A class that can be used to parse parameters stored in a map.  Allows the 
             params to be accessed as various data types and to be validated.
             </summary>
            
        </member>
        <member name="F:Encog.Util.ParamsHolder._format">
             <summary>
             The format that numbers will be in.
             </summary>
            
        </member>
        <member name="F:Encog.Util.ParamsHolder._paras">
             <summary>
             The params that are to be parsed.
             </summary>
            
        </member>
        <member name="M:Encog.Util.ParamsHolder.#ctor(System.Collections.Generic.IDictionary{System.String,System.String},Encog.Util.CSV.CSVFormat)">
             <summary>
             Construct the object. Allow the format to be specified.
             </summary>
            
             <param name="theParams">The params to be used.</param>
             <param name="theFormat">The format to be used.</param>
        </member>
        <member name="M:Encog.Util.ParamsHolder.#ctor(System.Collections.Generic.IDictionary{System.String,System.String})">
             <summary>
             Construct the object. Allow the format to be specified.
             </summary>
            
             <param name="theParams">The params to be used.</param>
        </member>
        <member name="P:Encog.Util.ParamsHolder.Params">
            <value>the params</value>
        </member>
        <member name="M:Encog.Util.ParamsHolder.GetString(System.String,System.Boolean,System.String)">
             <summary>
             Get a param as a string.
             </summary>
            
             <param name="name">The name of the string.</param>
             <param name="required">True if this value is required.</param>
             <param name="defaultValue">The default value.</param>
             <returns>The value.</returns>
        </member>
        <member name="M:Encog.Util.ParamsHolder.GetInt(System.String,System.Boolean,System.Int32)">
             <summary>
             Get a param as a integer.
             </summary>
            
             <param name="name">The name of the integer.</param>
             <param name="required">True if this value is required.</param>
             <param name="defaultValue">The default value.</param>
             <returns>The value.</returns>
        </member>
        <member name="M:Encog.Util.ParamsHolder.GetDouble(System.String,System.Boolean,System.Double)">
             <summary>
             Get a param as a double.
             </summary>
            
             <param name="name">The name of the double.</param>
             <param name="required">True if this value is required.</param>
             <param name="defaultValue">The default value.</param>
             <returns>The value.</returns>
        </member>
        <member name="M:Encog.Util.ParamsHolder.GetBoolean(System.String,System.Boolean,System.Boolean)">
             <summary>
             Get a param as a boolean.
             </summary>
            
             <param name="name">The name of the double.</param>
             <param name="required">True if this value is required.</param>
             <param name="defaultValue">The default value.</param>
             <returns>The value.</returns>
        </member>
        <member name="T:Encog.Util.SimpleParser">
            <summary>
            A very simple text parser.
            </summary>
        </member>
        <member name="F:Encog.Util.SimpleParser._currentPosition">
            <summary>
            The current position.
            </summary>
        </member>
        <member name="F:Encog.Util.SimpleParser._marked">
            <summary>
            The marked position.
            </summary>
        </member>
        <member name="M:Encog.Util.SimpleParser.#ctor(System.String)">
            <summary>
            Construct the object for the specified line.
            </summary>
            <param name="line">The line to parse.</param>
        </member>
        <member name="P:Encog.Util.SimpleParser.Line">
            <summary>
            The line being parsed.
            </summary>
        </member>
        <member name="M:Encog.Util.SimpleParser.Remaining">
            <summary>
            The number of characters remaining.
            </summary>
            <returns>The number of characters remaining.</returns>
        </member>
        <member name="M:Encog.Util.SimpleParser.ParseThroughComma">
            <summary>
            Parse through a comma.
            </summary>
            <returns>True, if the comma was found.</returns>
        </member>
        <member name="M:Encog.Util.SimpleParser.IsIdentifier">
            <summary>
            CHeck to see if the next character is an identifier.
            </summary>
            <returns>True, if the next char is an identifier.</returns>
        </member>
        <member name="M:Encog.Util.SimpleParser.Peek">
            <summary>
            Peek ahead to see the next character.  But do not advance beyond it.
            </summary>
            <returns>The next character.</returns>
        </member>
        <member name="M:Encog.Util.SimpleParser.Advance">
            <summary>
            Advance beyond the next character.
            </summary>
        </member>
        <member name="M:Encog.Util.SimpleParser.IsWhiteSpace">
            <summary>
            Returns true if the next character is a white space.
            </summary>
            <returns>True, if the next character is a white space.</returns>
        </member>
        <member name="M:Encog.Util.SimpleParser.EOL">
            <summary>
            Returns true of there are no more characters to read.
            </summary>
            <returns>True, if we have reached end of line.</returns>
        </member>
        <member name="M:Encog.Util.SimpleParser.EatWhiteSpace">
            <summary>
            Strip any white space from the current position.
            </summary>
        </member>
        <member name="M:Encog.Util.SimpleParser.ReadChar">
            <summary>
            Read the next character.
            </summary>
            <returns>The next character.</returns>
        </member>
        <member name="M:Encog.Util.SimpleParser.ReadToWhiteSpace">
            <summary>
            Read text up to the next white space.
            </summary>
            <returns>The text read up to the next white space.</returns>
        </member>
        <member name="M:Encog.Util.SimpleParser.LookAhead(System.String,System.Boolean)">
            <summary>
            Look ahead to see if the specified string is present.
            </summary>
            <param name="str">The string searching for.</param>
            <param name="ignoreCase">True if case is to be ignored.</param>
            <returns>True if the string is present.</returns>
        </member>
        <member name="M:Encog.Util.SimpleParser.Advance(System.Int32)">
            <summary>
            Advance the specified number of characters.
            </summary>
            <param name="p">The number of characters to advance.</param>
        </member>
        <member name="M:Encog.Util.SimpleParser.Mark">
            <summary>
            Mark the current position.
            </summary>
        </member>
        <member name="M:Encog.Util.SimpleParser.Reset">
            <summary>
            Reset back to the marked position.
            </summary>
        </member>
        <member name="M:Encog.Util.SimpleParser.ReadQuotedString">
            <summary>
            Read a quoted string.
            </summary>
            <returns>The string that was read.</returns>
        </member>
        <member name="M:Encog.Util.SimpleParser.ReadToChars(System.String)">
            <summary>
            Read forward to the specified characters.
            </summary>
            <param name="chs">The characters to stop at.</param>
            <returns>The string that was read.</returns>
        </member>
        <member name="T:Encog.Util.Simple.TrainingSetUtil">
            <summary>
            Provides some utilities for training sets.
            </summary>
        </member>
        <member name="M:Encog.Util.Simple.TrainingSetUtil.LoadCSVTOMemory(Encog.Util.CSV.CSVFormat,System.String,System.Boolean,System.Int32,System.Int32)">
             <summary>
             Load a CSV file into a memory dataset.  
             </summary>
            
             <param name="format">The CSV format to use.</param>
             <param name="filename">The filename to load.</param>
             <param name="headers">True if there is a header line.</param>
             <param name="inputSize">The input size.  Input always comes first in a file.</param>
             <param name="idealSize">The ideal size, 0 for unsupervised.</param>
             <returns>A NeuralDataSet that holds the contents of the CSV file.</returns>
        </member>
        <member name="M:Encog.Util.Simple.TrainingSetUtil.TrainingToArray(Encog.ML.Data.IMLDataSet)">
            <summary>
            Convert a training set to an array.
            </summary>
            <param name="training"></param>
            <returns></returns>
        </member>
        <member name="T:Encog.Util.Simple.EncogUtility">
            <summary>
            General utility class for Encog.  Provides for some common Encog procedures.
            </summary>
        </member>
        <member name="M:Encog.Util.Simple.EncogUtility.#ctor">
            <summary>
            Private constructor.
            </summary>
        </member>
        <member name="M:Encog.Util.Simple.EncogUtility.ConvertCSV2Binary(System.String,Encog.Util.CSV.CSVFormat,System.String,System.Int32,System.Int32,System.Boolean,System.Boolean)">
            <summary>
            Convert a CSV file to a binary training file.
            </summary>
            <param name="csvFile">The CSV file.</param>
            <param name="format">The format.</param>
            <param name="binFile">The binary file.</param>
            <param name="inputCount">The number of input values.</param>
            <param name="outputCount">The number of output values.</param>
            <param name="headers">True, if there are headers on the3 CSV.</param>
            <param name="expectSignificance">Should a significance column be expected.</param>
        </member>
        <member name="M:Encog.Util.Simple.EncogUtility.ConvertCSV2Binary(System.IO.FileInfo,Encog.Util.CSV.CSVFormat,System.IO.FileInfo,System.Int32[],System.Int32[],System.Boolean)">
            <summary>
            Convert a CSV file to binary.
            </summary>
            <param name="csvFile">The CSV file to convert.</param>
            <param name="format">The format.</param>
            <param name="binFile">The binary file.</param>
            <param name="input">The input.</param>
            <param name="ideal">The ideal.</param>
            <param name="headers">True, if headers are present.</param>
        </member>
        <member name="M:Encog.Util.Simple.EncogUtility.LoadCSV2Memory(System.String,System.Int32,System.Int32,System.Boolean,Encog.Util.CSV.CSVFormat,System.Boolean)">
            <summary>
            Load CSV to memory.
            </summary>
            <param name="filename">The CSV file to load.</param>
            <param name="input">The input count.</param>
            <param name="ideal">The ideal count.</param>
            <param name="headers">True, if headers are present.</param>
            <param name="format">The loaded dataset.</param>
            <param name="expectSignificance">The loaded dataset.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.Simple.EncogUtility.Evaluate(Encog.ML.IMLRegression,Encog.ML.Data.IMLDataSet)">
            <summary>
            Evaluate the network and display (to the console) the output for every
            value in the training set. Displays ideal and actual.
            </summary>
            <param name="network">The network to evaluate.</param>
            <param name="training">The training set to evaluate.</param>
        </member>
        <member name="M:Encog.Util.Simple.EncogUtility.FormatNeuralData(Encog.ML.Data.IMLData)">
            <summary>
            Format neural data as a list of numbers.
            </summary>
            <param name="data">The neural data to format.</param>
            <returns>The formatted neural data.</returns>
        </member>
        <member name="M:Encog.Util.Simple.EncogUtility.SimpleFeedForward(System.Int32,System.Int32,System.Int32,System.Int32,System.Boolean)">
            <summary>
            Create a simple feedforward neural network.
            </summary>
            <param name="input">The number of input neurons.</param>
            <param name="hidden1">The number of hidden layer 1 neurons.</param>
            <param name="hidden2">The number of hidden layer 2 neurons.</param>
            <param name="output">The number of output neurons.</param>
            <param name="tanh">True to use hyperbolic tangent activation function, false to
            use the sigmoid activation function.</param>
            <returns>The neural network.</returns>
        </member>
        <member name="M:Encog.Util.Simple.EncogUtility.TrainConsole(Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet,System.Int32)">
            <summary>
            Train the neural network, using SCG training, and output status to the
            console.
            </summary>
            <param name="network">The network to train.</param>
            <param name="trainingSet">The training set.</param>
            <param name="minutes">The number of minutes to train for.</param>
        </member>
        <member name="M:Encog.Util.Simple.EncogUtility.TrainConsole(Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet,System.Double)">
            <summary>
            Train the neural network, using SCG training, and output status to the
            console.
            </summary>
            <param name="network">The network to train.</param>
            <param name="trainingSet">The training set.</param>
            <param name="seconds">The seconds.</param>
        </member>
        <member name="M:Encog.Util.Simple.EncogUtility.TrainConsole(Encog.ML.Train.IMLTrain,Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet,System.Int32)">
            <summary>
            Train the network, using the specified training algorithm, and send the
            output to the console.
            </summary>
            <param name="train">The training method to use.</param>
            <param name="network">The network to train.</param>
            <param name="trainingSet">The training set.</param>
            <param name="minutes">The number of minutes to train for.</param>
        </member>
        <member name="M:Encog.Util.Simple.EncogUtility.TrainConsole(Encog.ML.Train.IMLTrain,Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet,System.Double)">
            <summary>
            Train the network, using the specified training algorithm, and send the
            output to the console.
            </summary>
            <param name="train">The training method to use.</param>
            <param name="network">The network to train.</param>
            <param name="trainingSet">The training set.</param>
            <param name="seconds">The second to train for.</param>
        </member>
        <member name="M:Encog.Util.Simple.EncogUtility.TrainDialog(Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet)">
            <summary>
            Train using RPROP and display progress to a dialog box.
            </summary>
            <param name="network">The network to train.</param>
            <param name="trainingSet">The training set to use.</param>
        </member>
        <member name="M:Encog.Util.Simple.EncogUtility.TrainDialog(Encog.ML.Train.IMLTrain,Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet)">
            <summary>
            Train, using the specified training method, display progress to a dialog
            box.
            </summary>
            <param name="train">The training method to use.</param>
            <param name="network">The network to train.</param>
            <param name="trainingSet">The training set to use.</param>
        </member>
        <member name="M:Encog.Util.Simple.EncogUtility.TrainToError(Encog.Neural.Networks.BasicNetwork,Encog.ML.Data.IMLDataSet,System.Double)">
            <summary>
            Train the network, to a specific error, send the output to the console.
            </summary>
            <param name="network">The network to train.</param>
            <param name="trainingSet">The training set to use.</param>
            <param name="error">The error level to train to.</param>
        </member>
        <member name="M:Encog.Util.Simple.EncogUtility.TrainToError(Encog.ML.Train.IMLTrain,Encog.ML.Data.IMLDataSet,System.Double)">
            <summary>
            Train to a specific error, using the specified training method, send the
            output to the console.
            </summary>
            <param name="train">The training method.</param>
            <param name="trainingSet">The training set to use.</param>
            <param name="error">The desired error level.</param>
        </member>
        <member name="M:Encog.Util.Simple.EncogUtility.CalculateRegressionError(Encog.ML.IMLRegression,Encog.ML.Data.IMLDataSet)">
            <summary>
            Calculate a regression error.
            </summary>
            <param name="method">The method to check.</param>
            <param name="data">The data to check.</param>
            <returns>The error.</returns>
        </member>
        <member name="M:Encog.Util.Simple.EncogUtility.SaveCSV(System.IO.FileInfo,Encog.Util.CSV.CSVFormat,Encog.ML.Data.IMLDataSet)">
            <summary>
            Save the dataset to a CSV file.
            </summary>
            <param name="targetFile">The target file.</param>
            <param name="format">The format to use.</param>
            <param name="set">The data set.</param>
        </member>
        <member name="M:Encog.Util.Simple.EncogUtility.CalculateClassificationError(Encog.ML.IMLClassification,Encog.ML.Data.IMLDataSet)">
            <summary>
            Calculate an error for a method that makes use of classification.
            </summary>
            <param name="method">The method to check.</param>
            <param name="data">The data to check.</param>
            <returns>The error.</returns>
        </member>
        <member name="M:Encog.Util.Simple.EncogUtility.LoadEGB2Memory(System.IO.FileInfo)">
            <summary>
            Load an EGB file to memory.
            </summary>
            <param name="filename">The file to load.</param>
            <returns>A memory data set.</returns>
        </member>
        <member name="M:Encog.Util.Simple.EncogUtility.TrainToError(Encog.ML.Train.IMLTrain,System.Double)">
             <summary>
             Train to a specific error, using the specified training method, send the
             output to the console.
             </summary>
            
             <param name="train">The training method.</param>
             <param name="error">The desired error level.</param>
        </member>
        <member name="M:Encog.Util.Simple.EncogUtility.SaveEGB(System.IO.FileInfo,Encog.ML.Data.IMLDataSet)">
            <summary>
            Save the training set to an EGB file.
            </summary>
            <param name="egbFile">The EGB file to save to.</param>
            <param name="data">The training data to save.</param>
        </member>
        <member name="T:Encog.Util.Simple.TrainingDialog">
            <summary>
            Training dialog.
            </summary>
        </member>
        <member name="T:Encog.Util.Simple.TrainingDialog.CommandDelegate">
            <summary>
            Delegate to issue a command, such as close.
            </summary>
        </member>
        <member name="T:Encog.Util.Simple.TrainingDialog.StatsDelegate">
            <summary>
            Delegate to update the stats.
            </summary>
            <param name="iterations">Number of iterations.</param>
            <param name="error">Current error.</param>
            <param name="time">Elapsed time.</param>
        </member>
        <member name="M:Encog.Util.Simple.TrainingDialog.#ctor">
            <summary>
            Constructor.
            </summary>
        </member>
        <member name="P:Encog.Util.Simple.TrainingDialog.ShouldStop">
            <summary>
            Should training stop.
            </summary>
        </member>
        <member name="P:Encog.Util.Simple.TrainingDialog.Train">
            <summary>
            The training alog.
            </summary>
        </member>
        <member name="M:Encog.Util.Simple.TrainingDialog.UpdateStats(System.String,System.String,System.String)">
            <summary>
            Called to update the stats.
            </summary>
            <param name="iterations">The number</param>
            <param name="error">The current error.</param>
            <param name="time"></param>
        </member>
        <member name="M:Encog.Util.Simple.TrainingDialog.PerformClose">
            <summary>
            Close the window.
            </summary>
        </member>
        <member name="M:Encog.Util.Simple.TrainingDialog.PerformButtonUpdate">
            <summary>
            Update the update button to "stopping".
            </summary>
        </member>
        <member name="F:Encog.Util.Simple.TrainingDialog.components">
            <summary>
            Required designer variable.
            </summary>
        </member>
        <member name="M:Encog.Util.Simple.TrainingDialog.Dispose(System.Boolean)">
            <summary>
            Clean up any resources being used.
            </summary>
            <param name="disposing">true if managed resources should be disposed; otherwise, false.</param>
        </member>
        <member name="M:Encog.Util.Simple.TrainingDialog.InitializeComponent">
            <summary>
            Required method for Designer support - do not modify
            the contents of this method with the code editor.
            </summary>
        </member>
        <member name="T:Encog.Util.Time.NumericDateUtil">
            <summary>
            A utility for storing dates as numeric values.
            </summary>
        </member>
        <member name="F:Encog.Util.Time.NumericDateUtil.YearOffset">
            <summary>
            The numeric offset for a year.
            </summary>
        </member>
        <member name="F:Encog.Util.Time.NumericDateUtil.MonthOffset">
            <summary>
            The numeric offset for a month.
            </summary>
        </member>
        <member name="F:Encog.Util.Time.NumericDateUtil.HourOffset">
            <summary>
            The numeric offset for an hour.
            </summary>
        </member>
        <member name="F:Encog.Util.Time.NumericDateUtil.MinuteOffset">
            <summary>
            The numeric offset for a minute.
            </summary>
        </member>
        <member name="M:Encog.Util.Time.NumericDateUtil.DateTime2Long(System.DateTime)">
            <summary>
            Convert a date/time to a long.
            </summary>
            <param name="time">The time to convert.</param>
            <returns>A numeric date.</returns>
        </member>
        <member name="M:Encog.Util.Time.NumericDateUtil.Long2DateTime(System.UInt64)">
            <summary>
            Convert a numeric date time to a regular date time.
            </summary>
            <param name="l">The numeric date time.</param>
            <returns>The converted date/time.</returns>
        </member>
        <member name="M:Encog.Util.Time.NumericDateUtil.StripTime(System.DateTime)">
            <summary>
            Strip the time element.
            </summary>
            <param name="dt">The time-date element to strip.</param>
            <returns>A new date-time with the time stripped.</returns>
        </member>
        <member name="M:Encog.Util.Time.NumericDateUtil.HaveSameDate(System.DateTime,System.DateTime)">
            <summary>
            Determine of two values have the same date.
            </summary>
            <param name="d1">The first date/time.</param>
            <param name="d2">The second date/time.</param>
            <returns>True, if they have the same date.</returns>
        </member>
        <member name="M:Encog.Util.Time.NumericDateUtil.Int2Time(System.DateTime,System.UInt32)">
            <summary>
            Convert an int to a time.
            </summary>
            <param name="date">The date-time that provides date information.</param>
            <param name="i">The int that holds the time.</param>
            <returns>The converted date/time.</returns>
        </member>
        <member name="M:Encog.Util.Time.NumericDateUtil.Time2Int(System.DateTime)">
            <summary>
            Convert a time to an int.
            </summary>
            <param name="time">The time to convert.</param>
            <returns>The time as an int.</returns>
        </member>
        <member name="M:Encog.Util.Time.NumericDateUtil.GetYear(System.UInt64)">
            <summary>
            Get the year part of a numeric date.
            </summary>
            <param name="date">The numeric date.</param>
            <returns>The year.</returns>
        </member>
        <member name="M:Encog.Util.Time.NumericDateUtil.GetMonth(System.UInt64)">
            <summary>
            Get the year month of a numeric date.
            </summary>
            <param name="l">The numeric date.</param>
            <returns>The month.</returns>
        </member>
        <member name="M:Encog.Util.Time.NumericDateUtil.GetMinutePeriod(System.UInt32,System.Int32)">
            <summary>
            Get the minute period.
            </summary>
            <param name="time">The time.</param>
            <param name="period">The period size, in minutes.</param>
            <returns>The number of minutes per period.</returns>
        </member>
        <member name="M:Encog.Util.Time.NumericDateUtil.Combine(System.UInt64,System.UInt32)">
            <summary>
            Combine a date and a time.
            </summary>
            <param name="date">The date.</param>
            <param name="time">The time.</param>
            <returns>The combined time.</returns>
        </member>
        <member name="M:Encog.Util.Time.NumericDateUtil.GetDayOfWeek(System.UInt64)">
            <summary>
            Get the day of the week for the specified numeric date.
            </summary>
            <param name="p">The time to check.</param>
            <returns>The day of the week, 0 is a sunday.</returns>
        </member>
        <member name="M:Encog.Util.Time.DateUtil.CreateDate(System.Int32,System.Int32,System.Int32)">
            <summary>
            January is 1.
            </summary>
            <param name="month"></param>
            <param name="day"></param>
            <param name="year"></param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.Time.DateUtil.TruncateDate(System.DateTime)">
            <summary>
            Truncate a date, remove the time.
            </summary>
            <param name="date">The date to truncate.</param>
            <returns>The date without the time.</returns>
        </member>
        <member name="T:Encog.Util.Time.TimeUnit">
            <summary>
            Time units.
            </summary>
        </member>
        <member name="F:Encog.Util.Time.TimeUnit.Seconds">
            <summary>
            Seconds
            </summary>
        </member>
        <member name="F:Encog.Util.Time.TimeUnit.Minutes">
            <summary>
            Minutes
            </summary>
        </member>
        <member name="F:Encog.Util.Time.TimeUnit.Hours">
            <summary>
            Hours
            </summary>
        </member>
        <member name="F:Encog.Util.Time.TimeUnit.Days">
            <summary>
            Days
            </summary>
        </member>
        <member name="F:Encog.Util.Time.TimeUnit.Weeks">
            <summary>
            Weeks
            </summary>
        </member>
        <member name="F:Encog.Util.Time.TimeUnit.Fortnights">
            <summary>
            Fortnights
            </summary>
        </member>
        <member name="F:Encog.Util.Time.TimeUnit.Months">
            <summary>
            Months
            </summary>
        </member>
        <member name="F:Encog.Util.Time.TimeUnit.Years">
            <summary>
            Years
            </summary>
        </member>
        <member name="F:Encog.Util.Time.TimeUnit.Decades">
            <summary>
            Decades
            </summary>
        </member>
        <member name="F:Encog.Util.Time.TimeUnit.Scores">
            <summary>
            Scores
            </summary>
        </member>
        <member name="F:Encog.Util.Time.TimeUnit.Centuries">
            <summary>
            Centuries
            </summary>
        </member>
        <member name="F:Encog.Util.Time.TimeUnit.Millennia">
            <summary>
            Millennia
            </summary>
        </member>
        <member name="F:Encog.Util.Time.TimeUnit.Ticks">
            <summary>
            Ticks
            </summary>
        </member>
        <member name="T:Encog.Util.CSV.NumberList">
            <summary>
            Utility class to take numbers to/from a list.
            </summary>
        </member>
        <member name="M:Encog.Util.CSV.NumberList.FromList(Encog.Util.CSV.CSVFormat,System.String)">
            <summary>
            Get an array of double's from a string of comma separated text.
            </summary>
            <param name="format">The way to format this list.</param>
            <param name="str">The string that contains a list of numbers.</param>
            <returns>An array of doubles parsed from the string.</returns>
        </member>
        <member name="M:Encog.Util.CSV.NumberList.FromListInt(Encog.Util.CSV.CSVFormat,System.String)">
            <summary>
            Get an array of ints's from a string of comma separated text.
            </summary>
            <param name="format">The way to format this list.</param>
            <param name="str">The string that contains a list of numbers.</param>
            <returns>An array of ints parsed from the string.</returns>
        </member>
        <member name="M:Encog.Util.CSV.NumberList.ToList(Encog.Util.CSV.CSVFormat,System.Text.StringBuilder,System.Double[])">
            <summary>
            Convert an array of doubles to a comma separated list.
            </summary>
            <param name="format">The way to format this list.</param>
            <param name="result">This string will have the values appended to it.</param>
            <param name="data">The array of doubles to use.</param>
        </member>
        <member name="M:Encog.Util.CSV.NumberList.ToList(Encog.Util.CSV.CSVFormat,System.Int32,System.Text.StringBuilder,System.Double[])">
            <summary>
            Convert an array of doubles to a comma separated list.
            </summary>
            <param name="format">The way to format this list.</param>
            <param name="precision">The precision.</param>
            <param name="result">This string will have the values appended to it.</param>
            <param name="data">The array of doubles to use.</param>
        </member>
        <member name="M:Encog.Util.CSV.NumberList.ToListInt(Encog.Util.CSV.CSVFormat,System.Text.StringBuilder,System.Int32[])">
            <summary>
            Convert an array of ints to a comma separated list.
            </summary>
            <param name="format">The way to format this list.</param>
            <param name="result">This string will have the values appended to it.</param>
            <param name="data">The array of doubles to use.</param>
        </member>
        <member name="T:Encog.Util.CSV.CSVError">
            <summary>
            Used to report errors for CSV formatting.
            </summary>
        </member>
        <member name="M:Encog.Util.CSV.CSVError.#ctor(System.String)">
            <summary>
            Construct a message exception.
            </summary>
            <param name="str">The message.</param>
        </member>
        <member name="M:Encog.Util.CSV.CSVError.#ctor(System.Exception)">
            <summary>
            Pass on an exception.
            </summary>
            <param name="e">The other exception.</param>
        </member>
        <member name="T:Encog.Util.CSV.CSVFormat">
            <summary>
            Describes how to format number lists, such as CSV.
            </summary>
        </member>
        <member name="F:Encog.Util.CSV.CSVFormat.MaxFormats">
            <summary>
            The maximum number of digits.
            </summary>
        </member>
        <member name="M:Encog.Util.CSV.CSVFormat.#ctor(System.Char,System.Char)">
            <summary>
            Create a CSV format for the specified decimal char and separator char.
            </summary>
            <param name="decimalChar">The character for a decimal point or comma.</param>
            <param name="separatorChar">The separator char for a number list, likely comma or semicolon.</param>
        </member>
        <member name="M:Encog.Util.CSV.CSVFormat.#ctor">
            <summary>
            Default constructor for reflection.
            </summary>
        </member>
        <member name="P:Encog.Util.CSV.CSVFormat.DecimalPoint">
            <summary>
            A format that uses a decimal point and a comma to separate fields.
            </summary>
        </member>
        <member name="P:Encog.Util.CSV.CSVFormat.DecimalComma">
            <summary>
            A format that uses a decimal comma and a semicolon to separate fields.
            </summary>
        </member>
        <member name="P:Encog.Util.CSV.CSVFormat.English">
            <summary>
            The typical format for English speaking countries is a decimal
            point and a comma for field separation.  
            </summary>
        </member>
        <member name="P:Encog.Util.CSV.CSVFormat.EgFormat">
            <summary>
            It is important that an EG file produced on one system, in one region
            be readable by another system in a different region.  Because of this
            EG files internally use a decimal point and comma separator.  Of course
            programs should display numbers to the user using regional settings.
            </summary>
        </member>
        <member name="P:Encog.Util.CSV.CSVFormat.DecimalChar">
            <summary>
            The decimal character, usually either a period or comma.
            </summary>
        </member>
        <member name="P:Encog.Util.CSV.CSVFormat.Separator">
            <summary>
            The separator character for a list of fields in CSV, usually either comma or
            semicolon.
            </summary>
        </member>
        <member name="P:Encog.Util.CSV.CSVFormat.DecimalCharacter">
            <summary>
            The decimal character for the current region.
            </summary>
        </member>
        <member name="M:Encog.Util.CSV.CSVFormat.Parse(System.String)">
            <summary>
            Parse the specified string into a number.
            </summary>
            <param name="str">The string to parse.</param>
            <returns>The number that has been parsed.</returns>
        </member>
        <member name="M:Encog.Util.CSV.CSVFormat.Format(System.Double,System.Int32)">
            <summary>
            Format the specified number into a string.
            </summary>
            <param name="d">The number to parse.</param>
            <param name="digits">The number of fractional digits.</param>
            <returns>The formatted number.</returns>
        </member>
        <member name="T:Encog.Util.CSV.ReadCSV">
            <summary>
            Read and parse CSV format files.
            </summary>
        </member>
        <member name="F:Encog.Util.CSV.ReadCSV._columnNames">
            <summary>
            The names of the columns.
            </summary>
        </member>
        <member name="F:Encog.Util.CSV.ReadCSV._columns">
            <summary>
            The names of the columns.
            </summary>
        </member>
        <member name="F:Encog.Util.CSV.ReadCSV._reader">
            <summary>
            The file to read.
            </summary>
        </member>
        <member name="F:Encog.Util.CSV.ReadCSV._data">
            <summary>
            The data.
            </summary>
        </member>
        <member name="F:Encog.Util.CSV.ReadCSV._delim">
            <summary>
            The delimiter.
            </summary>
        </member>
        <member name="M:Encog.Util.CSV.ReadCSV.#ctor(System.IO.Stream,System.Boolean,System.Char)">
            <summary>
            Construct a CSV reader from an input stream.
            </summary>
            <param name="istream">The InputStream to read from.</param>
            <param name="headers">Are headers present?</param>
            <param name="delim">What is the delimiter.</param>
        </member>
        <member name="M:Encog.Util.CSV.ReadCSV.#ctor(System.String,System.Boolean,System.Char)">
            <summary>
            Construct a CSV reader from a filename.
            </summary>
            <param name="filename">The filename.</param>
            <param name="headers">The headers.</param>
            <param name="delim">The delimiter.</param>
        </member>
        <member name="M:Encog.Util.CSV.ReadCSV.#ctor(System.String,System.Boolean,Encog.Util.CSV.CSVFormat)">
            <summary>
            Construct a CSV reader from a filename.
            Allows a delimiter character to be specified.
            Numbers will be parsed using the current
            locale.
            </summary>
            <param name="filename">The filename.</param>
            <param name="headers">The headers.</param>
            <param name="format">The delimiter.</param>
        </member>
        <member name="M:Encog.Util.CSV.ReadCSV.#ctor(System.IO.Stream,System.Boolean,Encog.Util.CSV.CSVFormat)">
            <summary>
            Construct a CSV reader from an input stream.
            The format parameter specifies the separator 
            character to use, as well as the number
            format.
            </summary>
            <param name="stream">The Stream to read from.</param>
            <param name="headers">Are headers present?</param>
            <param name="format">What is the CSV format.</param>
        </member>
        <member name="P:Encog.Util.CSV.ReadCSV.DateFormat">
            <summary>
            The format that dates are expected to be in. (i.e. "yyyy-MM-dd")
            </summary>
        </member>
        <member name="P:Encog.Util.CSV.ReadCSV.TimeFormat">
            <summary>
            The format that times are expected to be in. (i.e. "hhmmss").
            </summary>
        </member>
        <member name="P:Encog.Util.CSV.ReadCSV.Format">
            <summary>
            The current format.
            </summary>
        </member>
        <member name="P:Encog.Util.CSV.ReadCSV.ColumnNames">
            <summary>
            The names of the columns.
            </summary>
        </member>
        <member name="P:Encog.Util.CSV.ReadCSV.ColumnCount">
            <summary>
            Return the number of columns, if known. 
            </summary>
        </member>
        <member name="M:Encog.Util.CSV.ReadCSV.ParseDate(System.String,System.String)">
            <summary>
            Parse a date using the specified format.
            </summary>
            <param name="when">A string that contains a date in the specified format.</param>
            <param name="dateFormat">The date format.</param>
            <returns>A DateTime that was parsed.</returns>
        </member>
        <member name="M:Encog.Util.CSV.ReadCSV.Begin(System.Boolean,Encog.Util.CSV.CSVFormat)">
            <summary>
            Read the headers.
            </summary>
            <param name="format">The format of this CSV file.</param>
            <param name="headers">Are headers present.</param>
        </member>
        <member name="M:Encog.Util.CSV.ReadCSV.Close">
            <summary>
            Close the file.
            </summary>
        </member>
        <member name="M:Encog.Util.CSV.ReadCSV.Get(System.Int32)">
            <summary>
            Get the specified column as a string.
            </summary>
            <param name="i">The column index, starting at zero.</param>
            <returns>The column as a string.</returns>
        </member>
        <member name="M:Encog.Util.CSV.ReadCSV.Get(System.String)">
            <summary>
            Get the column by its string name, as a string. This will only work if
            column headers were defined that have string names.
            </summary>
            <param name="column">The column name.</param>
            <returns>The column data as a string.</returns>
        </member>
        <member name="M:Encog.Util.CSV.ReadCSV.GetCount">
            <summary>
            Get the column count.
            </summary>
            <returns>The column count.</returns>
        </member>
        <member name="M:Encog.Util.CSV.ReadCSV.GetDate(System.String)">
            <summary>
            Read the specified column as a date.
            </summary>
            <param name="column">The specified column.</param>
            <returns>The specified column as a DateTime.</returns>
        </member>
        <member name="M:Encog.Util.CSV.ReadCSV.GetTime(System.String)">
            <summary>
            Read the specified column as a time.
            </summary>
            <param name="column">The specified column.</param>
            <returns>The specified column as a DateTime.</returns>
        </member>
        <member name="M:Encog.Util.CSV.ReadCSV.GetDate(System.Int32)">
            <summary>
            Read the specified column as a date.
            </summary>
            <param name="column">The specified column.</param>
            <returns>The specified column as a DateTime.</returns>
        </member>
        <member name="M:Encog.Util.CSV.ReadCSV.GetTime(System.Int32)">
            <summary>
            Read the specified column as a time.
            </summary>
            <param name="column">The specified column.</param>
            <returns>The specified column as a DateTime.</returns>
        </member>
        <member name="M:Encog.Util.CSV.ReadCSV.GetDouble(System.String)">
            <summary>
            Get the specified column as a double.
            </summary>
            <param name="column">The column to read.</param>
            <returns>The specified column as a double.</returns>
        </member>
        <member name="M:Encog.Util.CSV.ReadCSV.GetDouble(System.Int32)">
            <summary>
            Get the specified column as a double.
            </summary>
            <param name="column">The column to read.</param>
            <returns>The specified column as a double.</returns>
        </member>
        <member name="M:Encog.Util.CSV.ReadCSV.GetInt(System.String)">
            <summary>
            Get an integer that has the specified name.
            </summary>
            <param name="col">The column name to read.</param>
            <returns>The specified column as an int.</returns>
        </member>
        <member name="M:Encog.Util.CSV.ReadCSV.InitData(System.String)">
            <summary>
            Count the columns and create a an array to hold them.
            </summary>
            <param name="line">One line from the file</param>
        </member>
        <member name="M:Encog.Util.CSV.ReadCSV.Next">
            <summary>
            Read the next line.
            </summary>
            <returns>True if there are more lines to read.</returns>
        </member>
        <member name="M:Encog.Util.CSV.ReadCSV.ParseCharSep(System.String)">
            <summary>
            Parse the line into a list of values.
            </summary>
            <param name="line">The line to parse.</param>
            <returns>The elements on this line.</returns>
        </member>
        <member name="M:Encog.Util.CSV.ReadCSV.ParseSpaceSep(System.String)">
            <summary>
            Parse a line with space separators.
            </summary>
            <param name="line">The line to parse.</param>
            <returns>The list of items from the line.</returns>
        </member>
        <member name="M:Encog.Util.CSV.ReadCSV.HasMissing">
            <summary>
            Check to see if there are any missing values on the current row.
            </summary>
            <returns>True, if there are missing values.</returns>
        </member>
        <member name="T:Encog.Util.DirectoryUtil">
            <summary>
            Directory utilities.
            </summary>
        </member>
        <member name="F:Encog.Util.DirectoryUtil.BufferSize">
            <summary>
            Default buffer size for read/write operations.
            </summary>
        </member>
        <member name="M:Encog.Util.DirectoryUtil.CopyFile(System.String,System.String)">
            <summary>
            Copy the specified file.
            </summary>
            <param name="source">The file to copy.</param>
            <param name="target">The target of the copy.</param>
        </member>
        <member name="M:Encog.Util.DirectoryUtil.ReadStream(System.IO.Stream)">
            <summary>
            Read the entire contents of a stream into a string.
            </summary>
            <param name="istream">The input stream to read from.</param>
            <returns>The string that was read in.</returns>
        </member>
        <member name="M:Encog.Util.DirectoryUtil.ReadTextFile(System.String)">
            <summary>
            Read the entire contents of a stream into a string.
            </summary>
            <param name="filename">The input stream to read from.</param>
            <returns>The string that was read in.</returns>
        </member>
        <member name="T:Encog.Util.DownSample.IDownSample">
            <summary>
            A class that is able to downsample an image.
            </summary>
        </member>
        <member name="P:Encog.Util.DownSample.IDownSample.DownSampleBottom">
            <summary>
            Get the bottom boundary of the image.
            </summary>
        </member>
        <member name="P:Encog.Util.DownSample.IDownSample.DownSampleLeft">
            <summary>
            The left boundary of the image.
            </summary>
        </member>
        <member name="P:Encog.Util.DownSample.IDownSample.DownSampleRight">
            <summary>
            Get the right boundary of the image.
            </summary>
        </member>
        <member name="P:Encog.Util.DownSample.IDownSample.DownSampleTop">
            <summary>
            Get the top boundary of the image.
            </summary>
        </member>
        <member name="P:Encog.Util.DownSample.IDownSample.ImageHeight">
            <summary>
            The height of the image.
            </summary>
        </member>
        <member name="P:Encog.Util.DownSample.IDownSample.ImageWidth">
            <summary>
            The width of the image.
            </summary>
        </member>
        <member name="P:Encog.Util.DownSample.IDownSample.PixelMap">
            <summary>
            The image pixel map.
            </summary>
        </member>
        <member name="P:Encog.Util.DownSample.IDownSample.RatioX">
            <summary>
            The x-ratio of the downsample.
            </summary>
        </member>
        <member name="P:Encog.Util.DownSample.IDownSample.RatioY">
            <summary>
            The y-ratio of the downsample.
            </summary>
        </member>
        <member name="M:Encog.Util.DownSample.IDownSample.DownSample(System.Drawing.Bitmap,System.Int32,System.Int32)">
            <summary>
            Downsample the image to the specified height and width.
            </summary>
            <param name="image">The image to downsample.</param>
            <param name="height">The height to downsample to.</param>
            <param name="width">The width to downsample to.</param>
            <returns>The downsampled image.</returns>
        </member>
        <member name="M:Encog.Util.DownSample.IDownSample.FindBounds">
            <summary>
            Find the bounds around the image to exclude whitespace.
            </summary>
        </member>
        <member name="M:Encog.Util.DownSample.IDownSample.ProcessImage(System.Drawing.Bitmap)">
            <summary>
            Process the specified image.
            </summary>
            <param name="image">The image to process.</param>
        </member>
        <member name="T:Encog.Util.DownSample.RGBDownsample">
            <summary>
            Downsample an image keeping the RGB colors.
            </summary>
        </member>
        <member name="F:Encog.Util.DownSample.RGBDownsample._downSampleBottom">
            <summary>
            The bottom boundary of the downsample.
            </summary>
        </member>
        <member name="F:Encog.Util.DownSample.RGBDownsample._downSampleLeft">
            <summary>
            The left boundary of the downsample.
            </summary>
        </member>
        <member name="F:Encog.Util.DownSample.RGBDownsample._downSampleRight">
            <summary>
            The right boundary of the downsample.
            </summary>
        </member>
        <member name="F:Encog.Util.DownSample.RGBDownsample._downSampleTop">
            <summary>
            The top boundary of the downsample.
            </summary>
        </member>
        <member name="F:Encog.Util.DownSample.RGBDownsample._imageHeight">
            <summary>
            The image height.
            </summary>
        </member>
        <member name="F:Encog.Util.DownSample.RGBDownsample._imageWidth">
            <summary>
            The image width.
            </summary>
        </member>
        <member name="F:Encog.Util.DownSample.RGBDownsample._ratioX">
            <summary>
            The downsample x-ratio.
            </summary>
        </member>
        <member name="F:Encog.Util.DownSample.RGBDownsample._ratioY">
            <summary>
            The downsample y-ratio.
            </summary>
        </member>
        <member name="P:Encog.Util.DownSample.RGBDownsample.CurrentRed">
            <summary>
            The current red average.
            </summary>
        </member>
        <member name="P:Encog.Util.DownSample.RGBDownsample.CurrentBlue">
            <summary>
            The current blue average.
            </summary>
        </member>
        <member name="P:Encog.Util.DownSample.RGBDownsample.CurrentGreen">
            <summary>
            The current green average.
            </summary>
        </member>
        <member name="P:Encog.Util.DownSample.RGBDownsample.Image">
            <summary>
            The current image being processed.
            </summary>
        </member>
        <member name="P:Encog.Util.DownSample.RGBDownsample.PixelMap">
            <summary>
            The pixel map from the image.
            </summary>
        </member>
        <member name="M:Encog.Util.DownSample.RGBDownsample.DownSample(System.Drawing.Bitmap,System.Int32,System.Int32)">
            <summary>
            Called to downsample the image and store it in the down sample component.
            </summary>
            <param name="image">The image to downsample.</param>
            <param name="height">The height to downsample to.</param>
            <param name="width">THe width to downsample to.</param>
            <returns>The downsampled image.</returns>
        </member>
        <member name="M:Encog.Util.DownSample.RGBDownsample.FindBounds">
            <summary>
            This method is called to automatically crop the image so that whitespace
            is removed.
            </summary>
        </member>
        <member name="P:Encog.Util.DownSample.RGBDownsample.DownSampleBottom">
            <summary>
            The bottom of the downsample.
            </summary>
        </member>
        <member name="P:Encog.Util.DownSample.RGBDownsample.DownSampleLeft">
            <summary>
            The left of the downsample.
            </summary>
        </member>
        <member name="P:Encog.Util.DownSample.RGBDownsample.DownSampleRight">
            <summary>
            The right of the downsample.
            </summary>
        </member>
        <member name="P:Encog.Util.DownSample.RGBDownsample.DownSampleTop">
            <summary>
            The top of the downsample.
            </summary>
        </member>
        <member name="P:Encog.Util.DownSample.RGBDownsample.ImageHeight">
            <summary>
            The image height.
            </summary>
        </member>
        <member name="P:Encog.Util.DownSample.RGBDownsample.ImageWidth">
            <summary>
            The image width.
            </summary>
        </member>
        <member name="P:Encog.Util.DownSample.RGBDownsample.RatioX">
            <summary>
            The x-ratio.
            </summary>
        </member>
        <member name="P:Encog.Util.DownSample.RGBDownsample.RatioY">
            <summary>
            The y-ratio.
            </summary>
        </member>
        <member name="M:Encog.Util.DownSample.RGBDownsample.ProcessImage(System.Drawing.Bitmap)">
            <summary>
            Process the image and prepare it to be downsampled.
            </summary>
            <param name="image">The image to downsample.</param>
        </member>
        <member name="M:Encog.Util.DownSample.RGBDownsample.DownSampleRegion(System.Int32,System.Int32)">
            <summary>
            Called to downsample a region of the image.
            </summary>
            <param name="x">The x coordinate of the resulting downsample.</param>
            <param name="y">The y coordinate of the resulting downsample.</param>
        </member>
        <member name="M:Encog.Util.DownSample.RGBDownsample.HLineClear(System.Int32)">
            <summary>
            This method is called internally to see if there are any pixels in the
            given scan line. This method is used to perform autocropping.
            </summary>
            <param name="y"></param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.DownSample.RGBDownsample.VLineClear(System.Int32)">
            <summary>
            This method is called internally to see if there are any pixels in the
            given scan line. This method is used to perform autocropping.
            </summary>
            <param name="x">The vertical line to scan.</param>
            <returns>True if there are any pixels in the specified vertical line.</returns>
        </member>
        <member name="T:Encog.Util.DownSample.SimpleIntensityDownsample">
            <summary>
            Downsample an image using a simple intensity scale. Color information is
            discarded.
            </summary>
        </member>
        <member name="M:Encog.Util.DownSample.SimpleIntensityDownsample.DownSample(System.Drawing.Bitmap,System.Int32,System.Int32)">
            <summary>
            Called to downsample the image and store it in the down sample component. 
            </summary>
            <param name="image">The image to downsample.</param>
            <param name="height">The height to downsample to.</param>
            <param name="width">THe width to downsample to.</param>
            <returns>The downsampled image.</returns>
        </member>
        <member name="T:Encog.Util.HTTP.FormUtility">
            <summary>
            FormUtility: This class is used to construct responses to
            HTML forms. The class supports both standard HTML forms,
            as well as multipart forms.
            </summary>
        </member>
        <member name="F:Encog.Util.HTTP.FormUtility._boundary">
            <summary>
            The boundary used for a multipart post. This field is
            null if this is not a multipart form and has a value if
            this is a multipart form.
            </summary>
        </member>
        <member name="F:Encog.Util.HTTP.FormUtility._os">
            <summary>
            The stream to output the encoded form to.
            </summary>
        </member>
        <member name="F:Encog.Util.HTTP.FormUtility._writer">
            <summary>
            The text writer to use.
            </summary>
        </member>
        <member name="F:Encog.Util.HTTP.FormUtility._first">
            <summary>
            Keep track of if we're on the first form element.
            </summary>
        </member>
        <member name="M:Encog.Util.HTTP.FormUtility.#ctor(System.IO.Stream,System.String)">
            <summary>
            Prepare to access either a regular, or multipart, form.
            </summary>
            <param name="os">The stream to output to.</param>
            <param name="boundary">The boundary to be used, or null if this is
            not a multipart form.</param>
        </member>
        <member name="M:Encog.Util.HTTP.FormUtility.GetBoundary">
            <summary>
            Generate a boundary for a multipart form.
            </summary>
            <returns>The boundary.</returns>
        </member>
        <member name="M:Encog.Util.HTTP.FormUtility.Encode(System.String)">
            <summary>
            Encode the specified string. This encodes all special
            characters.
            </summary>
            <param name="str">The string to encode.</param>
            <returns>The encoded string.</returns>
        </member>
        <member name="M:Encog.Util.HTTP.FormUtility.RandomString">
            <summary>
            Generate a random string, of a specified length. This
            is used to generate the multipart boundary.
            </summary>
            <returns>A random string.</returns>
        </member>
        <member name="M:Encog.Util.HTTP.FormUtility.AddFile(System.String,System.String)">
            <summary>
            Add a file to a multipart form.  Default mime type to
            application/octet-stream.
            </summary>
            <param name="name">The field name.</param>
            <param name="file">The file to attach.</param>
        </member>
        <member name="M:Encog.Util.HTTP.FormUtility.AddFile(System.String,System.String,System.String)">
            <summary>
            Add a file to a multipart form.
            </summary>
            <param name="name">The field name.</param>
            <param name="file">he file to attach.</param>
            <param name="type">The mime type</param>
        </member>
        <member name="M:Encog.Util.HTTP.FormUtility.Add(System.String,System.String)">
            <summary>
            Add a regular text field to either a regular or
            multipart form.
            </summary>
            <param name="name">The name of the field.</param>
            <param name="v">The value of the field.</param>
        </member>
        <member name="M:Encog.Util.HTTP.FormUtility.Complete">
            <summary>
            Complete the building of the form.
            </summary>
        </member>
        <member name="M:Encog.Util.HTTP.FormUtility.Boundary">
            <summary>
            Generate a multipart form boundary.
            </summary>
        </member>
        <member name="M:Encog.Util.HTTP.FormUtility.Newline">
            <summary>
            Create a new line by displaying a carriage return and
            linefeed.
            </summary>
        </member>
        <member name="M:Encog.Util.HTTP.FormUtility.Write(System.String)">
            <summary>
            Write the specified string, without a carriage return
            and line feed.
            </summary>
            <param name="str">The string to write.</param>
        </member>
        <member name="M:Encog.Util.HTTP.FormUtility.WriteName(System.String)">
            <summary>
            Write the name element for a multipart post.
            </summary>
            <param name="name">The name of the field.</param>
        </member>
        <member name="M:Encog.Util.HTTP.FormUtility.Writeln(System.String)">
            <summary>
            Write a string, with a carriage return and linefeed.
            </summary>
            <param name="str">The string to write.</param>
        </member>
        <member name="T:Encog.Util.HTTP.URLUtility">
            <summary>
            URLUtility: THis class contains several useful methods
            for dealing with URL's.
            </summary>
        </member>
        <member name="F:Encog.Util.HTTP.URLUtility.IndexFile">
            <summary>
            The name of an HTML index file.
            </summary>
        </member>
        <member name="M:Encog.Util.HTTP.URLUtility.ConstructURL(System.Uri,System.String,System.Boolean)">
            <summary>
            Construct a URL from a string.
            </summary>
            <param name="baseURL">The page that the URL was found on.</param>
            <param name="url">The URL found.</param>
            <param name="stripFragment">Should fragments be stripped.  Fragments are the part of a URL after the # sign.  They do not specify actual pages, but rather part of a page.  As a result, they are usually not needed by a spider or bot.</param>
            <returns>The constructed URL.</returns>
        </member>
        <member name="M:Encog.Util.HTTP.URLUtility.ContainsInvalidURLCharacters(System.String)">
            <summary>
            Does the URL contain invalid characters?
            </summary>
            <param name="url">The URL</param>
            <returns>True if the URL contains invalid characters.</returns>
        </member>
        <member name="M:Encog.Util.HTTP.URLUtility.ConvertFilename(System.String,System.Uri,System.Boolean)">
            <summary>
            Convert a filename for local storage. Also create the
            directory tree.
            </summary>
            <param name="basePath">The local path that forms the base of the
            downloaded web tree.</param>
            <param name="url">The URL path.</param>
            <param name="mkdir">True if a directory structure should be created
            to support this file.  Directories will only be
            created, if needed.</param>
            <returns></returns>
        </member>
        <member name="T:Encog.Util.Identity.BasicGenerateID">
            <summary>
            Generate unique id's.  ID's start at 1.
            </summary>
        </member>
        <member name="M:Encog.Util.Identity.BasicGenerateID.#ctor">
            <summary>
            Construct an ID generator.
            </summary>
        </member>
        <member name="P:Encog.Util.Identity.BasicGenerateID.CurrentID">
            <summary>
            The current id to generate.  This is the next id returned.
            </summary>
        </member>
        <member name="M:Encog.Util.Identity.BasicGenerateID.Generate">
            <summary>
            Generate a unique id.
            </summary>
            <returns>The unique id.</returns>
        </member>
        <member name="T:Encog.Util.Identity.IGenerateID">
            <summary>
            Interface for ID generation.
            </summary>
        </member>
        <member name="P:Encog.Util.Identity.IGenerateID.CurrentID">
            <summary>
            Get the value for the current id.
            </summary>
        </member>
        <member name="M:Encog.Util.Identity.IGenerateID.Generate">
            <summary>
            Generate an ID number.
            </summary>
            <returns>The ID number generated.</returns>
        </member>
        <member name="T:Encog.Util.ObjectCloner">
            <summary>
            A simple Object cloner that uses serialization. Actually works really well
            for the somewhat complex nature of BasicNetwork. Performs a deep copy without
            all the headache of programming a custom clone.
            
            From a Java example at:
            
            http://www.javaworld.com/javaworld/javatips/jw-javatip76.html?page=2
            
            </summary>
        </member>
        <member name="M:Encog.Util.ObjectCloner.#ctor">
            <summary>
            Private constructor.
            </summary>
        </member>
        <member name="M:Encog.Util.ObjectCloner.DeepCopy(System.Object)">
            <summary>
            Perform a deep copy.
            </summary>
            <param name="oldObj">The old object.</param>
            <returns>The new object.</returns>
        </member>
        <member name="T:Encog.Util.ReflectionUtil">
            <summary>
            A set of C# reflection utilities.
            </summary>
        </member>
        <member name="F:Encog.Util.ReflectionUtil.AfPath">
            <summary>
            Path to the activation functions.
            </summary>
        </member>
        <member name="F:Encog.Util.ReflectionUtil.RBFPath">
            <summary>
            Path to RBF's.
            </summary>
        </member>
        <member name="F:Encog.Util.ReflectionUtil.ClassMap">
            <summary>
            A map between short class names and the full path names.
            </summary>
        </member>
        <member name="M:Encog.Util.ReflectionUtil.#ctor">
            <summary>
            Private constructor.
            </summary>
        </member>
        <member name="M:Encog.Util.ReflectionUtil.FindField(System.Type,System.String)">
            <summary>
            Find the specified field, look also in superclasses.
            </summary>
            <param name="c">The class to search.</param>
            <param name="name">The name of the field we are looking for.</param>
            <returns>The field.</returns>
        </member>
        <member name="M:Encog.Util.ReflectionUtil.GetAllFields(System.Type)">
            <summary>
            Get all of the fields from the specified class as a collection.
            </summary>
            <param name="c">The class to access.</param>
            <returns>All of the fields from this class and subclasses.</returns>
        </member>
        <member name="M:Encog.Util.ReflectionUtil.GetAllFields(System.Type,System.Collections.Generic.IList{System.Reflection.FieldInfo})">
            <summary>
            Get all of the fields for the specified class and recurse to check the base class.
            </summary>
            <param name="c">The class to scan.</param>
            <param name="result">A list of fields.</param>
        </member>
        <member name="M:Encog.Util.ReflectionUtil.LoadClassmap">
            <summary>
            Load the classmap file. This allows classes to be resolved using just the
            simple name.
            </summary>
        </member>
        <member name="M:Encog.Util.ReflectionUtil.ResolveEncogClass(System.String)">
            <summary>
            Resolve an encog class using its simple name.
            </summary>
            <param name="name">The simple name of the class.</param>
            <returns>The class requested.</returns>
        </member>
        <member name="M:Encog.Util.ReflectionUtil.HasAttribute(System.Reflection.FieldInfo,System.Type)">
            <summary>
            Determine if the specified field has the specified attribute.
            </summary>
            <param name="field">The field to check.</param>
            <param name="t">See if the field has this attribute.</param>
            <returns>True if the field has the specified attribute.</returns>
        </member>
        <member name="M:Encog.Util.ReflectionUtil.HasAttribute(System.Type,System.Type)">
            <summary>
            Determine if the specified type contains the specified attribute.
            </summary>
            <param name="t">The type.</param>
            <param name="attribute">The attribute.</param>
            <returns>True if the type contains the attribute.</returns>
        </member>
        <member name="M:Encog.Util.ReflectionUtil.ResolveEnum(System.Reflection.FieldInfo,System.Reflection.FieldInfo)">
            <summary>
            Resolve an enumeration.
            </summary>
            <param name="field">The field to resolve.</param>
            <param name="v">The value to get the enum for.</param>
            <returns>The enum that was resolved.</returns>
        </member>
        <member name="M:Encog.Util.ReflectionUtil.LoadObject(System.String)">
            <summary>
            Loop over all loaded assembles and try to create the class.
            </summary>
            <param name="name">The class to create.</param>
            <returns>The created class.</returns>
        </member>
        <member name="T:Encog.Util.SerializeObject">
            <summary>
            SerializeObject: Load or save an object using DotNet serialization.
            </summary>
        </member>
        <member name="M:Encog.Util.SerializeObject.#ctor">
            <summary>
            Private constructor, call everything statically.
            </summary>
        </member>
        <member name="M:Encog.Util.SerializeObject.Load(System.String)">
            <summary>
            Load the specified filename.
            </summary>
            <param name="filename">The filename to load from.</param>
            <returns>The object loaded from that file.</returns>
        </member>
        <member name="M:Encog.Util.SerializeObject.Save(System.String,System.Object)">
            <summary>
            Save the specified object.
            </summary>
            <param name="filename">The filename to save to.</param>
            <param name="obj">The object to save.</param>
        </member>
        <member name="T:Encog.Util.StringUtil">
            <summary>
            Simple class for string utilities.
            </summary>
        </member>
        <member name="M:Encog.Util.StringUtil.EqualsIgnoreCase(System.String,System.String)">
            <summary>
            Compare two strings, ignore case.
            </summary>
            <param name="a">The first string.</param>
            <param name="b">The second string.</param>
            <returns></returns>
        </member>
        <member name="M:Encog.Util.StringUtil.FromBytes(System.Byte[])">
            <summary>
            Simple utility to take an array of ASCII bytes and convert to
            a String.  Works with Silverlight as well.
            </summary>
            <param name="b">The byte array.</param>
            <returns>The string created from the byte array.</returns>
        </member>
        <member name="T:Encog.Util.Validate.ValidateNetwork">
            <summary>
            Perform validations on a network.
            </summary>
        </member>
        <member name="M:Encog.Util.Validate.ValidateNetwork.ValidateMethodToData(Encog.ML.IMLMethod,Encog.ML.Data.IMLDataSet)">
            <summary>
            Validate that the specified data can be used with the method.
            </summary>
            <param name="method">The method to validate.</param>
            <param name="training">The training data.</param>
        </member>
        <member name="T:Encog.Util.YahooSearch">
            <summary>
            Perform a search using Yahoo.
            </summary>
        </member>
        <member name="M:Encog.Util.YahooSearch.DoSearch(System.Uri)">
            <summary>
            Perform a Yahoo search.
            </summary>
            <param name="url">The REST URL.</param>
            <returns>The search results.</returns>
        </member>
        <member name="M:Encog.Util.YahooSearch.Search(System.String)">
            <summary>
            Perform a Yahoo search.
            </summary>
            <param name="searchFor">What are we searching for.</param>
            <returns>The URLs that contain the specified item.</returns>
        </member>
        <member name="T:Encog.NullStatusReportable">
            <summary>
            A report object that does nothing.
            </summary>
        </member>
        <member name="M:Encog.NullStatusReportable.Report(System.Int32,System.Int32,System.String)">
            <summary>
            Simply ignore any status reports.
            </summary>
            <param name="total">Not used.</param>
            <param name="current">Not used.</param>
            <param name="message">Not used.</param>
        </member>
        <member name="T:Encog.Parse.ParseError">
            <summary>
            Indicates an error has occurred in one of the parsers.
            </summary>
        </member>
        <member name="M:Encog.Parse.ParseError.#ctor(System.String)">
            <summary>
            Construct a message exception.
            </summary>
            <param name="str">The message.</param>
        </member>
        <member name="M:Encog.Parse.ParseError.#ctor(System.Exception)">
            <summary>
            Pass on an exception.
            </summary>
            <param name="e">The other exception.</param>
        </member>
        <member name="T:Encog.Parse.PeekableInputStream">
            <summary>
            PeekableInputStream: This class allows a stream to be
            read like normal.  However, the ability to peek is added.
            The calling method can peek as far as is needed.  This is
            used by the ParseHTML class.
            </summary>
        </member>
        <member name="F:Encog.Parse.PeekableInputStream._stream">
            <summary>
            The underlying stream.
            </summary>
        </member>
        <member name="F:Encog.Parse.PeekableInputStream._peekBytes">
            <summary>
            Bytes that have been peeked at.
            </summary>
        </member>
        <member name="F:Encog.Parse.PeekableInputStream._peekLength">
            <summary>
            How many bytes have been peeked at.
            </summary>
        </member>
        <member name="M:Encog.Parse.PeekableInputStream.#ctor(System.IO.Stream)">
            <summary>
            Construct a peekable input stream based on the specified stream.
            </summary>
            <param name="stream">The underlying stream.</param>
        </member>
        <member name="P:Encog.Parse.PeekableInputStream.CanRead">
            <summary>
            Specifies that the stream can read.
            </summary>
        </member>
        <member name="P:Encog.Parse.PeekableInputStream.CanWrite">
            <summary>
            Specifies that the stream cannot write.
            </summary>
        </member>
        <member name="P:Encog.Parse.PeekableInputStream.CanSeek">
            <summary>
            Specifies that the stream cannot seek.
            </summary>
        </member>
        <member name="P:Encog.Parse.PeekableInputStream.Length">
            <summary>
            Specifies that the stream cannot determine its length.
            </summary>
        </member>
        <member name="P:Encog.Parse.PeekableInputStream.Position">
            <summary>
            Specifies that the stream cannot determine its position.
            </summary>
        </member>
        <member name="M:Encog.Parse.PeekableInputStream.Flush">
            <summary>
            Not supported.
            </summary>
        </member>
        <member name="M:Encog.Parse.PeekableInputStream.SetLength(System.Int64)">
            <summary>
            Not supported.
            </summary>
            <param name="v">The length.</param>
        </member>
        <member name="M:Encog.Parse.PeekableInputStream.Seek(System.Int64,System.IO.SeekOrigin)">
            <summary>
            Not supported.
            </summary>
            <param name="offset"></param>
            <param name="origin"></param>
            <returns></returns>
        </member>
        <member name="M:Encog.Parse.PeekableInputStream.Read(System.Byte[],System.Int32,System.Int32)">
            <summary>
            Read bytes from the stream.
            </summary>
            <param name="buffer">The buffer to read the bytes into.</param>
            <param name="offset">The offset to begin storing the bytes at.</param>
            <param name="count">How many bytes to read.</param>
            <returns>The number of bytes read.</returns>
        </member>
        <member name="M:Encog.Parse.PeekableInputStream.Write(System.Byte[],System.Int32,System.Int32)">
            <summary>
            Not supported.
            </summary>
            <param name="buffer"></param>
            <param name="offset"></param>
            <param name="count"></param>
        </member>
        <member name="M:Encog.Parse.PeekableInputStream.Read">
            <summary>
            Read a single byte.
            </summary>
            <returns>The byte read, or -1 for end of stream.</returns>
        </member>
        <member name="M:Encog.Parse.PeekableInputStream.Peek(System.Int32)">
            <summary>
            Peek ahead the specified depth.
            </summary>
            <param name="depth">How far to peek ahead.</param>
            <returns>The byte read.</returns>
        </member>
        <member name="M:Encog.Parse.PeekableInputStream.Peek">
            <summary>
            Peek at the next character from the stream.
            </summary>
            <returns>The next character.</returns>
        </member>
        <member name="M:Encog.Parse.PeekableInputStream.Peek(System.String)">
            <summary>
            Peek ahead and see if the specified string is present.
            </summary>
            <param name="str">The string we are looking for.</param>
            <returns>True if the string was found.</returns>
        </member>
        <member name="M:Encog.Parse.PeekableInputStream.Skip(System.Int64)">
            <summary>
            Skip the specified number of bytes.
            </summary>
            <param name="count">The number of bytes to skip.</param>
            <returns>The actual number of bytes skipped.</returns>
        </member>
        <member name="T:Encog.Parse.Tags.Read.ReadHTML">
            <summary>
            This class is designed to parse HTML documents.  It will parse the
            individual tags and text between the tags.
            </summary>
        </member>
        <member name="M:Encog.Parse.Tags.Read.ReadHTML.#ctor(System.IO.Stream)">
            <summary>
            Construct a HTML reader.
            </summary>
            <param name="istream">The input stream to read from.</param>
        </member>
        <member name="M:Encog.Parse.Tags.Read.ReadHTML.ParseAttributeName">
            <summary>
            Parse the attribute name.
            </summary>
            <returns>The attribute name.</returns>
        </member>
        <member name="T:Encog.Parse.Tags.Read.ReadTags">
            <summary>
            Base class used to read tags.  This base class is used by both the
            XML and HTML parsing.
            </summary>
        </member>
        <member name="F:Encog.Parse.Tags.Read.ReadTags.CharBullet">
            <summary>
            The bullet character.
            </summary>
        </member>
        <member name="F:Encog.Parse.Tags.Read.ReadTags.CharTrademark">
            <summary>
            The bullet character.
            </summary>
        </member>
        <member name="F:Encog.Parse.Tags.Read.ReadTags.MaxLength">
            <summary>
            Maximum length string to read.
            </summary>
        </member>
        <member name="F:Encog.Parse.Tags.Read.ReadTags._charMap">
            <summary>
            A mapping of certain HTML encoded values to their actual
            character values.
            </summary>
        </member>
        <member name="F:Encog.Parse.Tags.Read.ReadTags._source">
            <summary>
            The stream that we are parsing from.
            </summary>
        </member>
        <member name="F:Encog.Parse.Tags.Read.ReadTags._tag">
            <summary>
            The current HTML tag. Access this property if the read function returns
            0.
            </summary>
        </member>
        <member name="F:Encog.Parse.Tags.Read.ReadTags._lockedEndTag">
            <summary>
            Are we locked, looking for an end tag?  Such as the end of a
            comment?
            </summary>
        </member>
        <member name="F:Encog.Parse.Tags.Read.ReadTags._insertEndTag">
            <summary>
            Does a "fake" end-tag need to be added, because of a compound
            tag (i.e. <br/>)?  If so, this will hold a string for that tag.
            </summary>
        </member>
        <member name="M:Encog.Parse.Tags.Read.ReadTags.#ctor(System.IO.Stream)">
            <summary>
            The constructor should be passed an InputStream that we will parse from.
            </summary>
            <param name="istream">A stream to parse from.</param>
        </member>
        <member name="M:Encog.Parse.Tags.Read.ReadTags.EatWhitespace">
            <summary>
            Remove any whitespace characters that are next in the InputStream.
            </summary>
        </member>
        <member name="P:Encog.Parse.Tags.Read.ReadTags.LastTag">
            <summary>
            Return the last tag found, this is normally called just after the read
            function returns a zero.
            </summary>
        </member>
        <member name="M:Encog.Parse.Tags.Read.ReadTags.IsIt(System.String,System.Boolean)">
            <summary>
            Checks to see if the next tag is the tag specified.
            </summary>
            <param name="name">The name of the tag desired.</param>
            <param name="start">True if a starting tag is desired.</param>
            <returns>True if the next tag matches these criteria.</returns>
        </member>
        <member name="M:Encog.Parse.Tags.Read.ReadTags.ParseAttributeName">
            <summary>
            Parse an attribute name, if one is present.
            </summary>
            <returns>Return the attribute name, or null if none present.</returns>
        </member>
        <member name="M:Encog.Parse.Tags.Read.ReadTags.ParseSpecialCharacter">
            <summary>
            Parse any special characters
            </summary>
            <returns>The character that was parsed.</returns>
        </member>
        <member name="M:Encog.Parse.Tags.Read.ReadTags.ParseString">
            <summary>
            Called to parse a double or single quote string.
            </summary>
            <returns>The string parsed.</returns>
        </member>
        <member name="M:Encog.Parse.Tags.Read.ReadTags.ParseTag">
            <summary>
            Called when a tag is detected. This method will parse the tag.
            </summary>
        </member>
        <member name="M:Encog.Parse.Tags.Read.ReadTags.PeekEndTag(System.Collections.Generic.IEnumerable{System.Char})">
            <summary>
            Check to see if the ending tag is present.
            </summary>
            <param name="name">The type of end tag being sought.</param>
            <returns>True if the ending tag was found.</returns>
        </member>
        <member name="M:Encog.Parse.Tags.Read.ReadTags.Read">
            <summary>
            Read a single character from the HTML source, if this function returns
            zero(0) then you should call getTag to see what tag was found. Otherwise
            the value returned is simply the next character found.
            </summary>
            <returns>The character read, or zero if there is an HTML tag. If zero is
            returned, then call getTag to get the next tag.</returns>
        </member>
        <member name="M:Encog.Parse.Tags.Read.ReadTags.ReadToTag">
            <summary>
            Read until we reach the next tag.
            </summary>
            <returns>True if a tag was found, false on EOF.</returns>
        </member>
        <member name="M:Encog.Parse.Tags.Read.ReadTags.ToString">
            <summary>
            Returns this object as a string.
            </summary>
            <returns>This object as a string.</returns>
        </member>
        <member name="T:Encog.Parse.Tags.Read.ReadXML">
            <summary>
            Parse XML data.
            </summary>
        </member>
        <member name="M:Encog.Parse.Tags.Read.ReadXML.#ctor(System.IO.Stream)">
            <summary>
            Construct an XML reader.
            </summary>
            <param name="istream">The input stream to read from.</param>
        </member>
        <member name="M:Encog.Parse.Tags.Read.ReadXML.FindTag(System.String,System.Boolean)">
            <summary>
            Advance until the specified tag is found.
            </summary>
            <param name="name">The name of the tag we are looking for.</param>
            <param name="beginTag">True if this is a begin tage, false otherwise.</param>
            <returns>True if the tag was found.</returns>
        </member>
        <member name="M:Encog.Parse.Tags.Read.ReadXML.ReadIntToTag">
            <summary>
            Read an integer that is contained between the current position, and the
            next tag.
            </summary>
            <returns>The integer that was found.</returns>
        </member>
        <member name="M:Encog.Parse.Tags.Read.ReadXML.ReadPropertyBlock">
            <summary>
            Read all property data until an end tag, which corrisponds to the current
            tag, is found. The properties found will be returned in a map.
            </summary>
            <returns>The properties found.</returns>
        </member>
        <member name="M:Encog.Parse.Tags.Read.ReadXML.ReadTextToTag">
            <summary>
            Read all text between the current position and the next tag.
            </summary>
            <returns>The string that was read.</returns>
        </member>
        <member name="T:Encog.Parse.Tags.Tag">
            <summary>
            HTMLTag: This class holds a single HTML tag. This class subclasses the
            AttributeList class. This allows the HTMLTag class to hold a collection of
            attributes, just as an actual HTML tag does.
            </summary>
        </member>
        <member name="T:Encog.Parse.Tags.Tag.Type">
            <summary>
            Tag types.
            </summary>
        </member>
        <member name="F:Encog.Parse.Tags.Tag.Type.Begin">
            <summary>
            A beginning tag.
            </summary>
        </member>
        <member name="F:Encog.Parse.Tags.Tag.Type.End">
            <summary>
            An ending tag.
            </summary>
        </member>
        <member name="F:Encog.Parse.Tags.Tag.Type.Comment">
            <summary>
            A comment.
            </summary>
        </member>
        <member name="F:Encog.Parse.Tags.Tag.Type.CDATA">
            <summary>
            A CDATA section.
            </summary>
        </member>
        <member name="F:Encog.Parse.Tags.Tag._attributes">
            <summary>
            The tag's attributes.
            </summary>
        </member>
        <member name="F:Encog.Parse.Tags.Tag._name">
            <summary>
            The tag name.
            </summary>
        </member>
        <member name="F:Encog.Parse.Tags.Tag._type">
            <summary>
            The tag type.
            </summary>
        </member>
        <member name="M:Encog.Parse.Tags.Tag.Clear">
            <summary>
            Clear the name, type and attributes.
            </summary>
        </member>
        <member name="M:Encog.Parse.Tags.Tag.Clone">
            <summary>
            Clone this object.
            </summary>
            <returns>A cloned copy of the object.</returns>
        </member>
        <member name="M:Encog.Parse.Tags.Tag.GetAttributeInt(System.String)">
            <summary>
            Get the specified attribute as an integer.
            </summary>
            <param name="attributeId">The attribute name.</param>
            <returns>The attribute value.</returns>
        </member>
        <member name="P:Encog.Parse.Tags.Tag.Attributes">
            <summary>
            The attributes for this tag as a dictionary.
            </summary>
        </member>
        <member name="M:Encog.Parse.Tags.Tag.GetAttributeValue(System.String)">
            <summary>
            Get the value of the specified attribute.
            </summary>
            <param name="name">The name of an attribute.</param>
            <returns>The value of the specified attribute.</returns>
        </member>
        <member name="P:Encog.Parse.Tags.Tag.Name">
            <summary>
            The tag name.
            </summary>
        </member>
        <member name="P:Encog.Parse.Tags.Tag.TagType">
            <summary>
            The tag type.
            </summary>
        </member>
        <member name="M:Encog.Parse.Tags.Tag.SetAttribute(System.String,System.String)">
            <summary>
            Set a HTML attribute.
            </summary>
            <param name="name">The name of the attribute.</param>
            <param name="valueRen">The value of the attribute.</param>
        </member>
        <member name="M:Encog.Parse.Tags.Tag.ToString">
            <summary>
            Convert this tag back into string form, with the 
            beginning &lt; and ending &gt;.
            </summary>
            <returns>The Attribute object that was found.</returns>
        </member>
        <member name="T:Encog.Parse.Tags.TagConst">
            <summary>
            Constants to use while parsing the tags.
            </summary>
        </member>
        <member name="F:Encog.Parse.Tags.TagConst.CommentBegin">
            <summary>
            The beginning of a comment.
            </summary>
        </member>
        <member name="F:Encog.Parse.Tags.TagConst.CommentEnd">
            <summary>
            The end of a comment.
            </summary>
        </member>
        <member name="F:Encog.Parse.Tags.TagConst.CDATABegin">
            <summary>
            The beginning of a CDATA section.
            </summary>
        </member>
        <member name="F:Encog.Parse.Tags.TagConst.CDATAEnd">
            <summary>
            The end of a CDATA section.
            </summary>
        </member>
        <member name="M:Encog.Parse.Tags.TagConst.#ctor">
            <summary>
            Private constructor.
            </summary>
        </member>
        <member name="T:Encog.Parse.Tags.Write.WriteTags">
            <summary>
            Class used to write out tags, such as XML or HTML.
            </summary>
        </member>
        <member name="F:Encog.Parse.Tags.Write.WriteTags._output">
            <summary>
            The output stream to write to.
            </summary>
        </member>
        <member name="F:Encog.Parse.Tags.Write.WriteTags._tagStack">
            <summary>
            Stack to keep track of beginning and ending tags.
            </summary>
        </member>
        <member name="F:Encog.Parse.Tags.Write.WriteTags._attributes">
            <summary>
            The attributes for the current tag.
            </summary>
        </member>
        <member name="F:Encog.Parse.Tags.Write.WriteTags._encoder">
            <summary>
            Used to encode strings to bytes.
            </summary>
        </member>
        <member name="M:Encog.Parse.Tags.Write.WriteTags.#ctor(System.IO.Stream)">
            <summary>
            Construct an object to write tags.
            </summary>
            <param name="output">THe output stream.</param>
        </member>
        <member name="M:Encog.Parse.Tags.Write.WriteTags.AddAttribute(System.String,System.String)">
            <summary>
            Add an attribute to be written with the next tag.
            </summary>
            <param name="name">The name of the attribute.</param>
            <param name="v">The value of the attribute.</param>
        </member>
        <member name="M:Encog.Parse.Tags.Write.WriteTags.AddCDATA(System.String)">
            <summary>
            Add CDATA to the output stream. XML allows a large block of unformatted
            text to be added as a CDATA tag.
            </summary>
            <param name="text">The text to add.</param>
        </member>
        <member name="M:Encog.Parse.Tags.Write.WriteTags.AddProperty(System.String,System.Double)">
            <summary>
            Add a property as a double. A property is a value enclosed in two tags.
            </summary>
            <param name="name">The name of the enclosing tags.</param>
            <param name="d">The value to store.</param>
        </member>
        <member name="M:Encog.Parse.Tags.Write.WriteTags.AddProperty(System.String,System.Int32)">
            <summary>
            Add a property as an integer. A property is a value enclosed in two tags.
            </summary>
            <param name="name">The name of the enclosing tags.</param>
            <param name="i">The value to store.</param>
        </member>
        <member name="M:Encog.Parse.Tags.Write.WriteTags.AddProperty(System.String,System.String)">
            <summary>
            Add a property as a string. A property is a value enclosed in two tags.
            </summary>
            <param name="name">The name of the enclosing tags.</param>
            <param name="str">The value to store.</param>
        </member>
        <member name="M:Encog.Parse.Tags.Write.WriteTags.AddText(System.String)">
            <summary>
            Add text.
            </summary>
            <param name="text">The text to add.</param>
        </member>
        <member name="M:Encog.Parse.Tags.Write.WriteTags.BeginDocument">
            <summary>
            Called to begin the document.
            </summary>
        </member>
        <member name="M:Encog.Parse.Tags.Write.WriteTags.BeginTag(System.String)">
            <summary>
            Begin a tag with the specified name.
            </summary>
            <param name="name">The tag to begin.</param>
        </member>
        <member name="M:Encog.Parse.Tags.Write.WriteTags.Close">
            <summary>
            Close this object.
            </summary>
        </member>
        <member name="M:Encog.Parse.Tags.Write.WriteTags.EndDocument">
            <summary>
            End the document.
            </summary>
        </member>
        <member name="M:Encog.Parse.Tags.Write.WriteTags.EndTag">
            <summary>
            End the current tag.
            </summary>
        </member>
        <member name="M:Encog.Parse.Tags.Write.WriteTags.AddProperty(System.String,System.Double[],System.Int32)">
            <summary>
            Write an array as a property.
            </summary>
            <param name="name">The name of the property.</param>
            <param name="array">The array to write.</param>
            <param name="len">The length of the array to write.</param>
        </member>
        <member name="M:Encog.Parse.Tags.Write.WriteTags.AddProperty(System.String,System.Int32[],System.Int32)">
            <summary>
            Write an array as a property.
            </summary>
            <param name="name">The name of the property.</param>
            <param name="array">The array to write.</param>
            <param name="len">The length of the array to write.</param>
        </member>
        <member name="M:Encog.Parse.Tags.Write.WriteTags.EndTag(System.String)">
            <summary>
            End a tag, require that we are ending the specified tag.
            </summary>
            <param name="name">The tag to be ending.</param>
        </member>
        <member name="T:Encog.Parse.Tags.Write.WriteXML">
            <summary>
            Contains specifics to writing XML.
            </summary>
        </member>
        <member name="M:Encog.Parse.Tags.Write.WriteXML.#ctor(System.IO.Stream)">
            <summary>
            Construct an object to write an XML file.
            </summary>
            <param name="os">The output stream.</param>
        </member>
    </members>
</doc>
