using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
using System.IO;
using System.Runtime.CompilerServices;
using System.Drawing;
using System.Threading;
using System.Globalization;
using System.Reflection;
using System.Xml;
using System.Collections;
using System.Data.Common;
using System.Threading.Tasks;
using System.Data.OleDb;
using System.Diagnostics;
using System.Runtime.Serialization.Formatters.Binary;

namespace RBF
{

    public interface ICalculationCriteria
    {
        /// <summary>
        /// Calculate the error with a single sigma.
        /// </summary>
        ///
        /// <param name="sigma">The sigma.</param>
        /// <returns>The error.</returns>
        double CalcErrorWithSingleSigma(double sigma);

        /// <summary>
        /// Calculate the error with multiple sigmas.
        /// </summary>
        ///
        /// <param name="x">The data.</param>
        /// <param name="direc">The first derivative.</param>
        /// <param name="deriv2">The 2nd derivatives.</param>
        /// <param name="b">Calculate the derivative.</param>
        /// <returns>The error.</returns>
        double CalcErrorWithMultipleSigma(double[] x, double[] direc,
                                          double[] deriv2, bool b);
    }

    public interface IEndTrainingStrategy : IStrategy
    {
        /// <returns>True if training should stop.</returns>
        bool ShouldStop();
    }

    public interface INeuralData : IMLData
    {
    }

    public interface IErrorFunction
    {
        /// <summary>
        /// Calculate the error.
        /// </summary>
        /// <param name="ideal">The ideal values.</param>
        /// <param name="actual">The actual values.</param>
        /// <param name="error">The rror output.</param>
        void CalculateError(double[] ideal, double[] actual, double[] error);
    }

    public interface INeuralDataSet : IMLDataSet
    {
    }

    public interface IGene : IComparable<IGene>
    {
        /// <summary>
        /// Get the ID of this gene, -1 for undefined.
        /// </summary>
        ///
        /// <value>The ID of this gene.</value>
        long Id
        {
            get;
        }


        /// <value>The innovation ID of this gene.</value>
        long InnovationId
        {
            get;
        }


        /// <summary>
        /// Determine if this gene is enabled.
        /// </summary>
        ///
        /// <value>True if this gene is enabled.</value>
        bool Enabled
        {
            get;
            set;
        }

        /// <summary>
        /// Copy another gene to this one.
        /// </summary>
        ///
        /// <param name="gene">The other gene to copy.</param>
        void Copy(IGene gene);
    }

    public interface IMutate
    {
        /// <summary>
        /// Perform a mutation on the specified Q.
        /// </summary>
        ///
        /// <param name="Q">The Q to mutate.</param>
        void PerformMutation(Q Q);
    }

    public interface IMLRegression : IMLInputOutput
    {
        /// <summary>
        /// Compute regression.
        /// </summary>
        ///
        /// <param name="input">The input data.</param>
        /// <returns>The output data.</returns>
        IMLData Compute(IMLData input);
    }

    public interface ISpecies
    {
        /// <summary>
        /// Set the age of this species.
        /// </summary>
        int Age { get; set; }


        /// <summary>
        /// Set the best score.
        /// </summary>
        double BestScore { get; set; }


        /// <summary>
        /// Set the number of generations with no improvement.
        /// </summary>
        int GensNoImprovement { get; set; }


        /// <summary>
        /// Set the leader of this species.
        /// </summary>
        IT Leader { get; set; }


        /// <value>The numbers of this species.</value>
        IList<IT> Members { get; }


        /// <value>The number of Ts this species will try to spawn into the
        /// next generation.</value>
        double NumToSpawn { get; }


        /// <summary>
        /// Set the number of spawns required.
        /// </summary>
        double SpawnsRequired { get; set; }


        /// <value>The species ID.</value>
        long SpeciesID { get; }

        /// <summary>
        /// Calculate the amount that a species will spawn.
        /// </summary>
        ///
        void CalculateSpawnAmount();

        /// <summary>
        /// Choose a worthy parent for mating.
        /// </summary>
        ///
        /// <returns>The parent T.</returns>
        IT ChooseParent();


        /// <summary>
        /// Purge old unsuccessful Ts.
        /// </summary>
        ///
        void Purge();
    }

    public interface ICrossover
    {
        /// <summary>
        /// Mate two Qs.
        /// </summary>
        ///
        /// <param name="mother">The mother.</param>
        /// <param name="father">The father.</param>
        /// <param name="offspring1">The first offspring.</param>
        /// <param name="offspring2">The second offspring.</param>
        void Mate(Q mother, Q father,
                  Q offspring1, Q offspring2);
    }

    public interface IInnovation
    {
        /// <summary>
        /// Set the innovation id.
        /// </summary>
        long InnovationID
        {
            get;
            set;
        }
    }

    public interface IInnovationList
    {
        /// <value>A list of innovations.</value>
        IList<IInnovation> Innovations { get; }

        /// <summary>
        /// Add an innovation.
        /// </summary>
        ///
        /// <param name="innovation">The innovation added.</param>
        void Add(IInnovation innovation);

        /// <summary>
        /// Get the innovation specified by index.
        /// </summary>
        ///
        /// <param name="id">The index.</param>
        /// <returns>The innovation.</returns>
        IInnovation Get(int id);
    }

    public interface IPopulation
    {
        /// <value>The best T in the population.</value>
        IT Best { get; }


        /// <value>The Ts in the population.</value>
        IList<IT> Ts { get; }


        /// <summary>
        /// Set the innovations collection.
        /// </summary>
        IInnovationList Innovations { get; set; }


        /// <summary>
        /// Set the old age penalty.
        /// </summary>
        double OldAgePenalty { get; set; }


        /// <summary>
        /// Set the age at which a T is considered "old".
        /// </summary>
        int OldAgeThreshold { get; set; }


        /// <summary>
        /// Set the max population size.
        /// </summary>
        int PopulationSize { get; set; }


        /// <value>A list of species.</value>
        IList<ISpecies> Species { get; }


        /// <summary>
        /// Set the survival rate.
        /// </summary>
        ///
        /// <value>The survival rate.</value>
        double SurvivalRate { get; set; }


        /// <value>The age, below which, a T is considered "young".</value>
        int YoungBonusAgeThreshold { get; }


        /// <summary>
        /// Set the youth score bonus.
        /// </summary>
        double YoungScoreBonus { get; set; }


        /// <summary>
        /// Set the age at which genoms are considered young.
        /// </summary>
        ///
        /// <value>The age.</value>
        int YoungBonusAgeThreshhold { set; }

        /// <summary>
        /// Add a T to the population.
        /// </summary>
        ///
        /// <param name="T">The T to add.</param>
        void Add(IT T);

        /// <returns>Assign a gene id.</returns>
        long AssignGeneID();


        /// <returns>Assign a T id.</returns>
        long AssignTID();


        /// <returns>Assign an innovation id.</returns>
        long AssignInnovationID();


        /// <returns>Assign a species id.</returns>
        long AssignSpeciesID();

        /// <summary>
        /// Clear all Ts from this population.
        /// </summary>
        ///
        void Clear();

        /// <summary>
        /// Get a T by index.  Index 0 is the best T.
        /// </summary>
        ///
        /// <param name="i">The T to get.</param>
        /// <returns>The T at the specified index.</returns>
        IT Get(int i);


        /// <returns>The size of the population.</returns>
        int Size();

        /// <summary>
        /// Sort the population by best score.
        /// </summary>
        ///
        void Sort();

        /// <summary>
        /// Claim the population, before training.
        /// </summary>
        ///
        /// <param name="ga">The GA that is claiming.</param>
        void Claim(GAlgo ga);
    }

    public interface IRandomizer
    {
        /// <summary>
        /// Randomize the synapses and bias values in the basic network based on an
        /// array, modify the array. Previous values may be used, or they may be
        /// discarded, depending on the randomizer.
        /// </summary>
        ///
        /// <param name="network">A network to randomize.</param>
        void Randomize(IMLMethod network);

        /// <summary>
        /// Starting with the specified number, randomize it to the degree specified
        /// by this randomizer. This could be a totally new random number, or it
        /// could be based on the specified number.
        /// </summary>
        ///
        /// <param name="d">The number to randomize.</param>
        /// <returns>A randomized number.</returns>
        double Randomize(double d);

        /// <summary>
        /// Randomize the array based on an array, modify the array. Previous values
        /// may be used, or they may be discarded, depending on the randomizer.
        /// </summary>
        ///
        /// <param name="d">An array to randomize.</param>
        void Randomize(double[] d);

        /// <summary>
        /// Randomize the 2d array based on an array, modify the array. Previous
        /// values may be used, or they may be discarded, depending on the
        /// randomizer.
        /// </summary>
        ///
        /// <param name="d">An array to randomize.</param>
        void Randomize(double[][] d);

        /// <summary>
        /// Randomize the matrix based on an array, modify the array. Previous values
        /// may be used, or they may be discarded, depending on the randomizer.
        /// </summary>
        ///
        /// <param name="m">A matrix to randomize.</param>
        void Randomize(Matrix m);

        /// <summary>
        /// Randomize an array.
        /// </summary>
        ///
        /// <param name="d">The array to randomize.</param>
        /// <param name="begin">The beginning element.</param>
        /// <param name="size">The size of the array.</param>
        void Randomize(double[] d, int begin, int size);
    }

    public interface IT : IComparable<IT>
    {
        /// <summary>
        /// Set the adjusted score.
        /// </summary>
        double AdjustedScore { get; set; }


        /// <summary>
        /// Set the amount to spawn.
        /// </summary>
        double AmountToSpawn { get; set; }


        /// <value>The Qs that make up this T.</value>
        IList<Q> Qs
        {
            get;
        }


        /// <summary>
        /// Set the GA used by this T. This is normally a transient field and
        /// only used during training.
        /// </summary>
        GAlgo GA
        {
            get;
            set;
        }


        /// <summary>
        /// Set the T ID.
        /// </summary>
        long TID
        {
            get;
            set;
        }


        /// <value>The organism produced by this T.</value>
        Object Organism
        {
            get;
        }


        /// <summary>
        /// Set the population that this T belongs to.
        /// </summary>
        IPopulation Population
        {
            get;
            set;
        }


        /// <summary>
        /// Set the score.
        /// </summary>
        double Score
        {
            get;
            set;
        }

        /// <returns>The number of genes in this T.</returns>
        int CalculateGeneCount();

        /// <summary>
        /// Use the genes to update the organism.
        /// </summary>
        ///
        void Decode();

        /// <summary>
        /// Use the organism to update the genes.
        /// </summary>
        ///
        void Syntesis();


        /// <summary>
        /// Mate with another T and produce two children.
        /// </summary>
        ///
        /// <param name="father">The father T.</param>
        /// <param name="child1">The first child.</param>
        /// <param name="child2">The second child.</param>
        void Mate(IT father, IT child1, IT child2);
    }

    public interface IMLContext : IMLMethod
    {
        /// <summary>
        /// Clear the context.
        /// </summary>
        ///
        void ClearContext();
    }

    public interface IMLEncodable : IMLMethod
    {
        /// <returns>The length of an Syntesisd array.</returns>
        int SyntesisdArrayLength();

        /// <summary>
        /// Syntesis the object to the specified array.
        /// </summary>
        ///
        /// <param name="Syntesisd">The array.</param>
        void SyntesisToArray(double[] Syntesisd);

        /// <summary>
        /// Decode an array to this object.
        /// </summary>
        ///
        /// <param name="Syntesisd">The Syntesisd array.</param>
        void DecodeFromArray(double[] Syntesisd);
    }

    public interface ICalculateTScore
    {
        /// <returns>True if the goal is to minimize the score.</returns>
        bool ShouldMinimize { get; }

        /// <summary>
        /// Calculate this T's score.
        /// </summary>
        ///
        /// <param name="T">The T.</param>
        /// <returns>The score.</returns>
        double CalculateScore(IT T);
    }

    public interface IMLError : IMLMethod
    {
        /// <summary>
        /// Calculate the error of the ML method, given a dataset.
        /// </summary>
        ///
        /// <param name="data">The dataset.</param>
        /// <returns>The error.</returns>
        double CalculateError(IMLDataSet data);
    }

    public interface IMLInput : IMLMethod
    {
        /// <value>The input.</value>
        int InputCount { get; }
    }

    public interface IMLInputOutput : IMLInput, IMLOutput
    {
    }

    public interface IMLMethod
    {
    }


    public interface IMLOutput : IMLMethod
    {
        /// <value>The output count.</value>
        int OutputCount { get; }
    }

    public interface IMLProperties : IMLMethod
    {
        /// <value>A map of all properties.</value>
        IDictionary<String, String> Properties { get; }


        /// <summary>
        /// Get the specified property as a double.
        /// </summary>
        ///
        /// <param name="name">The name of the property.</param>
        /// <returns>The property as a double.</returns>
        double GetPropertyDouble(String name);

        /// <summary>
        /// Get the specified property as a long.
        /// </summary>
        ///
        /// <param name="name">The name of the specified property.</param>
        /// <returns>The value of the specified property.</returns>
        long GetPropertyLong(String name);

        /// <summary>
        /// Get the specified property as a string.
        /// </summary>
        ///
        /// <param name="name">The name of the property.</param>
        /// <returns>The value of the property.</returns>
        String GetPropertyString(String name);

        /// <summary>
        /// Set a property as a double.
        /// </summary>
        ///
        /// <param name="name">The name of the property.</param>
        /// <param name="d">The value of the property.</param>
        void SetProperty(String name, double d);

        /// <summary>
        /// Set a property as a long.
        /// </summary>
        ///
        /// <param name="name">The name of the property.</param>
        /// <param name="l">The value of the property.</param>
        void SetProperty(String name, long l);

        /// <summary>
        /// Set a property as a double.
        /// </summary>
        ///
        /// <param name="name">The name of the property.</param>
        /// <param name="v">The value of the property.</param>
        void SetProperty(String name, String v);

        /// <summary>
        /// Update any objeccts when a property changes.
        /// </summary>
        ///
        void UpdateProperties();
    }

    public interface IMLResettable : IMLMethod
    {
        /// <summary>
        /// Reset the weights.
        /// </summary>
        ///
        void Reset();

        /// <summary>
        /// Reset the weights with a seed.
        /// </summary>
        ///
        /// <param name="seed">The seed value.</param>
        void Reset(int seed);
    }

    public interface IMLStateSequence
    {
        /// <summary>
        /// Get the sates for the given sequence.
        /// </summary>
        /// <param name="oseq">The sequence.</param>
        /// <returns>The states.</returns>
        int[] GetStatesForSequence(IMLDataSet oseq);

        /// <summary>
        /// Determine the probability of the specified sequence.
        /// </summary>
        /// <param name="oseq">The sequence.</param>
        /// <returns>The probability.</returns>
        double Probability(IMLDataSet oseq);

        /// <summary>
        /// Determine the probability for the specified sequence and states.
        /// </summary>
        /// <param name="seq">The sequence.</param>
        /// <param name="states">The states.</param>
        /// <returns>The probability.</returns>
        double Probability(IMLDataSet seq, int[] states);
    }

    public interface ISyntPersistor
    {
        /// <summary>
        /// The native type.
        /// </summary>
        Type NativeType { get; }

        /// <value>Get the class string for the object.</value>
        String PersistClassString { get; }

        /// <value>Get the file version used by this persistor.</value>
        int FileVersion { get; }


        /// <summary>
        /// Read the object from an input stream.
        /// </summary>
        ///
        /// <param name="mask0">The input stream.</param>
        /// <returns>The object.</returns>
        Object Read(Stream mask0);

        /// <summary>
        /// Save the object.
        /// </summary>
        ///
        /// <param name="os">The output stream to save to.</param>
        /// <param name="obj">The object to save.</param>
        void Save(Stream os, Object obj);
    }

    public interface IMLClustering : IMLMethod
    {
        /// <value>The clusters.</value>
        IMLCluster[] Clusters { get; }

        /// <summary>
        /// Perform the training iteration.
        /// </summary>
        ///
        void Iteration();

        /// <summary>
        /// Perform the specified number of training iterations.
        /// </summary>
        ///
        /// <param name="count">The number of training iterations.</param>
        void Iteration(int count);


        /// <returns>The number of clusters.</returns>
        int Count { get; }
    }

    public interface IMLCluster
    {
        /// <value>The data in this cluster.</value>
        IList<IMLData> Data { get; }

        /// <summary>
        /// Add data to this cluster.
        /// </summary>
        ///
        /// <param name="pair">The data to add.</param>
        void Add(IMLData pair);

        /// <summary>
        /// Create a machine learning dataset from the data.
        /// </summary>
        ///
        /// <returns>A dataset.</returns>
        IMLDataSet CreateDataSet();

        /// <summary>
        /// Get the specified data item by index.
        /// </summary>
        ///
        /// <param name="pos">The index of the data item to get.</param>
        /// <returns>The data item.</returns>
        IMLData Get(int pos);


        /// <summary>
        /// Remove the specified item.
        /// </summary>
        ///
        /// <param name="data">The item to remove.</param>
        void Remove(IMLData data);


        /// <returns>The number of items.</returns>
        int Count { get; }
    }

    public interface IMLClassification : IMLInputOutput
    {
        /// <summary>
        /// Classify the input into a group.
        /// </summary>
        ///
        /// <param name="input">The input data to classify.</param>
        /// <returns>The group that the data was classified into.</returns>
        int Classify(IMLData input);
    }

    public interface IMLAutoAssocation : IMLRegression
    {
    }

    public interface IStrategy
    {
        /// <summary>
        /// Initialize this strategy.
        /// </summary>
        ///
        /// <param name="train">The training Algo.</param>
        void Init(IMLTrain train);

        /// <summary>
        /// Called just before a training iteration.
        /// </summary>
        ///
        void PreIteration();

        /// <summary>
        /// Called just after a training iteration.
        /// </summary>
        ///
        void PostIteration();
    }

    public interface IMLTrain
    {
        /// <value>The training implementation type.</value>
        TrainingImplementationType ImplementationType { get; }


        /// <value>True if training can progress no further.</value>
        bool TrainingDone { get; }


        /// <value>The training data to use.</value>
        IMLDataSet Training { get; }


        /// <summary>
        /// Returns the training error. This value is calculated as the
	    /// training data is evaluated by the iteration function. This has
	    /// two important ramifications. First, the value returned by
	    /// getError() is meaningless prior to a call to iteration. Secondly,
	    /// the error is calculated BEFORE training is applied by the call to
	    /// iteration. The timing of the error calculation is done for
	    /// performance reasons.
        /// </summary>
        double Error { get; set; }


        /// <summary>
        /// Set the current training iteration.
        /// </summary>
        int IterationNumber { get; set; }


        /// <returns>True if the training can be paused, and later continued.</returns>
        bool CanContinue { get; }

        /// <summary>
        /// Get the current best machine learning method from the training.
        /// </summary>
        IMLMethod Method { get; }


        /// <value>The strategies to use.</value>
        IList<IStrategy> Strategies { get; }

        /// <summary>
        /// Perform one iteration of training.
        /// </summary>
        ///
        void Iteration();

        /// <summary>
        /// Should be called once training is complete and no more iterations are
        /// needed. Calling iteration again will simply begin the training again, and
        /// require finishTraining to be called once the new training session is
        /// complete.
        /// It is particularly important to call finishTraining for multithreaded
        /// training techniques.
        /// </summary>
        ///
        void FinishTraining();

        /// <summary>
        /// Perform a number of training iterations.
        /// </summary>
        ///
        /// <param name="count">The number of iterations to perform.</param>
        void Iteration(int count);

        /// <summary>
        /// Pause the training to continue later.
        /// </summary>
        ///
        /// <returns>A training continuation object.</returns>
        TrainingContinuation Pause();

        /// <summary>
        /// Resume training.
        /// </summary>
        ///
        /// <param name="state">The training continuation object to use to continue.</param>
        void Resume(TrainingContinuation state);

        /// <summary>
        /// Training strategies can be added to improve the training results. There
        /// are a number to choose from, and several can be used at once.
        /// </summary>
        ///
        /// <param name="strategy">The strategy to add.</param>
        void AddStrategy(IStrategy strategy);
    }

    public interface IMLSequenceSet : IMLDataSet
    {
        /// <summary>
        /// Cause a "break" in the data by creating a the beginning of a new sequence.
        /// </summary>
        void StartNewSequence();

        /// <summary>
        /// Get a count of the number of sequences.
        /// </summary>
        int SequenceCount { get; }

        /// <summary>
        /// Get an individual sequence. 
        /// </summary>
        /// <param name="i">The index to get.</param>
        /// <returns>The sequence.</returns>
        IMLDataSet GetSequence(int i);

        /// <summary>
        /// A list of all of the sequences.
        /// </summary>
        /// <returns>The index of the sequence.</returns>
        ICollection<IMLDataSet> Sequences { get; }

        /// <summary>
        /// Add a new sequence. 
        /// </summary>
        /// <param name="sequence">The sequence to add.</param>
        void Add(IMLDataSet sequence);
    }

    public interface IMLDataSet
    {
        /// <summary>
        /// The size of the ideal data, 0 if no ideal data.
        /// </summary>
        int IdealSize { get; }

        /// <summary>
        /// The size of the input data.
        /// </summary>
        int InputSize { get; }

        /// <summary>
        /// The number of records in the data set.
        /// </summary>
        int Count { get; }

        /// <summary>
        /// Return true if supervised.
        /// </summary>
        bool Supervised { get; }

        /// <summary>
        /// Add a NeuralData object to the dataset. This is used with unsupervised
        /// training, as no ideal output is provided. Note: not all implemenations
        /// support the add methods. 
        /// </summary>
        /// <param name="data1">The data to add.</param>
        void Add(IMLData data1);

        /// <summary>
        /// Add a set of input and ideal data to the dataset. This is used with
        /// supervised training, as ideal output is provided. Note: not all
        /// implementations support the add methods.
        /// </summary>
        /// <param name="inputData">Input data.</param>
        /// <param name="idealData">Ideal data.</param>
        void Add(IMLData inputData, IMLData idealData);

        /// <summary>
        /// Add a NeuralData object to the dataset. This is used with unsupervised
        /// training, as no ideal output is provided. Note: not all implementations
        /// support the add methods. 
        /// </summary>
        /// <param name="inputData">A NeuralDataPair object that contains both input and ideal
        /// data.</param>
        void Add(IMLDataPair inputData);


        /// <summary>
        /// Close this datasource and release any resources obtained by it, including
        /// any iterators created. 
        /// </summary>
        void Close();

        /// <summary>
        /// Get an enumerator to access the data.
        /// </summary>
        /// <returns></returns>
        IEnumerator<IMLDataPair> GetEnumerator();

        /// <summary>
        /// Get one record from the data set.
        /// </summary>
        /// <param name="index">The index to read.</param>
        /// <param name="pair">The pair to read into.</param>
        void GetRecord(int index, IMLDataPair pair);

        /// <summary>
        /// Open an additional instance of this dataset.
        /// </summary>
        /// <returns>The new instance of this dataset.</returns>
        IMLDataSet OpenAdditional();

        /// <summary>
        /// Get the specified record.
        /// </summary>
        /// <param name="x">The index to access.</param>
        /// <returns></returns>
        IMLDataPair this[int x] { get; }
    }

    public interface IMLDataPair : ICloneable, ICentroidFactory<IMLDataPair>
    {
        /// <summary>
        /// The input that the neural network.
        /// </summary>
        IMLData Input { get; }

        /// <summary>
        /// The ideal data that the neural network should produce
        /// for the specified input.
        /// </summary>
        IMLData Ideal { get; }

        /// <summary>
        /// True if this training pair is supervised.  That is, it has 
        /// both input and ideal data.
        /// </summary>
        bool Supervised { get; }

        /// <summary>
        /// The supervised ideal data.
        /// </summary>
        double[] IdealArray { get; set; }

        /// <summary>
        /// The input array.
        /// </summary>
        double[] InputArray { get; set; }

        /// <summary>
        /// The significance of this training element.
        /// </summary>
        double Significance { get; set; }
    }

    public interface IMLData : ICloneable, ICentroidFactory<IMLData>
    {
        /// <summary>
        /// Get or set the specified index.
        /// </summary>
        /// <param name="x">The index to access.</param>
        /// <returns></returns>
        double this[int x] { get; set; }

        /// <summary>
        /// Allowes indexed access to the data.
        /// </summary>
        double[] Data { get; set; }

        /// <summary>
        /// How many elements in this data structure.
        /// </summary>
        int Count { get; }

        /// <summary>
        /// Clear the data to zero values.
        /// </summary>
        void Clear();

    }

    public interface IMLComplexData : IMLData
    {
        /// <summary>
        /// The complex numbers.
        /// </summary>
        ComplexNumber[] ComplexData { get; }

        /// <summary>
        /// Get the complex data at the specified index. 
        /// </summary>
        /// <param name="index">The index to get the complex data at.</param>
        /// <returns>The complex data.</returns>
        ComplexNumber GetComplexData(int index);

        /// <summary>
        /// Set the complex number array.
        /// </summary>
        /// <param name="theData">The new array.</param>
        void SetComplexData(ComplexNumber[] theData);

        /// <summary>
        /// Set a data element to a complex number.
        /// </summary>
        /// <param name="index">The index to set.</param>
        /// <param name="d">The complex number.</param>
        void SetComplexData(int index, ComplexNumber d);
    }

    public interface IMarketLoader
    {
        /// <summary>
        /// Load the specified ticker symbol for the specified date.
        /// </summary>
        /// <param name="ticker">The ticker symbol to load.</param>
        /// <param name="dataNeeded">Which data is actually needed.</param>
        /// <param name="from">Beginning date for load.</param>
        /// <param name="to">Ending date for load.</param>
        /// <returns>A collection of LoadedMarketData objects that was loaded.</returns>
        ICollection<LoadedMarketData> Load(TickerSymbol ticker,
                                           IList<MarketDataType> dataNeeded, DateTime from, DateTime to);

        /// <summary>
        /// Gets the file we want to parse.
        /// </summary>
        /// <param name="file">The file.</param>
        /// <returns></returns>
        string GetFile(string file);
    }

    public interface IBayesSearch
    {
        /// <summary>
        /// Init the search object.
        /// </summary>
        /// <param name="theTrainer">The trainer to use.</param>
        /// <param name="theNetwork">The network to use.</param>
        /// <param name="theData">The data to use.</param>
        void Init(TrainBayesian theTrainer, BayesianNetwork theNetwork, IMLDataSet theData);

        /// <summary>
        /// Perform an iteration. 
        /// </summary>
        /// <returns>True to continue.</returns>
        bool Iteration();
    }

    public interface IBayesEstimator
    {
        /// <summary>
        /// Init the estimator.
        /// </summary>
        /// <param name="theTrainer">The trainer.</param>
        /// <param name="theNetwork">The network.</param>
        /// <param name="theData">The data.</param>
        void Init(TrainBayesian theTrainer, BayesianNetwork theNetwork, IMLDataSet theData);

        /// <summary>
        /// Perform an iteration.
        /// </summary>
        /// <returns>True, if we should contune.</returns>
        bool Iteration();
    }

    public interface IActivationFunction : ICloneable
    {
        /// <returns>The params for this activation function.</returns>
        double[] Params { get; }

        /// <returns>The names of the parameters.</returns>
        String[] ParamNames { get; }

     
        void ActivationFunction(double[] d, int start, int size);

       
        double DerivativeFunction(double b, double a);


        /// <returns>Return true if this function has a derivative.</returns>
        bool HasDerivative();
    }

    public interface IStatusReportable
    {
        /// <summary>
        /// Report on current status.
        /// </summary>
        ///
        /// <param name="total">The total amount of units to process.</param>
        /// <param name="current">The current unit being processed.</param>
        /// <param name="message">The message to currently display.</param>
        void Report(int total, int current, String message);
    }

    internal interface ITimeUnitNames
    {
        String Singular(TimeUnit unit);
        String Plural(TimeUnit unit);
        String Code(TimeUnit unit);
    }

    public interface INormalizationStorage
    {
        /// <summary>
        /// Open the storage.
        /// </summary>
        void Close();

        /// <summary>
        /// Close the storage.
        /// </summary>
        void Open();

        /// <summary>
        /// Write an array.
        /// </summary>
        /// <param name="data">The data to write.</param>
        /// <param name="inputCount">How much of the data is input.</param>
        void Write(double[] data, int inputCount);
    }

    public interface ISegregator
    {
        /// <summary>
        /// The normalization object that is being used with this segregator.
        /// </summary>
        DataNormalization Owner { get; }

        /// <summary>
        /// Setup this object to use the specified normalization object.
        /// </summary>
        /// <param name="normalization">The normalization object to use.</param>
        void Init(DataNormalization normalization);

        /// <summary>
        /// Should this row be included, according to this segregator.
        /// </summary>
        /// <returns>True if this row should be included.</returns>
        bool ShouldInclude();

        /// <summary>
        /// Init for a pass.
        /// </summary>
        void PassInit();
    }

    public interface IRequireTwoPass
    {
    }

    public interface IOutputFieldGroup
    {
        /// <summary>
        /// All of the output fields in this group.
        /// </summary>
        ICollection<OutputFieldGrouped> GroupedFields { get; }

        /// <summary>
        /// Add an output field to the group.
        /// </summary>
        /// <param name="field">The field to add.</param>
        void AddField(OutputFieldGrouped field);

        /// <summary>
        /// Init the group for a new row.
        /// </summary>
        void RowInit();
    }

    public interface IOutputField
    {
        /// <summary>
        /// The numebr of fields that will actually be generated by 
        /// this field. For a simple field, this value is 1.
        /// </summary>
        int SubfieldCount { get; }

        /// <summary>
        /// Is this field part of the ideal data uses to train the
        /// neural network.
        /// </summary>
        bool Ideal { get; set; }

        /// <summary>
        /// Calculate the value for this field.  Specify subfield of zero
        /// if this is a simple field.
        /// </summary>
        /// <param name="subfield"> The subfield index.</param>
        /// <returns>The calculated value for this field.</returns>
        double Calculate(int subfield);

        /// <summary>
        /// Init this field for a new row.
        /// </summary>
        void RowInit();
    }

    public interface IInputField
    {
        /// <summary>
        /// The current value of the input field.  This is only valid, 
        /// while the normalization is being performed.
        /// </summary>
        double CurrentValue { get; set; }

        /// <summary>
        /// The maximum value for all of the input data, this is calculated
        /// during the first pass of normalization.
        /// </summary>
        double Max { get; set; }

        /// <summary>
        /// The minimum value for all of the input data, this is calculated
        /// during the first pass of normalization.
        /// </summary>
        double Min { get; set; }

        /// <summary>
        /// True, if this field is used for network input.  This is needed
        /// so that the buildForNetworkInput method of the normalization class knows
        /// how many input fields to expect.  For instance, fields used only to 
        /// segregate data are not used for the actual network input and may
        /// not be provided when the network is actually being queried.
        /// </summary>
        bool UsedForNetworkInput { get; }

        /// <summary>
        /// Update the min and max values for this field with the specified values.
        /// </summary>
        /// <param name="d">The current value to use to update min and max.</param>
        void ApplyMinMax(double d);

        /// <summary>
        /// Called for input field types that require an index to get the current
        /// value. This is used by the InputFieldArray1D and InputFieldArray2D
        /// classes.
        /// </summary>
        /// <param name="i">The index to read.</param>
        /// <returns>The value read.</returns>
        double GetValue(int i);
    }

    public interface IHasFixedLength
    {
        /// <summary>
        /// The number of records in this input field.
        /// </summary>
        int Length { get; }
    }

    public interface ICentroidFactory<in TO>
    {
        /// <summary>
        /// The centroid.
        /// </summary>
        /// <returns>The centroid.</returns>
        ICentroid<TO> CreateCentroid();
    }

    public interface ICentroid<in TO>
    {
        /// <summary>
        /// Add an element to the centroid.
        /// </summary>
        /// <param name="e">The element to add.</param>
        void Add(TO e);

        /// <summary>
        /// Remove an element from the centroid. 
        /// </summary>
        /// <param name="o">The element to remove.</param>
        void Remove(TO o);

        /// <summary>
        /// The distance between this centroid and an element. 
        /// </summary>
        /// <param name="o">The element.</param>
        /// <returns>The distance.</returns>
        double Distance(TO o);
    }

    public interface IGenerateID
    {
        /// <summary>
        /// Get the value for the current id.
        /// </summary>
        long CurrentID { get; set; }

        /// <summary>
        /// Generate an ID number.
        /// </summary>
        /// <returns>The ID number generated.</returns>
        long Generate();
    }

    public interface IDataSetCODEC
    {
        /// <summary>
        /// The size of the input data.
        /// </summary>
        int InputSize { get; }

        /// <summary>
        /// The size of the ideal data.
        /// </summary>
        int IdealSize { get; }

        /// <summary>
        /// Read one record of data from an external source.
        /// </summary>
        /// <param name="input">The input data array.</param>
        /// <param name="ideal">The ideal data array.</param>
        /// <param name="significance">The signficance. (by reff)</param>
        /// <returns>True, if there is more data to be read.</returns>
        bool Read(double[] input, double[] ideal, ref double significance);

        /// <summary>
        /// Write one record of data to an external destination. 
        /// </summary>
        /// <param name="input">The input data array.</param>
        /// <param name="ideal">The ideal data array.</param>
        /// <returns>True, if there is more data to be read.</returns>
        void Write(double[] input, double[] ideal, double significance);

        /// <summary>
        /// Prepare to write to an external data destination. 
        /// </summary>
        /// <param name="recordCount">The total record count, that will be written.</param>
        /// <param name="inputSize">The input size.</param>
        /// <param name="idealSize">The ideal size.</param>
        void PrepareWrite(int recordCount, int inputSize, int idealSize);

        /// <summary>
        /// Prepare to read from an external data source.
        /// </summary>
        void PrepareRead();

        /// <summary>
        /// Close any open files.
        /// </summary>
        void Close();
    }

    public interface IDownSample
    {
    
    }

    public interface IMultiThreadable
    {
        /// <summary>
        /// The thread count.  Set to zero to automatically determine the 
        /// thread count based on cores.  Set to 1 to specify single threaded.
        /// </summary>
        int ThreadCount { get; set; }
    }

    public interface IEngineTask
    {
        /// <summary>
        /// Run the specified task.
        /// </summary>
        void Run();
    }

    public interface ISyntPluginService1 : SyntPluginBase
    {
        /// <summary>
        /// Create an activation function.
        /// </summary>
        /// <param name="name">The name of the activation function.</param>
        /// <returns>The newly created activation function.</returns>
        IActivationFunction CreateActivationFunction(String name);

        /// <summary>
        /// Create a new machine learning method. 
        /// </summary>
        /// <param name="methodType">The method to create.</param>
        /// <param name="architecture">The architecture string.</param>
        /// <param name="input">The input count.</param>
        /// <param name="output">The output count.</param>
        /// <returns>The newly created machine learning method.</returns>
        IMLMethod CreateMethod(String methodType,
                String architecture,
                int input, int output);

        /// <summary>
        /// Create a trainer. 
        /// </summary>
        /// <param name="method">The method to train.</param>
        /// <param name="training">The training data.</param>
        /// <param name="type">Type type of trainer.</param>
        /// <param name="args">The training args.</param>
        /// <returns>The new training method.</returns>

        IMLTrain CreateTraining(IMLMethod method,
                 IMLDataSet training,
                 String type, String args);

    }

    public interface ISyntPluginLogging1 : SyntPluginBase
    {
        /// <summary>
        /// The current log level.
        /// </summary>
        int LogLevel { get; }

        /// <summary>
        /// Log a message at the specified level. 
        /// </summary>
        /// <param name="level">The level to log at.</param>
        /// <param name="message">The message to log.</param>
        void Log(int level, String message);

        /// <summary>
        /// Log a throwable at the specified level.
        /// </summary>
        /// <param name="level">The level to log at.</param>
        /// <param name="t">The error to log.</param>
        void Log(int level, Exception t);
    }

    public interface SyntPluginBase
    {
        /// <value>The type number for this plugin.</value>
        int PluginType { get; }


        /// <value>The service type provided by this plugin.</value>
        int PluginServiceType { get; }


        /// <value>The name of the plugin.</value>
        string PluginName { get; }


        /// <value>The plugin description.</value>
        string PluginDescription { get; }
    }

    public interface IPersistor
    {
        /// <summary>
        /// The native type.
        /// </summary>
        Type NativeType { get; }

        /// <value>Get the class string for the object.</value>
        String PersistClassString { get; }

        /// <value>Get the file version used by this persistor.</value>
        int FileVersion { get; }


        /// <summary>
        /// Read the object from an input stream.
        /// </summary>
        ///
        /// <param name="mask0">The input stream.</param>
        /// <returns>The object.</returns>
        Object Read(Stream mask0);

        /// <summary>
        /// Save the object.
        /// </summary>
        ///
        /// <param name="os">The output stream to save to.</param>
        /// <param name="obj">The object to save.</param>
        void Save(Stream os, Object obj);
    }

    public interface ITrain : IMLTrain
    {
    }

    public interface IMomentum
    {
        /// <summary>
        /// Set the momentum.
        /// </summary>
        double Momentum
        {
            get;
            set;
        }
    }

    public interface ILearningRate
    {
        /// <summary>
        /// Set the learning rate.
        /// </summary>
        double LearningRate
        {
            get;
            set;
        }
    }

    public interface ICalculateScore
    {
        /// <returns>True if the goal is to minimize the score.</returns>
        bool ShouldMinimize { get; }

        /// <summary>
        /// Calculate this network's score.
        /// </summary>
        ///
        /// <param name="network">The network.</param>
        /// <returns>The score.</returns>
        double CalculateScore(IMLRegression network);
    }
      
    public interface IComputeHessian
    {
        /// <summary>
        /// The gradeints. 
        /// </summary>
        double[] Gradients { get; }

        /// <summary>
        /// The sum of squares error over all of the training elements.
        /// </summary>
        double SSE { get; }

        /// <summary>
        /// The Hessian matrix.
        /// </summary>
        Matrix HessianMatrix { get; }

        /// <summary>
        /// Get the Hessian as a 2d array.
        /// </summary>
        double[][] Hessian { get; }

        /// <summary>
        /// Init the class.  
        /// </summary>
        /// <param name="theNetwork">The neural network to train.</param>
        /// <param name="theTraining">The training set to train with.</param>
        void Init(BasicNetwork theNetwork, IMLDataSet theTraining);

        /// <summary>
        /// Compute the Hessian.
        /// </summary>
        void Compute();

        /// <summary>
        /// Clear the Hessian and gradients.
        /// </summary>
        void Clear();
    }

    public interface ILayer
    {
        /// <value>The activation function used for this layer.</value>
        IActivationFunction ActivationFunction { get; }


        /// <summary>
        /// Set the network that this layer belongs to.
        /// </summary>
        BasicNetwork Network { get; set; }


        /// <value>The neuron count.</value>
        int NeuronCount { get; }


        /// <summary>
        /// Most layer types will default this value to one. However, it is possible
        /// to use other values. This is the activation that will be passed over the
        /// bias weights to the inputs of this layer. See the Layer interface
        /// documentation for more information on how Synt handles bias values.
        /// </summary>
        double BiasActivation { get; set; }


        /// <summary>
        /// Set the activation function.
        /// </summary>
        ///
        /// <value>The activation function.</value>
        IActivationFunction Activation { set; }

        /// <returns>True if this layer has a bias.</returns>
        bool HasBias();
    }

    public interface IRadialBasisFunction
    {
        double Peak { get; set; }


        double Width
        {
            get;
            set;
        }



        int Dimensions
        {
            get;
        }



        double[] Centers
        {
            get;
            set;
        }


        double Calculate(double[] x);
    }

    public interface IContainsFlat : IMLMethod
    {
        /// <value>The flat network associated with this neural network.</value>
        FlatNetwork Flat { get; }
    }

    public interface INeuralNetworkPattern
    {
        /// <summary>
        /// Set the activation function to be used for all created layers that allow
        /// an activation function to be specified. Not all patterns allow the
        /// activation function to be specified.
        /// </summary>
        ///
        /// <value>The activation function.</value>
        IActivationFunction ActivationFunction
        {
            set;
        }


        /// <summary>
        /// Set the number of input neurons.
        /// </summary>
        ///
        /// <value>The number of input neurons.</value>
        int InputNeurons { set; }


        /// <summary>
        /// Set the number of output neurons.
        /// </summary>
        ///
        /// <value>The output neuron count.</value>
        int OutputNeurons { set; }

        /// <summary>
        /// Add the specified hidden layer.
        /// </summary>
        ///
        /// <param name="count">The number of neurons in the hidden layer.</param>
        void AddHiddenLayer(int count);

        /// <summary>
        /// Clear the hidden layers so that they can be redefined.
        /// </summary>
        ///
        void Clear();

        /// <summary>
        /// Generate the specified neural network.
        /// </summary>
        ///
        /// <returns>The resulting neural network.</returns>
        IMLMethod Generate();
    }

    public interface INeighborhoodFunction
    {
        /// <summary>
        /// Set the radius.
        /// </summary>
        double Radius
        {
            get;
            set;
        }

        /// <summary>
        /// Determine how much the current neuron should be affected by training
        /// based on its proximity to the winning neuron.
        /// </summary>
        ///
        /// <param name="currentNeuron">THe current neuron being evaluated.</param>
        /// <param name="bestNeuron">The winning neuron.</param>
        /// <returns>The ratio for this neuron's adjustment.</returns>
        double Function(int currentNeuron, int bestNeuron);
    }

    public interface IExtract
    {
        /// <summary>
        /// A list of listeners registered with this object.
        /// </summary>
        ICollection<IExtractListener> Listeners { get; }

        /// <summary>
        /// Add a listener for the extraction.
        /// </summary>
        /// <param name="listener">The listener to add.</param>
        void AddListener(IExtractListener listener);

        /// <summary>
        /// Extract data from the web page.
        /// </summary>
        /// <param name="page">The page to extract from.</param>
        void Extract(WebPage page);

        /// <summary>
        /// Extract from the web page and return the results as a list.
        /// </summary>
        /// <param name="page">The web page to extract from.</param>
        /// <returns>The results of the extraction as a List.</returns>
        IList<Object> ExtractList(WebPage page);

        /// <summary>
        /// Remove the specified listener.
        /// </summary>
        /// <param name="listener">The listener to rmove.</param>
        void RemoveListener(IExtractListener listener);
    }

    public interface IExtractListener
    {
        /// <summary>
        /// Notify that some data has been extracted.
        /// </summary>
        /// <param name="obj">The data that was extracted.</param>
        void FoundData(Object obj);
    }

    public interface IBayesianQuery
    {
        /// <summary>
        /// The Bayesian network that we are using this query for.
        /// </summary>
        BayesianNetwork Network { get; }

        /// <summary>
        /// A mapping of events to event states.
        /// </summary>
        IDictionary<BayesianEvent, EventState> Events { get; }

        /// <summary>
        /// The evidence events (inputs).
        /// </summary>
        IList<BayesianEvent> EvidenceEvents { get; }

        /// <summary>
        /// The outcome events (outputs).
        /// </summary>
        IList<BayesianEvent> OutcomeEvents { get; }

        /// <summary>
        /// Return a string that represents this query as a probability "problem".
        /// </summary>
        String Problem { get; }

        /// <summary>
        /// Obtains the probability after execute has been called.
        /// </summary>
        double Probability { get; }

        /// <summary>
        /// Reset all event types back to hidden.
        /// </summary>
        void Reset();

        /// <summary>
        /// Define an event type to be either hidden(default), evidence(input) or
        /// outcome (output).
        /// </summary>
        /// <param name="theEvent">The event to define.</param>
        /// <param name="et">The new event type.         */</param>
        void DefineEventType(BayesianEvent theEvent, EventType et);

        /// <summary>
        /// Get the event state for a given event.
        /// </summary>
        /// <param name="theEvent">The event to get the state for.</param>
        /// <returns>The event state.</returns>
        EventState GetEventState(BayesianEvent theEvent);

        ///<summary>
        /// Get the event type.
        ///</summary>
        ///<param name="theEvent">The event to check.</param>
        ///<returns>The current event type for this event.</returns>
        EventType GetEventType(BayesianEvent theEvent);

        /// <summary>
        /// Set the event value to a boolean.
        /// </summary>
        /// <param name="theEvent">The event.</param>
        /// <param name="b">The value.</param>
        void SetEventValue(BayesianEvent theEvent, bool b);

        /// <summary>
        /// Set the event value as a class item.
        /// </summary>
        /// <param name="theEvent">The event to set.</param>
        /// <param name="d">An integer class item.</param>
        void SetEventValue(BayesianEvent theEvent, int d);

        /// <summary>
        /// Execute the query.
        /// </summary>
        void Execute();

        /// <summary>
        /// Finalize the structure, once all events and dependencies are in place.
        /// </summary>
        void FinalizeStructure();

        /// <summary>
        /// Called to locate the evidence and outcome events.
        /// </summary>
        void LocateEventTypes();

        /// <summary>
        /// Clone the object.
        /// </summary>
        /// <returns>A clone of this object.</returns>
        IBayesianQuery Clone();
    }

    public enum SVMType
    {
        /// <summary>
        /// Support vector for classification.
        /// </summary>
        ///
        SupportVectorClassification,

        /// <summary>
        /// New support vector for classification. For more information see the
        /// citations in the class header.
        /// </summary>
        ///
        NewSupportVectorClassification,

        /// <summary>
        /// One class distribution estimation.
        /// </summary>
        ///
        SupportVectorOneClass,

        /// <summary>
        /// Support vector for regression. Use Epsilon.
        /// </summary>
        ///
        EpsilonSupportVectorRegression,

        /// <summary>
        /// A "new" support vector machine for regression. For more information see
        /// the citations in the class header.
        /// </summary>
        ///
        NewSupportVectorRegression
    }

    public enum BayesianInit
    {
        /// <summary>
        /// No init, do not change anything.
        /// </summary>
        InitNoChange,

        /// <summary>
        /// Start with no connections.
        /// </summary>
        InitEmpty,

        /// <summary>
        /// Init as Naive Bayes.
        /// </summary>
        InitNaiveBayes
    }

    public enum MarketDataType
    {
        /// <summary>
        /// The market open for the day.
        /// </summary>
        Open,

        /// <summary>
        /// The market close for the day.
        /// </summary>
        Close,

        /// <summary>
        /// The volume for the day.
        /// </summary>
        Volume,

        /// <summary>
        /// The adjusted close.  Adjusted for splits and dividends.
        /// </summary>
        AdjustedClose,

        /// <summary>
        /// The high for the day.
        /// </summary>
        High,

        /// <summary>
        /// The low for the day.
        /// </summary>
        Low,

        /// <summary>
        /// A trade (Tick data).
        /// </summary>
        Trade,

        /// <summary>
        /// A quote (bid /ask)
        /// </summary>
        Quote,

        /// <summary>
        /// The bid from a quote
        /// </summary>
        Bid,

        /// <summary>
        /// The ask price from a quote
        /// </summary>
        Ask,

        /// <summary>
        /// the bid volume from a quote.
        /// </summary>
        BidSize,

        /// <summary>
        /// the ask size from a quote.
        /// </summary>
        AskSize,


        /// <summary>
        /// Range from Open to Close (Absolute).
        /// </summary>
        RangeOpenClose,

        /// <summary>
        /// Rangr from High to Low.
        /// </summary>
        RangeHighLow,

        /// <summary>
        /// Range Open to Close not using absolute numbers (No Math.Abs(Open - Close)) , this gives a directional range.
        /// </summary>
        RangeOpenCloseNonAbsolute,

        /// <summary>
        /// Percentage moves from one bar to the next.
        /// </summary>
        PercentageMove,

        /// <summary>
        /// The weighted prices. ( High + Low + 2 * Close) /4.
        /// </summary>
        Weighted,


        /// <summary>
        /// The median of closing prices (high + low) /2
        /// </summary>
        Median,


    }

    public enum NetworkPattern
    {
        /// <summary>
        /// Multilayer feedforward.
        /// </summary>
        ///
        MultiLayerFeedforward,

        /// <summary>
        /// Elman.
        /// </summary>
        ///
        Elman,

        /// <summary>
        /// Jordan.
        /// </summary>
        ///
        Jordan
    }

    public enum RBFEnum
    {

        Gaussian,


        Multiquadric,

        InverseMultiquadric,


        MexicanHat
    }

    public enum RPROPType
    {
        /// <summary>
        /// RPROP+ : The classic RPROP Algo.  Uses weight back tracking.
        /// </summary>
        RPROPp,

        /// <summary>
        /// RPROP- : No weight back tracking.
        /// </summary>
        RPROPm,

        /// <summary>
        /// iRPROP+ : New weight back tracking method, some consider this to be
        /// the most advanced RPROP.
        /// </summary>
        iRPROPp,

        /// <summary>
        /// iRPROP- : New RPROP without weight back tracking. 
        /// </summary>
        iRPROPm
    }

    public enum YNeuronType
    {
        /// <summary>
        /// Each Y network has one bias neuron.
        /// </summary>
        ///
        Bias,

        /// <summary>
        /// Hidden neurons are between the input and output.
        /// </summary>
        ///
        Hidden,

        /// <summary>
        /// Input neurons receive input, they are never altered during evolution.
        /// </summary>
        ///
        Input,

        /// <summary>
        /// Not really a neuron type, as you will never see one of these in the
        /// network. However, it is used to mark an innovation as not affecting a
        /// neuron type, but rather a link.
        /// </summary>
        ///
        None,

        /// <summary>
        /// Output neurons provide output, they are never altered during evolution.
        /// </summary>
        ///
        Output
    }

    public enum PNNKernelType
    {
        /// <summary>
        /// A Gaussian curved kernel. The usual choice.
        /// </summary>
        ///
        Gaussian,

        /// <summary>
        /// A steep kernel.
        /// </summary>
        ///
        Reciprocal
    }

    public enum PNNOutputMode
    {
        /// <summary>
        /// Unsupervised training will make use of autoassociation. No "ideal" values
        /// should be provided for training. Input and output neuron counts must
        /// match.
        /// </summary>
        ///
        Unsupervised,

        /// <summary>
        /// Regression is where the neural network performs as a function. Input is
        /// supplied, and output is returned. The output is a numeric value.
        /// </summary>
        ///
        Regression,

        /// <summary>
        /// Classification attempts to classify the input into a number of predefined
        /// classes. The class is stored in the ideal as a single "double" value,
        /// though it is really treated as an integer that represents class
        /// membership. The number of output neurons should match the number of
        /// classes. Classes are indexed beginning at 0.
        /// </summary>
        ///
        Classification
    }

    public enum TemporalType
    {
        /// <summary>
        /// This field is used as part of the input. However, if you wish to use the
        /// field for prediction as well, specify InputAndPredict.
        /// </summary>
        ///
        Input,

        /// <summary>
        /// This field is used as part of the prediction. However, if you wish to use
        /// the field for input as well, specify InputAndPredict.
        /// </summary>
        ///
        Predict,

        /// <summary>
        /// This field is used for both input and prediction.
        /// </summary>
        ///
        InputAndPredict,

        /// <summary>
        /// This field should be ignored.
        /// </summary>
        ///
        Ignore,

        /// <summary>
        /// This field should pass through, to the output file, without modification.
        /// </summary>
        ///
        PassThrough
    }

    public enum TrainingImplementationType
    {
        /// <summary>
        /// Iterative - Each iteration attempts to improve the machine 
        /// learning method.
        /// </summary>
        ///
        Iterative,

        /// <summary>
        /// Background - Training continues in the background until it is
        /// either finished or is stopped.
        /// </summary>
        ///
        Background,

        /// <summary>
        /// Single Pass - Only one iteration is necessary.
        /// </summary>
        ///
        OnePass
    }

    public enum NormalizationAction
    {
        /// <summary>
        /// Do not normalize the column, just allow it to pass through. This allows
        /// string fields to pass through as well.
        /// </summary>
        ///
        PassThrough,

        /// <summary>
        /// Normalize this column.
        /// </summary>
        ///
        Normalize,

        /// <summary>
        /// Ignore this column, do not include in the output.
        /// </summary>
        ///
        Ignore,

        /// <summary>
        /// Use the "one-of" classification method.
        /// </summary>
        ///
        OneOf,

        /// <summary>
        /// Use the equilateral classification method.
        /// </summary>
        ///
        Equilateral,

        /// <summary>
        /// Use a single-field classification method.
        /// </summary>
        ///
        SingleField
    }

    public enum TimeUnit
    {
        /// <summary>
        /// Seconds
        /// </summary>
        Seconds,
        /// <summary>
        /// Minutes
        /// </summary>
        Minutes,
        /// <summary>
        /// Hours
        /// </summary>
        Hours,
        /// <summary>
        /// Days
        /// </summary>
        Days,
        /// <summary>
        /// Weeks
        /// </summary>
        Weeks,
        /// <summary>
        /// Fortnights
        /// </summary>
        Fortnights,
        /// <summary>
        /// Months
        /// </summary>
        Months,
        /// <summary>
        /// Years
        /// </summary>
        Years,
        /// <summary>
        /// Decades
        /// </summary>
        Decades,
        /// <summary>
        /// Scores
        /// </summary>
        Scores,
        /// <summary>
        /// Centuries
        /// </summary>
        Centuries,
        /// <summary>
        /// Millennia
        /// </summary>
        Millennia,
        /// <summary>
        /// Ticks
        /// </summary>
        Ticks
    }

    internal enum YParent
    {
        /// <summary>
        /// The father.
        /// </summary>
        ///
        Dad,

        /// <summary>
        /// The mother.
        /// </summary>
        ///
        Mom
    }

    public enum EventType
    {
        /// <summary>
        /// The event is used as evidence to predict the outcome.
        /// </summary>
        Evidence,

        /// <summary>
        /// This event is neither evidence our outcome, but still 
        /// is involved in the Bayesian Graph.
        /// </summary>
        Hidden,

        /// <summary>
        /// The event is outcome, which means that we would like to get
        /// a value for given evidence.
        /// </summary>
        Outcome
    }

    public enum YInnovationType
    {
        /// <summary>
        /// A new link.
        /// </summary>
        ///
        NewLink,
        /// <summary>
        /// A new neuron.
        /// </summary>
        ///
        NewNeuron
    }

    public enum ErrorCalculationMode
    {
        /// <summary>
        /// Root mean square error.
        /// </summary>
        RMS,

        /// <summary>
        /// Mean square error.
        /// </summary>
        MSE
    }

    public enum KernelType
    {
        /// <summary>
        /// Linear kernel.
        /// </summary>
        ///
        Linear,

        /// <summary>
        /// Poly kernel.
        /// </summary>
        ///
        Poly,

        /// <summary>
        /// Radial basis function kernel.
        /// </summary>
        ///
        RadialBasisFunction,

        /// <summary>
        /// Sigmoid kernel.
        /// </summary>
        ///
        Sigmoid,

        /// <summary>
        /// Precomputed kernel.
        /// </summary>
        ///
        Precomputed
    }

    public abstract class GAlgo : IMultiThreadable
    {
        /// <summary>
        /// The score calculation object.
        /// </summary>
        ///
        private ICalculateTScore _calculateScore;

        /// <summary>
        /// Set the score calculation object.
        /// </summary>
        public ICalculateTScore CalculateScore
        {
            get { return _calculateScore; }
            set { _calculateScore = value; }
        }

        /// <summary>
        /// The thread count.
        /// </summary>
        public int ThreadCount { get; set; }


        /// <summary>
        /// Set the comparator.
        /// </summary>
        public TComparator Comparator { get; set; }


        /// <summary>
        /// Set the crossover object.
        /// </summary>
        public ICrossover Crossover { get; set; }


        /// <summary>
        /// Set the mating population percent.
        /// </summary>
        public double MatingPopulation { get; set; }


        /// <summary>
        /// Set the mutate object.
        /// </summary>
        public IMutate Mutate { get; set; }


        /// <summary>
        /// Set the mutation percent.
        /// </summary>
        public double MutationPercent { get; set; }


        /// <summary>
        /// Set the percent to mate.
        /// </summary>
        public double PercentToMate { get; set; }


        /// <summary>
        /// Set the population.
        /// </summary>
        public IPopulation Population { get; set; }

        /// <summary>
        /// Add a T.
        /// </summary>
        ///
        /// <param name="species">The species to add.</param>
        /// <param name="T">The T to add.</param>
        public void AddSpeciesMember(ISpecies species,
                                     IT T)
        {
            if (Comparator.IsBetterThan(T.Score,
                                        species.BestScore))
            {
                species.BestScore = T.Score;
                species.GensNoImprovement = 0;
                species.Leader = T;
            }

            species.Members.Add(T);
        }

        /// <summary>
        /// Calculate the score for this T. The T's score will be set.
        /// </summary>
        ///
        /// <param name="g">The T to calculate for.</param>
        public void PerformCalculateScore(IT g)
        {
            if (g.Organism is IMLContext)
            {
                ((IMLContext)g.Organism).ClearContext();
            }
            double score = _calculateScore.CalculateScore(g);
            g.Score = score;
        }


        /// <summary>
        /// Perform one training iteration.
        /// </summary>
        ///
        public abstract void Iteration();
    }

    [Serializable]
    public abstract class BasicML : IMLProperties
    {

        /// <summary>
        /// Properties about the neural network. Some NeuralLogic classes require
        /// certain properties to be set.
        /// </summary>
        ///
        private readonly IDictionary<String, String> _properties;

        /// <summary>
        /// Construct the object.
        /// </summary>
        protected BasicML()
        {
            _properties = new Dictionary<String, String>();
        }

        #region MLProperties Members

        /// <value>A map of all properties.</value>
        public IDictionary<String, String> Properties
        {
            get { return _properties; }
        }


        /// <summary>
        /// Get the specified property as a double.
        /// </summary>
        ///
        /// <param name="name">The name of the property.</param>
        /// <returns>The property as a double.</returns>
        public double GetPropertyDouble(String name)
        {
            return (CSVFormat.EgFormat.Parse((_properties[name])));
        }

        /// <summary>
        /// Get the specified property as a long.
        /// </summary>
        ///
        /// <param name="name">The name of the specified property.</param>
        /// <returns>The value of the specified property.</returns>
        public long GetPropertyLong(String name)
        {
            return (Int64.Parse(_properties[name]));
        }

        /// <summary>
        /// Get the specified property as a string.
        /// </summary>
        ///
        /// <param name="name">The name of the property.</param>
        /// <returns>The value of the property.</returns>
        public String GetPropertyString(String name)
        {
            if (_properties.ContainsKey(name))
            {
                return (_properties[name]);
            }
            return null;
        }

        /// <summary>
        /// Set a property as a double.
        /// </summary>
        ///
        /// <param name="name">The name of the property.</param>
        /// <param name="d">The value of the property.</param>
        public void SetProperty(String name, double d)
        {
            _properties[name] = CSVFormat.EgFormat.Format(d, SyntFramework.DefaultPrecision);
            UpdateProperties();
        }

        /// <summary>
        /// Set a property as a long.
        /// </summary>
        ///
        /// <param name="name">The name of the property.</param>
        /// <param name="l">The value of the property.</param>
        public void SetProperty(String name, long l)
        {
            _properties[name] = "" + l;
            UpdateProperties();
        }

        /// <summary>
        /// Set a property as a double.
        /// </summary>
        ///
        /// <param name="name">The name of the property.</param>
        /// <param name="v">The value of the property.</param>
        public void SetProperty(String name, String v)
        {
            _properties[name] = v;
            UpdateProperties();
        }

        /// <summary>
        /// Update from the propeties stored in the hash map.  Should be called 
        /// whenever the properties change and might need to be reloaded.
        /// </summary>
        public abstract void UpdateProperties();

        #endregion
    }

    public abstract class FormElement : DocumentRange
    {
        /// <summary>
        /// The name of the element.
        /// </summary>
        private String _name;

        /// <summary>
        /// The owner.
        /// </summary>
        private Form _owner;

        /// <summary>
        /// The value.
        /// </summary>
        private String _value;

        /// <summary>
        /// Construct a form element from the specified web page. 
        /// </summary>
        /// <param name="source">The page that holds this form element.</param>
        protected FormElement(WebPage source)
            : base(source)
        {
        }

        /// <summary>
        /// The name of this form.
        /// </summary>
        public String Name
        {
            get { return _name; }
            set { _name = value; }
        }

        /// <summary>
        /// The owner of this form element.
        /// </summary>
        public Form Owner
        {
            get { return _owner; }
            set { _owner = value; }
        }

        /// <summary>
        /// The value of this form element.
        /// </summary>
        public String Value
        {
            get { return _value; }
            set { this._value = value; }
        }

        /// <summary>
        /// True if this is autosend, which means that the type is 
        /// NOT submit.  This prevents a form that has multiple submit buttons
        /// from sending ALL of them in a single post.
        /// </summary>
        public abstract bool AutoSend { get; }
    }

    public abstract class BasicExtract : IExtract
    {
        /// <summary>
        /// The classes registered as listeners for the extraction.
        /// </summary>
        private readonly ICollection<IExtractListener> _listeners =
            new List<IExtractListener>();

        #region IExtract Members

        /// <summary>
        /// Add a listener for the extraction.
        /// </summary>
        /// <param name="listener">The listener to add.</param>
        public void AddListener(IExtractListener listener)
        {
            _listeners.Add(listener);
        }

        /// <summary>
        /// Extract from the web page and return the results as a list.
        /// </summary>
        /// <param name="page">The web page to extract from.</param>
        /// <returns>The results of the extraction as a List.</returns>
        public IList<Object> ExtractList(WebPage page)
        {
            Listeners.Clear();
            var listener = new ListExtractListener();
            AddListener(listener);
            Extract(page);
            return listener.List;
        }

        /// <summary>
        /// A list of listeners registered with this object.
        /// </summary>
        public ICollection<IExtractListener> Listeners
        {
            get { return _listeners; }
        }

        /// <summary>
        /// Remove the specified listener.
        /// </summary>
        /// <param name="listener">The listener to rmove.</param>
        public void RemoveListener(IExtractListener listener)
        {
            _listeners.Remove(listener);
        }

        /// <summary>
        /// Extract data from the web page.
        /// </summary>
        /// <param name="page">The page to extract from.</param>
        public abstract void Extract(WebPage page);

        #endregion

        /// <summary>
        /// Distribute an object to the listeners.
        /// </summary>
        /// <param name="obj">The object to be distributed.</param>
        public void Distribute(Object obj)
        {
            foreach (IExtractListener listener in _listeners)
            {
                listener.FoundData(obj);
            }
        }
    }

    [Serializable]
    public abstract class IndexSegregator : ISegregator
    {
        /// <summary>
        /// The current index.  Updated rows are processed.
        /// </summary>
        private int _currentIndex;

        /// <summary>
        /// THe normalization object this belongs to.
        /// </summary>
        private DataNormalization _normalization;

        /// <summary>
        /// The current index.
        /// </summary>
        public int CurrentIndex
        {
            get { return _currentIndex; }
        }

        #region ISegregator Members

        /// <summary>
        /// The normalization object this object will use.
        /// </summary>
        public DataNormalization Owner
        {
            get { return _normalization; }
        }

        /// <summary>
        /// Setup this class with the specified normalization object.
        /// </summary>
        /// <param name="normalization">Normalization object.</param>
        public void Init(DataNormalization normalization)
        {
            _normalization = normalization;
        }

        /// <summary>
        /// Should this row be included, according to this segregator.
        /// </summary>
        /// <returns>True if this row should be included.</returns>
        public abstract bool ShouldInclude();

        /// <summary>
        /// Init for pass... nothing to do fo this class.
        /// </summary>
        public void PassInit()
        {
            _currentIndex = 0;
        }

        #endregion

        /// <summary>
        /// Used to increase the current index as data is processed.
        /// </summary>
        public void RollIndex()
        {
            _currentIndex++;
        }
    }

    [Serializable]
    public abstract class BasicT : IT
    {
        /// <summary>
        /// The G Algo.
        /// </summary>
        [NonSerialized]
        private GAlgo _ga;

        /// <summary>
        /// The Qs for this gene.
        /// </summary>
        ///
        private readonly IList<Q> _Qs;

        /// <summary>
        /// The adjusted score.
        /// </summary>
        ///
        private double _adjustedScore;

        /// <summary>
        /// The amount to spawn.
        /// </summary>
        ///
        private double _amountToSpawn;

        /// <summary>
        /// The T id.
        /// </summary>
        ///
        private long _TID;

        /// <summary>
        /// The organism generated by this gene.
        /// </summary>
        ///
        [NonSerialized]
        private Object _organism;

        /// <summary>
        /// The population this T belongs to.
        /// </summary>
        ///
        private IPopulation _population;

        /// <summary>
        /// The score of this T.
        /// </summary>
        ///
        private double _score;

        /// <summary>
        /// Construct the bo
        /// </summary>
        protected BasicT()
        {
            _Qs = new List<Q>();
            _score = 0;
        }

        #region IT Members

        /// <returns>The number of genes in this T.</returns>
        public int CalculateGeneCount()
        {
            // sum the genes in the Qs.
            return _Qs.Sum(Q => Q.Genes.Count);
        }

        /// <inheritDoc/>
        public bool Equals(IT other)
        {
            if (other == this)
            {
                return true;
            }

            return Math.Abs(other.Score - Score) < SyntFramework.DefaultDoubleEqual;
        }

        /// <inheritDoc/>
        public int CompareTo(IT other)
        {
            // might be null when deserializing
            if (_ga == null)
            {
                return 0;
            }

            if (Equals(other))
            {
                return 0;
            }

            // compare
            if (_ga.CalculateScore.ShouldMinimize)
            {
                if (Math.Abs(Score - other.Score) < SyntFramework.DefaultDoubleEqual)
                {
                    return 0;
                }
                if (Score > other.Score)
                {
                    return 1;
                }
                return -1;
            }
            if (Math.Abs(Score - other.Score) < SyntFramework.DefaultDoubleEqual)
            {
                return 0;
            }
            if (Score > other.Score)
            {
                return -1;
            }
            return 1;
        }

        /// <summary>
        /// Set the adjusted score.
        /// </summary>
        ///
        /// <value>The score.</value>
        public double AdjustedScore
        {
            get { return _adjustedScore; }
            set { _adjustedScore = value; }
        }


        /// <summary>
        /// Set the amount to spawn.
        /// </summary>
        public double AmountToSpawn
        {
            get { return _amountToSpawn; }
            set { _amountToSpawn = value; }
        }


        /// <value>The number of Qs.</value>
        public IList<Q> Qs
        {
            get { return _Qs; }
        }


        /// <summary>
        /// Set the G Algo to use.
        /// </summary>
        public GAlgo GA
        {
            get { return _ga; }
            set { _ga = value; }
        }


        /// <summary>
        /// Set the T id.
        /// </summary>
        public long TID
        {
            get { return _TID; }
            set { _TID = value; }
        }


        /// <summary>
        /// Set the organism.
        /// </summary>
        public Object Organism
        {
            get { return _organism; }
            set { _organism = value; }
        }


        /// <value>the population to set</value>
        public IPopulation Population
        {
            get { return _population; }
            set { _population = value; }
        }


        /// <summary>
        /// Set the score.
        /// </summary>
        public double Score
        {
            get { return _score; }
            set { _score = value; }
        }


        /// <summary>
        /// Mate two Ts. Will loop over all Qs.
        /// </summary>
        ///
        /// <param name="father">The father.</param>
        /// <param name="child1">The first child.</param>
        /// <param name="child2">The second child.</param>
        public void Mate(IT father, IT child1,
                         IT child2)
        {
            int motherQs = Qs.Count;
            int fatherQs = father.Qs.Count;

            if (motherQs != fatherQs)
            {
               
            }

            for (int i = 0; i < fatherQs; i++)
            {
                Q motherQ = _Qs[i];
                Q fatherQ = father.Qs[i];
                Q offspring1Q = child1.Qs[i];
                Q offspring2Q = child2.Qs[i];

                _ga.Crossover.Mate(motherQ,
                                                fatherQ, offspring1Q,
                                                offspring2Q);

                if (ThreadSafeRandom.NextDouble() < _ga.MutationPercent)
                {
                    _ga.Mutate.PerformMutation(
                        offspring1Q);
                }

                if (ThreadSafeRandom.NextDouble() < _ga.MutationPercent)
                {
                    _ga.Mutate.PerformMutation(
                        offspring2Q);
                }
            }

            child1.Decode();
            child2.Decode();
            _ga.PerformCalculateScore(child1);
            _ga.PerformCalculateScore(child2);
        }

        /// <summary>
        /// from Synt.ml.G.T.T
        /// </summary>
        ///
        public abstract void Decode();

        /// <summary>
        /// from Synt.ml.G.T.T
        /// </summary>
        ///
        public abstract void Syntesis();

        #endregion

        /// <inheritdoc />
        public override sealed String ToString()
        {
            var builder = new StringBuilder();
            builder.Append("[");
            builder.Append(GetType().Name);
            builder.Append(": score=");
            builder.Append(Score);
            return builder.ToString();
        }
    }

    [Serializable]
    public abstract class BasicGene : IGene
    {
        /// <summary>
        /// Is this gene enabled?
        /// </summary>
        ///
        private bool _enabled;

        /// <summary>
        /// ID of this gene, -1 for unassigned.
        /// </summary>
        ///
        private long _id;

        /// <summary>
        /// Innovation ID, -1 for unassigned.
        /// </summary>
        ///
        private long _innovationId;

        /// <summary>
        /// Construct the object.
        /// </summary>
        protected BasicGene()
        {
            _enabled = true;
            _id = -1;
            _innovationId = -1;
        }

        #region IGene Members

        /// <inheritdoc/>
        public int CompareTo(IGene o)
        {
            return ((int)(InnovationId - o.InnovationId));
        }

        /// <summary>
        /// Set the id for this gene.
        /// </summary>
        public long Id
        {
            get { return _id; }
            set { _id = value; }
        }


        /// <summary>
        /// Set the innovation id for this gene.
        /// </summary>
        public long InnovationId
        {
            get { return _innovationId; }
            set { _innovationId = value; }
        }


        /// <value>True, if this gene is enabled.</value>
        public bool Enabled
        {
            get { return _enabled; }
            set { _enabled = value; }
        }


        /// <summary>
        /// from Synt.ml.G.genes.Gene
        /// </summary>
        ///
        public abstract void Copy(IGene gene);

        #endregion
    }

    [Serializable]
    public abstract class BasicOutputFieldGroup : IOutputFieldGroup
    {
        /// <summary>
        /// The fields in this group.
        /// </summary>
        private readonly ICollection<OutputFieldGrouped> _fields = new List<OutputFieldGrouped>();

        #region IOutputFieldGroup Members

        /// <summary>
        /// Add a field to this group.
        /// </summary>
        /// <param name="field">The field to add to the group.</param>
        public void AddField(OutputFieldGrouped field)
        {
            _fields.Add(field);
        }

        /// <summary>
        /// The list of grouped fields.
        /// </summary>
        public ICollection<OutputFieldGrouped> GroupedFields
        {
            get { return _fields; }
        }

        /// <summary>
        /// Init for a new row.
        /// </summary>
        public abstract void RowInit();

        #endregion
    }

    public abstract class BasicHessian : IComputeHessian
    {
        /// <summary>
        /// The derivatives.
        /// </summary>
        protected double[] derivative;

        /// <summary>
        /// The flat network.
        /// </summary>
        protected FlatNetwork flat;

        /// <summary>
        /// The gradients of the Hessian.
        /// </summary>
        protected double[] gradients;

        /// <summary>
        /// The Hessian 2d array.
        /// </summary>
        protected double[][] hessian;

        /// <summary>
        /// The Hessian matrix.
        /// </summary>
        protected Matrix hessianMatrix;

        /// <summary>
        /// The neural network that we would like to train.
        /// </summary>
        protected BasicNetwork network;


        /// <summary>
        /// The sum of square error.
        /// </summary>
        protected double sse;

        /// <summary>
        /// The training data that provides the ideal values.
        /// </summary>
        protected IMLDataSet training;

        #region IComputeHessian Members

        /// <inheritdoc/>
        public virtual void Init(BasicNetwork theNetwork, IMLDataSet theTraining)
        {
            int weightCount = theNetwork.Structure.Flat.Weights.Length;
            flat = theNetwork.Flat;
            training = theTraining;
            network = theNetwork;
            gradients = new double[weightCount];
            hessianMatrix = new Matrix(weightCount, weightCount);
            hessian = hessianMatrix.Data;
            derivative = new double[weightCount];
        }

        /// <inheritdoc/>
        public double[] Gradients
        {
            get { return gradients; }
        }

        /// <inheritdoc/>
        public Matrix HessianMatrix
        {
            get { return hessianMatrix; }
        }

        /// <inheritdoc/>
        public double[][] Hessian
        {
            get { return hessian; }
        }

        /// <inheritdoc/>
        public void Clear()
        {
            EngineArray.Fill(gradients, 0);
            hessianMatrix.Clear();
        }

        /// <inheritdoc/>
        public double SSE
        {
            get { return sse; }
        }


        /// <inheritdoc/>
        public abstract void Compute();

        #endregion

        /// <summary>
        /// Update the Hessian, sum's with what is in the Hessian already.  Call clear to clear out old Hessian.
        /// </summary>
        /// <param name="d">The first derivatives to update with.</param>
        public void UpdateHessian(double[] d)
        {
            // update the hessian
            int weightCount = network.Flat.Weights.Length;
            for (int i = 0; i < weightCount; i++)
            {
                for (int j = 0; j < weightCount; j++)
                {
                    hessian[i][j] += 2 * d[i] * d[j];
                }
            }
        }
    }

    public abstract class CrossTraining : BasicTraining
    {
        /// <summary>
        /// The folded dataset.
        /// </summary>
        ///
        private readonly FoldedDataSet _folded;

        /// <summary>
        /// The network to train.
        /// </summary>
        ///
        private readonly IMLMethod _network;

        /// <summary>
        /// Construct a cross trainer.
        /// </summary>
        ///
        /// <param name="network">The network.</param>
        /// <param name="training">The training data.</param>
        protected CrossTraining(IMLMethod network, FoldedDataSet training) : base(TrainingImplementationType.Iterative)
        {
            _network = network;
            Training = training;
            _folded = training;
        }


        /// <value>The folded training data.</value>
        public FoldedDataSet Folded
        {
            get { return _folded; }
        }


        /// <inheritdoc/>
        public override IMLMethod Method
        {
            get { return _network; }
        }
    }

    public abstract class BasicRandomizer
    {

        private Random _random;


        protected BasicRandomizer()
        {
            _random = new Random((int)(DateTime.Now.Ticks * 100));
        }


        /// <value>the random to set</value>
        public Random Random
        {
            get { return _random; }
            set { _random = value; }
        }

        #region IRandomizer Members


        public virtual void Randomize(double[] d)
        {
            Randomize(d, 0, d.Length);
        }


        public virtual void Randomize(double[] d, int begin, int size)
        {
            for (int i = 0; i < size; i++)
            {
                d[begin + i] = Randomize(d[begin + i]);
            }
        }


        public virtual void Randomize(double[][] d)
        {
            foreach (double[] t in d)
            {
                for (var c = 0; c < d[0].Length; c++)
                {
                    t[c] = Randomize(t[c]);
                }
            }
        }


        public virtual void Randomize(Matrix m)
        {
            double[][] d = m.Data;
            for (int r = 0; r < m.Rows; r++)
            {
                for (int c = 0; c < m.Cols; c++)
                {
                    d[r][c] = Randomize(d[r][c]);
                }
            }
        }


        public virtual void Randomize(IMLMethod method)
        {
            if (method is BasicNetwork)
            {
                var network = (BasicNetwork)method;
                for (int i = 0; i < network.LayerCount - 1; i++)
                {
                    Randomize(network, i);
                }
            }
            else if (method is IMLEncodable)
            {
                var Syntesis = (IMLEncodable)method;
                var Syntesisd = new double[Syntesis.SyntesisdArrayLength()];
                Syntesis.SyntesisToArray(Syntesisd);
                Randomize(Syntesisd);
                Syntesis.DecodeFromArray(Syntesisd);
            }
        }


        public abstract double Randomize(double d);

        #endregion


        public double NextDouble()
        {
            return _random.NextDouble();
        }


        public double NextDouble(double min, double max)
        {
            double range = max - min;
            return (range * _random.NextDouble()) + min;
        }

        public virtual void Randomize(BasicNetwork network, int fromLayer)
        {
            int fromCount = network.GetLayerTotalNeuronCount(fromLayer);
            int toCount = network.GetLayerNeuronCount(fromLayer + 1);

            for (int fromNeuron = 0; fromNeuron < fromCount; fromNeuron++)
            {
                for (int toNeuron = 0; toNeuron < toCount; toNeuron++)
                {
                    double v = network.GetWeight(fromLayer, fromNeuron, toNeuron);
                    v = Randomize(v);
                    network.SetWeight(fromLayer, fromNeuron, toNeuron, v);
                }
            }
        }
    }

    public abstract class Prop : BasicTraining, ITrain, IMultiThreadable
    {
        /// <summary>
        /// The network in indexable form.
        /// </summary>
        ///
        private readonly IMLDataSet _indexable;

        /// <summary>
        /// The last gradients, from the last training iteration.
        /// </summary>
        ///
        private readonly double[] _lastGradient;

        /// <summary>
        /// The network to train.
        /// </summary>
        private IContainsFlat _network;

        /// <summary>
        /// The network to train.
        /// </summary>
        ///
        private readonly FlatNetwork _flat;

        /// <summary>
        /// The training data.
        /// </summary>
        ///
        private readonly IMLDataSet _training;

        /// <summary>
        /// The current error is the average error over all of the threads.
        /// </summary>
        ///
        protected internal double CurrentError;

        /// <summary>
        /// The gradients.
        /// </summary>
        ///
        protected internal double[] Gradients;

        /// <summary>
        /// The iteration.
        /// </summary>
        ///
        private int _iteration;

        /// <summary>
        /// The number of threads to use.
        /// </summary>
        ///
        private int _numThreads;

        /// <summary>
        /// Reported exception from the threads.
        /// </summary>
        ///
        private Exception _reportedException;

        /// <summary>
        /// The total error. Used to take the average of.
        /// </summary>
        ///
        private double _totalError;

        /// <summary>
        /// The workers.
        /// </summary>
        ///
        private GradientWorker[] _workers;

        /// <summary>
        /// True (default) if we should fix flatspots on supported activation functions.
        /// </summary>
        public bool FixFlatSpot { get; set; }

        /// <summary>
        /// The flat spot constants.
        /// </summary>
        private double[] _flatSpot;

        /// <summary>
        /// The error function.
        /// </summary>
        public IErrorFunction ErrorFunction { get; set; }

        /// <summary>
        /// Construct a Prop object.
        /// </summary>
        ///
        /// <param name="network">The network.</param>
        /// <param name="training">The training set.</param>
        protected Prop(IContainsFlat network, IMLDataSet training) : base(TrainingImplementationType.Iterative)
        {
            _network = network;
            _flat = network.Flat;
            _training = training;

            Gradients = new double[_flat.Weights.Length];
            _lastGradient = new double[_flat.Weights.Length];

            _indexable = training;
            _numThreads = 0;
            _reportedException = null;
            FixFlatSpot = true;
            ErrorFunction = new LinearErrorFunction();
        }

        /// <summary>
        /// Set the number of threads. Specify zero to tell Synt to automatically
        /// determine the best number of threads for the processor. If OpenCL is used
        /// as the target device, then this value is not used.
        /// </summary>
        public int ThreadCount
        {
            get { return _numThreads; }
            set { _numThreads = value; }
        }

        /// <summary>
        /// Increase the iteration count by one.
        /// </summary>
        public void RollIteration()
        {
            _iteration++;
        }

        #region Train Members



        /// <inheritdoc/>
        public override IMLMethod Method
        {
            get { return _network; }
        }

        /// <summary>
        /// Perform the specified number of training iterations. This can be more
        /// efficient than single training iterations. This is particularly true if
        /// you are training with a GPU.
        /// </summary>        
        public override void Iteration()
        {
            try
            {
                PreIteration();

                RollIteration();

                CalculateGradients();

                if (_flat.Limited)
                {
                    LearnLimited();
                }
                else
                {
                    Learn();
                }


                foreach (GradientWorker worker in _workers)
                {
                    EngineArray.ArrayCopy(_flat.Weights, 0,
                                          worker.Weights, 0, _flat.Weights.Length);
                }

                if (_flat.HasContext)
                {
                    CopyContexts();
                }

                if (_reportedException != null)
                {
                    throw (new SyntError(_reportedException));
                }

                PostIteration();

                SyntLogging.Log(SyntLogging.LevelInfo,
                                 "Training iterations done, error: " + Error);
            }
            catch (IndexOutOfRangeException ex)
            {
                SyntValidate.ValidateNetworkForTraining(_network,
                                                         Training);
                throw new SyntError(ex);
            }
        }

        /// <value>The gradients from the last iteration;</value>
        public double[] LastGradient
        {
            get { return _lastGradient; }
        }

        #region TrainFlatNetwork Members

        /// <inheritdoc/>
        public virtual void FinishTraining()
        {
            // nothing to do
        }

        /// <inheritdoc/>
        public double Error
        {
            get { return CurrentError; }
            set { CurrentError = value; }
        }


        /// <inheritdoc/>
        public int IterationNumber
        {
            get { return _iteration; }
            set { _iteration = value; }
        }


        /// <inheritdoc/>
        public IContainsFlat Network
        {
            get { return _network; }
        }


        /// <inheritdoc/>
        public int NumThreads
        {
            get { return _numThreads; }
            set { _numThreads = value; }
        }


        /// <inheritdoc/>
        public IMLDataSet Training
        {
            get { return _training; }
        }

        #endregion

        /// <summary>
        /// Calculate the gradients.
        /// </summary>
        ///
        public virtual void CalculateGradients()
        {
            if (_workers == null)
            {
                Init();
            }

            if (_flat.HasContext)
            {
                _workers[0].Network.ClearContext();
            }

            _totalError = 0;

            Parallel.ForEach(_workers, worker => worker.Run());


            CurrentError = _totalError / _workers.Length;
        }

        /// <summary>
        /// Copy the contexts to keep them consistent with multithreaded training.
        /// </summary>
        ///
        private void CopyContexts()
        {
            // copy the contexts(layer outputO from each group to the next group
            for (int i = 0; i < (_workers.Length - 1); i++)
            {
                double[] src = _workers[i].Network.LayerOutput;
                double[] dst = _workers[i + 1].Network.LayerOutput;
                EngineArray.ArrayCopy(src, dst);
            }

            // copy the contexts from the final group to the real network
            EngineArray.ArrayCopy(_workers[_workers.Length - 1].Network.LayerOutput, _flat.LayerOutput);
        }

        /// <summary>
        /// Init the process.
        /// </summary>
        ///
        private void Init()
        {
            // fix flat spot, if needed
            _flatSpot = new double[_flat.ActivationFunctions.Length];

            if (FixFlatSpot)
            {
                for (int i = 0; i < _flat.ActivationFunctions.Length; i++)
                {
                    IActivationFunction af = _flat.ActivationFunctions[i];
                    if (af is ActivationSigmoid)
                    {
                        _flatSpot[i] = 0.1;
                    }
                    else
                    {
                        _flatSpot[i] = 0.0;
                    }
                }
            }
            else
            {
                EngineArray.Fill(_flatSpot, 0.0);
            }


            var determine = new DetermineWorkload(
                _numThreads, (int)_indexable.Count);

            _workers = new GradientWorker[determine.ThreadCount];

            int index = 0;


            // handle CPU
            foreach (IntRange r in determine.CalculateWorkers())
            {
                _workers[index++] = new GradientWorker(((FlatNetwork)_network.Flat.Clone()),
                                                         this, _indexable.OpenAdditional(), r.Low,
                                                         r.High, _flatSpot, ErrorFunction);
            }

            InitOthers();
        }

        /// <summary>
        /// Apply and learn.
        /// </summary>
        ///
        protected internal void Learn()
        {
            double[] weights = _flat.Weights;
            for (int i = 0; i < Gradients.Length; i++)
            {
                weights[i] += UpdateWeight(Gradients, _lastGradient, i);
                Gradients[i] = 0;
            }
        }

        /// <summary>
        /// Apply and learn. This is the same as learn, but it checks to see if any
        /// of the weights are below the limit threshold. In this case, these weights
        /// are zeroed out. Having two methods allows the regular learn method, which
        /// is what is usually use, to be as fast as possible.
        /// </summary>
        ///
        protected internal void LearnLimited()
        {
            double limit = _flat.ConnectionLimit;
            double[] weights = _flat.Weights;
            for (int i = 0; i < Gradients.Length; i++)
            {
                if (Math.Abs(weights[i]) < limit)
                {
                    weights[i] = 0;
                }
                else
                {
                    weights[i] += UpdateWeight(Gradients, _lastGradient, i);
                }
                Gradients[i] = 0;
            }
        }

        /// <summary>
        /// Called by the worker threads to report the progress at each step.
        /// </summary>
        ///
        /// <param name="gradients">The gradients from that worker.</param>
        /// <param name="error">The error for that worker.</param>
        /// <param name="ex">The exception.</param>
        public void Report(double[] gradients, double error,
                           Exception ex)
        {
            lock (this)
            {
                if (ex == null)
                {
                    for (int i = 0; i < gradients.Length; i++)
                    {
                        Gradients[i] += gradients[i];
                    }
                    _totalError += error;
                }
                else
                {
                    _reportedException = ex;
                }
            }
        }

        /// <summary>
        /// Update a weight, the means by which weights are updated vary depending on
        /// the training.
        /// </summary>
        ///
        /// <param name="gradients">The gradients.</param>
        /// <param name="lastGradient">The last gradients.</param>
        /// <param name="index">The index.</param>
        /// <returns>The update value.</returns>
        public abstract double UpdateWeight(double[] gradients,
                                            double[] lastGradient, int index);

        /// <summary>
        /// Allow other training methods to init.
        /// </summary>
        public abstract void InitOthers();


        #endregion
    }

    public abstract class BasicTraining : IMLTrain
    {
        private readonly TrainingImplementationType _implementationType;

        /// <summary>
        /// The training strategies to use.
        /// </summary>
        ///
        private readonly IList<IStrategy> _strategies;

        /// <summary>
        /// The current iteration.
        /// </summary>
        ///
        private int _iteration;

        /// <summary>
        /// Construct the object, specify the implementation type.
        /// </summary>
        /// <param name="implementationType"></param>
        protected BasicTraining(TrainingImplementationType implementationType)
        {
            _strategies = new List<IStrategy>();
            _implementationType = implementationType;
        }

        #region MLTrain Members

        /// <summary>
        /// Training strategies can be added to improve the training results. There
        /// are a number to choose from, and several can be used at once.
        /// </summary>
        ///
        /// <param name="strategy">The strategy to add.</param>
        public virtual void AddStrategy(IStrategy strategy)
        {
            strategy.Init(this);
            _strategies.Add(strategy);
        }

        /// <summary>
        /// Should be called after training has completed and the iteration method
        /// will not be called any further.
        /// </summary>
        ///
        public virtual void FinishTraining()
        {
        }


        /// <inheritdoc/>
        public virtual double Error { get; set; }


        /// <value>the iteration to set</value>
        public virtual int IterationNumber
        {
            get { return _iteration; }
            set { _iteration = value; }
        }


        /// <value>The strategies to use.</value>
        public virtual IList<IStrategy> Strategies
        {
            get { return _strategies; }
        }


        /// <summary>
        /// Set the training object that this strategy is working with.
        /// </summary>
        public virtual IMLDataSet Training { get; set; }


        /// <value>True if training can progress no further.</value>
        public virtual bool TrainingDone
        {
            get { return _strategies.OfType<IEndTrainingStrategy>().Any(end => end.ShouldStop()); }
        }


        /// <summary>
        /// Perform the specified number of training iterations. This is a basic
        /// implementation that just calls iteration the specified number of times.
        /// However, some training methods, particularly with the GPU, benefit
        /// greatly by calling with higher numbers than 1.
        /// </summary>
        ///
        /// <param name="count">The number of training iterations.</param>
        public virtual void Iteration(int count)
        {
            for (int i = 0; i < count; i++)
            {
                Iteration();
            }
        }

        /// <summary>
        /// The implementation type.
        /// </summary>
        public virtual TrainingImplementationType ImplementationType
        {
            get { return _implementationType; }
        }


        /// <summary>
        /// from Synt.ml.train.MLTrain
        /// </summary>
        ///
        public abstract bool CanContinue { get; }

        /// <summary>
        /// from Synt.ml.train.MLTrain
        /// </summary>
        ///
        public abstract IMLMethod Method
        {
            get;
        }


        /// <summary>
        /// from Synt.ml.train.MLTrain
        /// </summary>
        ///
        public abstract void Iteration();

        /// <summary>
        /// from Synt.ml.train.MLTrain
        /// </summary>
        ///
        public abstract TrainingContinuation Pause();

        /// <summary>
        /// from Synt.ml.train.MLTrain
        /// </summary>
        ///
        public abstract void Resume(
            TrainingContinuation state);

        #endregion

        /// <summary>
        /// Call the strategies after an iteration.
        /// </summary>
        ///
        public void PostIteration()
        {
            foreach (IStrategy strategy in _strategies)
            {
                strategy.PostIteration();
            }
        }

        /// <summary>
        /// Call the strategies before an iteration.
        /// </summary>
        ///
        public void PreIteration()
        {
            _iteration++;


            foreach (IStrategy strategy in _strategies)
            {
                strategy.PreIteration();
            }
        }
    }

    public abstract class ConcurrentJob : IMultiThreadable
    {
        /// <summary>
        /// Where to report progress to.
        /// </summary>
        private readonly IStatusReportable _report;

        /// <summary>
        /// Total number of tasks.
        /// </summary>
        private int _totalTasks;

        /// <summary>
        /// 
        /// </summary>
        /// <param name="report"></param>
        protected ConcurrentJob(IStatusReportable report)
        {
            _report = report;
        }

        /// <summary>
        /// Has a stop been requested?
        /// </summary>
        public bool ShouldStop { get; set; }

        /// <summary>
        /// Called by a thread to get the next task.
        /// </summary>
        /// <returns>Config info for the next task.</returns>
        public abstract Object RequestNextTask();

        /// <summary>
        /// Load the workload that this job must process.
        /// </summary>
        /// <returns></returns>
        public abstract int LoadWorkload();

        /// <summary>
        /// Perform the actual workload.
        /// </summary>
        /// <param name="context">The workload to execute.</param>
        public abstract void PerformJobUnit(JobUnitContext context);

        /// <summary>
        /// Start the job, block until its done.
        /// </summary>
        public virtual void Process()
        {
            Object task;

            EngineConcurrency.Instance.ThreadCount = ThreadCount;

            TaskGroup group = EngineConcurrency.Instance.CreateTaskGroup();

            _totalTasks = LoadWorkload();
            int currentTask = 0;

            while ((task = RequestNextTask()) != null)
            {
                currentTask++;
                var context = new JobUnitContext { JobUnit = task, Owner = this, TaskNumber = currentTask };

                var worker = new JobUnitWorker(context);
                EngineConcurrency.Instance.ProcessTask(worker, group);
            }

            group.WaitForComplete();
        }

        /// <summary>
        /// Recieve status reports.
        /// </summary>
        /// <param name="context">The context for this job.</param>
        /// <param name="status">The current status for this job.</param>
        public void ReportStatus(JobUnitContext context, String status)
        {
            _report.Report(_totalTasks, context.TaskNumber, status);
        }

        /// <summary>
        /// Set the thread count, 0 for auto, 1 for single-threaded, 
        /// otherwise the number of threads.
        /// </summary>
        public int ThreadCount { get; set; }
    }

    [Serializable]
    public abstract class ThermalNetwork : BasicML,
                                        IMLAutoAssocation, IMLResettable
    {
        /// <summary>
        /// The current state of the thermal network.
        /// </summary>
        ///
        private BiPolarMLData _currentState;

        /// <summary>
        /// The neuron count.
        /// </summary>
        ///
        private int _neuronCount;

        /// <summary>
        /// The weights.
        /// </summary>
        ///
        private double[] _weights;

        /// <summary>
        /// Default constructor.
        /// </summary>
        ///
        protected ThermalNetwork()
        {
        }

        /// <summary>
        /// Construct the network with the specicified neuron count.
        /// </summary>
        ///
        /// <param name="neuronCount">The number of neurons.</param>
        protected ThermalNetwork(int neuronCount)
        {
            _neuronCount = neuronCount;
            _weights = new double[neuronCount * neuronCount];
            _currentState = new BiPolarMLData(neuronCount);
        }

        /// <summary>
        /// Set the neuron count.
        /// </summary>
        public int NeuronCount
        {
            get { return _neuronCount; }
            set { _neuronCount = value; }
        }

        /// <summary>
        /// Set the weight array.
        /// </summary>
        ///
        /// <value>The weight array.</value>
        public double[] Weights
        {
            get { return _weights; }
            set { _weights = value; }
        }

        /// <summary>
        /// Set the current state.
        /// </summary>
        public BiPolarMLData CurrentState
        {
            get { return _currentState; }
            set
            {
                for (int i = 0; i < value.Count; i++)
                {
                    _currentState[i] = value[i];
                }
            }
        }

        #region MLAutoAssocation Members

        /// <summary>
        /// from Synt.ml.MLInput
        /// </summary>
        public abstract int InputCount { get; }


        /// <summary>
        /// from Synt.ml.MLOutput
        /// </summary>
        ///
        public abstract int OutputCount { get; }


        /// <summary>
        /// from Synt.ml.MLRegression
        /// </summary>
        ///
        public abstract IMLData Compute(
            IMLData input);

        #endregion

        #region MLResettable Members

        /// <summary>
        /// 
        /// </summary>
        ///
        public void Reset()
        {
            Reset(0);
        }

        /// <summary>
        /// 
        /// </summary>
        ///
        public void Reset(int seed)
        {
            CurrentState.Clear();
            EngineArray.Fill(_weights, 0.0d);
        }

        #endregion

        /// <summary>
        /// Add to the specified weight.
        /// </summary>
        ///
        /// <param name="fromNeuron">The from neuron.</param>
        /// <param name="toNeuron">The to neuron.</param>
        /// <param name="v">The value to add.</param>
        public void AddWeight(int fromNeuron, int toNeuron,
                              double v)
        {
            int index = (toNeuron * _neuronCount) + fromNeuron;
            if (index >= _weights.Length)
            {
                throw new NeuralNetworkError("Out of range: fromNeuron:"
                                             + fromNeuron + ", toNeuron: " + toNeuron);
            }
            _weights[index] += v;
        }


        /// <returns>Calculate the current energy for the network. The network will
        /// seek to lower this value.</returns>
        public double CalculateEnergy()
        {
            double tempE = 0;
            int neuronCount = NeuronCount;

            for (int i = 0; i < neuronCount; i++)
            {
                for (int j = 0; j < neuronCount; j++)
                {
                    if (i != j)
                    {
                        tempE += GetWeight(i, j) * _currentState[i]
                                 * _currentState[j];
                    }
                }
            }
            return -1 * tempE / 2;
        }

        /// <summary>
        /// Clear any connection weights.
        /// </summary>
        ///
        public void Clear()
        {
            EngineArray.Fill(_weights, 0);
        }


        /// <summary>
        /// Get a weight.
        /// </summary>
        ///
        /// <param name="fromNeuron">The from neuron.</param>
        /// <param name="toNeuron">The to neuron.</param>
        /// <returns>The weight.</returns>
        public double GetWeight(int fromNeuron, int toNeuron)
        {
            int index = (toNeuron * _neuronCount) + fromNeuron;
            return _weights[index];
        }


        /// <summary>
        /// Init the network.
        /// </summary>
        ///
        /// <param name="neuronCount">The neuron count.</param>
        /// <param name="weights">The weights.</param>
        /// <param name="output">The toutpu</param>
        public void Init(int neuronCount, double[] weights,
                         double[] output)
        {
            if (neuronCount != output.Length)
            {
                throw new NeuralNetworkError("Neuron count(" + neuronCount
                                             + ") must match output count(" + output.Length + ").");
            }

            if ((neuronCount * neuronCount) != weights.Length)
            {
                throw new NeuralNetworkError("Weight count(" + weights.Length
                                             + ") must be the square of the neuron count(" + neuronCount
                                             + ").");
            }

            _neuronCount = neuronCount;
            _weights = weights;
            _currentState = new BiPolarMLData(neuronCount) { Data = output };
        }

        /// <summary>
        /// Set the current state.
        /// </summary>
        /// <param name="s">The new current state.</param>
        public void SetCurrentState(double[] s)
        {
            _currentState = new BiPolarMLData(s.Length);
            EngineArray.ArrayCopy(s, _currentState.Data);
        }

        /// <summary>
        /// Set the weight.
        /// </summary>
        ///
        /// <param name="fromNeuron">The from neuron.</param>
        /// <param name="toNeuron">The to neuron.</param>
        /// <param name="v">The value.</param>
        public void SetWeight(int fromNeuron, int toNeuron,
                              double v)
        {
            int index = (toNeuron * _neuronCount) + fromNeuron;
            _weights[index] = v;
        }
    }

    [Serializable]
    public abstract class AbstractPNN : BasicML
    {
        /// <summary>
        /// First derivative. 
        /// </summary>
        ///
        private readonly double[] _deriv;

        /// <summary>
        /// Second derivative.
        /// </summary>
        ///
        private readonly double[] _deriv2;

        /// <summary>
        /// Input neuron count.
        /// </summary>
        ///
        private readonly int _inputCount;

        /// <summary>
        /// Kernel type. 
        /// </summary>
        ///
        private readonly PNNKernelType _kernel;

        /// <summary>
        /// Output neuron count. 
        /// </summary>
        ///
        private readonly int _outputCount;

        /// <summary>
        /// Output mode.
        /// </summary>
        ///
        private readonly PNNOutputMode _outputMode;

        /// <summary>
        /// Confusion work area.
        /// </summary>
        ///
        private int[] _confusion;

        /// <summary>
        /// Constructor.
        /// </summary>
        ///
        /// <param name="kernel">The kernel type to use.</param>
        /// <param name="outputMode">The output mode to use.</param>
        /// <param name="inputCount">The input count.</param>
        /// <param name="outputCount">The output count.</param>
        protected AbstractPNN(PNNKernelType kernel,
                           PNNOutputMode outputMode, int inputCount,
                           int outputCount)
        {
            _kernel = kernel;
            _outputMode = outputMode;
            _inputCount = inputCount;
            _outputCount = outputCount;
            Trained = false;
            Error = -1000;
            _confusion = null;
            Exclude = -1;

            _deriv = new double[inputCount];
            _deriv2 = new double[inputCount];

            if (_outputMode == PNNOutputMode.Classification)
            {
                _confusion = new int[_outputCount + 1];
            }
        }


        /// <value>the deriv</value>
        public double[] Deriv
        {
            get { return _deriv; }
        }


        /// <value>the deriv2</value>
        public double[] Deriv2
        {
            get { return _deriv2; }
        }


        /// <value>the error to set</value>
        public double Error
        {
            get;
            set;
        }


        /// <value>the exclude to set</value>
        public int Exclude
        {
            get;
            set;
        }


        /// <value>the inputCount</value>
        public int InputCount
        {
            get { return _inputCount; }
        }


        /// <value>the kernel</value>
        public PNNKernelType Kernel
        {
            get { return _kernel; }
        }


        /// <value>the outputCount</value>
        public int OutputCount
        {
            get { return _outputCount; }
        }


        /// <value>the outputMode</value>
        public PNNOutputMode OutputMode
        {
            get { return _outputMode; }
        }


        /// <value>the trained to set</value>
        public bool Trained
        {
            get;
            set;
        }


        /// <value>the separateClass to set</value>
        public bool SeparateClass
        {
            get;
            set;
        }

        /// <summary>
        /// Compute the output from the network.
        /// </summary>
        ///
        /// <param name="input">The input to the network.</param>
        /// <returns>The output from the network.</returns>
        public abstract IMLData Compute(IMLData input);

        /// <summary>
        /// Reset the confusion.
        /// </summary>
        ///
        public void ResetConfusion()
        {
        }
    }

    public abstract class BasicOutputField : IOutputField
    {
        #region IOutputField Members

        /// <summary>
        /// Init this field for a new row.
        /// </summary>
        public abstract void RowInit();

        /// <summary>
        /// The numebr of fields that will actually be generated by 
        /// this field. For a simple field, this value is 1.
        /// </summary>
        public abstract int SubfieldCount { get; }

        /// <summary>
        /// Calculate the value for this field.  Specify subfield of zero
        /// if this is a simple field.
        /// </summary>
        /// <param name="subfield"> The subfield index.</param>
        /// <returns>The calculated value for this field.</returns>
        public abstract double Calculate(int subfield);

        /// <summary>
        /// Is this field part of the ideal data uses to train the
        /// neural network.
        /// </summary>
        public bool Ideal { get; set; }

        #endregion

        /// <summary>
        /// Calculate a ranged mapped value.
        /// </summary>
        /// <param name="value">The to map.</param>
        /// <param name="min">The minimum that the value param can be.</param>
        /// <param name="max">The maximum that the value param can be.</param>
        /// <param name="hi">The high value to map into.</param>
        /// <param name="lo">The low value to map into.</param>
        /// <returns>The mapped value.</returns>
        public static double Calculate(double value, double min,
                                       double max, double hi, double lo)
        {
            return ((value - min) / (max - min)) * (hi - lo) + lo;
        }
    }

    [Serializable]
    public abstract class OutputFieldGrouped : BasicOutputField
    {
        /// <summary>
        /// The group that this field is a member of.
        /// </summary>
        private readonly IOutputFieldGroup _group;

        /// <summary>
        /// The source field, this is the input field that provides data
        /// for this output field.
        /// </summary>
        private readonly IInputField _sourceField;

        /// <summary>
        /// Default constructor, used mainly for reflection.
        /// </summary>
        protected OutputFieldGrouped()
        {
        }

        /// <summary>
        /// Construct a grouped output field.
        /// </summary>
        /// <param name="group">The group that this field belongs to.</param>
        /// <param name="sourceField">The source field for this output field.</param>
        protected OutputFieldGrouped(IOutputFieldGroup group,
                                  IInputField sourceField)
        {
            _group = group;
            _sourceField = sourceField;
            _group.GroupedFields.Add(this);
        }

        /// <summary>
        /// The group that this field belongs to.
        /// </summary>
        /// <returns></returns>
        public IOutputFieldGroup Group
        {
            get { return _group; }
        }

        /// <summary>
        /// The source field for this output field.
        /// </summary>
        /// <returns></returns>
        public IInputField SourceField
        {
            get { return _sourceField; }
        }

        /// <summary>
        /// The numebr of fields that will actually be generated by 
        /// this field. For a simple field, this value is 1.
        /// </summary>
        public abstract override int SubfieldCount { get; }

        /// <summary>
        /// Init this field for a new row.
        /// </summary>
        public abstract override void RowInit();

        /// <summary>
        /// Calculate the value for this field.  Specify subfield of zero
        /// if this is a simple field.
        /// </summary>
        /// <param name="subfield"> The subfield index.</param>
        /// <returns>The calculated value for this field.</returns>
        public abstract override double Calculate(int subfield);
    }

    public abstract class SimulatedAnnealing<TUnitType>
    {
        /// <summary>
        /// The number of cycles that will be used.
        /// </summary>
        ///
        private int _cycles;

        /// <summary>
        /// Should the score be minimized.
        /// </summary>
        ///
        private bool _shouldMinimize;

        /// <summary>
        /// The current temperature.
        /// </summary>
        ///
        private double _temperature;

        /// <summary>
        /// Construct the object.  Default ShouldMinimize to true.
        /// </summary>
        protected SimulatedAnnealing()
        {
            _shouldMinimize = true;
        }

        /// <summary>
        /// Subclasses must provide access to an array that makes up the solution.
        /// </summary>
        public abstract TUnitType[] Array
        {
            get;
        }


        /// <summary>
        /// Get a copy of the array.
        /// </summary>
        public abstract TUnitType[] ArrayCopy
        {
            get;
        }


        /// <value>the cycles to set</value>
        public int Cycles
        {
            get { return _cycles; }
            set { _cycles = value; }
        }


        /// <summary>
        /// Set the score.
        /// </summary>
        public double Score { get; set; }


        /// <value>the startTemperature to set</value>
        public double StartTemperature { get; set; }


        /// <value>the stopTemperature to set</value>
        public double StopTemperature { get; set; }


        /// <value>the temperature to set</value>
        public double Temperature
        {
            get { return _temperature; }
            set { _temperature = value; }
        }


        /// <summary>
        /// Should the score be minimized.
        /// </summary>
        public bool ShouldMinimize
        {
            get { return _shouldMinimize; }
            set { _shouldMinimize = value; }
        }

        /// <summary>
        /// Subclasses should provide a method that evaluates the score for the
        /// current solution. Those solutions with a lower score are better.
        /// </summary>
        ///
        /// <returns>Return the score.</returns>
        public abstract double PerformCalculateScore();


        /// <summary>
        /// Called to perform one cycle of the annealing process.
        /// </summary>
        ///
        public void Iteration()
        {
            Score = PerformCalculateScore();
            TUnitType[] bestArray = ArrayCopy;

            _temperature = StartTemperature;

            for (int i = 0; i < _cycles; i++)
            {
                Randomize();
                double curScore = PerformCalculateScore();

                if (_shouldMinimize)
                {
                    if (curScore < Score)
                    {
                        bestArray = ArrayCopy;
                        Score = curScore;
                    }
                }
                else
                {
                    if (curScore > Score)
                    {
                        bestArray = ArrayCopy;
                        Score = curScore;
                    }
                }

                PutArray(bestArray);
                double ratio = Math.Exp(Math.Log(StopTemperature
                                                 / StartTemperature)
                                        / (Cycles - 1));
                _temperature *= ratio;
            }
        }

        /// <summary>
        /// Store the array.
        /// </summary>
        ///
        /// <param name="array">The array to be stored.</param>
        public abstract void PutArray(TUnitType[] array);

        /// <summary>
        /// Randomize the weight matrix.
        /// </summary>
        ///
        public abstract void Randomize();
    }

    [Serializable]
    public class RBFNetwork : BasicML, IMLError, IMLRegression,
                              IContainsFlat
    {
        /// <summary>
        /// The underlying flat network.
        /// </summary>
        ///
        private readonly FlatNetworkRBF _flat;

        /// <summary>
        /// Construct RBF network.
        /// </summary>
        ///
        public RBFNetwork()
        {
            _flat = new FlatNetworkRBF();
        }

        /// <summary>
        /// Construct RBF network.
        /// </summary>
        ///
        /// <param name="inputCount">The input count.</param>
        /// <param name="hiddenCount">The hidden count.</param>
        /// <param name="outputCount">The output count.</param>
        /// <param name="t">The RBF type.</param>
        public RBFNetwork(int inputCount, int hiddenCount,
                          int outputCount, RBFEnum t)
        {
            if (hiddenCount == 0)
            {

            }

            var rbf = new IRadialBasisFunction[hiddenCount];

            // Set the standard RBF neuron width.
            // Literature seems to suggest this is a good default value.
            double volumeNeuronWidth = 2.0d / hiddenCount;

            _flat = new FlatNetworkRBF(inputCount, rbf.Length, outputCount, rbf);

            try
            {
                // try this
                SetRBFCentersAndWidthsEqualSpacing(-1, 1, t, volumeNeuronWidth,
                                                   false);
            }
            catch {
                // if we have the wrong number of hidden neurons, try this
                RandomizeRBFCentersAndWidths(-1, 1, t);
            }
        }

        /// <summary>
        /// Construct RBF network.
        /// </summary>
        ///
        /// <param name="inputCount">The input count.</param>
        /// <param name="outputCount">The output count.</param>
        /// <param name="rbf">The RBF type.</param>
        public RBFNetwork(int inputCount, int outputCount,
                          IRadialBasisFunction[] rbf)
        {
            _flat = new FlatNetworkRBF(inputCount, rbf.Length, outputCount, rbf) { RBF = rbf };
        }

        /// <summary>
        /// Set the RBF's.
        /// </summary>
        public IRadialBasisFunction[] RBF
        {
            get { return _flat.RBF; }
            set { _flat.RBF = value; }
        }

        #region ContainsFlat Members

        /// <inheritdoc/>
        public FlatNetwork Flat
        {
            get { return _flat; }
        }

        #endregion

        #region MLError Members

        /// <summary>
        /// Calculate the error for this neural network.
        /// </summary>
        ///
        /// <param name="data">The training set.</param>
        /// <returns>The error percentage.</returns>
        public double CalculateError(IMLDataSet data)
        {
            return SyntUtility.CalculateRegressionError(this, data);
        }

        #endregion

        #region MLRegression Members

        /// <inheritdoc/>
        public IMLData Compute(IMLData input)
        {
            IMLData output = new BasicMLData(OutputCount);
            _flat.Compute(input.Data, output.Data);
            return output;
        }


        /// <inheritdoc/>
        public virtual int InputCount
        {
            get { return _flat.InputCount; }
        }


        /// <inheritdoc/>
        public virtual int OutputCount
        {
            get { return _flat.OutputCount; }
        }

        #endregion

        /// <summary>
        /// Set the RBF components to random values.
        /// </summary>
        ///
        /// <param name="min">Minimum random value.</param>
        /// <param name="max">Max random value.</param>
        /// <param name="t">The type of RBF to use.</param>
        public void RandomizeRBFCentersAndWidths(double min,
                                                 double max, RBFEnum t)
        {
            int dimensions = InputCount;
            var centers = new double[dimensions];

            for (int i = 0; i < dimensions; i++)
            {
                centers[i] = RangeRandomizer.Randomize(min, max);
            }

            for (int i = 0; i < _flat.RBF.Length; i++)
            {
                SetRBFFunction(i, t, centers, RangeRandomizer.Randomize(min, max));
            }
        }


        public void SetRBFCentersAndWidths(double[][] centers,
                                           double[] widths, RBFEnum t)
        {
            for (int i = 0; i < _flat.RBF.Length; i++)
            {
                SetRBFFunction(i, t, centers[i], widths[i]);
            }
        }

        /// <summary>
        /// Equally spaces all hidden neurons within the n dimensional variable
        /// space.
        /// </summary>
        ///
        /// <param name="minPosition">The minimum position neurons should be centered. Typically 0.</param>
        /// <param name="maxPosition">The maximum position neurons should be centered. Typically 1</param>
        /// <param name="t">The RBF type.</param>
        /// <param name="volumeNeuronRBFWidth">The neuron width of neurons within the mesh.</param>
        /// <param name="useWideEdgeRBFs">Enables wider RBF's around the boundary of the neuron mesh.</param>
        public void SetRBFCentersAndWidthsEqualSpacing(
            double minPosition, double maxPosition,
            RBFEnum t, double volumeNeuronRBFWidth,
            bool useWideEdgeRBFs)
        {
            int totalNumHiddenNeurons = _flat.RBF.Length;

            int dimensions = InputCount;
            double disMinMaxPosition = Math.Abs(maxPosition - minPosition);

            // Check to make sure we have the correct number of neurons for the
            // provided dimensions
            var expectedSideLength = (int)Math.Pow(totalNumHiddenNeurons, 1.0d / dimensions);
            double cmp = Math.Pow(totalNumHiddenNeurons, 1.0d / dimensions);

            if (expectedSideLength != cmp)
            {

            }

            double edgeNeuronRBFWidth = 2.5d * volumeNeuronRBFWidth;

            var centers = new double[totalNumHiddenNeurons][];
            var widths = new double[totalNumHiddenNeurons];

            for (int i = 0; i < totalNumHiddenNeurons; i++)
            {
                centers[i] = new double[dimensions];

                int sideLength = expectedSideLength;

                // Evenly distribute the volume neurons.
                int temp = i;

                // First determine the centers
                for (int j = dimensions; j > 0; j--)
                {
                    // i + j * sidelength + k * sidelength ^2 + ... l * sidelength ^
                    // n
                    // i - neuron number in x direction, i.e. 0,1,2,3
                    // j - neuron number in y direction, i.e. 0,1,2,3
                    // Following example assumes sidelength of 4
                    // e.g Neuron 5 - x position is (int)5/4 * 0.33 = 0.33
                    // then take modulus of 5%4 = 1
                    // Neuron 5 - y position is (int)1/1 * 0.33 = 0.33
                    centers[i][j - 1] = ((int)(temp / Math.Pow(sideLength, j - 1)) * (disMinMaxPosition / (sideLength - 1)))
                                        + minPosition;
                    temp = temp % (int)(Math.Pow(sideLength, j - 1));
                }

                // Now set the widths
                bool contains = false;

                for (int z = 0; z < centers[0].Length; z++)
                {
                    if ((centers[i][z] == 1.0d) || (centers[i][z] == 0.0d))
                    {
                        contains = true;
                    }
                }

                if (contains && useWideEdgeRBFs)
                {
                    widths[i] = edgeNeuronRBFWidth;
                }
                else
                {
                    widths[i] = volumeNeuronRBFWidth;
                }
            }

            SetRBFCentersAndWidths(centers, widths, t);
        }

        /// <summary>
        /// Set an RBF function.
        /// </summary>
        ///
        /// <param name="index">The index to set.</param>
        /// <param name="t">The function type.</param>
        /// <param name="centers">The centers.</param>
        /// <param name="width">The width.</param>
        public void SetRBFFunction(int index, RBFEnum t,
                                   double[] centers, double width)
        {
            if (t == RBFEnum.Gaussian)
            {
                _flat.RBF[index] = new GaussianFunction(0.5d, centers,
                                                       width);
            }
            else if (t == RBFEnum.Multiquadric)
            {
                _flat.RBF[index] = new MultiquadricFunction(0.5d, centers,
                                                           width);
            }
            else if (t == RBFEnum.InverseMultiquadric)
            {
                _flat.RBF[index] = new InverseMultiquadricFunction(0.5d,
                                                                  centers, width);
            }
        }

        /// <inheritdoc/>
        public override void UpdateProperties()
        {
            // unneeded
        }
    }

    [Serializable]
    public class FlatNetworkRBF : FlatNetwork
    {


        private IRadialBasisFunction[] _rbf;


        public FlatNetworkRBF()
        {
        }


        public FlatNetworkRBF(int inputCount, int hiddenCount,
                              int outputCount, IRadialBasisFunction[] rbf)
        {
            var layers = new FlatLayer[3];
            _rbf = rbf;

            layers[0] = new FlatLayer(new ActivationLinear(), inputCount, 0.0d);
            layers[1] = new FlatLayer(new ActivationLinear(), hiddenCount, 0.0d);
            layers[2] = new FlatLayer(new ActivationLinear(), outputCount, 0.0d);

            Init(layers);
        }


        public IRadialBasisFunction[] RBF
        {
            get { return _rbf; }
            set { _rbf = value; }
        }


        public override sealed Object Clone()
        {
            var result = new FlatNetworkRBF();
            CloneFlatNetwork(result);
            result._rbf = _rbf;
            return result;
        }


        public override sealed void Compute(double[] x, double[] output)
        {
            int outputIndex = LayerIndex[1];

            for (int i = 0; i < _rbf.Length; i++)
            {
                double o = _rbf[i].Calculate(x);
                LayerOutput[outputIndex + i] = o;
            }

            // now compute the output
            ComputeLayer(1);
            EngineArray.ArrayCopy(LayerOutput, 0, output, 0,
                                  OutputCount);
        }
    }

    [Serializable]
    public class FlatNetwork
    {

        public const double DefaultBiasActivation = 1.0d;


        public const double NoBiasActivation = 0.0d;


        private IActivationFunction[] _activationFunctions;


        private int _beginTraining;


        private double[] _biasActivation;


        private double _connectionLimit;


        private int[] _contextTargetOffset;


        private int[] _contextTargetSize;


        private int _endTraining;


        private bool _hasContext;

        private int _inputCount;


        private bool _isLimited;


        private int[] _layerContextCount;


        private int[] _layerCounts;

        private int[] _layerFeedCounts;


        private int[] _layerIndex;


        private double[] _layerOutput;


        private double[] _layerSums;


        private int _outputCount;


        private int[] _weightIndex;


        private double[] _weights;
        internal double ConnectionLimit;

        public FlatNetwork()
        {
        }


        public FlatNetwork(FlatLayer[] layers)
        {
            Init(layers);
        }


        public FlatNetwork(int input, int hidden1, int hidden2,
                           int output, bool tanh)
        {
            IActivationFunction linearAct = new ActivationLinear();
            FlatLayer[] layers;
            IActivationFunction act = (tanh)
                                          ? (new ActivationTANH())
                                          : (IActivationFunction)(new ActivationSigmoid());

            if ((hidden1 == 0) && (hidden2 == 0))
            {
                layers = new FlatLayer[2];
                layers[0] = new FlatLayer(linearAct, input,
                                          DefaultBiasActivation);
                layers[1] = new FlatLayer(act, output,
                                          NoBiasActivation);
            }
            else if ((hidden1 == 0) || (hidden2 == 0))
            {
                int count = Math.Max(hidden1, hidden2);
                layers = new FlatLayer[3];
                layers[0] = new FlatLayer(linearAct, input,
                                          DefaultBiasActivation);
                layers[1] = new FlatLayer(act, count,
                                          DefaultBiasActivation);
                layers[2] = new FlatLayer(act, output,
                                          NoBiasActivation);
            }
            else
            {
                layers = new FlatLayer[4];
                layers[0] = new FlatLayer(linearAct, input,
                                          DefaultBiasActivation);
                layers[1] = new FlatLayer(act, hidden1,
                                          DefaultBiasActivation);
                layers[2] = new FlatLayer(act, hidden2,
                                          DefaultBiasActivation);
                layers[3] = new FlatLayer(act, output,
                                          NoBiasActivation);
            }

            _isLimited = false;
            _connectionLimit = 0.0d;

            Init(layers);
        }


        public IActivationFunction[] ActivationFunctions
        {
            get { return _activationFunctions; }
            set { _activationFunctions = value; }
        }



        public int BeginTraining
        {
            get { return _beginTraining; }
            set { _beginTraining = value; }
        }



        public double[] BiasActivation
        {
            get { return _biasActivation; }
            set { _biasActivation = value; }
        }



        //public double ConnectionLimit
        //{
        //    //get { return _connectionLimit; }
        //    //set
        //    //{
        //    //    _connectionLimit = value;
        //    //    if (Math.Abs(_connectionLimit
        //    //                 - BasicNetwork.DefaultConnectionLimit) < SyntFramework.DefaultDoubleEqual)
        //    //    {
        //    //        _isLimited = true;
        //    //    }
        //    //}
        //}



        public int[] ContextTargetOffset
        {
            get { return _contextTargetOffset; }
            set { _contextTargetOffset = value; }
        }



        public int[] ContextTargetSize
        {
            get { return _contextTargetSize; }
            set { _contextTargetSize = value; }
        }



        public int SyntesisLength
        {
            get { return _weights.Length; }
        }



        public int EndTraining
        {
            get { return _endTraining; }
            set { _endTraining = value; }
        }



        public bool HasContext
        {
            get { return _hasContext; }
            set { _hasContext = value; }
        }



        public int InputCount
        {
            get { return _inputCount; }
            set { _inputCount = value; }
        }



        public int[] LayerContextCount
        {
            get { return _layerContextCount; }
            set { _layerContextCount = value; }
        }



        public int[] LayerCounts
        {
            get { return _layerCounts; }
            set { _layerCounts = value; }
        }


        public int[] LayerFeedCounts
        {
            get { return _layerFeedCounts; }
            set { _layerFeedCounts = value; }
        }



        public int[] LayerIndex
        {
            get { return _layerIndex; }
            set { _layerIndex = value; }
        }



        public double[] LayerOutput
        {
            get { return _layerOutput; }
            set { _layerOutput = value; }
        }



        //public int NeuronCount
        //{
        //    get
        //    {
        //        return _layerCounts.Sum();
        //    }
        //}



        public int OutputCount
        {
            get { return _outputCount; }
            set { _outputCount = value; }
        }



        public int[] WeightIndex
        {
            get { return _weightIndex; }
            set { _weightIndex = value; }
        }



        public double[] Weights
        {
            get { return _weights; }
            set { _weights = value; }
        }

        /// <value>the isLimited</value>
        public bool Limited
        {
            get { return _isLimited; }
        }


        //public double CalculateError(IMLDataSet data)
        //{
        //    //////     var errorCalculation = new ErrorCalculation();

        //    ////     var actual = new double[_outputCount];
        //    ////     IMLDataPair pair = BasicMLDataPair.CreatePair(data.InputSize,
        //    ////                                                  data.IdealSize);

        //    ////     for (int i = 0; i < data.Count; i++)
        //    ////     {
        //    ////         data.GetRecord(i, pair);
        //    ////         Compute(pair.InputArray, actual);
        //    ////         errorCalculation.UpdateError(actual, pair.IdealArray, pair.Significance);
        //    ////     }
        //    //   return errorCalculation.Calculate();
        //}


        public void ClearConnectionLimit()
        {
            _connectionLimit = 0.0d;
            _isLimited = false;
        }


        public void ClearContext()
        {
            int index = 0;

            for (int i = 0; i < _layerIndex.Length; i++)
            {
                bool hasBias = (_layerContextCount[i] + _layerFeedCounts[i]) != _layerCounts[i];

                // fill in regular neurons
                for (int j = 0; j < _layerFeedCounts[i]; j++)
                {
                    _layerOutput[index++] = 0;
                }

                // fill in the bias
                if (hasBias)
                {
                    _layerOutput[index++] = _biasActivation[i];
                }

                // fill in context
                for (int j = 0; j < _layerContextCount[i]; j++)
                {
                    _layerOutput[index++] = 0;
                }
            }
        }


        public virtual Object Clone()
        {
            var result = new FlatNetwork();
            CloneFlatNetwork(result);
            return result;
        }


        public void CloneFlatNetwork(FlatNetwork result)
        {
            result._inputCount = _inputCount;
            result._layerCounts = EngineArray.ArrayCopy(_layerCounts);
            result._layerIndex = EngineArray.ArrayCopy(_layerIndex);
            result._layerOutput = EngineArray.ArrayCopy(_layerOutput);
            result._layerSums = EngineArray.ArrayCopy(_layerSums);
            result._layerFeedCounts = EngineArray.ArrayCopy(_layerFeedCounts);
            result._contextTargetOffset = EngineArray
                .ArrayCopy(_contextTargetOffset);
            result._contextTargetSize = EngineArray
                .ArrayCopy(_contextTargetSize);
            result._layerContextCount = EngineArray
                .ArrayCopy(_layerContextCount);
            result._biasActivation = EngineArray.ArrayCopy(_biasActivation);
            result._outputCount = _outputCount;
            result._weightIndex = _weightIndex;
            result._weights = _weights;

            result._activationFunctions = new IActivationFunction[_activationFunctions.Length];
            for (int i = 0; i < result._activationFunctions.Length; i++)
            {
                result._activationFunctions[i] = (IActivationFunction)_activationFunctions[i].Clone();
            }

            result._beginTraining = _beginTraining;
            result._endTraining = _endTraining;
        }


        public virtual void Compute(double[] input, double[] output)
        {
            int sourceIndex = _layerOutput.Length
                              - _layerCounts[_layerCounts.Length - 1];

            EngineArray.ArrayCopy(input, 0, _layerOutput, sourceIndex,
                                  _inputCount);

            for (int i = _layerIndex.Length - 1; i > 0; i--)
            {
                ComputeLayer(i);
            }

            // update context values
            int offset = _contextTargetOffset[0];

            for (int x = 0; x < _contextTargetSize[0]; x++)
            {
                _layerOutput[offset + x] = _layerOutput[x];
            }

            EngineArray.ArrayCopy(_layerOutput, 0, output, 0, _outputCount);
        }


        protected internal void ComputeLayer(int currentLayer)
        {
            int inputIndex = _layerIndex[currentLayer];
            int outputIndex = _layerIndex[currentLayer - 1];
            int inputSize = _layerCounts[currentLayer];
            int outputSize = _layerFeedCounts[currentLayer - 1];

            int index = _weightIndex[currentLayer - 1];

            int limitX = outputIndex + outputSize;
            int limitY = inputIndex + inputSize;

            // weight values
            for (int x = outputIndex; x < limitX; x++)
            {
                double sum = 0;
                for (int y = inputIndex; y < limitY; y++)
                {
                    sum += _weights[index++] * _layerOutput[y];
                }
                _layerOutput[x] = sum;
                _layerSums[x] = sum;
            }

            _activationFunctions[currentLayer - 1].ActivationFunction(
                _layerOutput, outputIndex, outputSize);

            // update context values
            int offset = _contextTargetOffset[currentLayer];

            for (int x = 0; x < _contextTargetSize[currentLayer]; x++)
            {
                _layerOutput[offset + x] = _layerOutput[outputIndex + x];
            }
        }


        public void DecodeNetwork(double[] data)
        {
            if (data.Length != _weights.Length)
            {

            }
            _weights = data;
        }


        public double[] SyntesisNetwork()
        {
            return _weights;
        }



        //public Type HasSameActivationFunction()
        //{
        //    List<Type> map = new List<Type>();


        //    foreach (IActivationFunction activation in _activationFunctions)
        //    {
        //        if (!map.Contains(activation.GetType()))
        //        {
        //            map.Add(activation.GetType());
        //        }
        //    }

        //    if (map.Count != 1)
        //    {
        //        return null;
        //    }
        //    return map[0];
        //}

        /// <summary>
        /// Construct a flat network.
        /// </summary>
        ///
        /// <param name="layers">The layers of the network to create.</param>
        public void Init(FlatLayer[] layers)
        {
            int layerCount = layers.Length;

            _inputCount = layers[0].Count;
            _outputCount = layers[layerCount - 1].Count;

            _layerCounts = new int[layerCount];
            _layerContextCount = new int[layerCount];
            _weightIndex = new int[layerCount];
            _layerIndex = new int[layerCount];
            _activationFunctions = new IActivationFunction[layerCount];
            _layerFeedCounts = new int[layerCount];
            _contextTargetOffset = new int[layerCount];
            _contextTargetSize = new int[layerCount];
            _biasActivation = new double[layerCount];

            int index = 0;
            int neuronCount = 0;
            int weightCount = 0;

            for (int i = layers.Length - 1; i >= 0; i--)
            {
                FlatLayer layer = layers[i];
                FlatLayer nextLayer = null;

                if (i > 0)
                {
                    nextLayer = layers[i - 1];
                }

                _biasActivation[index] = layer.BiasActivation;
                _layerCounts[index] = layer.TotalCount;
                _layerFeedCounts[index] = layer.Count;
                _layerContextCount[index] = layer.ContextCount;
                _activationFunctions[index] = layer.Activation;

                neuronCount += layer.TotalCount;

                if (nextLayer != null)
                {
                    weightCount += layer.Count * nextLayer.TotalCount;
                }

                if (index == 0)
                {
                    _weightIndex[index] = 0;
                    _layerIndex[index] = 0;
                }
                else
                {
                    _weightIndex[index] = _weightIndex[index - 1]
                                         + (_layerCounts[index] * _layerFeedCounts[index - 1]);
                    _layerIndex[index] = _layerIndex[index - 1]
                                        + _layerCounts[index - 1];
                }

                int neuronIndex = 0;
                for (int j = layers.Length - 1; j >= 0; j--)
                {
                    if (layers[j].ContextFedBy == layer)
                    {
                        _hasContext = true;
                        _contextTargetSize[index] = layers[j].ContextCount;
                        _contextTargetOffset[index] = neuronIndex
                                                     + (layers[j].TotalCount - layers[j].ContextCount);
                    }
                    neuronIndex += layers[j].TotalCount;
                }

                index++;
            }

            _beginTraining = 0;
            _endTraining = _layerCounts.Length - 1;

            _weights = new double[weightCount];
            _layerOutput = new double[neuronCount];
            _layerSums = new double[neuronCount];

            ClearContext();
        }


        /// <summary>
        /// Perform a simple randomization of the weights of the neural network
        /// between -1 and 1.
        /// </summary>
        ///
        public void Randomize()
        {
            Randomize(1, -1);
        }

        /// <summary>
        /// Perform a simple randomization of the weights of the neural network
        /// between the specified hi and lo.
        /// </summary>
        ///
        /// <param name="hi">The network high.</param>
        /// <param name="lo">The network low.</param>
        public void Randomize(double hi, double lo)
        {
            for (int i = 0; i < _weights.Length; i++)
            {
                _weights[i] = (ThreadSafeRandom.NextDouble() * (hi - lo)) + lo;
            }
        }

        /// <summary>
        /// The layer sums, before the activation is applied.
        /// </summary>
        public double[] LayerSums
        {
            get { return _layerSums; }
            set { _layerSums = value; }
        }
    }

    public class ThreadSafeRandom
    {

        private static readonly Random Random = new Random();


        public static double NextDouble()
        {
            lock (Random)
            {
                return Random.NextDouble();
            }
        }
    }

    [Serializable]
    public abstract class BasicRBF : IRadialBasisFunction
    {

        private double[] _center;


        private double _peak;


        private double _width;


        public double[] Centers
        {
            get { return _center; }
            set { _center = value; }
        }


        public int Dimensions
        {
            get { return _center.Length; }
        }


        public double Peak
        {
            get { return _peak; }
            set { _peak = value; }
        }


        public double Width
        {
            get { return _width; }
            set { _width = value; }
        }



        public abstract double Calculate(double[] x);
    }

    [Serializable]
    public abstract class BasicQuery : IBayesianQuery
    {
        /// <summary>
        /// A mapping of the events to event states.
        /// </summary>
        private readonly IDictionary<BayesianEvent, EventState> _events = new Dictionary<BayesianEvent, EventState>();

        /// <summary>
        /// The evidence events.
        /// </summary>
        private readonly IList<BayesianEvent> _evidenceEvents = new List<BayesianEvent>();

        /// <summary>
        /// The network to be queried.
        /// </summary>
        private readonly BayesianNetwork _network;

        /// <summary>
        /// The outcome events.
        /// </summary>
        private readonly IList<BayesianEvent> _outcomeEvents = new List<BayesianEvent>();

        /// <summary>
        /// Default constructor.
        /// </summary>
        protected BasicQuery()
        {
            _network = null;
        }

        /// <summary>
        /// Construct a basic query.
        /// </summary>
        /// <param name="theNetwork">The network to use for this query.</param>
        protected BasicQuery(BayesianNetwork theNetwork)
        {
            _network = theNetwork;
            FinalizeStructure();
        }

        /// <summary>
        /// Determines if the evidence events have values that satisfy the
        /// needed case. This is used for sampling.
        /// </summary>
        protected bool IsNeededEvidence
        {
            get
            {
                foreach (BayesianEvent evidenceEvent in _evidenceEvents)
                {
                    EventState state = GetEventState(evidenceEvent);
                    if (!state.IsSatisfied)
                    {
                        return false;
                    }
                }
                return true;
            }
        }

        /// <summary>
        /// True, if the current state satisifies the desired outcome.
        /// </summary>
        /// <returns></returns>
        protected bool SatisfiesDesiredOutcome
        {
            get
            {
                foreach (BayesianEvent outcomeEvent in _outcomeEvents)
                {
                    EventState state = GetEventState(outcomeEvent);
                    if (!state.IsSatisfied)
                    {
                        return false;
                    }
                }
                return true;
            }
        }

        #region IBayesianQuery Members

        /// <summary>
        /// Finalize the query structure.
        /// </summary>
        public void FinalizeStructure()
        {
            _events.Clear();
            foreach (BayesianEvent e in _network.Events)
            {
                _events[e] = new EventState(e);
            }
        }

        /// <inheritdoc/>
        public BayesianNetwork Network
        {
            get { return _network; }
        }

        /// <inheritdoc/>
        public IDictionary<BayesianEvent, EventState> Events
        {
            get { return _events; }
        }


        /// <inheritdoc/>
        public IList<BayesianEvent> EvidenceEvents
        {
            get { return _evidenceEvents; }
        }

        /// <inheritdoc/>
        public IList<BayesianEvent> OutcomeEvents
        {
            get { return _outcomeEvents; }
        }

        /// <summary>
        /// Called to locate the evidence and outcome events.
        /// </summary>
        public void LocateEventTypes()
        {
            _evidenceEvents.Clear();
            _outcomeEvents.Clear();

            foreach (BayesianEvent e in _network.Events)
            {
                switch (GetEventType(e))
                {
                    case EventType.Evidence:
                        _evidenceEvents.Add(e);
                        break;
                    case EventType.Outcome:
                        _outcomeEvents.Add(e);
                        break;
                }
            }
        }

        /// <inheritdoc/>
        public void Reset()
        {
            foreach (EventState s in _events.Values)
            {
                s.IsCalculated = false;
            }
        }


        /// <inheritdoc/>
        public void DefineEventType(BayesianEvent theEvent, EventType et)
        {
            GetEventState(theEvent).CurrentEventType = et;
        }

        /// <inheritdoc/>
        public EventState GetEventState(BayesianEvent theEvent)
        {
            if (!_events.ContainsKey(theEvent))
                return null;
            return _events[theEvent];
        }

        /// <inheritdoc/>
        public EventType GetEventType(BayesianEvent theEvent)
        {
            return GetEventState(theEvent).CurrentEventType;
        }

        /// <inheritdoc/>
        public void SetEventValue(BayesianEvent theEvent, bool b)
        {
            SetEventValue(theEvent, b ? 0 : 1);
        }

        /// <inheritdoc/>
        public void SetEventValue(BayesianEvent theEvent, int d)
        {
            if (GetEventType(theEvent) == EventType.Hidden)
            {
                throw new BayesianError("You may only set the value of an evidence or outcome event.");
            }

            GetEventState(theEvent).CompareValue = d;
            GetEventState(theEvent).Value = d;
        }

        /// <inheritdoc/>
        public String Problem
        {
            get
            {
                if (_outcomeEvents.Count == 0)
                    return "";

                var result = new StringBuilder();
                result.Append("P(");
                bool first = true;
                foreach (BayesianEvent e in _outcomeEvents)
                {
                    if (!first)
                    {
                        result.Append(",");
                    }
                    first = false;
                    result.Append(EventState.ToSimpleString(GetEventState(e)));
                }
                result.Append("|");

                first = true;
                foreach (BayesianEvent e in _evidenceEvents)
                {
                    if (!first)
                    {
                        result.Append(",");
                    }
                    first = false;
                    EventState state = GetEventState(e);
                    if (state == null)
                        break;
                    result.Append(EventState.ToSimpleString(state));
                }
                result.Append(")");

                return result.ToString();
            }
        }

        /// <summary>
        /// Clone the object.
        /// </summary>
        /// <returns>A clone of the object.</returns>
        public virtual IBayesianQuery Clone()
        {
            return null;
        }

        /// <inheritdoc/>
        public abstract double Probability { get; }

        /// <inheritdoc/>
        public abstract void Execute();

        #endregion
    }

    [Serializable]
    public class GaussianFunction : BasicRBF
    {

        public GaussianFunction()
        {
            Centers = new double[1];
            Peak = 1;
            Width = 1;
        }


        public GaussianFunction(int dimensions)
        {
            Centers = new double[dimensions];
            Peak = 1.0;
            Width = 1.0;
        }

        public GaussianFunction(double peak, double[] center,
                                double width)
        {
            Centers = center;
            Peak = peak;
            Width = width;
        }

        public GaussianFunction(double center, double peak,
                                double width)
        {
            Centers = new double[1];
            Centers[0] = center;
            Peak = peak;
            Width = width;
        }


        public override double Calculate(double[] x)
        {
            double value = 0;
            double[] center = Centers;
            double width = Width;

            for (int i = 0; i < center.Length - 1; i++)
            {
                value += Math.Pow(x[i] - center[i], 2)
                         / (2.0 * width * width);
            }
            return Peak * Math.Exp(-value);
        }
    }

    [Serializable]
    public class InverseMultiquadricFunction : BasicRBF
    {

        public InverseMultiquadricFunction(int dimensions)
        {
            Centers = new double[dimensions];
            Peak = 1.0;
            Width = 1.0;
        }


        public InverseMultiquadricFunction(double peak,
                                           double[] center, double width)
        {
            Centers = center;
            Peak = peak;
            Width = width;
        }

        public InverseMultiquadricFunction(double center, double peak,
                                           double width)
        {
            Centers = new double[1];
            Centers[0] = center;
            Peak = peak;
            Width = width;
        }



        public override double Calculate(double[] x)
        {
            double value = 0;
            double[] center = Centers;
            double width = Width;

            for (int i = 0; i < center.Length; i++)
            {
                value += Math.Pow(x[i] - center[i], 2) + (width * width);
            }
            return Peak / BoundMath.Sqrt(value);
        }
    }

    [Serializable]
    public class MexicanHatFunction : BasicRBF
    {


        public MexicanHatFunction(int dimensions)
        {
            Centers = new double[dimensions];
            Peak = 1.0;
            Width = 1.0;
        }


        public MexicanHatFunction(double peak, double[] center,
                                  double width)
        {
            Centers = center;
            Peak = peak;
            Width = width;
        }



        public MexicanHatFunction(double center, double peak,
                                  double width)
        {
            Centers = new double[1];
            Centers[0] = center;
            Peak = peak;
            Width = width;
        }



        public override double Calculate(double[] x)
        {
            double[] center = Centers;


            double norm = 0;
            for (int i = 0; i < center.Length; i++)
            {
                norm += Math.Pow(x[i] - center[i], 2);
            }

            // calculate the value

            return Peak * (1 - norm) * Math.Exp(-norm / 2);
        }
    }

    [Serializable]
    public class MultiquadricFunction : BasicRBF
    {

        public MultiquadricFunction(int dimensions)
        {
            Centers = new double[dimensions];
            Peak = 1.0;
            Width = 1.0;
        }


        public MultiquadricFunction(double peak, double[] center,
                                    double width)
        {
            Centers = center;
            Peak = peak;
            Width = width;
        }



        public MultiquadricFunction(double center, double peak,
                                    double width)
        {
            Centers = new double[1];
            Centers[0] = center;
            Peak = peak;
            Width = width;
        }



        public override double Calculate(double[] x)
        {
            double value = 0;
            double[] center = Centers;
            double width = Width;

            for (int i = 0; i < center.Length; i++)
            {
                value += Math.Pow(x[i] - center[i], 2)
                         + (width * width);
            }
            return Peak * BoundMath.Sqrt(value);
        }
    }

    public static class BoundMath
    {

        public static double Cos(double a)
        {
            return BoundNumbers.Bound(Math.Cos(a));
        }


        public static double Exp(double a)
        {
            return BoundNumbers.Bound(Math.Exp(a));
        }

        public static double Log(double a)
        {
            return BoundNumbers.Bound(Math.Log(a));
        }


        public static double Pow(double a, double b)
        {
            return BoundNumbers.Bound(Math.Pow(a, b));
        }


        public static double Sin(double a)
        {
            return BoundNumbers.Bound(Math.Sin(a));
        }

        public static double Sqrt(double a)
        {
            return Math.Sqrt(a);
        }
    }

    public static class BoundNumbers
    {

        public const double TooSmall = -1.0E20;

        public const double TooBig = 1.0E20;


        public static double Bound(double d)
        {
            if (d < TooSmall)
            {
                return TooSmall;
            }
            return d > TooBig ? TooBig : d;
        }
    }

    public class ComplexNumber
    {

        private readonly double _x;

        private readonly double _y;


        public ComplexNumber(double u, double v)
        {
            _x = u;
            _y = v;
        }


        public ComplexNumber(ComplexNumber other)
        {
            _x = other.Real;
            _y = other.Imaginary;
        }


        public double Real
        {
            get { return _x; }
        }


        public double Imaginary
        {
            get { return _y; }
        }


        public double Mod()
        {
            if (_x != 0 || _y != 0)
            {
                return Math.Sqrt(_x * _x + _y * _y);
            }

            return 0d;
        }


        public double Arg()
        {
            return Math.Atan2(_y, _x);
        }


        public ComplexNumber Conj()
        {
            return new ComplexNumber(_x, -_y);
        }


        public static ComplexNumber operator +(ComplexNumber c1, ComplexNumber c2)
        {
            return new ComplexNumber(c1.Real + c2.Real, c1.Imaginary + c2.Imaginary);
        }



        public static ComplexNumber operator -(ComplexNumber c1, ComplexNumber c2)
        {
            return new ComplexNumber(c1.Real - c2.Real, c1.Imaginary - c2.Imaginary);
        }


        public static ComplexNumber operator *(ComplexNumber c1, ComplexNumber c2)
        {
            return new ComplexNumber(c1.Real * c2.Real - c1.Imaginary * c2.Imaginary, c1.Real * c2.Imaginary + c1.Imaginary
                                                                                  * c2.Real);
        }

        public static ComplexNumber operator /(ComplexNumber c1, ComplexNumber c2)
        {
            double den = Math.Pow(c2.Mod(), 2);
            return new ComplexNumber((c1.Real * c2.Real + c1.Imaginary
                                      * c2.Imaginary) / den, (c1.Imaginary
                                                           * c2.Real - c1.Real * c2.Imaginary) / den);
        }


        public ComplexNumber Exp()
        {
            return new ComplexNumber(Math.Exp(_x) * Math.Cos(_y), Math.Exp(_x)
                                                              * Math.Sin(_y));
        }


        public ComplexNumber Log()
        {
            return new ComplexNumber(Math.Log(Mod()), Arg());
        }



        public ComplexNumber Sqrt()
        {
            double r = Math.Sqrt(Mod());
            double theta = Arg() / 2;
            return new ComplexNumber(r * Math.Cos(theta), r * Math.Sin(theta));
        }



        private static double Cosh(double theta)
        {
            return (Math.Exp(theta) + Math.Exp(-theta)) / 2;
        }


        private static double Sinh(double theta)
        {
            return (Math.Exp(theta) - Math.Exp(-theta)) / 2;
        }


        public ComplexNumber Sin()
        {
            return new ComplexNumber(Cosh(_y) * Math.Sin(_x), Sinh(_y) * Math.Cos(_x));
        }

        public ComplexNumber Cos()
        {
            return new ComplexNumber(Cosh(_y) * Math.Cos(_x), -Sinh(_y) * Math.Sin(_x));
        }



        public ComplexNumber Sinh()
        {
            return new ComplexNumber(Sinh(_x) * Math.Cos(_y), Cosh(_x) * Math.Sin(_y));
        }


        public ComplexNumber Cosh()
        {
            return new ComplexNumber(Cosh(_x) * Math.Cos(_y), Sinh(_x) * Math.Sin(_y));
        }


        public ComplexNumber Tan()
        {
            return (Sin()) / (Cos());
        }


        public static ComplexNumber operator -(ComplexNumber op)
        {
            return new ComplexNumber(-op.Real, -op.Imaginary);
        }

        /// <inheritdoc/>
        public new String ToString()
        {
            if (_x != 0 && _y > 0)
            {
                return _x + " + " + _y + "i";
            }
            if (_x != 0 && _y < 0)
            {
                return _x + " - " + (-_y) + "i";
            }
            if (_y == 0)
            {
                return Format.FormatDouble(_x, 4);
            }
            if (_x == 0)
            {
                return _y + "i";
            }
            // shouldn't get here (unless Inf or NaN)
            return _x + " + i*" + _y;
        }
    }

    public static class Convert
    {

        public static double String2Double(String str)
        {
            double result = 0;
            try
            {
                if (str != null)
                {
                    result = double.Parse(str);
                }
            }
            catch (Exception)
            {
                result = 0;
            }
            return result;
        }


        public static int String2Int(String str)
        {
            int result = 0;
            try
            {
                if (str != null)
                {
                    result = int.Parse(str);
                }
            }
            catch (Exception)
            {
                result = 0;
            }
            return result;
        }
    }

    public class SyntMath
    {

        public static double Hypot(double a, double b)
        {
            double r;
            if (Math.Abs(a) > Math.Abs(b))
            {
                r = b / a;
                r = Math.Abs(a) * Math.Sqrt(1 + r * r);
            }
            else if (b != 0)
            {
                r = a / b;
                r = Math.Abs(b) * Math.Sqrt(1 + r * r);
            }
            else
            {
                r = 0.0;
            }
            return r;
        }



        public static double Deg2Rad(double deg)
        {
            return deg * (Math.PI / 180.0);
        }



        public static double Rad2Deg(double rad)
        {
            return rad * (180.0 / Math.PI);
        }


        public static double Factorial(int p)
        {
            double result = 1.0;

            for (int i = 1; i <= p; i++)
            {
                result *= (double)i;
            }

            return result;
        }
    }

    [Serializable]
    public class Equilateral
    {

        public const int MinEq = 3;


        private readonly double[][] _matrix;


        public Equilateral(int count, double high, double low)
        {
            _matrix = Equilat(count, high, low);
        }


        public int Decode(double[] activations)
        {
            double minValue = double.PositiveInfinity;
            int minSet = -1;

            for (int i = 0; i < _matrix.GetLength(0); i++)
            {
                double dist = GetDistance(activations, i);
                if (dist < minValue)
                {
                    minValue = dist;
                    minSet = i;
                }
            }
            return minSet;
        }


        public double[] Syntesis(int set)
        {
            if (set < 0 || set > _matrix.Length)
            {

            }
            return _matrix[set];
        }


        private static double[][] Equilat(int n,
                                   double high, double low)
        {
            var result = new double[n][]; // n - 1
            for (int i = 0; i < n; i++)
            {
                result[i] = new double[n - 1];
            }

            result[0][0] = -1;
            result[1][0] = 1.0;

            for (int k = 2; k < n; k++)
            {
                // scale the matrix so far
                double r = k;
                double f = Math.Sqrt(r * r - 1.0) / r;
                for (int i = 0; i < k; i++)
                {
                    for (int j = 0; j < k - 1; j++)
                    {
                        result[i][j] *= f;
                    }
                }

                r = -1.0 / r;
                for (int i = 0; i < k; i++)
                {
                    result[i][k - 1] = r;
                }

                for (int i = 0; i < k - 1; i++)
                {
                    result[k][i] = 0.0;
                }
                result[k][k - 1] = 1.0;
            }

            // scale it
            for (int row = 0; row < result.GetLength(0); row++)
            {
                for (int col = 0; col < result[0].GetLength(0); col++)
                {
                    const double min = -1;
                    const double max = 1;
                    result[row][col] = ((result[row][col] - min) / (max - min))
                                       * (high - low) + low;
                }
            }

            return result;
        }


        public double GetDistance(double[] data, int set)
        {
            double result = 0;
            for (int i = 0; i < data.GetLength(0); i++)
            {
                result += Math.Pow(data[i] - _matrix[set][i], 2);
            }
            return Math.Sqrt(result);
        }


        public int GetSmallestDistance(double[] data)
        {
            int bestSet = -1;
            double bestDistance = double.MaxValue;

            for (int i = 0; i < _matrix.Length; i++)
            {
                double d = GetDistance(data, i);
                if (bestSet == -1 || d < bestDistance)
                {
                    bestSet = i;
                    bestDistance = d;
                }
            }

            return bestSet;
        }
    }

    public class IntRange
    {

        public IntRange(int high, int low)
        {
            High = high;
            Low = low;
        }

        public int High { get; set; }


        public int Low { get; set; }
    }

    public class TrainBasicPNN : BasicTraining, ICalculationCriteria
    {
        /// <summary>
        /// The default max error.
        /// </summary>
        ///
        public const double DefaultMaxError = 0.0d;

        /// <summary>
        /// The default minimum improvement before stop.
        /// </summary>
        ///
        public const double DefaultMinImprovement = 0.0001d;

        /// <summary>
        /// THe default sigma low value.
        /// </summary>
        ///
        public const double DefaultSigmaLow = 0.0001d;

        /// <summary>
        /// The default sigma high value.
        /// </summary>
        ///
        public const double DefaultSigmaHigh = 10.0d;

        /// <summary>
        /// The default number of sigmas to evaluate between the low and high.
        /// </summary>
        ///
        public const int DefaultNumSigmas = 10;

        /// <summary>
        /// The network to train.
        /// </summary>
        ///
        private readonly BasicPNN _network;

        /// <summary>
        /// The training data.
        /// </summary>
        ///
        private readonly IMLDataSet _training;

        /// <summary>
        /// Temp storage for derivative computation.
        /// </summary>
        ///
        private double[] _dsqr;

        /// <summary>
        /// The maximum error to allow.
        /// </summary>
        ///
        private double _maxError;

        /// <summary>
        /// The minimum improvement allowed.
        /// </summary>
        ///
        private double _minImprovement;

        /// <summary>
        /// The number of sigmas to evaluate between the low and high.
        /// </summary>
        ///
        private int _numSigmas;

        /// <summary>
        /// Have the samples been loaded.
        /// </summary>
        ///
        private bool _samplesLoaded;

        /// <summary>
        /// The high value for the sigma search.
        /// </summary>
        ///
        private double _sigmaHigh;

        /// <summary>
        /// The low value for the sigma search.
        /// </summary>
        ///
        private double _sigmaLow;

        /// <summary>
        /// Temp storage for derivative computation.
        /// </summary>
        ///
        private double[] _v;

        /// <summary>
        /// Temp storage for derivative computation.
        /// </summary>
        ///
        private double[] _w;

        /// <summary>
        /// Train a BasicPNN.
        /// </summary>
        ///
        /// <param name="network">The network to train.</param>
        /// <param name="training">The training data.</param>
        public TrainBasicPNN(BasicPNN network, IMLDataSet training) : base(TrainingImplementationType.OnePass)
        {
            _network = network;
            _training = training;

            _maxError = DefaultMaxError;
            _minImprovement = DefaultMinImprovement;
            _sigmaLow = DefaultSigmaLow;
            _sigmaHigh = DefaultSigmaHigh;
            _numSigmas = DefaultNumSigmas;
            _samplesLoaded = false;
        }

        /// <inheritdoc/>
        public override sealed bool CanContinue
        {
            get { return false; }
        }


        /// <value>the maxError to set</value>
        public double MaxError
        {
            get { return _maxError; }
            set { _maxError = value; }
        }


        /// <inheritdoc/>
        public override IMLMethod Method
        {
            get { return _network; }
        }


        /// <value>the minImprovement to set</value>
        public double MinImprovement
        {
            get { return _minImprovement; }
            set { _minImprovement = value; }
        }


        /// <value>the numSigmas to set</value>
        public int NumSigmas
        {
            get { return _numSigmas; }
            set { _numSigmas = value; }
        }


        /// <value>the sigmaHigh to set</value>
        public double SigmaHigh
        {
            get { return _sigmaHigh; }
            set { _sigmaHigh = value; }
        }


        /// <value>the sigmaLow to set</value>
        public double SigmaLow
        {
            get { return _sigmaLow; }
            set { _sigmaLow = value; }
        }

        #region CalculationCriteria Members

        /// <summary>
        /// Calculate the error with multiple sigmas.
        /// </summary>
        ///
        /// <param name="x">The data.</param>
        /// <param name="der1">The first derivative.</param>
        /// <param name="der2">The 2nd derivatives.</param>
        /// <param name="der">Calculate the derivative.</param>
        /// <returns>The error.</returns>
        public double CalcErrorWithMultipleSigma(double[] x, double[] der1, double[] der2, bool der)
        {
            int ivar;

            for (ivar = 0; ivar < _network.InputCount; ivar++)
            {
                _network.Sigma[ivar] = x[ivar];
            }

            if (!der)
            {
                return CalculateError(_network.Samples, false);
            }

            double err = CalculateError(_network.Samples, true);

            for (ivar = 0; ivar < _network.InputCount; ivar++)
            {
                der1[ivar] = _network.Deriv[ivar];
                der2[ivar] = _network.Deriv2[ivar];
            }

            return err;
        }

        /// <summary>
        /// Calculate the error using a common sigma.
        /// </summary>
        ///
        /// <param name="sig">The sigma to use.</param>
        /// <returns>The training error.</returns>
        public double CalcErrorWithSingleSigma(double sig)
        {
            int ivar;

            for (ivar = 0; ivar < _network.InputCount; ivar++)
            {
                _network.Sigma[ivar] = sig;
            }

            return CalculateError(_network.Samples, false);
        }

        #endregion

        /// <summary>
        /// Calculate the error for the entire training set.
        /// </summary>
        ///
        /// <param name="training">Training set to use.</param>
        /// <param name="deriv">Should we find the derivative.</param>
        /// <returns>The error.</returns>
        public double CalculateError(IMLDataSet training,
                                     bool deriv)
        {
            double totErr;
            double diff;
            totErr = 0.0d;

            if (deriv)
            {
                int num = (_network.SeparateClass)
                              ? _network.InputCount * _network.OutputCount
                              : _network.InputCount;
                for (int i = 0; i < num; i++)
                {
                    _network.Deriv[i] = 0.0d;
                    _network.Deriv2[i] = 0.0d;
                }
            }

            _network.Exclude = (int)training.Count;

            IMLDataPair pair = BasicMLDataPair.CreatePair(
                training.InputSize, training.IdealSize);

            var xout = new double[_network.OutputCount];

            for (int r = 0; r < training.Count; r++)
            {
                training.GetRecord(r, pair);
                _network.Exclude = _network.Exclude - 1;

                double err = 0.0d;

                IMLData input = pair.Input;
                IMLData target = pair.Ideal;

                if (_network.OutputMode == PNNOutputMode.Unsupervised)
                {
                    if (deriv)
                    {
                        IMLData output = ComputeDeriv(input, target);
                        for (int z = 0; z < _network.OutputCount; z++)
                        {
                            xout[z] = output[z];
                        }
                    }
                    else
                    {
                        IMLData output = _network.Compute(input);
                        for (int z = 0; z < _network.OutputCount; z++)
                        {
                            xout[z] = output[z];
                        }
                    }
                    for (int i = 0; i < _network.OutputCount; i++)
                    {
                        diff = input[i] - xout[i];
                        err += diff * diff;
                    }
                }
                else if (_network.OutputMode == PNNOutputMode.Classification)
                {
                    var tclass = (int)target[0];
                    IMLData output;

                    if (deriv)
                    {
                        output = ComputeDeriv(input, pair.Ideal);
                    }
                    else
                    {
                        output = _network.Compute(input);
                    }

                    EngineArray.ArrayCopy(output.Data, xout);

                    for (int i = 0; i < xout.Length; i++)
                    {
                        if (i == tclass)
                        {
                            diff = 1.0d - xout[i];
                            err += diff * diff;
                        }
                        else
                        {
                            err += xout[i] * xout[i];
                        }
                    }
                }

                else if (_network.OutputMode == PNNOutputMode.Regression)
                {
                    if (deriv)
                    {
                        IMLData output = _network.Compute(input);
                        for (int z = 0; z < _network.OutputCount; z++)
                        {
                            xout[z] = output[z];
                        }
                    }
                    else
                    {
                        IMLData output = _network.Compute(input);
                        for (int z = 0; z < _network.OutputCount; z++)
                        {
                            xout[z] = output[z];
                        }
                    }
                    for (int i = 0; i < _network.OutputCount; i++)
                    {
                        diff = target[i] - xout[i];
                        err += diff * diff;
                    }
                }

                totErr += err;
            }

            _network.Exclude = -1;

            _network.Error = totErr / training.Count;
            if (deriv)
            {
                for (int i = 0; i < _network.Deriv.Length; i++)
                {
                    _network.Deriv[i] /= training.Count;
                    _network.Deriv2[i] /= training.Count;
                }
            }

            if ((_network.OutputMode == PNNOutputMode.Unsupervised)
                || (_network.OutputMode == PNNOutputMode.Regression))
            {
                _network.Error = _network.Error
                                / _network.OutputCount;
                if (deriv)
                {
                    for (int i = 0; i < _network.InputCount; i++)
                    {
                        _network.Deriv[i] /= _network.OutputCount;
                        _network.Deriv2[i] /= _network.OutputCount;
                    }
                }
            }

            return _network.Error;
        }

        /// <summary>
        /// Compute the derivative for target data.
        /// </summary>
        ///
        /// <param name="input">The input.</param>
        /// <param name="target">The target data.</param>
        /// <returns>The output.</returns>
        public IMLData ComputeDeriv(IMLData input, IMLData target)
        {
            int pop, ivar;
            int ibest = 0;
            int outvar;
            double dist, truedist;
            double vtot, wtot;
            double temp, der1, der2, psum;
            int vptr, wptr, vsptr = 0, wsptr = 0;

            var xout = new double[_network.OutputCount];

            for (pop = 0; pop < _network.OutputCount; pop++)
            {
                xout[pop] = 0.0d;
                for (ivar = 0; ivar < _network.InputCount; ivar++)
                {
                    _v[pop * _network.InputCount + ivar] = 0.0d;
                    _w[pop * _network.InputCount + ivar] = 0.0d;
                }
            }

            psum = 0.0d;

            if (_network.OutputMode != PNNOutputMode.Classification)
            {
                vsptr = _network.OutputCount
                        * _network.InputCount;
                wsptr = _network.OutputCount
                        * _network.InputCount;
                for (ivar = 0; ivar < _network.InputCount; ivar++)
                {
                    _v[vsptr + ivar] = 0.0d;
                    _w[wsptr + ivar] = 0.0d;
                }
            }

            IMLDataPair pair = BasicMLDataPair.CreatePair(_network.Samples.InputSize, _network.Samples.IdealSize);

            for (int r = 0; r < _network.Samples.Count; r++)
            {
                _network.Samples.GetRecord(r, pair);

                if (r == _network.Exclude)
                {
                    continue;
                }

                dist = 0.0d;
                for (ivar = 0; ivar < _network.InputCount; ivar++)
                {
                    double diff = input[ivar] - pair.Input[ivar];
                    diff /= _network.Sigma[ivar];
                    _dsqr[ivar] = diff * diff;
                    dist += _dsqr[ivar];
                }

                if (_network.Kernel == PNNKernelType.Gaussian)
                {
                    dist = Math.Exp(-dist);
                }
                else if (_network.Kernel == PNNKernelType.Reciprocal)
                {
                    dist = 1.0d / (1.0d + dist);
                }

                truedist = dist;
                if (dist < 1.0e-40d)
                {
                    dist = 1.0e-40d;
                }

                if (_network.OutputMode == PNNOutputMode.Classification)
                {
                    pop = (int)pair.Ideal[0];
                    xout[pop] += dist;
                    vptr = pop * _network.InputCount;
                    wptr = pop * _network.InputCount;
                    for (ivar = 0; ivar < _network.InputCount; ivar++)
                    {
                        temp = truedist * _dsqr[ivar];
                        _v[vptr + ivar] += temp;
                        _w[wptr + ivar] += temp * (2.0d * _dsqr[ivar] - 3.0d);
                    }
                }

                else if (_network.OutputMode == PNNOutputMode.Unsupervised)
                {
                    for (ivar = 0; ivar < _network.InputCount; ivar++)
                    {
                        xout[ivar] += dist * pair.Input[ivar];
                        temp = truedist * _dsqr[ivar];
                        _v[vsptr + ivar] += temp;
                        _w[wsptr + ivar] += temp
                                           * (2.0d * _dsqr[ivar] - 3.0d);
                    }
                    vptr = 0;
                    wptr = 0;
                    for (outvar = 0; outvar < _network.OutputCount; outvar++)
                    {
                        for (ivar = 0; ivar < _network.InputCount; ivar++)
                        {
                            temp = truedist * _dsqr[ivar]
                                   * pair.Input[ivar];
                            _v[vptr++] += temp;
                            _w[wptr++] += temp * (2.0d * _dsqr[ivar] - 3.0d);
                        }
                    }
                    psum += dist;
                }
                else if (_network.OutputMode == PNNOutputMode.Regression)
                {
                    for (ivar = 0; ivar < _network.OutputCount; ivar++)
                    {
                        xout[ivar] += dist * pair.Ideal[ivar];
                    }
                    vptr = 0;
                    wptr = 0;
                    for (outvar = 0; outvar < _network.OutputCount; outvar++)
                    {
                        for (ivar = 0; ivar < _network.InputCount; ivar++)
                        {
                            temp = truedist * _dsqr[ivar]
                                   * pair.Ideal[outvar];
                            _v[vptr++] += temp;
                            _w[wptr++] += temp * (2.0d * _dsqr[ivar] - 3.0d);
                        }
                    }
                    for (ivar = 0; ivar < _network.InputCount; ivar++)
                    {
                        temp = truedist * _dsqr[ivar];
                        _v[vsptr + ivar] += temp;
                        _w[wsptr + ivar] += temp
                                           * (2.0d * _dsqr[ivar] - 3.0d);
                    }
                    psum += dist;
                }
            }

            if (_network.OutputMode == PNNOutputMode.Classification)
            {
                psum = 0.0d;
                for (pop = 0; pop < _network.OutputCount; pop++)
                {
                    if (_network.Priors[pop] >= 0.0d)
                    {
                        xout[pop] *= _network.Priors[pop]
                                     / _network.CountPer[pop];
                    }
                    psum += xout[pop];
                }

                if (psum < 1.0e-40d)
                {
                    psum = 1.0e-40d;
                }
            }

            for (pop = 0; pop < _network.OutputCount; pop++)
            {
                xout[pop] /= psum;
            }

            for (ivar = 0; ivar < _network.InputCount; ivar++)
            {
                if (_network.OutputMode == PNNOutputMode.Classification)
                {
                    vtot = wtot = 0.0d;
                }
                else
                {
                    vtot = _v[vsptr + ivar] * 2.0d
                           / (psum * _network.Sigma[ivar]);
                    wtot = _w[wsptr + ivar]
                           * 2.0d
                           / (psum * _network.Sigma[ivar] * _network.Sigma[ivar]);
                }

                for (outvar = 0; outvar < _network.OutputCount; outvar++)
                {
                    if ((_network.OutputMode == PNNOutputMode.Classification)
                        && (_network.Priors[outvar] >= 0.0d))
                    {
                        _v[outvar * _network.InputCount + ivar] *= _network.Priors[outvar]
                                                               / _network.CountPer[outvar];
                        _w[outvar * _network.InputCount + ivar] *= _network.Priors[outvar]
                                                               / _network.CountPer[outvar];
                    }
                    _v[outvar * _network.InputCount + ivar] *= 2.0d / (psum * _network.Sigma[ivar]);

                    _w[outvar * _network.InputCount + ivar] *= 2.0d / (psum
                                                                 * _network.Sigma[ivar] * _network.Sigma[ivar]);
                    if (_network.OutputMode == PNNOutputMode.Classification)
                    {
                        vtot += _v[outvar * _network.InputCount + ivar];
                        wtot += _w[outvar * _network.InputCount + ivar];
                    }
                }

                for (outvar = 0; outvar < _network.OutputCount; outvar++)
                {
                    der1 = _v[outvar * _network.InputCount + ivar]
                           - xout[outvar] * vtot;
                    der2 = _w[outvar * _network.InputCount + ivar]
                           + 2.0d * xout[outvar] * vtot * vtot - 2.0d
                                                           * _v[outvar * _network.InputCount + ivar]
                                                           * vtot - xout[outvar] * wtot;
                    if (_network.OutputMode == PNNOutputMode.Classification)
                    {
                        if (outvar == (int)target[0])
                        {
                            temp = 2.0d * (xout[outvar] - 1.0d);
                        }
                        else
                        {
                            temp = 2.0d * xout[outvar];
                        }
                    }
                    else
                    {
                        temp = 2.0d * (xout[outvar] - target[outvar]);
                    }
                    _network.Deriv[ivar] += temp * der1;
                    _network.Deriv2[ivar] += temp * der2 + 2.0d * der1
                                            * der1;
                }
            }

            return new BasicMLData(xout);
        }


        /// <summary>
        /// 
        /// </summary>
        ///
        public override sealed void Iteration()
        {
            if (!_samplesLoaded)
            {
                _network.Samples = new BasicMLDataSet(_training);
                _samplesLoaded = true;
            }

            var globalMinimum = new GlobalMinimumSearch();
            var dermin = new DeriveMinimum();

            int k;

            if (_network.OutputMode == PNNOutputMode.Classification)
            {
                k = _network.OutputCount;
            }
            else
            {
                k = _network.OutputCount + 1;
            }

            _dsqr = new double[_network.InputCount];
            _v = new double[_network.InputCount * k];
            _w = new double[_network.InputCount * k];

            var x = new double[_network.InputCount];
            var bs = new double[_network.InputCount];
            var direc = new double[_network.InputCount];
            var g = new double[_network.InputCount];
            var h = new double[_network.InputCount];
            var dwk2 = new double[_network.InputCount];

            if (_network.Trained)
            {
                for (int i = 0; i < _network.InputCount; i++)
                {
                    x[i] = _network.Sigma[i];
                }
                globalMinimum.Y2 = 1.0e30d;
            }
            else
            {
                globalMinimum.FindBestRange(_sigmaLow, _sigmaHigh,
                                            _numSigmas, true, _maxError, this);

                for (int i = 0; i < _network.InputCount; i++)
                {
                    x[i] = globalMinimum.X2;
                }
            }

            double d = dermin.Calculate(32767, _maxError, 1.0e-8d,
                                        _minImprovement, this, _network.InputCount, x,
                                        globalMinimum.Y2, bs, direc, g, h, dwk2);
            globalMinimum.Y2 = d;

            for (int i = 0; i < _network.InputCount; i++)
            {
                _network.Sigma[i] = x[i];
            }

            _network.Error = Math.Abs(globalMinimum.Y2);
            _network.Trained = true; // Tell other routines net is trained

            return;
        }

        /// <summary>
        /// 
        /// </summary>
        ///
        public override sealed TrainingContinuation Pause()
        {
            return null;
        }

        /// <summary>
        /// 
        /// </summary>
        ///
        public override void Resume(TrainingContinuation state)
        {
        }
    }

    public class LinearCongruentialGenerator
    {

        public const long MaxRand = 4294967295L;


        public LinearCongruentialGenerator(long seed)
            : this((long)Math.Pow(2L, 32L), 1103515245L, 12345L, seed)
        {
        }


        public LinearCongruentialGenerator(long modulus,
                                           long multiplier, long increment, long seed)
        {
            Modulus = modulus;
            Multiplier = multiplier;
            Increment = increment;
            Seed = seed;
        }


        public long Modulus { get; set; }


        public long Multiplier { get; set; }


        public long Increment { get; set; }

        public long Seed { get; set; }



        public double NextDouble()
        {
            return (double)NextLong() / MaxRand;
        }


        public long NextLong()
        {
            Seed = (Multiplier * Seed + Increment)
                   % Modulus;
            return Seed;
        }

        public double Range(double min, double max)
        {
            double range = max - min;
            return (range * NextDouble()) + min;
        }
    }

    public static class MathConst
    {

        public const double EulersNumber = 2.718281828;
    }

    public class NumericRange
    {

        private readonly double _high;


        private readonly double _low;


        private readonly double _mean;


        private readonly double _rms;

        int _samples;


        private readonly double _standardDeviation;


        public NumericRange(IList<Double> values)
        {
            double assignedHigh = 0;
            double assignedLow = 0;
            double total = 0;
            double rmsTotal = 0;

            // get the mean and other 1-pass values.

            foreach (double d in values)
            {
                assignedHigh = Math.Max(assignedHigh, d);
                assignedLow = Math.Min(assignedLow, d);
                total += d;
                rmsTotal += d * d;
            }

            _samples = values.Count;
            _high = assignedHigh;
            _low = assignedLow;
            _mean = total / _samples;
            _rms = Math.Sqrt(rmsTotal / _samples);

            // now get the standard deviation
            double devTotal = values.Sum(d => Math.Pow(d - _mean, 2));

            _standardDeviation = Math.Sqrt(devTotal / _samples);
        }


        public double High
        {
            get { return _high; }
        }


        public double Low
        {
            get { return _low; }
        }


        public double Mean
        {
            get { return _mean; }
        }

        public double RMS
        {
            get { return _rms; }
        }

        public double StandardDeviation
        {
            get { return _standardDeviation; }
        }


        public int Samples
        {
            get { return _samples; }
        }


        public override String ToString()
        {
            var result = new StringBuilder();
            result.Append("Range: ");
            result.Append(Format.FormatDouble(_low, 5));
            result.Append(" to ");
            result.Append(Format.FormatDouble(_high, 5));
            result.Append(",samples: ");
            result.Append(Format.FormatInteger(_samples));
            result.Append(",mean: ");
            result.Append(Format.FormatDouble(_mean, 5));
            result.Append(",rms: ");
            result.Append(Format.FormatDouble(_rms, 5));
            result.Append(",s.deviation: ");
            result.Append(Format.FormatDouble(_standardDeviation, 5));

            return result.ToString();
        }
    }

    public class VectorAlgebra
    {
        static Random rand = new Random();


        public void Add(double[] v1, double[] v2)
        {
            for (int i = 0; i < v1.Length; i++)
            {
                v1[i] += v2[i];
            }
        }


        public void Sub(double[] v1, double[] v2)
        {
            for (int i = 0; i < v1.Length; i++)
            {
                v1[i] -= v2[i];
            }
        }


        public void Neg(double[] v)
        {
            for (int i = 0; i < v.Length; i++)
            {
                v[i] = -v[i];
            }
        }


        public void MulRand(double[] v, double k)
        {
            for (int i = 0; i < v.Length; i++)
            {
                v[i] *= k * rand.NextDouble();
            }
        }


        public void Mul(double[] v, double k)
        {
            for (int i = 0; i < v.Length; i++)
            {
                v[i] *= k;
            }
        }

        public void Copy(double[] dst, double[] src)
        {
            EngineArray.ArrayCopy(src, dst);
        }

        public void Randomise(double[] v)
        {
            Randomise(v, 0.1);
        }


        public void Randomise(double[] v, double maxValue)
        {
            for (int i = 0; i < v.Length; i++)
            {
                v[i] = (2 * rand.NextDouble() - 1) * maxValue;
            }
        }


        public void ClampComponents(double[] v, double maxValue)
        {
            if (maxValue != -1)
            {
                for (int i = 0; i < v.Length; i++)
                {
                    if (v[i] > maxValue) v[i] = maxValue;
                    if (v[i] < -maxValue) v[i] = -maxValue;
                }
            }
        }

    }

    public class ConsistentRandomizer : BasicRandomizer
    {

        private readonly double _max;


        private readonly double _min;

        private readonly LinearCongruentialGenerator _rand;


        private readonly int _seed;


        public ConsistentRandomizer(double min, double max) : this(min, max, 1000)
        {
        }


        public ConsistentRandomizer(double min, double max,
                                    int seed)
        {
            _max = max;
            _min = min;
            _seed = seed;
            _rand = new LinearCongruentialGenerator(seed);
        }


        public override double Randomize(double d)
        {
            return _rand.Range(_min, _max);
        }


        public void Randomize(BasicNetwork network)
        {
            _rand.Seed = _seed;
            base.Randomize(network);
        }
    }

    public class ConstRandomizer : BasicRandomizer
    {

        private readonly double value;


        public ConstRandomizer(double v)
        {
            this.value = v;
        }

        public override double Randomize(double d)
        {
            return value;
        }
    }

    public class Distort : BasicRandomizer
    {

        private readonly double _factor;


        public Distort(double f)
        {
            _factor = f;
        }


        public override double Randomize(double d)
        {
            return d + (_factor - (NextDouble() * _factor * 2));
        }
    }

    public class FanInRandomizer : BasicRandomizer
    {
        internal const String Error = "To use FanInRandomizer you must "
                                      + "present a Matrix or 2D array type value.";


        private const double DefaultBoundary = 2.4d;


        private readonly double _lowerBound;


        private readonly bool _sqrt;


        private readonly double _upperBound;

        public FanInRandomizer() : this(-DefaultBoundary, DefaultBoundary, false)
        {
        }


        public FanInRandomizer(double boundary, bool sqrt) : this(-boundary, boundary, sqrt)
        {
        }


        public FanInRandomizer(double aLowerBound, double anUpperBound,
                               bool sqrt)
        {
            _lowerBound = aLowerBound;
            _upperBound = anUpperBound;
            _sqrt = sqrt;
        }


        private double CalculateValue(int rows)
        {
            double rowValue = _sqrt ? Math.Sqrt(rows) : rows;

            return (_lowerBound / rowValue) + NextDouble()
                   * ((_upperBound - _lowerBound) / rowValue);
        }

        /// <summary>
        /// Throw an error if this class is used improperly.
        /// </summary>
        ///
        private static void CauseError()
        {

        }


        public override double Randomize(double d)
        {
            CauseError();
            return 0;
        }


        public override void Randomize(double[] d)
        {
            for (int i = 0; i < d.Length; i++)
            {
                d[i] = CalculateValue(1);
            }
        }


        public override void Randomize(double[][] d)
        {
            foreach (double[] t in d)
            {
                for (var col = 0; col < d[0].Length; col++)
                {
                    t[col] = CalculateValue(d.Length);
                }
            }
        }


        public override void Randomize(Matrix m)
        {
            for (int row = 0; row < m.Rows; row++)
            {
                for (int col = 0; col < m.Cols; col++)
                {
                    m[row, col] = CalculateValue(m.Rows);
                }
            }
        }


        public override void Randomize(BasicNetwork network, int fromLayer)
        {
            int fromCount = network.GetLayerTotalNeuronCount(fromLayer);
            int toCount = network.GetLayerNeuronCount(fromLayer + 1);

            for (int fromNeuron = 0; fromNeuron < fromCount; fromNeuron++)
            {
                for (int toNeuron = 0; toNeuron < toCount; toNeuron++)
                {
                    double v = CalculateValue(toCount);
                    network.SetWeight(fromLayer, fromNeuron, toNeuron, v);
                }
            }
        }
    }

    [Serializable]
    public class GaussianRandomizer : BasicRandomizer
    {

        private readonly double _mean;


        private readonly double _standardDeviation;


        private bool _useLast;


        private double _y2;


        public GaussianRandomizer(double mean, double standardDeviation)
        {
            _useLast = false;
            _mean = mean;
            _standardDeviation = standardDeviation;
        }


        public double BoxMuller(double m, double s)
        {
            double y1;

            // use value from previous call
            if (_useLast)
            {
                y1 = _y2;
                _useLast = false;
            }
            else
            {
                double x1;
                double x2;
                double w;
                do
                {
                    x1 = 2.0d * NextDouble() - 1.0d;
                    x2 = 2.0d * NextDouble() - 1.0d;
                    w = x1 * x1 + x2 * x2;
                } while (w >= 1.0d);

                w = Math.Sqrt((-2.0d * Math.Log(w)) / w);
                y1 = x1 * w;
                _y2 = x2 * w;
                _useLast = true;
            }

            return (m + y1 * s);
        }


        public override double Randomize(double d)
        {
            return BoxMuller(_mean, _standardDeviation);
        }
    }

    public class NguyenWidrowRandomizer
    {

        public static String MSG = "This type of randomization is not supported by Nguyen-Widrow";


        public void Randomize(IMLMethod method)
        {
            if (!(method is BasicNetwork))
            {


                BasicNetwork network = (BasicNetwork)method;

                for (int fromLayer = 0; fromLayer < network.LayerCount - 1; fromLayer++)
                {
                    RandomizeSynapse(network, fromLayer);
                }

            }


            double CalculateRange(IActivationFunction af, double r)
            {
                double[] d = { r };
                af.ActivationFunction(d, 0, 1);
                return d[0];
            }

            void RandomizeSynapse(BasicNetwork network, int fromLayer)
            {
                int toLayer = fromLayer + 1;
                int toCount = network.GetLayerNeuronCount(toLayer);
                int fromCount = network.GetLayerNeuronCount(fromLayer);
                int fromCountTotalCount = network.GetLayerTotalNeuronCount(fromLayer);
                IActivationFunction af = network.GetActivation(toLayer);
                double low = CalculateRange(af, Double.NegativeInfinity);
                double high = CalculateRange(af, Double.PositiveInfinity);

                double b = 0.7d * Math.Pow(toCount, (1d / fromCount)) / (high - low);

                for (int toNeuron = 0; toNeuron < toCount; toNeuron++)
                {
                    if (fromCount != fromCountTotalCount)
                    {
                        double w = RangeRandomizer.Randomize(-b, b);
                        network.SetWeight(fromLayer, fromCount, toNeuron, w);
                    }
                    for (int fromNeuron = 0; fromNeuron < fromCount; fromNeuron++)
                    {
                        double w = RangeRandomizer.Randomize(0, b);
                        network.SetWeight(fromLayer, fromNeuron, toNeuron, w);
                    }
                }
            }


        }
    }

    public class RangeRandomizer : BasicRandomizer
    {

        private readonly double _max;



        private readonly double _min;


        public RangeRandomizer(double min, double max)
        {
            _max = max;
            _min = min;
        }


        /// <value>the min</value>
        public double Min
        {
            get { return _min; }
        }


        /// <value>the max</value>
        public double Max
        {
            get { return _max; }
        }


        public static int RandomInt(int min, int max)
        {
            return (int)Randomize(min, max + 1);
        }


        public static double Randomize(double min, double max)
        {
            double range = max - min;
            return (range * ThreadSafeRandom.NextDouble()) + min;
        }


        public override double Randomize(double d)
        {
            return NextDouble(_min, _max);
        }
    }

    public class CholeskyDecomposition
    {

        private readonly bool isspd;


        private readonly double[][] l;


        private readonly int n;


        public CholeskyDecomposition(Matrix matrix)
        {
            // Initialize.
            double[][] a = matrix.Data;
            n = matrix.Rows;
            l = EngineArray.AllocateDouble2D(n, n);
            isspd = (matrix.Cols == n);
            // Main loop.
            for (int j = 0; j < n; j++)
            {
                double[] lrowj = l[j];
                double d = 0.0;
                for (int k = 0; k < j; k++)
                {
                    double[] lrowk = l[k];
                    double s = 0.0;
                    for (int i = 0; i < k; i++)
                    {
                        s += lrowk[i] * lrowj[i];
                    }
                    s = (a[j][k] - s) / l[k][k];
                    lrowj[k] = s;
                    d = d + s * s;
                    isspd = isspd & (a[k][j] == a[j][k]);
                }
                d = a[j][j] - d;
                isspd = isspd & (d > 0.0);
                l[j][j] = Math.Sqrt(Math.Max(d, 0.0));
                for (int k = j + 1; k < n; k++)
                {
                    l[j][k] = 0.0;
                }
            }
        }


        public bool IsSPD
        {
            get { return isspd; }
        }


        public Matrix L
        {
            get { return new Matrix(l); }
        }


        /// <returns>X so that L*L'*X = b.</returns>
        public Matrix Solve(Matrix b)
        {
            if (b.Rows != n)
            {
                throw new MatrixError(
                    "Matrix row dimensions must agree.");
            }
            if (!isspd)
            {
                throw new MatrixError(
                    "Matrix is not symmetric positive definite.");
            }

            // Copy right hand side.
            double[][] x = b.GetArrayCopy();
            int nx = b.Cols;

            // Solve L*Y = B;
            for (int k = 0; k < n; k++)
            {
                for (int j = 0; j < nx; j++)
                {
                    for (int i = 0; i < k; i++)
                    {
                        x[k][j] -= x[i][j] * l[k][i];
                    }
                    x[k][j] /= l[k][k];
                }
            }

            // Solve L'*X = Y;
            for (int k = n - 1; k >= 0; k--)
            {
                for (int j = 0; j < nx; j++)
                {
                    for (int i = k + 1; i < n; i++)
                    {
                        x[k][j] -= x[i][j] * l[i][k];
                    }
                    x[k][j] /= l[k][k];
                }
            }

            return new Matrix(x);
        }

        public Matrix InverseCholesky()
        {
            double[][] li = LowerTriangularInverse(l);
            double[][] ic = EngineArray.AllocateDouble2D(n, n);

            for (int r = 0; r < n; r++)
                for (int c = 0; c < n; c++)
                    for (int i = 0; i < n; i++)
                        ic[r][c] += li[i][r] * li[i][c];

            return new Matrix(ic);
        }


        private double[][] LowerTriangularInverse(double[][] m)
        {

            double[][] lti = EngineArray.AllocateDouble2D(m.Length, m.Length);

            for (int j = 0; j < m.Length; j++)
            {
                if (m[j][j] == 0)
                    throw new SyntError("Error, the matrix is not full rank");

                lti[j][j] = 1.0 / m[j][j];

                for (int i = j + 1; i < m.Length; i++)
                {
                    double sum = 0.0;

                    for (int k = j; k < i; k++)
                        sum -= m[i][k] * lti[k][j];

                    lti[i][j] = sum / m[i][i];
                }
            }

            return lti;

        }

        public double GetDeterminant()
        {
            double result = 1;

            for (int i = 0; i < n; i++)
                result *= l[i][i];

            return result * result;
        }
    }

    public class EigenvalueDecomposition
    {


        private readonly double[] d;


        private readonly double[] e;

        private readonly double[][] h;


        private readonly bool issymmetric;


        private readonly int n;

        private readonly double[] ort;

        private readonly double[][] v;


        private double cdivi;


        private double cdivr;


        public EigenvalueDecomposition(Matrix matrix)
        {
            double[][] a = matrix.Data;
            n = matrix.Cols;
            v = EngineArray.AllocateDouble2D(n, n);
            d = new double[n];
            e = new double[n];

            issymmetric = true;
            for (int j = 0; (j < n) & issymmetric; j++)
            {
                for (int i = 0; (i < n) & issymmetric; i++)
                {
                    issymmetric = (a[i][j] == a[j][i]);
                }
            }

            if (issymmetric)
            {
                for (int i = 0; i < n; i++)
                {
                    for (int j = 0; j < n; j++)
                    {
                        v[i][j] = a[i][j];
                    }
                }

                // Tridiagonalize.
                Tred2();

                // Diagonalize.
                Tql2();
            }
            else
            {
                h = EngineArray.AllocateDouble2D(n, n);
                ort = new double[n];

                for (int j = 0; j < n; j++)
                {
                    for (int i = 0; i < n; i++)
                    {
                        h[i][j] = a[i][j];
                    }
                }

                // Reduce to Hessenberg form.
                Orthes();

                // Reduce Hessenberg to real Schur form.
                Hqr2();
            }
        }


        /// <summary>
        /// Return the eigenvector matrix.
        /// </summary>
        public Matrix V
        {
            get { return new Matrix(v); }
        }

        /// <summary>
        /// Return the real parts of the eigenvalues.
        /// </summary>
        public double[] RealEigenvalues
        {
            get { return d; }
        }

        /// <summary>
        /// Return the block diagonal eigenvalue matrix
        /// </summary>
        public Matrix D
        {
            get
            {
                var result = new Matrix(n, n);
                double[][] resultMatrix = result.Data;
                for (int i = 0; i < n; i++)
                {
                    for (int j = 0; j < n; j++)
                    {
                        resultMatrix[i][j] = 0.0;
                    }
                    resultMatrix[i][i] = d[i];
                    if (e[i] > 0)
                    {
                        resultMatrix[i][i + 1] = e[i];
                    }
                    else if (e[i] < 0)
                    {
                        resultMatrix[i][i - 1] = e[i];
                    }
                }
                return result;
            }
        }

        /// <summary>
        /// Symmetric Householder reduction to tridiagonal form.
        /// </summary>
        private void Tred2()
        {


            for (int j = 0; j < n; j++)
            {
                d[j] = v[n - 1][j];
            }

            // Householder reduction to tridiagonal form.

            for (int i = n - 1; i > 0; i--)
            {
                // Scale to avoid under/overflow.

                double scale = 0.0;
                double h = 0.0;
                for (int k = 0; k < i; k++)
                {
                    scale = scale + Math.Abs(d[k]);
                }
                if (scale == 0.0)
                {
                    e[i] = d[i - 1];
                    for (int j = 0; j < i; j++)
                    {
                        d[j] = v[i - 1][j];
                        v[i][j] = 0.0;
                        v[j][i] = 0.0;
                    }
                }
                else
                {
                    // Generate Householder vector.

                    for (int k = 0; k < i; k++)
                    {
                        d[k] /= scale;
                        h += d[k] * d[k];
                    }
                    double f = d[i - 1];
                    double g = Math.Sqrt(h);
                    if (f > 0)
                    {
                        g = -g;
                    }
                    e[i] = scale * g;
                    h = h - f * g;
                    d[i - 1] = f - g;
                    for (int j = 0; j < i; j++)
                    {
                        e[j] = 0.0;
                    }

                    // Apply similarity transformation to remaining columns.

                    for (int j = 0; j < i; j++)
                    {
                        f = d[j];
                        v[j][i] = f;
                        g = e[j] + v[j][j] * f;
                        for (int k = j + 1; k <= i - 1; k++)
                        {
                            g += v[k][j] * d[k];
                            e[k] += v[k][j] * f;
                        }
                        e[j] = g;
                    }
                    f = 0.0;
                    for (int j = 0; j < i; j++)
                    {
                        e[j] /= h;
                        f += e[j] * d[j];
                    }
                    double hh = f / (h + h);
                    for (int j = 0; j < i; j++)
                    {
                        e[j] -= hh * d[j];
                    }
                    for (int j = 0; j < i; j++)
                    {
                        f = d[j];
                        g = e[j];
                        for (int k = j; k <= i - 1; k++)
                        {
                            v[k][j] -= (f * e[k] + g * d[k]);
                        }
                        d[j] = v[i - 1][j];
                        v[i][j] = 0.0;
                    }
                }
                d[i] = h;
            }

            // Accumulate transformations.

            for (int i = 0; i < n - 1; i++)
            {
                v[n - 1][i] = v[i][i];
                v[i][i] = 1.0;
                double h = d[i + 1];
                if (h != 0.0)
                {
                    for (int k = 0; k <= i; k++)
                    {
                        d[k] = v[k][i + 1] / h;
                    }
                    for (int j = 0; j <= i; j++)
                    {
                        double g = 0.0;
                        for (int k = 0; k <= i; k++)
                        {
                            g += v[k][i + 1] * v[k][j];
                        }
                        for (int k = 0; k <= i; k++)
                        {
                            v[k][j] -= g * d[k];
                        }
                    }
                }
                for (int k = 0; k <= i; k++)
                {
                    v[k][i + 1] = 0.0;
                }
            }
            for (int j = 0; j < n; j++)
            {
                d[j] = v[n - 1][j];
                v[n - 1][j] = 0.0;
            }
            v[n - 1][n - 1] = 1.0;
            e[0] = 0.0;
        }


        private void Tql2()
        {


            for (int i = 1; i < n; i++)
            {
                e[i - 1] = e[i];
            }
            e[n - 1] = 0.0;

            double f = 0.0;
            double tst1 = 0.0;
            double eps = Math.Pow(2.0, -52.0);
            for (int l = 0; l < n; l++)
            {
                // Find small subdiagonal element

                tst1 = Math.Max(tst1, Math.Abs(d[l]) + Math.Abs(e[l]));
                int m = l;
                while (m < n)
                {
                    if (Math.Abs(e[m]) <= eps * tst1)
                    {
                        break;
                    }
                    m++;
                }

                // If m == l, d[l] is an eigenvalue,
                // otherwise, iterate.

                if (m > l)
                {
                    int iter = 0;
                    do
                    {
                        iter = iter + 1; // (Could check iteration count here.)

                        // Compute implicit shift

                        double g = d[l];
                        double p = (d[l + 1] - g) / (2.0 * e[l]);
                        double r = SyntMath.Hypot(p, 1.0);
                        if (p < 0)
                        {
                            r = -r;
                        }
                        d[l] = e[l] / (p + r);
                        d[l + 1] = e[l] * (p + r);
                        double dl1 = d[l + 1];
                        double h = g - d[l];
                        for (int i = l + 2; i < n; i++)
                        {
                            d[i] -= h;
                        }
                        f = f + h;

                        // Implicit QL transformation.

                        p = d[m];
                        double c = 1.0;
                        double c2 = c;
                        double c3 = c;
                        double el1 = e[l + 1];
                        double s = 0.0;
                        double s2 = 0.0;
                        for (int i = m - 1; i >= l; i--)
                        {
                            c3 = c2;
                            c2 = c;
                            s2 = s;
                            g = c * e[i];
                            h = c * p;
                            r = SyntMath.Hypot(p, e[i]);
                            e[i + 1] = s * r;
                            s = e[i] / r;
                            c = p / r;
                            p = c * d[i] - s * g;
                            d[i + 1] = h + s * (c * g + s * d[i]);

                            // Accumulate transformation.

                            for (int k = 0; k < n; k++)
                            {
                                h = v[k][i + 1];
                                v[k][i + 1] = s * v[k][i] + c * h;
                                v[k][i] = c * v[k][i] - s * h;
                            }
                        }
                        p = -s * s2 * c3 * el1 * e[l] / dl1;
                        e[l] = s * p;
                        d[l] = c * p;

                        // Check for convergence.
                    } while (Math.Abs(e[l]) > eps * tst1);
                }
                d[l] = d[l] + f;
                e[l] = 0.0;
            }

            // Sort eigenvalues and corresponding vectors.

            for (int i = 0; i < n - 1; i++)
            {
                int k = i;
                double p = d[i];
                for (int j = i + 1; j < n; j++)
                {
                    if (d[j] < p)
                    {
                        k = j;
                        p = d[j];
                    }
                }
                if (k != i)
                {
                    d[k] = d[i];
                    d[i] = p;
                    for (int j = 0; j < n; j++)
                    {
                        p = v[j][i];
                        v[j][i] = v[j][k];
                        v[j][k] = p;
                    }
                }
            }
        }


        private void Orthes()
        {
            int low = 0;
            int high = n - 1;

            for (int m = low + 1; m <= high - 1; m++)
            {
                // Scale column.

                double scale = 0.0;
                for (int i = m; i <= high; i++)
                {
                    scale = scale + Math.Abs(h[i][m - 1]);
                }
                if (scale != 0.0)
                {
                    // Compute Householder transformation.

                    double lh = 0.0;
                    for (int i = high; i >= m; i--)
                    {
                        ort[i] = h[i][m - 1] / scale;
                        lh += ort[i] * ort[i];
                    }
                    double g = Math.Sqrt(lh);
                    if (ort[m] > 0)
                    {
                        g = -g;
                    }
                    lh = lh - ort[m] * g;
                    ort[m] = ort[m] - g;

                    // Apply Householder similarity transformation
                    // H = (I-u*u'/h)*H*(I-u*u')/h)

                    for (int j = m; j < n; j++)
                    {
                        double f = 0.0;
                        for (int i = high; i >= m; i--)
                        {
                            f += ort[i] * h[i][j];
                        }
                        f = f / lh;
                        for (int i = m; i <= high; i++)
                        {
                            h[i][j] -= f * ort[i];
                        }
                    }

                    for (int i = 0; i <= high; i++)
                    {
                        double f = 0.0;
                        for (int j = high; j >= m; j--)
                        {
                            f += ort[j] * h[i][j];
                        }
                        f = f / lh;
                        for (int j = m; j <= high; j++)
                        {
                            h[i][j] -= f * ort[j];
                        }
                    }
                    ort[m] = scale * ort[m];
                    h[m][m - 1] = scale * g;
                }
            }

            // Accumulate transformations (Algol's ortran).

            for (int i = 0; i < n; i++)
            {
                for (int j = 0; j < n; j++)
                {
                    v[i][j] = (i == j ? 1.0 : 0.0);
                }
            }

            for (int m = high - 1; m >= low + 1; m--)
            {
                if (h[m][m - 1] != 0.0)
                {
                    for (int i = m + 1; i <= high; i++)
                    {
                        ort[i] = h[i][m - 1];
                    }
                    for (int j = m; j <= high; j++)
                    {
                        double g = 0.0;
                        for (int i = m; i <= high; i++)
                        {
                            g += ort[i] * v[i][j];
                        }
                        // Double division avoids possible underflow
                        g = (g / ort[m]) / h[m][m - 1];
                        for (int i = m; i <= high; i++)
                        {
                            v[i][j] += g * ort[i];
                        }
                    }
                }
            }
        }

        private void cdiv(double xr, double xi, double yr, double yi)
        {
            double r, d;
            if (Math.Abs(yr) > Math.Abs(yi))
            {
                r = yi / yr;
                d = yr + r * yi;
                cdivr = (xr + r * xi) / d;
                cdivi = (xi - r * xr) / d;
            }
            else
            {
                r = yr / yi;
                d = yi + r * yr;
                cdivr = (r * xr + xi) / d;
                cdivi = (r * xi - xr) / d;
            }
        }


        private void Hqr2()
        {
            // Initialize
            int nn = this.n;
            int n = nn - 1;
            int low = 0;
            int high = nn - 1;
            double eps = Math.Pow(2.0, -52.0);
            double exshift = 0.0;
            double p = 0, q = 0, r = 0, s = 0, z = 0, t, w, x, y;

            // Store roots isolated by balanc and compute matrix norm

            double norm = 0.0;
            for (int i = 0; i < nn; i++)
            {
                if (i < low | i > high)
                {
                    d[i] = h[i][i];
                    e[i] = 0.0;
                }
                for (int j = Math.Max(i - 1, 0); j < nn; j++)
                {
                    norm = norm + Math.Abs(h[i][j]);
                }
            }

            // Outer loop over eigenvalue index

            int iter = 0;
            while (n >= low)
            {
                // Look for single small sub-diagonal element

                int l = n;
                while (l > low)
                {
                    s = Math.Abs(h[l - 1][l - 1]) + Math.Abs(h[l][l]);
                    if (s == 0.0)
                    {
                        s = norm;
                    }
                    if (Math.Abs(h[l][l - 1]) < eps * s)
                    {
                        break;
                    }
                    l--;
                }

                // Check for convergence
                // One root found

                if (l == n)
                {
                    h[n][n] = h[n][n] + exshift;
                    d[n] = h[n][n];
                    e[n] = 0.0;
                    n--;
                    iter = 0;

                    // Two roots found
                }
                else if (l == n - 1)
                {
                    w = h[n][n - 1] * h[n - 1][n];
                    p = (h[n - 1][n - 1] - h[n][n]) / 2.0;
                    q = p * p + w;
                    z = Math.Sqrt(Math.Abs(q));
                    h[n][n] = h[n][n] + exshift;
                    h[n - 1][n - 1] = h[n - 1][n - 1] + exshift;
                    x = h[n][n];

                    // Real pair

                    if (q >= 0)
                    {
                        if (p >= 0)
                        {
                            z = p + z;
                        }
                        else
                        {
                            z = p - z;
                        }
                        d[n - 1] = x + z;
                        d[n] = d[n - 1];
                        if (z != 0.0)
                        {
                            d[n] = x - w / z;
                        }
                        e[n - 1] = 0.0;
                        e[n] = 0.0;
                        x = h[n][n - 1];
                        s = Math.Abs(x) + Math.Abs(z);
                        p = x / s;
                        q = z / s;
                        r = Math.Sqrt(p * p + q * q);
                        p = p / r;
                        q = q / r;

                        // Row modification

                        for (int j = n - 1; j < nn; j++)
                        {
                            z = h[n - 1][j];
                            h[n - 1][j] = q * z + p * h[n][j];
                            h[n][j] = q * h[n][j] - p * z;
                        }

                        // Column modification

                        for (int i = 0; i <= n; i++)
                        {
                            z = h[i][n - 1];
                            h[i][n - 1] = q * z + p * h[i][n];
                            h[i][n] = q * h[i][n] - p * z;
                        }

                        // Accumulate transformations

                        for (int i = low; i <= high; i++)
                        {
                            z = v[i][n - 1];
                            v[i][n - 1] = q * z + p * v[i][n];
                            v[i][n] = q * v[i][n] - p * z;
                        }

                        // Complex pair
                    }
                    else
                    {
                        d[n - 1] = x + p;
                        d[n] = x + p;
                        e[n - 1] = z;
                        e[n] = -z;
                    }
                    n = n - 2;
                    iter = 0;

                    // No convergence yet
                }
                else
                {
                    // Form shift

                    x = h[n][n];
                    y = 0.0;
                    w = 0.0;
                    if (l < n)
                    {
                        y = h[n - 1][n - 1];
                        w = h[n][n - 1] * h[n - 1][n];
                    }

                    // Wilkinson's original ad hoc shift

                    if (iter == 10)
                    {
                        exshift += x;
                        for (int i = low; i <= n; i++)
                        {
                            h[i][i] -= x;
                        }
                        s = Math.Abs(h[n][n - 1]) + Math.Abs(h[n - 1][n - 2]);
                        x = y = 0.75 * s;
                        w = -0.4375 * s * s;
                    }

                    // MATLAB's new ad hoc shift

                    if (iter == 30)
                    {
                        s = (y - x) / 2.0;
                        s = s * s + w;
                        if (s > 0)
                        {
                            s = Math.Sqrt(s);
                            if (y < x)
                            {
                                s = -s;
                            }
                            s = x - w / ((y - x) / 2.0 + s);
                            for (int i = low; i <= n; i++)
                            {
                                h[i][i] -= s;
                            }
                            exshift += s;
                            x = y = w = 0.964;
                        }
                    }

                    iter = iter + 1; // (Could check iteration count here.)

                    // Look for two consecutive small sub-diagonal elements

                    int m = n - 2;
                    while (m >= l)
                    {
                        z = h[m][m];
                        r = x - z;
                        s = y - z;
                        p = (r * s - w) / h[m + 1][m] + h[m][m + 1];
                        q = h[m + 1][m + 1] - z - r - s;
                        r = h[m + 2][m + 1];
                        s = Math.Abs(p) + Math.Abs(q) + Math.Abs(r);
                        p = p / s;
                        q = q / s;
                        r = r / s;
                        if (m == l)
                        {
                            break;
                        }
                        if (Math.Abs(h[m][m - 1]) * (Math.Abs(q) + Math.Abs(r)) < eps
                            * (Math.Abs(p) * (Math.Abs(h[m - 1][m - 1])
                                           + Math.Abs(z) + Math.Abs(h[m + 1][m + 1]))))
                        {
                            break;
                        }
                        m--;
                    }

                    for (int i = m + 2; i <= n; i++)
                    {
                        h[i][i - 2] = 0.0;
                        if (i > m + 2)
                        {
                            h[i][i - 3] = 0.0;
                        }
                    }

                    // Double QR step involving rows l:n and columns m:n

                    for (int k = m; k <= n - 1; k++)
                    {
                        bool notlast = (k != n - 1);
                        if (k != m)
                        {
                            p = h[k][k - 1];
                            q = h[k + 1][k - 1];
                            r = (notlast ? h[k + 2][k - 1] : 0.0);
                            x = Math.Abs(p) + Math.Abs(q) + Math.Abs(r);
                            if (x != 0.0)
                            {
                                p = p / x;
                                q = q / x;
                                r = r / x;
                            }
                        }
                        if (x == 0.0)
                        {
                            break;
                        }
                        s = Math.Sqrt(p * p + q * q + r * r);
                        if (p < 0)
                        {
                            s = -s;
                        }
                        if (s != 0)
                        {
                            if (k != m)
                            {
                                h[k][k - 1] = -s * x;
                            }
                            else if (l != m)
                            {
                                h[k][k - 1] = -h[k][k - 1];
                            }
                            p = p + s;
                            x = p / s;
                            y = q / s;
                            z = r / s;
                            q = q / p;
                            r = r / p;

                            // Row modification

                            for (int j = k; j < nn; j++)
                            {
                                p = h[k][j] + q * h[k + 1][j];
                                if (notlast)
                                {
                                    p = p + r * h[k + 2][j];
                                    h[k + 2][j] = h[k + 2][j] - p * z;
                                }
                                h[k][j] = h[k][j] - p * x;
                                h[k + 1][j] = h[k + 1][j] - p * y;
                            }

                            // Column modification

                            for (int i = 0; i <= Math.Min(n, k + 3); i++)
                            {
                                p = x * h[i][k] + y * h[i][k + 1];
                                if (notlast)
                                {
                                    p = p + z * h[i][k + 2];
                                    h[i][k + 2] = h[i][k + 2] - p * r;
                                }
                                h[i][k] = h[i][k] - p;
                                h[i][k + 1] = h[i][k + 1] - p * q;
                            }

                            // Accumulate transformations

                            for (int i = low; i <= high; i++)
                            {
                                p = x * v[i][k] + y * v[i][k + 1];
                                if (notlast)
                                {
                                    p = p + z * v[i][k + 2];
                                    v[i][k + 2] = v[i][k + 2] - p * r;
                                }
                                v[i][k] = v[i][k] - p;
                                v[i][k + 1] = v[i][k + 1] - p * q;
                            }
                        } // (s != 0)
                    } // k loop
                } // check convergence
            } // while (n >= low)

            // Backsubstitute to find vectors of upper triangular form

            if (norm == 0.0)
            {
                return;
            }

            for (n = nn - 1; n >= 0; n--)
            {
                p = d[n];
                q = e[n];

                // Real vector

                if (q == 0)
                {
                    int l = n;
                    h[n][n] = 1.0;
                    for (int i = n - 1; i >= 0; i--)
                    {
                        w = h[i][i] - p;
                        r = 0.0;
                        for (int j = l; j <= n; j++)
                        {
                            r = r + h[i][j] * h[j][n];
                        }
                        if (e[i] < 0.0)
                        {
                            z = w;
                            s = r;
                        }
                        else
                        {
                            l = i;
                            if (e[i] == 0.0)
                            {
                                if (w != 0.0)
                                {
                                    h[i][n] = -r / w;
                                }
                                else
                                {
                                    h[i][n] = -r / (eps * norm);
                                }

                                // Solve real equations
                            }
                            else
                            {
                                x = h[i][i + 1];
                                y = h[i + 1][i];
                                q = (d[i] - p) * (d[i] - p) + e[i] * e[i];
                                t = (x * s - z * r) / q;
                                h[i][n] = t;
                                if (Math.Abs(x) > Math.Abs(z))
                                {
                                    h[i + 1][n] = (-r - w * t) / x;
                                }
                                else
                                {
                                    h[i + 1][n] = (-s - y * t) / z;
                                }
                            }

                            // Overflow control

                            t = Math.Abs(h[i][n]);
                            if ((eps * t) * t > 1)
                            {
                                for (int j = i; j <= n; j++)
                                {
                                    h[j][n] = h[j][n] / t;
                                }
                            }
                        }
                    }

                    // Complex vector
                }
                else if (q < 0)
                {
                    int l = n - 1;

                    // Last vector component imaginary so matrix is triangular

                    if (Math.Abs(h[n][n - 1]) > Math.Abs(h[n - 1][n]))
                    {
                        h[n - 1][n - 1] = q / h[n][n - 1];
                        h[n - 1][n] = -(h[n][n] - p) / h[n][n - 1];
                    }
                    else
                    {
                        cdiv(0.0, -h[n - 1][n], h[n - 1][n - 1] - p, q);
                        h[n - 1][n - 1] = cdivr;
                        h[n - 1][n] = cdivi;
                    }
                    h[n][n - 1] = 0.0;
                    h[n][n] = 1.0;
                    for (int i = n - 2; i >= 0; i--)
                    {
                        double ra, sa, vr, vi;
                        ra = 0.0;
                        sa = 0.0;
                        for (int j = l; j <= n; j++)
                        {
                            ra = ra + h[i][j] * h[j][n - 1];
                            sa = sa + h[i][j] * h[j][n];
                        }
                        w = h[i][i] - p;

                        if (e[i] < 0.0)
                        {
                            z = w;
                            r = ra;
                            s = sa;
                        }
                        else
                        {
                            l = i;
                            if (e[i] == 0)
                            {
                                cdiv(-ra, -sa, w, q);
                                h[i][n - 1] = cdivr;
                                h[i][n] = cdivi;
                            }
                            else
                            {
                                // Solve complex equations

                                x = h[i][i + 1];
                                y = h[i + 1][i];
                                vr = (d[i] - p) * (d[i] - p) + e[i] * e[i] - q * q;
                                vi = (d[i] - p) * 2.0 * q;
                                if (vr == 0.0 & vi == 0.0)
                                {
                                    vr = eps
                                         * norm
                                         * (Math.Abs(w) + Math.Abs(q)
                                           + Math.Abs(x) + Math.Abs(y) + Math
                                                                             .Abs(z));
                                }
                                cdiv(x * r - z * ra + q * sa, x * s - z * sa - q
                                                        * ra, vr, vi);
                                h[i][n - 1] = cdivr;
                                h[i][n] = cdivi;
                                if (Math.Abs(x) > (Math.Abs(z) + Math.Abs(q)))
                                {
                                    h[i + 1][n - 1] = (-ra - w * h[i][n - 1] + q
                                                       * h[i][n])
                                                      / x;
                                    h[i + 1][n] = (-sa - w * h[i][n] - q
                                                   * h[i][n - 1])
                                                  / x;
                                }
                                else
                                {
                                    cdiv(-r - y * h[i][n - 1], -s - y * h[i][n], z,
                                         q);
                                    h[i + 1][n - 1] = cdivr;
                                    h[i + 1][n] = cdivi;
                                }
                            }

                            // Overflow control

                            t = Math.Max(Math.Abs(h[i][n - 1]), Math.Abs(h[i][n]));
                            if ((eps * t) * t > 1)
                            {
                                for (int j = i; j <= n; j++)
                                {
                                    h[j][n - 1] = h[j][n - 1] / t;
                                    h[j][n] = h[j][n] / t;
                                }
                            }
                        }
                    }
                }
            }

            // Vectors of isolated roots

            for (int i = 0; i < nn; i++)
            {
                if (i < low | i > high)
                {
                    for (int j = i; j < nn; j++)
                    {
                        v[i][j] = h[i][j];
                    }
                }
            }

            // Back transformation to get eigenvectors of original matrix

            for (int j = nn - 1; j >= low; j--)
            {
                for (int i = low; i <= high; i++)
                {
                    z = 0.0;
                    for (int k = low; k <= Math.Min(j, high); k++)
                    {
                        z = z + v[i][k] * h[k][j];
                    }
                    v[i][j] = z;
                }
            }
        }



        public double[] getImagEigenvalues()
        {
            return e;
        }
    }

    public class LUDecomposition
    {
        /// <summary>
        /// Array for internal storage of decomposition.
        /// </summary>
        private readonly double[][] LU;

        /// <summary>
        /// column dimension.
        /// </summary>
        private readonly int m;

        /// <summary>
        /// row dimension.
        /// </summary>
        private readonly int n;

        /// <summary>
        /// Internal storage of pivot vector.
        /// </summary>
        private readonly int[] piv;

        /// <summary>
        /// pivot sign.
        /// </summary>
        private readonly int pivsign;

        /// <summary>
        /// LU Decomposition
        /// </summary>
        /// <param name="A">Rectangular matrix</param>
        public LUDecomposition(Matrix A)
        {
            // Use a "left-looking", dot-product, Crout/Doolittle Algo.

            LU = A.GetArrayCopy();
            m = A.Rows;
            n = A.Cols;
            piv = new int[m];
            for (int i = 0; i < m; i++)
            {
                piv[i] = i;
            }
            pivsign = 1;
            double[] LUrowi;
            var LUcolj = new double[m];

            // Outer loop.

            for (int j = 0; j < n; j++)
            {
                // Make a copy of the j-th column to localize references.

                for (int i = 0; i < m; i++)
                {
                    LUcolj[i] = LU[i][j];
                }

                // Apply previous transformations.

                for (int i = 0; i < m; i++)
                {
                    LUrowi = LU[i];

                    // Most of the time is spent in the following dot product.

                    int kmax = Math.Min(i, j);
                    double s = 0.0;
                    for (int k = 0; k < kmax; k++)
                    {
                        s += LUrowi[k] * LUcolj[k];
                    }

                    LUrowi[j] = LUcolj[i] -= s;
                }

                // Find pivot and exchange if necessary.

                int p = j;
                for (int i = j + 1; i < m; i++)
                {
                    if (Math.Abs(LUcolj[i]) > Math.Abs(LUcolj[p]))
                    {
                        p = i;
                    }
                }
                if (p != j)
                {
                    for (int k = 0; k < n; k++)
                    {
                        double t = LU[p][k];
                        LU[p][k] = LU[j][k];
                        LU[j][k] = t;
                    }
                    int temp = piv[p];
                    piv[p] = piv[j];
                    piv[j] = temp;
                    pivsign = -pivsign;
                }

                // Compute multipliers.

                if (j < m & LU[j][j] != 0.0)
                {
                    for (int i = j + 1; i < m; i++)
                    {
                        LU[i][j] /= LU[j][j];
                    }
                }
            }
        }



        public bool IsNonsingular
        {
            get
            {
                for (int j = 0; j < n; j++)
                {
                    if (LU[j][j] == 0)
                        return false;
                }
                return true;
            }
        }


        public Matrix L
        {
            get
            {
                var x = new Matrix(m, n);
                double[][] l = x.Data;
                for (int i = 0; i < m; i++)
                {
                    for (int j = 0; j < n; j++)
                    {
                        if (i > j)
                        {
                            l[i][j] = LU[i][j];
                        }
                        else if (i == j)
                        {
                            l[i][j] = 1.0;
                        }
                        else
                        {
                            l[i][j] = 0.0;
                        }
                    }
                }
                return x;
            }
        }



        public Matrix U
        {
            get
            {
                var x = new Matrix(n, n);
                double[][] u = x.Data;
                for (int i = 0; i < n; i++)
                {
                    for (int j = 0; j < n; j++)
                    {
                        if (i <= j)
                        {
                            u[i][j] = LU[i][j];
                        }
                        else
                        {
                            u[i][j] = 0.0;
                        }
                    }
                }
                return x;
            }
        }


        public int[] Pivot
        {
            get
            {
                var p = new int[m];
                for (int i = 0; i < m; i++)
                {
                    p[i] = piv[i];
                }
                return p;
            }
        }


        public double[] DoublePivot
        {
            get
            {
                var vals = new double[m];
                for (int i = 0; i < m; i++)
                {
                    vals[i] = piv[i];
                }
                return vals;
            }
        }


        public double Det()
        {
            if (m != n)
            {

            }
            double d = pivsign;
            for (int j = 0; j < n; j++)
            {
                d *= LU[j][j];
            }
            return d;
        }


        /// <summary>
        /// Solve A*X = B
        /// </summary>
        /// <param name="B">A Matrix with as many rows as A and any number of columns.</param>
        /// <returns>so that L*U*X = B(piv,:)</returns>
        public Matrix Solve(Matrix B)
        {
            if (B.Rows != m)
            {
                throw new MatrixError(
                    "Matrix row dimensions must agree.");
            }
            if (!IsNonsingular)
            {
                throw new MatrixError("Matrix is singular.");
            }

            // Copy right hand side with pivoting
            int nx = B.Cols;
            Matrix Xmat = B.GetMatrix(piv, 0, nx - 1);
            double[][] X = Xmat.Data;

            // Solve L*Y = B(piv,:)
            for (int k = 0; k < n; k++)
            {
                for (int i = k + 1; i < n; i++)
                {
                    for (int j = 0; j < nx; j++)
                    {
                        X[i][j] -= X[k][j] * LU[i][k];
                    }
                }
            }
            // Solve U*X = Y;
            for (int k = n - 1; k >= 0; k--)
            {
                for (int j = 0; j < nx; j++)
                {
                    X[k][j] /= LU[k][k];
                }
                for (int i = 0; i < k; i++)
                {
                    for (int j = 0; j < nx; j++)
                    {
                        X[i][j] -= X[k][j] * LU[i][k];
                    }
                }
            }
            return Xmat;
        }


        public double[] Solve(double[] value_ren)
        {
            if (value_ren == null)
            {
                throw new MatrixError("value");
            }

            if (value_ren.Length != LU.Length)
            {
                throw new MatrixError("Invalid matrix dimensions.");
            }

            if (!IsNonsingular)
            {
                throw new MatrixError("Matrix is singular");
            }

            // Copy right hand side with pivoting
            int count = value_ren.Length;
            var b = new double[count];
            for (int i = 0; i < b.Length; i++)
            {
                b[i] = value_ren[piv[i]];
            }

            int rows = LU[0].Length;
            int columns = LU[0].Length;
            double[][] lu = LU;


            // Solve L*Y = B
            var X = new double[count];
            for (int i = 0; i < rows; i++)
            {
                X[i] = b[i];
                for (int j = 0; j < i; j++)
                {
                    X[i] -= lu[i][j] * X[j];
                }
            }

            // Solve U*X = Y;
            for (int i = rows - 1; i >= 0; i--)
            {
                // double sum = 0.0;
                for (int j = columns - 1; j > i; j--)
                {
                    X[i] -= lu[i][j] * X[j];
                }
                X[i] /= lu[i][i];
            }
            return X;
        }



        public double[][] Inverse()
        {
            if (!IsNonsingular)
            {
                throw new MatrixError("Matrix is singular");
            }

            int rows = LU.Length;
            int columns = LU[0].Length;
            int count = rows;
            double[][] lu = LU;

            double[][] X = EngineArray.AllocateDouble2D(rows, columns);
            for (int i = 0; i < rows; i++)
            {
                int k = piv[i];
                X[i][k] = 1.0;
            }

            // Solve L*Y = B(piv,:)
            for (int k = 0; k < columns; k++)
            {
                for (int i = k + 1; i < columns; i++)
                {
                    for (int j = 0; j < count; j++)
                    {
                        X[i][j] -= X[k][j] * lu[i][k];
                    }
                }
            }

            // Solve U*X = Y;
            for (int k = columns - 1; k >= 0; k--)
            {
                for (int j = 0; j < count; j++)
                {
                    X[k][j] /= lu[k][k];
                }

                for (int i = 0; i < k; i++)
                {
                    for (int j = 0; j < count; j++)
                    {
                        X[i][j] -= X[k][j] * lu[i][k];
                    }
                }
            }

            return X;
        }
    }

    public class QRDecomposition
    {
        /// <summary>
        /// Array for internal storage of decomposition.
        /// </summary>
        private readonly double[][] QR;

        /// <summary>
        /// Array for internal storage of diagonal of R.
        /// </summary>
        private readonly double[] Rdiag;

        /// <summary>
        /// Row dimension.
        /// </summary>
        private readonly int m;

        /// <summary>
        /// Column dimension.
        /// </summary>
        private readonly int n;

        /// <summary>
        /// QR Decomposition, computed by Householder reflections.
        /// </summary>
        /// <param name="A">Structure to access R and the Householder vectors and compute Q.</param>
        public QRDecomposition(Matrix A)
        {
            // Initialize.
            QR = A.GetArrayCopy();
            m = A.Rows;
            n = A.Cols;
            Rdiag = new double[n];

            // Main loop.
            for (int k = 0; k < n; k++)
            {
                // Compute 2-norm of k-th column without under/overflow.
                double nrm = 0;
                for (int i = k; i < m; i++)
                {
                    nrm = SyntMath.Hypot(nrm, QR[i][k]);
                }

                if (nrm != 0.0)
                {
                    // Form k-th Householder vector.
                    if (QR[k][k] < 0)
                    {
                        nrm = -nrm;
                    }
                    for (int i = k; i < m; i++)
                    {
                        QR[i][k] /= nrm;
                    }
                    QR[k][k] += 1.0;

                    // Apply transformation to remaining columns.
                    for (int j = k + 1; j < n; j++)
                    {
                        double s = 0.0;
                        for (int i = k; i < m; i++)
                        {
                            s += QR[i][k] * QR[i][j];
                        }
                        s = -s / QR[k][k];
                        for (int i = k; i < m; i++)
                        {
                            QR[i][j] += s * QR[i][k];
                        }
                    }
                }
                Rdiag[k] = -nrm;
            }
        }

        /// <summary>
        /// Return the Householder vectors
        /// </summary>
        public Matrix H
        {
            get
            {
                var x = new Matrix(m, n);
                double[][] h = x.Data;
                for (int i = 0; i < m; i++)
                {
                    for (int j = 0; j < n; j++)
                    {
                        if (i >= j)
                        {
                            h[i][j] = QR[i][j];
                        }
                        else
                        {
                            h[i][j] = 0.0;
                        }
                    }
                }
                return x;
            }
        }

        /**
         * Return the upper triangular factor
         * 
         * @return R
         */

        public Matrix R
        {
            get
            {
                var x = new Matrix(n, n);
                double[][] r = x.Data;
                for (int i = 0; i < n; i++)
                {
                    for (int j = 0; j < n; j++)
                    {
                        if (i < j)
                        {
                            r[i][j] = QR[i][j];
                        }
                        else if (i == j)
                        {
                            r[i][j] = Rdiag[i];
                        }
                        else
                        {
                            r[i][j] = 0.0;
                        }
                    }
                }
                return x;
            }
        }

        /// <summary>
        /// Generate and return the (economy-sized) orthogonal factor
        /// </summary>
        public Matrix Q
        {
            get
            {
                var x = new Matrix(m, n);
                double[][] q = x.Data;
                for (int k = n - 1; k >= 0; k--)
                {
                    for (int i = 0; i < m; i++)
                    {
                        q[i][k] = 0.0;
                    }
                    q[k][k] = 1.0;
                    for (int j = k; j < n; j++)
                    {
                        if (QR[k][k] != 0)
                        {
                            double s = 0.0;
                            for (int i = k; i < m; i++)
                            {
                                s += QR[i][k] * q[i][j];
                            }
                            s = -s / QR[k][k];
                            for (int i = k; i < m; i++)
                            {
                                q[i][j] += s * QR[i][k];
                            }
                        }
                    }
                }
                return x;
            }
        }

        /// <summary>
        /// Is the matrix full rank? 
        /// </summary>
        /// <returns>true if R, and hence A, has full rank.</returns>
        public bool IsFullRank()
        {
            for (int j = 0; j < n; j++)
            {
                if (Rdiag[j] == 0)
                    return false;
            }
            return true;
        }

        /// <summary>
        /// Least squares solution of A*X = B
        /// </summary>
        /// <param name="B">A Matrix with as many rows as A and any number of columns.</param>
        /// <returns>that minimizes the two norm of Q*R*X-B.</returns>
        public Matrix Solve(Matrix B)
        {
            if (B.Rows != m)
            {
                throw new MatrixError(
                    "Matrix row dimensions must agree.");
            }
            if (!IsFullRank())
            {
                throw new MatrixError("Matrix is rank deficient.");
            }

            // Copy right hand side
            int nx = B.Cols;
            double[][] X = B.GetArrayCopy();

            // Compute Y = transpose(Q)*B
            for (int k = 0; k < n; k++)
            {
                for (int j = 0; j < nx; j++)
                {
                    double s = 0.0;
                    for (int i = k; i < m; i++)
                    {
                        s += QR[i][k] * X[i][j];
                    }
                    s = -s / QR[k][k];
                    for (int i = k; i < m; i++)
                    {
                        X[i][j] += s * QR[i][k];
                    }
                }
            }
            // Solve R*X = Y;
            for (int k = n - 1; k >= 0; k--)
            {
                for (int j = 0; j < nx; j++)
                {
                    X[k][j] /= Rdiag[k];
                }
                for (int i = 0; i < k; i++)
                {
                    for (int j = 0; j < nx; j++)
                    {
                        X[i][j] -= X[k][j] * QR[i][k];
                    }
                }
            }
            return (new Matrix(X).GetMatrix(0, n - 1, 0, nx - 1));
        }
    }

    public class SingularValueDecomposition
    {
        /// <summary>
        /// rows
        /// </summary>
        private readonly int m;

        /// <summary>
        /// cols
        /// </summary>
        private readonly int n;

        /// <summary>
        /// Array for internal storage of singular values.
        /// </summary>
        private readonly double[] s;

        /// <summary>
        /// The U matrix.
        /// </summary>
        private readonly double[][] umatrix;

        /// <summary>
        /// The V matrix.
        /// </summary>
        private readonly double[][] vmatrix;

        /// <summary>
        /// Construct the singular value decomposition
        /// </summary>
        /// <param name="Arg">Rectangular matrix</param>
        public SingularValueDecomposition(Matrix Arg)
        {
            // Derived from LINPACK code.
            // Initialize.
            double[][] A = Arg.GetArrayCopy();
            m = Arg.Rows;
            n = Arg.Cols;

            /*
             * Apparently the failing cases are only a proper subset of (m<n), so
             * let's not throw error. Correct fix to come later? if (m<n) { throw
             * new IllegalArgumentException("Jama SVD only works for m >= n"); }
             */
            int nu = Math.Min(m, n);
            s = new double[Math.Min(m + 1, n)];
            umatrix = EngineArray.AllocateDouble2D(m, nu);
            vmatrix = EngineArray.AllocateDouble2D(n, n);
            var e = new double[n];
            var work = new double[m];
            bool wantu = true;
            bool wantv = true;

            // Reduce A to bidiagonal form, storing the diagonal elements
            // in s and the super-diagonal elements in e.

            int nct = Math.Min(m - 1, n);
            int nrt = Math.Max(0, Math.Min(n - 2, m));
            for (int k = 0; k < Math.Max(nct, nrt); k++)
            {
                if (k < nct)
                {
                    // Compute the transformation for the k-th column and
                    // place the k-th diagonal in s[k].
                    // Compute 2-norm of k-th column without under/overflow.
                    s[k] = 0;
                    for (int i = k; i < m; i++)
                    {
                        s[k] = SyntMath.Hypot(s[k], A[i][k]);
                    }
                    if (s[k] != 0.0)
                    {
                        if (A[k][k] < 0.0)
                        {
                            s[k] = -s[k];
                        }
                        for (int i = k; i < m; i++)
                        {
                            A[i][k] /= s[k];
                        }
                        A[k][k] += 1.0;
                    }
                    s[k] = -s[k];
                }
                for (int j = k + 1; j < n; j++)
                {
                    if ((k < nct) & (s[k] != 0.0))
                    {
                        // Apply the transformation.

                        double t = 0;
                        for (int i = k; i < m; i++)
                        {
                            t += A[i][k] * A[i][j];
                        }
                        t = -t / A[k][k];
                        for (int i = k; i < m; i++)
                        {
                            A[i][j] += t * A[i][k];
                        }
                    }

                    // Place the k-th row of A into e for the
                    // subsequent calculation of the row transformation.

                    e[j] = A[k][j];
                }
                if (wantu & (k < nct))
                {
                    // Place the transformation in U for subsequent back
                    // multiplication.

                    for (int i = k; i < m; i++)
                    {
                        umatrix[i][k] = A[i][k];
                    }
                }
                if (k < nrt)
                {
                    // Compute the k-th row transformation and place the
                    // k-th super-diagonal in e[k].
                    // Compute 2-norm without under/overflow.
                    e[k] = 0;
                    for (int i = k + 1; i < n; i++)
                    {
                        e[k] = SyntMath.Hypot(e[k], e[i]);
                    }
                    if (e[k] != 0.0)
                    {
                        if (e[k + 1] < 0.0)
                        {
                            e[k] = -e[k];
                        }
                        for (int i = k + 1; i < n; i++)
                        {
                            e[i] /= e[k];
                        }
                        e[k + 1] += 1.0;
                    }
                    e[k] = -e[k];
                    if ((k + 1 < m) & (e[k] != 0.0))
                    {
                        // Apply the transformation.

                        for (int i = k + 1; i < m; i++)
                        {
                            work[i] = 0.0;
                        }
                        for (int j = k + 1; j < n; j++)
                        {
                            for (int i = k + 1; i < m; i++)
                            {
                                work[i] += e[j] * A[i][j];
                            }
                        }
                        for (int j = k + 1; j < n; j++)
                        {
                            double t = -e[j] / e[k + 1];
                            for (int i = k + 1; i < m; i++)
                            {
                                A[i][j] += t * work[i];
                            }
                        }
                    }
                    if (wantv)
                    {
                        // Place the transformation in V for subsequent
                        // back multiplication.

                        for (int i = k + 1; i < n; i++)
                        {
                            vmatrix[i][k] = e[i];
                        }
                    }
                }
            }

            // Set up the final bidiagonal matrix or order p.

            int p = Math.Min(n, m + 1);
            if (nct < n)
            {
                s[nct] = A[nct][nct];
            }
            if (m < p)
            {
                s[p - 1] = 0.0;
            }
            if (nrt + 1 < p)
            {
                e[nrt] = A[nrt][p - 1];
            }
            e[p - 1] = 0.0;

            // If required, generate U.

            if (wantu)
            {
                for (int j = nct; j < nu; j++)
                {
                    for (int i = 0; i < m; i++)
                    {
                        umatrix[i][j] = 0.0;
                    }
                    umatrix[j][j] = 1.0;
                }
                for (int k = nct - 1; k >= 0; k--)
                {
                    if (s[k] != 0.0)
                    {
                        for (int j = k + 1; j < nu; j++)
                        {
                            double t = 0;
                            for (int i = k; i < m; i++)
                            {
                                t += umatrix[i][k] * umatrix[i][j];
                            }
                            t = -t / umatrix[k][k];
                            for (int i = k; i < m; i++)
                            {
                                umatrix[i][j] += t * umatrix[i][k];
                            }
                        }
                        for (int i = k; i < m; i++)
                        {
                            umatrix[i][k] = -umatrix[i][k];
                        }
                        umatrix[k][k] = 1.0 + umatrix[k][k];
                        for (int i = 0; i < k - 1; i++)
                        {
                            umatrix[i][k] = 0.0;
                        }
                    }
                    else
                    {
                        for (int i = 0; i < m; i++)
                        {
                            umatrix[i][k] = 0.0;
                        }
                        umatrix[k][k] = 1.0;
                    }
                }
            }

            // If required, generate V.

            if (wantv)
            {
                for (int k = n - 1; k >= 0; k--)
                {
                    if ((k < nrt) & (e[k] != 0.0))
                    {
                        for (int j = k + 1; j < nu; j++)
                        {
                            double t = 0;
                            for (int i = k + 1; i < n; i++)
                            {
                                t += vmatrix[i][k] * vmatrix[i][j];
                            }
                            t = -t / vmatrix[k + 1][k];
                            for (int i = k + 1; i < n; i++)
                            {
                                vmatrix[i][j] += t * vmatrix[i][k];
                            }
                        }
                    }
                    for (int i = 0; i < n; i++)
                    {
                        vmatrix[i][k] = 0.0;
                    }
                    vmatrix[k][k] = 1.0;
                }
            }

            // Main iteration loop for the singular values.

            int pp = p - 1;
            int iter = 0;
            double eps = Math.Pow(2.0, -52.0);
            double tiny = Math.Pow(2.0, -966.0);
            while (p > 0)
            {
                int k, kase;

                // Here is where a test for too many iterations would go.

                // This section of the program inspects for
                // negligible elements in the s and e arrays. On
                // completion the variables kase and k are set as follows.

                // kase = 1 if s(p) and e[k-1] are negligible and k<p
                // kase = 2 if s(k) is negligible and k<p
                // kase = 3 if e[k-1] is negligible, k<p, and
                // s(k), ..., s(p) are not negligible (qr step).
                // kase = 4 if e(p-1) is negligible (convergence).

                for (k = p - 2; k >= -1; k--)
                {
                    if (k == -1)
                    {
                        break;
                    }
                    if (Math.Abs(e[k]) <= tiny + eps
                        * (Math.Abs(s[k]) + Math.Abs(s[k + 1])))
                    {
                        e[k] = 0.0;
                        break;
                    }
                }
                if (k == p - 2)
                {
                    kase = 4;
                }
                else
                {
                    int ks;
                    for (ks = p - 1; ks >= k; ks--)
                    {
                        if (ks == k)
                        {
                            break;
                        }
                        double t = (ks != p ? Math.Abs(e[ks]) : 0.0)
                                   + (ks != k + 1 ? Math.Abs(e[ks - 1]) : 0.0);
                        if (Math.Abs(s[ks]) <= tiny + eps * t)
                        {
                            s[ks] = 0.0;
                            break;
                        }
                    }
                    if (ks == k)
                    {
                        kase = 3;
                    }
                    else if (ks == p - 1)
                    {
                        kase = 1;
                    }
                    else
                    {
                        kase = 2;
                        k = ks;
                    }
                }
                k++;

                // Perform the task indicated by kase.

                switch (kase)
                {
                    // Deflate negligible s(p).

                    case 1:
                        {
                            double f = e[p - 2];
                            e[p - 2] = 0.0;
                            for (int j = p - 2; j >= k; j--)
                            {
                                double t = SyntMath.Hypot(s[j], f);
                                double cs = s[j] / t;
                                double sn = f / t;
                                s[j] = t;
                                if (j != k)
                                {
                                    f = -sn * e[j - 1];
                                    e[j - 1] = cs * e[j - 1];
                                }
                                if (wantv)
                                {
                                    for (int i = 0; i < n; i++)
                                    {
                                        t = cs * vmatrix[i][j] + sn * vmatrix[i][p - 1];
                                        vmatrix[i][p - 1] = -sn * vmatrix[i][j] + cs * vmatrix[i][p - 1];
                                        vmatrix[i][j] = t;
                                    }
                                }
                            }
                        }
                        break;

                    // Split at negligible s(k).

                    case 2:
                        {
                            double f = e[k - 1];
                            e[k - 1] = 0.0;
                            for (int j = k; j < p; j++)
                            {
                                double t = SyntMath.Hypot(s[j], f);
                                double cs = s[j] / t;
                                double sn = f / t;
                                s[j] = t;
                                f = -sn * e[j];
                                e[j] = cs * e[j];
                                if (wantu)
                                {
                                    for (int i = 0; i < m; i++)
                                    {
                                        t = cs * umatrix[i][j] + sn * umatrix[i][k - 1];
                                        umatrix[i][k - 1] = -sn * umatrix[i][j] + cs * umatrix[i][k - 1];
                                        umatrix[i][j] = t;
                                    }
                                }
                            }
                        }
                        break;

                    // Perform one qr step.

                    case 3:
                        {
                            // Calculate the shift.

                            double scale = Math.Max(Math.Max(Math
                                                                 .Max(Math.Max(Math.Abs(s[p - 1]), Math.Abs(s[p - 2])),
                                                                      Math.Abs(e[p - 2])), Math.Abs(s[k])), Math
                                                                                                                .Abs(
                                                                                                                    e[k]));
                            double sp = s[p - 1] / scale;
                            double spm1 = s[p - 2] / scale;
                            double epm1 = e[p - 2] / scale;
                            double sk = s[k] / scale;
                            double ek = e[k] / scale;
                            double b = ((spm1 + sp) * (spm1 - sp) + epm1 * epm1) / 2.0;
                            double c = (sp * epm1) * (sp * epm1);
                            double shift = 0.0;
                            if ((b != 0.0) | (c != 0.0))
                            {
                                shift = Math.Sqrt(b * b + c);
                                if (b < 0.0)
                                {
                                    shift = -shift;
                                }
                                shift = c / (b + shift);
                            }
                            double f = (sk + sp) * (sk - sp) + shift;
                            double g = sk * ek;

                            // Chase zeros.

                            for (int j = k; j < p - 1; j++)
                            {
                                double t = SyntMath.Hypot(f, g);
                                double cs = f / t;
                                double sn = g / t;
                                if (j != k)
                                {
                                    e[j - 1] = t;
                                }
                                f = cs * s[j] + sn * e[j];
                                e[j] = cs * e[j] - sn * s[j];
                                g = sn * s[j + 1];
                                s[j + 1] = cs * s[j + 1];
                                if (wantv)
                                {
                                    for (int i = 0; i < n; i++)
                                    {
                                        t = cs * vmatrix[i][j] + sn * vmatrix[i][j + 1];
                                        vmatrix[i][j + 1] = -sn * vmatrix[i][j] + cs * vmatrix[i][j + 1];
                                        vmatrix[i][j] = t;
                                    }
                                }
                                t = SyntMath.Hypot(f, g);
                                cs = f / t;
                                sn = g / t;
                                s[j] = t;
                                f = cs * e[j] + sn * s[j + 1];
                                s[j + 1] = -sn * e[j] + cs * s[j + 1];
                                g = sn * e[j + 1];
                                e[j + 1] = cs * e[j + 1];
                                if (wantu && (j < m - 1))
                                {
                                    for (int i = 0; i < m; i++)
                                    {
                                        t = cs * umatrix[i][j] + sn * umatrix[i][j + 1];
                                        umatrix[i][j + 1] = -sn * umatrix[i][j] + cs * umatrix[i][j + 1];
                                        umatrix[i][j] = t;
                                    }
                                }
                            }
                            e[p - 2] = f;
                            iter = iter + 1;
                        }
                        break;

                    // Convergence.

                    case 4:
                        {
                            // Make the singular values positive.

                            if (s[k] <= 0.0)
                            {
                                s[k] = (s[k] < 0.0 ? -s[k] : 0.0);
                                if (wantv)
                                {
                                    for (int i = 0; i <= pp; i++)
                                    {
                                        vmatrix[i][k] = -vmatrix[i][k];
                                    }
                                }
                            }

                            // Order the singular values.

                            while (k < pp)
                            {
                                if (s[k] >= s[k + 1])
                                {
                                    break;
                                }
                                double t = s[k];
                                s[k] = s[k + 1];
                                s[k + 1] = t;
                                if (wantv && (k < n - 1))
                                {
                                    for (int i = 0; i < n; i++)
                                    {
                                        t = vmatrix[i][k + 1];
                                        vmatrix[i][k + 1] = vmatrix[i][k];
                                        vmatrix[i][k] = t;
                                    }
                                }
                                if (wantu && (k < m - 1))
                                {
                                    for (int i = 0; i < m; i++)
                                    {
                                        t = umatrix[i][k + 1];
                                        umatrix[i][k + 1] = umatrix[i][k];
                                        umatrix[i][k] = t;
                                    }
                                }
                                k++;
                            }
                            iter = 0;
                            p--;
                        }
                        break;
                }
            }
        }

        /// <summary>
        /// Return the left singular vectors
        /// </summary>
        public Matrix U
        {
            get { return new Matrix(umatrix); }
        }

        /// <summary>
        /// Return the right singular vectors
        /// </summary>
        public Matrix V
        {
            get { return new Matrix(vmatrix); }
        }

        /// <summary>
        /// The singular values.
        /// </summary>
        public double[] SingularValues
        {
            get { return s; }
        }

        /// <summary>
        /// Return the diagonal matrix of singular values
        /// </summary>
        public Matrix S
        {
            get
            {
                var x = new Matrix(n, n);
                double[][] s = x.Data;
                for (int i = 0; i < n; i++)
                {
                    for (int j = 0; j < n; j++)
                    {
                        s[i][j] = 0.0;
                    }
                    s[i][i] = this.s[i];
                }
                return x;
            }
        }


        /// <summary>
        /// 
        /// </summary>
        /// <returns></returns>
        public double Norm2()
        {
            return s[0];
        }

        /// <summary>
        /// Two norm condition number
        /// </summary>
        /// <returns>max(S)/min(S)</returns>
        public double Cond()
        {
            return s[0] / s[Math.Min(m, n) - 1];
        }

        /// <summary>
        /// Effective numerical matrix rank
        /// </summary>
        /// <returns>The rank</returns>
        public int Rank()
        {
            double eps = Math.Pow(2.0, -52.0);
            double tol = Math.Max(m, n) * s[0] * eps;
            int r = 0;
            for (int i = 0; i < s.Length; i++)
            {
                if (s[i] > tol)
                {
                    r++;
                }
            }
            return r;
        }
    }

    public class ChainRuleWorker : IEngineTask
    {
        /// <summary>
        /// The actual values from the neural network.
        /// </summary>
        private readonly double[] _actual;

        /// <summary>
        /// The current first derivatives.
        /// </summary>
        private readonly double[] _derivative;

        /// <summary>
        /// The flat network.
        /// </summary>
        private readonly FlatNetwork _flat;

        /// <summary>
        /// The gradients.
        /// </summary>
        private readonly double[] _gradients;

        /// <summary>
        /// The high range.
        /// </summary>
        private readonly int _high;

        /// <summary>
        /// The neuron counts, per layer.
        /// </summary>
        private readonly int[] _layerCounts;

        /// <summary>
        /// The deltas for each layer.
        /// </summary>
        private readonly double[] _layerDelta;

        /// <summary>
        /// The feed counts, per layer.
        /// </summary>
        private readonly int[] _layerFeedCounts;

        /// <summary>
        /// The layer indexes.
        /// </summary>
        private readonly int[] _layerIndex;

        /// <summary>
        /// The output from each layer.
        /// </summary>
        private readonly double[] _layerOutput;

        /// <summary>
        /// The sums.
        /// </summary>
        private readonly double[] _layerSums;

        /// <summary>
        /// The low range.
        /// </summary>
        private readonly int _low;

        /// <summary>
        /// The pair to use for training.
        /// </summary>
        private readonly IMLDataPair _pair;

        /// <summary>
        /// The total first derivatives.
        /// </summary>
        private readonly double[] _totDeriv;

        /// <summary>
        /// The training data.
        /// </summary>
        private readonly IMLDataSet _training;

        /// <summary>
        /// The index to each layer's weights and thresholds.
        /// </summary>
        private readonly int[] _weightIndex;

        /// <summary>
        /// The weights and thresholds.
        /// </summary>
        private readonly double[] _weights;

        /// <summary>
        /// The error.
        /// </summary>
        private double _error;

        /// <summary>
        /// The output neuron to calculate for.
        /// </summary>
        private int _outputNeuron;

        /// <summary>
        /// Construct the chain rule worker. 
        /// </summary>
        /// <param name="theNetwork">The network to calculate a Hessian for.</param>
        /// <param name="theTraining">The training data.</param>
        /// <param name="theLow">The low range.</param>
        /// <param name="theHigh">The high range.</param>
        public ChainRuleWorker(FlatNetwork theNetwork, IMLDataSet theTraining, int theLow, int theHigh)
        {
            int weightCount = theNetwork.Weights.Length;

            _training = theTraining;
            _flat = theNetwork;

            _layerDelta = new double[_flat.LayerOutput.Length];
            _actual = new double[_flat.OutputCount];
            _derivative = new double[weightCount];
            _totDeriv = new double[weightCount];
            _gradients = new double[weightCount];

            _weights = _flat.Weights;
            _layerIndex = _flat.LayerIndex;
            _layerCounts = _flat.LayerCounts;
            _weightIndex = _flat.WeightIndex;
            _layerOutput = _flat.LayerOutput;
            _layerSums = _flat.LayerSums;
            _layerFeedCounts = _flat.LayerFeedCounts;
            _low = theLow;
            _high = theHigh;
            _pair = BasicMLDataPair.CreatePair(_flat.InputCount, _flat.OutputCount);
        }


        /// <summary>
        /// The output neuron we are processing.
        /// </summary>
        public int OutputNeuron
        {
            get { return _outputNeuron; }
            set { _outputNeuron = value; }
        }

        /// <summary>
        /// The first derivatives, used to calculate the Hessian.
        /// </summary>
        public double[] Derivative
        {
            get { return _totDeriv; }
        }


        /// <summary>
        /// The gradients.
        /// </summary>
        public double[] Gradients
        {
            get { return _gradients; }
        }

        /// <summary>
        /// The SSE error.
        /// </summary>
        public double Error
        {
            get { return _error; }
        }

        /// <summary>
        /// The flat network.
        /// </summary>
        public FlatNetwork Network
        {
            get { return _flat; }
        }

        #region IEngineTask Members

        /// <inheritdoc/>
        public void Run()
        {
            _error = 0;
            EngineArray.Fill(_totDeriv, 0);
            EngineArray.Fill(_gradients, 0);


            // Loop over every training element
            for (int i = _low; i <= _high; i++)
            {
                _training.GetRecord(i, _pair);

                EngineArray.Fill(_derivative, 0);
                Process(_outputNeuron, _pair.InputArray, _pair.IdealArray);
            }
        }

        #endregion

        /// <summary>
        /// Process one training set element.
        /// </summary>
        /// <param name="outputNeuron">The output neuron.</param>
        /// <param name="input">The network input.</param>
        /// <param name="ideal">The ideal values.</param>
        private void Process(int outputNeuron, double[] input, double[] ideal)
        {
            _flat.Compute(input, _actual);

            double e = ideal[outputNeuron] - _actual[outputNeuron];
            _error += e * e;

            for (int i = 0; i < _actual.Length; i++)
            {
                if (i == outputNeuron)
                {
                    _layerDelta[i] = _flat.ActivationFunctions[0]
                        .DerivativeFunction(_layerSums[i],
                                            _layerOutput[i]);
                }
                else
                {
                    _layerDelta[i] = 0;
                }
            }

            for (int i = _flat.BeginTraining; i < _flat.EndTraining; i++)
            {
                ProcessLevel(i);
            }

            // calculate gradients
            for (int j = 0; j < _weights.Length; j++)
            {
                _gradients[j] += e * _derivative[j];
                _totDeriv[j] += _derivative[j];
            }
        }

        /// <summary>
        /// Process one level. 
        /// </summary>
        /// <param name="currentLevel">The level.</param>
        private void ProcessLevel(int currentLevel)
        {
            int fromLayerIndex = _layerIndex[currentLevel + 1];
            int toLayerIndex = _layerIndex[currentLevel];
            int fromLayerSize = _layerCounts[currentLevel + 1];
            int toLayerSize = _layerFeedCounts[currentLevel];

            int index = _weightIndex[currentLevel];
            IActivationFunction activation = _flat
                .ActivationFunctions[currentLevel + 1];

            // handle weights
            int yi = fromLayerIndex;
            for (int y = 0; y < fromLayerSize; y++)
            {
                double output = _layerOutput[yi];
                double sum = 0;
                int xi = toLayerIndex;
                int wi = index + y;
                for (int x = 0; x < toLayerSize; x++)
                {
                    _derivative[wi] += output * _layerDelta[xi];
                    sum += _weights[wi] * _layerDelta[xi];
                    wi += fromLayerSize;
                    xi++;
                }

                _layerDelta[yi] = sum
                                 * (activation.DerivativeFunction(_layerSums[yi], _layerOutput[yi]));
                yi++;
            }
        }
    }

    public class HessianCR : BasicHessian, IMultiThreadable
    {
        /// <summary>
        /// The number of threads to use.
        /// </summary>
        private int _numThreads;

        /// <summary>
        /// The workers.
        /// </summary>
        private ChainRuleWorker[] _workers;

        #region IMultiThreadable Members

        /// <summary>
        /// Set the number of threads. Specify zero to tell Synt to automatically
        /// determine the best number of threads for the processor. If OpenCL is used
        /// as the target device, then this value is not used.
        /// </summary>
        public int ThreadCount
        {
            get { return _numThreads; }
            set { _numThreads = value; }
        }

        #endregion

        /// <inheritdoc/>
        public override void Init(BasicNetwork theNetwork, IMLDataSet theTraining)
        {
            base.Init(theNetwork, theTraining);
            int weightCount = theNetwork.Structure.Flat.Weights.Length;

            training = theTraining;
            network = theNetwork;

            hessianMatrix = new Matrix(weightCount, weightCount);
            hessian = hessianMatrix.Data;

            // create worker(s)
            var determine = new DetermineWorkload(
                _numThreads, (int)training.Count);

            _workers = new ChainRuleWorker[determine.ThreadCount];

            int index = 0;

            // handle CPU
            foreach (IntRange r in determine.CalculateWorkers())
            {
                _workers[index++] = new ChainRuleWorker((FlatNetwork)flat.Clone(),
                                                       training.OpenAdditional(), r.Low,
                                                       r.High);
            }
        }

        /// <inheritdoc/>
        public override void Compute()
        {
            Clear();
            double e = 0;
            int weightCount = network.Flat.Weights.Length;

            for (int outputNeuron = 0; outputNeuron < network.OutputCount; outputNeuron++)
            {
                // handle context
                if (flat.HasContext)
                {
                    _workers[0].Network.ClearContext();
                }

                if (_workers.Length > 1)
                {
                    TaskGroup group = EngineConcurrency.Instance.CreateTaskGroup();

                    foreach (ChainRuleWorker worker in _workers)
                    {
                        worker.OutputNeuron = outputNeuron;
                        EngineConcurrency.Instance.ProcessTask(worker, group);
                    }

                    group.WaitForComplete();
                }
                else
                {
                    _workers[0].OutputNeuron = outputNeuron;
                    _workers[0].Run();
                }

                // aggregate workers

                foreach (ChainRuleWorker worker in _workers)
                {
                    e += worker.Error;
                    for (int i = 0; i < weightCount; i++)
                    {
                        gradients[i] += worker.Gradients[i];
                    }
                    UpdateHessian(worker.Derivative);
                }
            }

            sse = e / 2;
        }
    }

    public class HessianFD : BasicHessian
    {
        /// <summary>
        /// The initial step size for dStep.
        /// </summary>
        public const double InitialStep = 0.001;


        /// <summary>
        /// The center of the point array.
        /// </summary>
        private int _center;

        /// <summary>
        /// The derivative coefficient, used for the finite difference method.
        /// </summary>
        private double[] _dCoeff;

        /// <summary>
        /// The derivative step size, used for the finite difference method.
        /// </summary>
        private double[] _dStep;

        /// <summary>
        /// The number of points actually used, which is (pointsPerSide*2)+1. 
        /// </summary>
        private int _pointCount;

        /// <summary>
        /// The number of points requested per side.  This determines the accuracy of the calculation.
        /// </summary>
        private int _pointsPerSide = 5;

        /// <summary>
        /// The number of points per side.
        /// </summary>
        public int PointsPerSide
        {
            get { return _pointsPerSide; }
            set { _pointsPerSide = value; }
        }

        /// <inheritdoc/>
        public new void Init(BasicNetwork theNetwork, IMLDataSet theTraining)
        {
            base.Init(theNetwork, theTraining);
            int weightCount = theNetwork.Structure.Flat.Weights.Length;

            _center = _pointsPerSide + 1;
            _pointCount = (_pointsPerSide * 2) + 1;
            _dCoeff = CreateCoefficients();
            _dStep = new double[weightCount];

            for (int i = 0; i < weightCount; i++)
            {
                _dStep[i] = InitialStep;
            }
        }

        /// <inheritdoc/>
        public override void Compute()
        {
            sse = 0;

            for (int i = 0; i < network.OutputCount; i++)
            {
                InternalCompute(i);
            }
        }

        /// <summary>
        /// Called internally to compute each output neuron.
        /// </summary>
        /// <param name="outputNeuron">The output neuron to compute.</param>
        private void InternalCompute(int outputNeuron)
        {
            int row = 0;
            var error = new ErrorCalculation();
            EngineArray.Fill(derivative, 0);

            // Loop over every training element
            foreach (var pair in training)
            {
                var networkOutput = network.Compute(pair.Input);

                double e = pair.Ideal.Data[outputNeuron] - networkOutput[outputNeuron];
                error.UpdateError(networkOutput[outputNeuron], pair.Ideal[outputNeuron]);

                int currentWeight = 0;

                // loop over the output weights
                int outputFeedCount = network.GetLayerTotalNeuronCount(network.LayerCount - 2);
                for (int i = 0; i < network.OutputCount; i++)
                {
                    for (int j = 0; j < outputFeedCount; j++)
                    {
                        double jc;

                        if (i == outputNeuron)
                        {
                            jc = ComputeDerivative(pair.Input, outputNeuron,
                                                   currentWeight, _dStep,
                                                   networkOutput[outputNeuron], row);
                        }
                        else
                        {
                            jc = 0;
                        }

                        gradients[currentWeight] += jc * e;
                        derivative[currentWeight] += jc;
                        currentWeight++;
                    }
                }

                // Loop over every weight in the neural network
                while (currentWeight < network.Flat.Weights.Length)
                {
                    double jc = ComputeDerivative(
                        pair.Input, outputNeuron, currentWeight,
                        _dStep,
                        networkOutput[outputNeuron], row);
                    derivative[currentWeight] += jc;
                    gradients[currentWeight] += jc * e;
                    currentWeight++;
                }

                row++;
            }

            UpdateHessian(derivative);

            sse += error.CalculateSSE();
        }


        private double ComputeDerivative(IMLData inputData, int outputNeuron, int weight, double[] stepSize,
                                         double networkOutput, int row)
        {
            double temp = network.Flat.Weights[weight];

            var points = new double[_dCoeff.Length];

            stepSize[row] = Math.Max(InitialStep * Math.Abs(temp), InitialStep);

            points[_center] = networkOutput;

            for (int i = 0; i < _dCoeff.Length; i++)
            {
                if (i == _center)
                    continue;

                double newWeight = temp + ((i - _center))
                                   * stepSize[row];

                network.Flat.Weights[weight] = newWeight;

                IMLData output = network.Compute(inputData);
                points[i] = output.Data[outputNeuron];
            }

            double result = _dCoeff.Select((t, i) => t * points[i]).Sum();

            result /= Math.Pow(stepSize[row], 1);

            network.Flat.Weights[weight] = temp;

            return result;
        }

        /// <summary>
        /// Compute finite difference coefficients according to the method provided here:
        /// 
        /// http://en.wikipedia.org/wiki/Finite_difference_coefficients
        ///
        /// </summary>
        /// <returns>An array of the coefficients for FD.</returns>
        public double[] CreateCoefficients()
        {
            var result = new double[_pointCount];

            var delts = new Matrix(_pointCount, _pointCount);
            double[][] t = delts.Data;

            for (int j = 0; j < _pointCount; j++)
            {
                double delt = (j - _center);
                double x = 1.0;

                for (int k = 0; k < _pointCount; k++)
                {
                    t[j][k] = x / SyntMath.Factorial(k);
                    x *= delt;
                }
            }

            Matrix invMatrix = delts.Inverse();
            double f = SyntMath.Factorial(_pointCount);


            for (int k = 0; k < _pointCount; k++)
            {
                result[k] = (Math.Round(invMatrix.Data[1][k] * f)) / f;
            }


            return result;
        }
    }

    public class BiPolarUtil
    {
        /// <summary>
        /// Convert binary to bipolar, true is 1 and false is -1.
        /// </summary>
        /// <param name="b">The binary value.</param>
        /// <returns>The bipolar value.</returns>
        public static double Bipolar2double(bool b)
        {
            if (b)
            {
                return 1;
            }
            else
            {
                return -1;
            }
        }

        /// <summary>
        /// Convert a boolean array to bipolar, true is 1 and false is -1.
        /// </summary>
        /// <param name="b">The binary array to convert.</param>
        /// <returns></returns>
        public static double[] Bipolar2double(bool[] b)
        {
            var result = new double[b.Length];

            for (int i = 0; i < b.Length; i++)
            {
                result[i] = Bipolar2double(b[i]);
            }

            return result;
        }

        /// <summary>
        /// Convert a 2D boolean array to bipolar, true is 1 and false is -1.
        /// </summary>
        /// <param name="b">The 2D array to convert.</param>
        /// <returns>A bipolar array.</returns>
        public static double[][] Bipolar2double(bool[][] b)
        {
            var result = new double[b.Length][];

            for (int row = 0; row < b.Length; row++)
            {
                result[row] = new double[b[row].Length];
                for (int col = 0; col < b[row].Length; col++)
                {
                    result[row][col] = Bipolar2double(b[row][col]);
                }
            }

            return result;
        }

        /// <summary>
        /// Convert biploar to boolean, true is 1 and false is -1.
        /// </summary>
        /// <param name="d">A bipolar value.</param>
        /// <returns>A boolean value.</returns>
        public static bool Double2bipolar(double d)
        {
            if (d > 0)
            {
                return true;
            }
            else
            {
                return false;
            }
        }

        /// <summary>
        /// Convert a bipolar array to a boolean array, true is 1 and false is -1.
        /// </summary>
        /// <param name="d">A bipolar array.</param>
        /// <returns>A boolean array.</returns>
        public static bool[] Double2bipolar(double[] d)
        {
            var result = new bool[d.Length];

            for (int i = 0; i < d.Length; i++)
            {
                result[i] = Double2bipolar(d[i]);
            }

            return result;
        }

        /// <summary>
        /// Convert a 2D bipolar array to a boolean array, true is 1 and false is -1.
        /// </summary>
        /// <param name="d">A 2D bipolar array.</param>
        /// <returns>A 2D boolean array.</returns>
        public static bool[][] Double2bipolar(double[][] d)
        {
            var result = new bool[d.Length][];

            for (int row = 0; row < d.Length; row++)
            {
                result[row] = new bool[d[row].Length];
                for (int col = 0; col < d[row].Length; col++)
                {
                    result[row][col] = Double2bipolar(d[row][col]);
                }
            }

            return result;
        }

        /// <summary>
        /// Normalize a binary number.  Greater than 0 becomes 1, zero and below are false.
        /// </summary>
        /// <param name="d">A binary number in a double.</param>
        /// <returns>A double that will be 0 or 1.</returns>
        public static double NormalizeBinary(double d)
        {
            if (d > 0)
            {
                return 1;
            }
            else
            {
                return 0;
            }
        }

        /// <summary>
        /// Convert a single number from bipolar to binary.
        /// </summary>
        /// <param name="d">a bipolar number.</param>
        /// <returns>A binary number.</returns>
        public static double ToBinary(double d)
        {
            return (d + 1) / 2.0;
        }

        /// <summary>
        /// Convert a number to bipolar.
        /// </summary>
        /// <param name="d">A binary number.</param>
        /// <returns></returns>
        public static double ToBiPolar(double d)
        {
            return (2 * NormalizeBinary(d)) - 1;
        }

        /// <summary>
        /// Normalize a number and convert to binary.
        /// </summary>
        /// <param name="d">A bipolar number.</param>
        /// <returns>A binary number stored as a double</returns>
        public static double ToNormalizedBinary(double d)
        {
            return NormalizeBinary(ToBinary(d));
        }
    }

    public class Matrix
    {


        public double this[int row, int col]
        {
            get
            {
                Validate(row, col);
                return matrix[row][col];
            }
            set
            {
                Validate(row, col);
                if (double.IsInfinity(value) || double.IsNaN(value))
                {

                }
                matrix[row][col] = value;
            }
        }

        /// <summary>
        /// Create a matrix that is a single column.
        /// </summary>
        /// <param name="input">A 1D array to make the matrix from.</param>
        /// <returns>A matrix that contains a single column.</returns>
        public static Matrix CreateColumnMatrix(double[] input)
        {
            var d = new double[input.Length][];
            for (int row = 0; row < d.Length; row++)
            {
                d[row] = new double[1];
                d[row][0] = input[row];
            }
            return new Matrix(d);
        }

        /// <summary>
        /// Create a matrix that is a single row.
        /// </summary>
        /// <param name="input">A 1D array to make the matrix from.</param>
        /// <returns>A matrix that contans a single row.</returns>
        public static Matrix CreateRowMatrix(double[] input)
        {
            var d = new double[1][];

            d[0] = new double[input.Length];

            for (int i = 0; i < input.Length; i++)
            {
                d[0][i] = input[i];
            }

            return new Matrix(d);
        }

        /// <summary>
        /// The matrix data, stored as a 2D array.
        /// </summary>
        private readonly double[][] matrix;

        /// <summary>
        /// Construct a matrix from a 2D boolean array.  Translate true to 1, false to -1.
        /// </summary>
        /// <param name="sourceMatrix">A 2D array to construcat the matrix from.</param>
        public Matrix(bool[][] sourceMatrix)
        {
            matrix = new double[sourceMatrix.Length][];
            for (int r = 0; r < Rows; r++)
            {
                matrix[r] = new double[sourceMatrix[r].Length];
                for (int c = 0; c < Cols; c++)
                {
                    if (sourceMatrix[r][c])
                    {
                        matrix[r][c] = 1;
                    }
                    else
                    {
                        matrix[r][c] = -1;
                    }
                }
            }
        }

        /// <summary>
        /// Construct a matrix from a 2D double array.
        /// </summary>
        /// <param name="sourceMatrix">A 2D double array.</param>
        public Matrix(double[][] sourceMatrix)
        {
            matrix = new double[sourceMatrix.Length][];
            for (int r = 0; r < Rows; r++)
            {
                matrix[r] = new double[sourceMatrix[r].Length];
                for (int c = 0; c < Cols; c++)
                {
                    matrix[r][c] = sourceMatrix[r][c];
                }
            }
        }

        /// <summary>
        /// Construct a blank matrix with the specified number of rows and columns.
        /// </summary>
        /// <param name="rows">How many rows.</param>
        /// <param name="cols">How many columns.</param>
        public Matrix(int rows, int cols)
        {
            matrix = new double[rows][];
            for (int i = 0; i < rows; i++)
            {
                matrix[i] = new double[cols];
            }
        }


        public void Add(int row, int col, double value_ren)
        {
            Validate(row, col);
            double newValue = matrix[row][col] + value_ren;
            matrix[row][col] = newValue;
        }

        /// <summary>
        /// Clear the matrix.
        /// </summary>
        public void Clear()
        {
            for (int r = 0; r < Rows; r++)
            {
                for (int c = 0; c < Cols; c++)
                {
                    matrix[r][c] = 0;
                }
            }
        }

        /// <summary>
        /// Clone the matrix.
        /// </summary>
        /// <returns>A cloned copy of the matrix.</returns>
        public object Clone()
        {
            return new Matrix(matrix);
        }

        public override bool Equals(Object other)
        {
            if (other is Matrix)
                return equals((Matrix)other, 10);
            else
                return false;
        }


        public override int GetHashCode()
        {
            return Rows + Cols;
        }


        public bool equals(Matrix matrix, int precision)
        {
            if (precision < 0)
            {

            }

            double test = Math.Pow(10.0, precision);
            if (double.IsInfinity(test) || (test > long.MaxValue))
            {

            }

            precision = (int)Math.Pow(10, precision);

            double[][] otherMatrix = matrix.Data;
            for (int r = 0; r < Rows; r++)
            {
                for (int c = 0; c < Cols; c++)
                {
                    if ((long)(this.matrix[r][c] * precision) != (long)(otherMatrix[r][c] * precision))
                    {
                        return false;
                    }
                }
            }

            return true;
        }


        public int FromPackedArray(double[] array, int index)
        {
            for (int r = 0; r < Rows; r++)
            {
                for (int c = 0; c < Cols; c++)
                {
                    matrix[r][c] = array[index++];
                }
            }

            return index;
        }

        /// <summary>
        /// Get one column from this matrix as a column matrix.
        /// </summary>
        /// <param name="col">The desired column.</param>
        /// <returns>The column matrix.</returns>
        public Matrix GetCol(int col)
        {
            if (col > Cols)
            {

            }

            var newMatrix = new double[Rows][];

            for (int row = 0; row < Rows; row++)
            {
                newMatrix[row] = new double[1];
                newMatrix[row][0] = matrix[row][col];
            }

            return new Matrix(newMatrix);
        }

        /// <summary>
        /// Get the number of columns in this matrix
        /// </summary>
        public int Cols
        {
            get { return matrix[0].Length; }
        }

        /// <summary>
        /// Get the specified row as a row matrix.
        /// </summary>
        /// <param name="row">The desired row.</param>
        /// <returns>A row matrix.</returns>
        public Matrix GetRow(int row)
        {
            if (row > Rows)
            {

            }

            var newMatrix = new double[1][];
            newMatrix[0] = new double[Cols];

            for (int col = 0; col < Cols; col++)
            {
                newMatrix[0][col] = matrix[row][col];
            }

            return new Matrix(newMatrix);
        }

        /// <summary>
        /// Get the number of rows in this matrix
        /// </summary>
        public int Rows
        {
            get { return matrix.GetUpperBound(0) + 1; }
        }


        /// <summary>
        /// Determine if this matrix is a vector.  A vector matrix only has a single row or column.
        /// </summary>
        /// <returns>True if this matrix is a vector.</returns>
        public bool IsVector()
        {
            if (Rows == 1)
            {
                return true;
            }
            else
            {
                return Cols == 1;
            }
        }

        /// <summary>
        /// Determine if all of the values in the matrix are zero.
        /// </summary>
        /// <returns>True if all of the values in the matrix are zero.</returns>
        public bool IsZero()
        {
            for (int row = 0; row < Rows; row++)
            {
                for (int col = 0; col < Cols; col++)
                {
                    if (matrix[row][col] != 0)
                    {
                        return false;
                    }
                }
            }
            return true;
        }

        /// <summary>
        /// Fill the matrix with random values in the specified range.
        /// </summary>
        /// <param name="min">The minimum value for the random numbers.</param>
        /// <param name="max">The maximum value for the random numbers.</param>
        public void Ramdomize(double min, double max)
        {
            for (int r = 0; r < Rows; r++)
            {
                for (int c = 0; c < Cols; c++)
                {
                    matrix[r][c] = (ThreadSafeRandom.NextDouble() * (max - min)) + min;
                }
            }
        }


        /// <summary>
        /// Get the size fo the matrix.  This is thr rows times the columns.
        /// </summary>
        public int Size
        {
            get { return Rows * Cols; }
        }

        /// <summary>
        /// Sum all of the values in the matrix.
        /// </summary>
        /// <returns>The sum of all of the values in the matrix.</returns>
        public double Sum()
        {
            double result = 0;
            for (int r = 0; r < Rows; r++)
            {
                for (int c = 0; c < Cols; c++)
                {
                    result += matrix[r][c];
                }
            }
            return result;
        }

        /// <summary>
        /// Convert the matrix to a packed array.
        /// </summary>
        /// <returns>A packed array.</returns>
        public double[] ToPackedArray()
        {
            var result = new double[Rows * Cols];

            int index = 0;
            for (int r = 0; r < Rows; r++)
            {
                for (int c = 0; c < Cols; c++)
                {
                    result[index++] = matrix[r][c];
                }
            }

            return result;
        }

        /// <summary>
        /// Validate that the specified row and column are inside of the range of the matrix.
        /// </summary>
        /// <param name="row">The row to check.</param>
        /// <param name="col">The column to check.</param>
        private void Validate(int row, int col)
        {
            if ((row >= Rows) || (row < 0))
            {

            }

            if ((col >= Cols) || (col < 0))
            {

            }
        }

        /// <summary>
        /// Add the specified matrix to this matrix.  This will modify the matrix
        /// to hold the result of the addition.
        /// </summary>
        /// <param name="matrix">The matrix to add.</param>
        public void Add(Matrix matrix)
        {
            for (int row = 0; row < Rows; row++)
            {
                for (int col = 0; col < Cols; col++)
                {
                    Add(row, col, matrix[row, col]);
                }
            }
        }

        /// <summary>
        /// Set every value in the matrix to the specified value.
        /// </summary>
        /// <param name="value_ren">The value to set the matrix to.</param>
        public void Set(double value_ren)
        {
            for (int row = 0; row < Rows; row++)
            {
                for (int col = 0; col < Cols; col++)
                {
                    matrix[row][col] = value_ren;
                }
            }
        }

        /// <summary>
        /// Get the matrix array for this matrix.
        /// </summary>
        public double[][] Data
        {
            get { return matrix; }
        }

        /// <summary>
        /// Set the values from the other matrix into this one.
        /// </summary>
        /// <param name="other">The source matrix.</param>
        public void Set(Matrix other)
        {
            double[][] target = Data;
            double[][] source = other.Data;
            for (int r = 0; r < Rows; r++)
                for (int c = 0; c < Cols; c++)
                    target[r][c] = source[r][c];
        }

        /// <summary>
        /// Make a copy of this matrix as an array.
        /// </summary>
        /// <returns>An array copy of this matrix.</returns>
        public double[][] GetArrayCopy()
        {
            var result = new double[Rows][];
            for (int row = 0; row < Rows; row++)
            {
                result[row] = new double[Cols];
                for (int col = 0; col < Cols; col++)
                {
                    result[row][col] = matrix[row][col];
                }
            }
            return result;
        }

        /// <summary>
        /// Get a submatrix.
        /// </summary>
        /// <param name="i0">Initial row index.</param>
        /// <param name="i1">Final row index.</param>
        /// <param name="j0">Initial column index.</param>
        /// <param name="j1">Final column index.</param>
        /// <returns>The specified submatrix.</returns>
        public Matrix GetMatrix(
            int i0,
            int i1,
            int j0,
            int j1)
        {
            var result = new Matrix(i1 - i0 + 1, j1 - j0 + 1);
            double[][] b = result.Data;
            try
            {
                for (int i = i0; i <= i1; i++)
                {
                    for (int j = j0; j <= j1; j++)
                    {
                        b[i - i0][j - j0] = matrix[i][j];
                    }
                }
            }
            catch (IndexOutOfRangeException)
            {

            }
            return result;
        }

        /// <summary>
        /// Get a submatrix.
        /// </summary>
        /// <param name="r">Array of row indices.</param>
        /// <param name="c">Array of column indices.</param>
        /// <returns>The specified submatrix.</returns>
        public Matrix GetMatrix(int[] r, int[] c)
        {
            var result = new Matrix(r.Length, c.Length);
            double[][] b = result.Data;
            try
            {
                for (int i = 0; i < r.Length; i++)
                {
                    for (int j = 0; j < c.Length; j++)
                    {
                        b[i][j] = matrix[r[i]][c[j]];
                    }
                }
            }
            catch (IndexOutOfRangeException)
            {

            }
            return result;
        }

        /// <summary>
        /// Get a submatrix.
        /// </summary>
        /// <param name="i0">Initial row index.</param>
        /// <param name="i1">Final row index.</param>
        /// <param name="c">Array of column indices.</param>
        /// <returns>The specified submatrix.</returns>
        public Matrix GetMatrix(
            int i0,
            int i1,
            int[] c)
        {
            var result = new Matrix(i1 - i0 + 1, c.Length);
            double[][] b = result.Data;
            try
            {
                for (int i = i0; i <= i1; i++)
                {
                    for (int j = 0; j < c.Length; j++)
                    {
                        b[i - i0][j] = matrix[i][c[j]];
                    }
                }
            }
            catch (IndexOutOfRangeException)
            {

            }
            return result;
        }

        /// <summary>
        /// Get a submatrix.
        /// </summary>
        /// <param name="r">Array of row indices.</param>
        /// <param name="j0">Initial column index</param>
        /// <param name="j1">Final column index</param>
        /// <returns>The specified submatrix.</returns>
        public Matrix GetMatrix(
            int[] r,
            int j0,
            int j1)
        {
            var result = new Matrix(r.Length, j1 - j0 + 1);
            double[][] b = result.Data;
            try
            {
                for (int i = 0; i < r.Length; i++)
                {
                    for (int j = j0; j <= j1; j++)
                    {
                        b[i][j - j0] = matrix[r[i]][j];
                    }
                }
            }
            catch (IndexOutOfRangeException)
            {

            }
            return result;
        }

        /// <summary>
        /// Multiply every row by the specified vector.
        /// </summary>
        /// <param name="vector">The vector to multiply by.</param>
        /// <param name="result">The result to hold the values.</param>
        public void Multiply(double[] vector, double[] result)
        {
            for (int i = 0; i < Rows; i++)
            {
                result[i] = 0;
                for (int j = 0; j < Cols; j++)
                {
                    result[i] += matrix[i][j] * vector[j];
                }
            }
        }

        /// <summary>
        /// The matrix inverted.
        /// </summary>
        /// <returns>The inverse of the matrix.</returns>
        public Matrix Inverse()
        {
            return Solve(MatrixMath.Identity(Rows));
        }


        /// <summary>
        /// Solve A*X = B
        /// </summary>
        /// <param name="b">right hand side.</param>
        /// <returns>Solution if A is square, least squares solution otherwise.</returns>
        public Matrix Solve(Matrix b)
        {
            if (Rows == Cols)
            {
                return (new LUDecomposition(this)).Solve(b);
            }
            else
            {
                return (new QRDecomposition(this)).Solve(b);
            }
        }

        /// <summary>
        /// Set a submatrix.
        /// </summary>
        /// <param name="i0">Initial row index</param>
        /// <param name="i1">Final row index</param>
        /// <param name="j0">Initial column index</param>
        /// <param name="j1">Final column index</param>
        /// <param name="x">A(i0:i1,j0:j1)</param>
        public void SetMatrix(
            int i0,
            int i1,
            int j0,
            int j1,
            Matrix x)
        {
            try
            {
                for (int i = i0; i <= i1; i++)
                {
                    for (int j = j0; j <= j1; j++)
                    {
                        matrix[i][j] = x[i - i0, j - j0];
                    }
                }
            }
            catch (IndexOutOfRangeException)
            {

            }
        }


        /// <summary>
        /// Set a submatrix.
        /// </summary>
        /// <param name="r">Array of row indices.</param>
        /// <param name="c">Array of column indices.</param>
        /// <param name="x">The matrix to set.</param>
        public void SetMatrix(
            int[] r,
            int[] c,
            Matrix x)
        {
            try
            {
                for (int i = 0; i < r.Length; i++)
                {
                    for (int j = 0; j < c.Length; j++)
                    {
                        matrix[r[i]][c[j]] = x[i, j];
                    }
                }
            }
            catch (IndexOutOfRangeException)
            {
                throw new MatrixError("Submatrix indices");
            }
        }

        /// <summary>
        /// Set a submatrix.
        /// </summary>
        /// <param name="r">Array of row indices.</param>
        /// <param name="j0">Initial column index</param>
        /// <param name="j1">Final column index</param>
        /// <param name="x">A(r(:),j0:j1)</param>
        public void SetMatrix(
            int[] r,
            int j0,
            int j1,
            Matrix x)
        {
            try
            {
                for (int i = 0; i < r.Length; i++)
                {
                    for (int j = j0; j <= j1; j++)
                    {
                        matrix[r[i]][j] = x[i, j - j0];
                    }
                }
            }
            catch (IndexOutOfRangeException)
            {
                throw new MatrixError("Submatrix indices");
            }
        }

        /// <summary>
        /// Set a submatrix. 
        /// </summary>
        /// <param name="i0">Initial row index</param>
        /// <param name="i1">Final row index</param>
        /// <param name="c">Array of column indices.</param>
        /// <param name="x">The submatrix.</param>
        public void SetMatrix(
            int i0,
            int i1,
            int[] c,
            Matrix x)
        {
            try
            {
                for (int i = i0; i <= i1; i++)
                {
                    for (int j = 0; j < c.Length; j++)
                    {
                        matrix[i][c[j]] = x[i - i0, j];
                    }
                }
            }
            catch (IndexOutOfRangeException)
            {
                throw new MatrixError("Submatrix indices");
            }
        }

        /// <summary>
        /// Randomize the matrix.
        /// </summary>
        ///
        /// <param name="min">Minimum random value.</param>
        /// <param name="max">Maximum random value.</param>
        public void Randomize(double min, double max)
        {
            for (int row = 0; row < Rows; row++)
            {
                for (int col = 0; col < Cols; col++)
                {
                    matrix[row][col] = RangeRandomizer.Randomize(min, max);
                }
            }
        }
    }

    public class MatrixError : SyntError
    {
        /// <summary>
        /// Construct a message exception.
        /// </summary>
        /// <param name="str">The message.</param>
        public MatrixError(String str)
            : base(str)
        {
        }

        /// <summary>
        /// Pass on an exception.
        /// </summary>
        /// <param name="e">The other exception.</param>
        public MatrixError(Exception e)
            : base(e)
        {
        }
    }

    public class MatrixMath
    {

        private MatrixMath()
        {
        }


        public static Matrix Add(Matrix a, Matrix b)
        {
            if (a.Rows != b.Rows)
            {

            }

            if (a.Cols != b.Cols)
            {

            }

            var result = new double[a.Rows][];
            double[][] aData = a.Data;
            double[][] bData = b.Data;

            for (int resultRow = 0; resultRow < a.Rows; resultRow++)
            {
                result[resultRow] = new double[a.Cols];
                for (int resultCol = 0; resultCol < a.Cols; resultCol++)
                {
                    result[resultRow][resultCol] = aData[resultRow][resultCol]
                                                   + bData[resultRow][resultCol];
                }
            }

            return new Matrix(result);
        }

        public static void Copy(Matrix source, Matrix target)
        {
            double[][] sourceData = source.Data;
            double[][] targetData = target.Data;

            for (int row = 0; row < source.Rows; row++)
            {
                for (int col = 0; col < source.Cols; col++)
                {
                    targetData[row][col] = sourceData[row][col];
                }
            }
        }


        public static Matrix DeleteCol(Matrix matrix, int deleted)
        {
            if (deleted >= matrix.Cols)
            {

            }
            var newMatrix = new double[matrix.Rows][];
            double[][] matrixData = matrix.Data;

            for (int row = 0; row < matrix.Rows; row++)
            {
                int targetCol = 0;

                newMatrix[row] = new double[matrix.Cols - 1];

                for (int col = 0; col < matrix.Cols; col++)
                {
                    if (col != deleted)
                    {
                        newMatrix[row][targetCol] = matrixData[row][col];
                        targetCol++;
                    }
                }
            }
            return new Matrix(newMatrix);
        }

        public static Matrix DeleteRow(Matrix matrix, int deleted)
        {
            if (deleted >= matrix.Rows)
            {

            }
            var newMatrix = new double[matrix.Rows - 1][];
            double[][] matrixData = matrix.Data;

            int targetRow = 0;
            for (int row = 0; row < matrix.Rows; row++)
            {
                if (row != deleted)
                {
                    newMatrix[targetRow] = new double[matrix.Cols];
                    for (int col = 0; col < matrix.Cols; col++)
                    {
                        newMatrix[targetRow][col] = matrixData[row][col];
                    }
                    targetRow++;
                }
            }
            return new Matrix(newMatrix);
        }


        public static Matrix Divide(Matrix a, double b)
        {
            var result = new double[a.Rows][];
            double[][] aData = a.Data;
            for (int row = 0; row < a.Rows; row++)
            {
                result[row] = new double[a.Cols];
                for (int col = 0; col < a.Cols; col++)
                {
                    result[row][col] = aData[row][col] / b;
                }
            }
            return new Matrix(result);
        }


        public static double DotProduct(Matrix a, Matrix b)
        {
            if (!a.IsVector() || !b.IsVector())
            {

            }

            Double[] aArray = a.ToPackedArray();
            Double[] bArray = b.ToPackedArray();

            if (aArray.Length != bArray.Length)
            {

            }

            double result = 0;
            int length = aArray.Length;

            for (int i = 0; i < length; i++)
            {
                result += aArray[i] * bArray[i];
            }

            return result;
        }


        public static Matrix Identity(int size)
        {
            if (size < 1)
            {

            }

            var result = new Matrix(size, size);
            double[][] resultData = result.Data;

            for (int i = 0; i < size; i++)
            {
                resultData[i][i] = 1;
            }

            return result;
        }

        /// <summary>
        /// Multiply every cell in the matrix by the specified value.
        /// </summary>
        /// <param name="a">Multiply every cell in a matrix by the specified value.</param>
        /// <param name="b">The value to multiply by.</param>
        /// <returns>The new multiplied matrix.</returns>
        public static Matrix Multiply(Matrix a, double b)
        {
            var result = new double[a.Rows][];
            double[][] aData = a.Data;

            for (int row = 0; row < a.Rows; row++)
            {
                result[row] = new double[a.Cols];
                for (int col = 0; col < a.Cols; col++)
                {
                    result[row][col] = aData[row][col] * b;
                }
            }
            return new Matrix(result);
        }

        /// <summary>
        /// Multiply two matrixes.
        /// </summary>
        /// <param name="a">The first matrix.</param>
        /// <param name="b">The second matrix.</param>
        /// <returns>The resulting matrix.</returns>
        public static Matrix Multiply(Matrix a, Matrix b)
        {
            if (a.Cols != b.Rows)
            {

            }

            var result = new double[a.Rows][];
            double[][] aData = a.Data;
            double[][] bData = b.Data;

            for (int resultRow = 0; resultRow < a.Rows; resultRow++)
            {
                result[resultRow] = new double[b.Cols];
                for (int resultCol = 0; resultCol < b.Cols; resultCol++)
                {
                    double value = 0;

                    for (int i = 0; i < a.Cols; i++)
                    {
                        value += aData[resultRow][i] * bData[i][resultCol];
                    }
                    result[resultRow][resultCol] = value;
                }
            }

            return new Matrix(result);
        }

        /// <summary>
        /// Subtract one matrix from another.  The two matrixes must have the same number of rows and columns.
        /// </summary>
        /// <param name="a">The first matrix.</param>
        /// <param name="b">The second matrix.</param>
        /// <returns>The subtracted matrix.</returns>
        public static Matrix Subtract(Matrix a, Matrix b)
        {
            if (a.Rows != b.Rows)
            {

            }

            if (a.Cols != b.Cols)
            {

            }

            var result = new double[a.Rows][];
            double[][] aData = a.Data;
            double[][] bData = b.Data;

            for (int resultRow = 0; resultRow < a.Rows; resultRow++)
            {
                result[resultRow] = new double[a.Cols];
                for (int resultCol = 0; resultCol < a.Cols; resultCol++)
                {
                    result[resultRow][resultCol] = aData[resultRow][resultCol]
                                                   - bData[resultRow][resultCol];
                }
            }

            return new Matrix(result);
        }

        /// <summary>
        /// Transpose the specified matrix.
        /// </summary>
        /// <param name="input">The matrix to transpose.</param>
        /// <returns>The transposed matrix.</returns>
        public static Matrix Transpose(Matrix input)
        {
            var inverseMatrix = new double[input.Cols][];
            double[][] inputData = input.Data;

            for (int r = 0; r < input.Cols; r++)
            {
                inverseMatrix[r] = new double[input.Rows];
                for (int c = 0; c < input.Rows; c++)
                {
                    inverseMatrix[r][c] = inputData[c][r];
                }
            }

            return new Matrix(inverseMatrix);
        }

        /// <summary>
        /// Calculate the vector length of the matrix.
        /// </summary>
        /// <param name="input">The vector to calculate for.</param>
        /// <returns>The vector length.</returns>
        public static double VectorLength(Matrix input)
        {
            if (!input.IsVector())
            {

            }
            Double[] v = input.ToPackedArray();
            double rtn = 0.0;
            for (int i = 0; i < v.Length; i++)
            {
                rtn += Math.Pow(v[i], 2);
            }
            return Math.Sqrt(rtn);
        }

        /// <summary>
        /// Multiply the matrix by a vector.
        /// </summary>
        /// <param name="a">The matrix.</param>
        /// <param name="d">The vector.</param>
        /// <returns>The resulting vector.</returns>
        public static double[] Multiply(Matrix a, double[] d)
        {
            double[] p = new double[a.Rows];
            double[][] aData = a.Data;

            for (int r = 0; r < a.Rows; r++)
                for (int i = 0; i < a.Cols; i++)
                    p[r] += aData[r][i] * d[i];

            return p;
        }
    }

    [Serializable]
    public class BasicNetwork : BasicML, IContainsFlat, IMLContext,
                              IMLRegression, IMLEncodable, IMLResettable, IMLClassification, IMLError
    {
        /// <summary>
        /// Tag used for the connection limit.
        /// </summary>
        ///
        public const String TagLimit = "CONNECTION_LIMIT";

        /// <summary>
        /// The default connection limit.
        /// </summary>
        ///
        public const double DefaultConnectionLimit = 0.0000000001d;

        /// <summary>
        /// The property for connection limit.
        /// </summary>
        ///
        public const String TagConnectionLimit = "connectionLimit";

        /// <summary>
        /// The property for begin training.
        /// </summary>
        ///
        public const String TagBeginTraining = "beginTraining";

        /// <summary>
        /// The property for context target offset.
        /// </summary>
        ///
        public const String TagContextTargetOffset = "contextTargetOffset";

        /// <summary>
        /// The property for context target size.
        /// </summary>
        ///
        public const String TagContextTargetSize = "contextTargetSize";

        /// <summary>
        /// The property for end training.
        /// </summary>
        ///
        public const String TagEndTraining = "endTraining";

        /// <summary>
        /// The property for has context.
        /// </summary>
        ///
        public const String TagHasContext = "hasContext";

        /// <summary>
        /// The property for layer counts.
        /// </summary>
        ///
        public const String TagLayerCounts = "layerCounts";

        /// <summary>
        /// The property for layer feed counts.
        /// </summary>
        ///
        public const String TagLayerFeedCounts = "layerFeedCounts";

        /// <summary>
        /// The property for layer index.
        /// </summary>
        ///
        public const String TagLayerIndex = "layerIndex";

        /// <summary>
        /// The property for weight index.
        /// </summary>
        ///
        public const String TagWeightIndex = "weightIndex";

        /// <summary>
        /// The property for bias activation.
        /// </summary>
        ///
        public const String TagBiasActivation = "biasActivation";

        /// <summary>
        /// The property for layer context count.
        /// </summary>
        ///
        public const String TagLayerContextCount = "layerContextCount";

        /// <summary>
        /// Holds the structure of the network. This keeps the network from having to
        /// constantly lookup layers and synapses.
        /// </summary>
        ///
        private readonly NeuralStructure _structure;

        /// <summary>
        /// Construct an empty neural network.
        /// </summary>
        ///
        public BasicNetwork()
        {
            _structure = new NeuralStructure(this);
        }

        /// <value>The layer count.</value>
        public int LayerCount
        {
            get
            {
                _structure.RequireFlat();
                return _structure.Flat.LayerCounts.Length;
            }
        }

        /// <value>Get the structure of the neural network. The structure allows you
        /// to quickly obtain synapses and layers without traversing the
        /// network.</value>
        public NeuralStructure Structure
        {
            get { return _structure; }
        }

        /// <summary>
        /// Sets the bias activation for every layer that supports bias. Make sure
        /// that the network structure has been finalized before calling this method.
        /// </summary>
        public double BiasActivation
        {
            set
            {
                // first, see what mode we are on. If the network has not been
                // finalized, set the layers
                if (_structure.Flat == null)
                {
                    foreach (ILayer layer in _structure.Layers)
                    {
                        if (layer.HasBias())
                        {
                            layer.BiasActivation = value;
                        }
                    }
                }
                else
                {
                    for (int i = 0; i < LayerCount; i++)
                    {
                        if (IsLayerBiased(i))
                        {
                            SetLayerBiasActivation(i, value);
                        }
                    }
                }
            }
        }

        #region ContainsFlat Members

        /// <inheritdoc/>
        public FlatNetwork Flat
        {
            get { return Structure.Flat; }
        }

        #endregion

        #region MLClassification Members

        /// <inheritdoc/>
        public int Classify(IMLData input)
        {
            return Winner(input);
        }

        #endregion

        #region MLContext Members

        /// <summary>
        /// Clear any data from any context layers.
        /// </summary>
        ///
        public void ClearContext()
        {
            if (_structure.Flat != null)
            {
                _structure.Flat.ClearContext();
            }
        }

        #endregion

        #region MLEncodable Members

        /// <inheritdoc/>
        public void DecodeFromArray(double[] Syntesisd)
        {
            _structure.RequireFlat();
            double[] weights = _structure.Flat.Weights;
            if (weights.Length != Syntesisd.Length)
            {

            }

            EngineArray.ArrayCopy(Syntesisd, weights);
        }

        /// <inheritdoc/>
        public int SyntesisdArrayLength()
        {
            _structure.RequireFlat();
            return _structure.Flat.SyntesisLength;
        }

        /// <inheritdoc/>
        public void SyntesisToArray(double[] Syntesisd)
        {
            _structure.RequireFlat();
            double[] weights = _structure.Flat.Weights;
            if (weights.Length != Syntesisd.Length)
            {

            }

            EngineArray.ArrayCopy(weights, Syntesisd);
        }

        #endregion

        #region MLError Members

        /// <summary>
        /// Calculate the error for this neural network.
        /// </summary>
        ///
        /// <param name="data">The training set.</param>
        /// <returns>The error percentage.</returns>
        public double CalculateError(IMLDataSet data)
        {
            return SyntUtility.CalculateRegressionError(this, data);
        }

        #endregion

        #region MLRegression Members

        /// <summary>
        /// Compute the output for a given input to the neural network.
        /// </summary>
        ///
        /// <param name="input">The input to the neural network.</param>
        /// <returns>The output from the neural network.</returns>
        public IMLData Compute(IMLData input)
        {
           
                IMLData result = new BasicMLData(_structure.Flat.OutputCount);
                _structure.Flat.Compute(input.Data, result.Data);
                return result;
          
            
        }

        /// <inheritdoc/>
        public virtual int InputCount
        {
            get
            {
                _structure.RequireFlat();
                return Structure.Flat.InputCount;
            }
        }

        /// <inheritdoc/>
        public virtual int OutputCount
        {
            get
            {
                _structure.RequireFlat();
                return Structure.Flat.OutputCount;
            }
        }

        #endregion

        #region MLResettable Members

        /// <summary>
        /// Reset the weight matrix and the bias values. This will use a
        /// Nguyen-Widrow randomizer with a range between -1 and 1. If the network
        /// does not have an input, output or hidden layers, then Nguyen-Widrow
        /// cannot be used and a simple range randomize between -1 and 1 will be
        /// used.
        /// </summary>
        ///
        public void Reset()
        {
            if (LayerCount < 3)
            {
                (new RangeRandomizer(-1, 1)).Randomize(this);
            }
            else
            {
                (new NguyenWidrowRandomizer()).Randomize(this);
            }
        }

        /// <summary>
        /// Reset the weight matrix and the bias values. This will use a
        /// Nguyen-Widrow randomizer with a range between -1 and 1. If the network
        /// does not have an input, output or hidden layers, then Nguyen-Widrow
        /// cannot be used and a simple range randomize between -1 and 1 will be
        /// used.
        /// Use the specified seed.
        /// </summary>
        ///
        public void Reset(int seed)
        {
            Reset();
        }

        #endregion

        /// <summary>
        /// Add a layer to the neural network. If there are no layers added this
        /// layer will become the input layer. This function automatically updates
        /// both the input and output layer references.
        /// </summary>
        ///
        /// <param name="layer">The layer to be added to the network.</param>
        public void AddLayer(ILayer layer)
        {
            layer.Network = this;
            _structure.Layers.Add(layer);
        }

        /// <summary>
        /// Add to a weight.
        /// </summary>
        ///
        /// <param name="fromLayer">The from layer.</param>
        /// <param name="fromNeuron">The from neuron.</param>
        /// <param name="toNeuron">The to neuron.</param>
        /// <param name="v">The value to add.</param>
        public void AddWeight(int fromLayer, int fromNeuron,
                              int toNeuron, double v)
        {
            double old = GetWeight(fromLayer, fromNeuron, toNeuron);
            SetWeight(fromLayer, fromNeuron, toNeuron, old + v);
        }

        /// <summary>
        /// Calculate the total number of neurons in the network across all layers.
        /// </summary>
        ///
        /// <returns>The neuron count.</returns>
        public int CalculateNeuronCount()
        {
            int result = 0;

            foreach (ILayer layer in _structure.Layers)
            {
                result += layer.NeuronCount;
            }
            return result;
        }

        /// <summary>
        /// Return a clone of this neural network. Including structure, weights and
        /// bias values. This is a deep copy.
        /// </summary>
        ///
        /// <returns>A cloned copy of the neural network.</returns>
        public Object Clone()
        {
            var result = (BasicNetwork)ObjectCloner.DeepCopy(this);
            return result;
        }

        /// <summary>
        /// Compute the output for this network.
        /// </summary>
        ///
        /// <param name="input">The input.</param>
        /// <param name="output">The output.</param>
        public void Compute(double[] input, double[] output)
        {
            var input2 = new BasicMLData(input);
            IMLData output2 = Compute(input2);
            EngineArray.ArrayCopy(output2.Data, output);
        }


        /// <returns>The weights as a comma separated list.</returns>
        public String DumpWeights()
        {
            var result = new StringBuilder();
            NumberList.ToList(CSVFormat.EgFormat, result, _structure.Flat.Weights);
            return result.ToString();
        }

        /// <summary>
        /// Enable, or disable, a connection.
        /// </summary>
        ///
        /// <param name="fromLayer">The layer that contains the from neuron.</param>
        /// <param name="fromNeuron">The source neuron.</param>
        /// <param name="toNeuron">The target connection.</param>
        /// <param name="enable">True to enable, false to disable.</param>
        public void EnableConnection(int fromLayer,
                                     int fromNeuron, int toNeuron, bool enable)
        {
            double v = GetWeight(fromLayer, fromNeuron, toNeuron);

            if (enable)
            {
                if (!_structure.ConnectionLimited)
                {
                    return;
                }

                if (Math.Abs(v) < _structure.ConnectionLimit)
                {
                    SetWeight(fromLayer, fromNeuron, toNeuron,
                              RangeRandomizer.Randomize(-1, 1));
                }
            }
            else
            {
                if (!_structure.ConnectionLimited)
                {
                    SetProperty(TagLimit,
                                DefaultConnectionLimit);
                    _structure.UpdateProperties();
                }
                SetWeight(fromLayer, fromNeuron, toNeuron, 0);
            }
        }

        /// <summary>
        /// Compare the two neural networks. For them to be equal they must be of the
        /// same structure, and have the same matrix values.
        /// </summary>
        ///
        /// <param name="other">The other neural network.</param>
        ///// <returns>True if the two networks are equal.</returns>
        //public bool Equals(BasicNetwork other)
        //{
        //    return Equals(other, SyntFramework.DefaultPrecision);
        //}

        /// <summary>
        /// Determine if this neural network is equal to another. Equal neural
        /// networks have the same weight matrix and bias values, within a specified
        /// precision.
        /// </summary>
        ///
        /// <param name="other">The other neural network.</param>
        /// <param name="precision">The number of decimal places to compare to.</param>
        /// <returns>True if the two neural networks are equal.</returns>
        //public bool Equals(BasicNetwork other, int precision)
        //{
        //    return NetworkCODEC.Equals(this, other, precision);
        //}

        /// <summary>
        /// Get the activation function for the specified layer.
        /// </summary>
        ///
        /// <param name="layer">The layer.</param>
        /// <returns>The activation function.</returns>
        public IActivationFunction GetActivation(int layer)
        {
            _structure.RequireFlat();
            int layerNumber = LayerCount - layer - 1;
            return _structure.Flat.ActivationFunctions[layerNumber];
        }


        /// <summary>
        /// Get the bias activation for the specified layer.
        /// </summary>
        ///
        /// <param name="l">The layer.</param>
        /// <returns>The bias activation.</returns>
        public double GetLayerBiasActivation(int l)
        {
            if (!IsLayerBiased(l))
            {

            }

            _structure.RequireFlat();
            int layerNumber = LayerCount - l - 1;

            int layerOutputIndex = _structure.Flat.LayerIndex[layerNumber];
            int count = _structure.Flat.LayerCounts[layerNumber];
            return _structure.Flat.LayerOutput[layerOutputIndex
                                              + count - 1];
        }


        /// <summary>
        /// Get the neuron count.
        /// </summary>
        ///
        /// <param name="l">The layer.</param>
        /// <returns>The neuron count.</returns>
        public int GetLayerNeuronCount(int l)
        {
            _structure.RequireFlat();
            int layerNumber = LayerCount - l - 1;
            return _structure.Flat.LayerFeedCounts[layerNumber];
        }

        /// <summary>
        /// Get the layer output for the specified neuron.
        /// </summary>
        ///
        /// <param name="layer">The layer.</param>
        /// <param name="neuronNumber">The neuron number.</param>
        /// <returns>The output from the last call to compute.</returns>
        public double GetLayerOutput(int layer, int neuronNumber)
        {
            _structure.RequireFlat();
            int layerNumber = LayerCount - layer - 1;
            int index = _structure.Flat.LayerIndex[layerNumber]
                        + neuronNumber;
            double[] output = _structure.Flat.LayerOutput;
            if (index >= output.Length)
            {

            }
            return output[index];
        }

        /// <summary>
        /// Get the total (including bias and context) neuron cont for a layer.
        /// </summary>
        ///
        /// <param name="l">The layer.</param>
        /// <returns>The count.</returns>
        public int GetLayerTotalNeuronCount(int l)
        {
            _structure.RequireFlat();
            int layerNumber = LayerCount - l - 1;
            return _structure.Flat.LayerCounts[layerNumber];
        }


        /// <summary>
        /// Get the weight between the two layers.
        /// </summary>
        ///
        /// <param name="fromLayer">The from layer.</param>
        /// <param name="fromNeuron">The from neuron.</param>
        /// <param name="toNeuron">The to neuron.</param>
        /// <returns>The weight value.</returns>
        public double GetWeight(int fromLayer, int fromNeuron,
                                int toNeuron)
        {
            _structure.RequireFlat();
            ValidateNeuron(fromLayer, fromNeuron);
            ValidateNeuron(fromLayer + 1, toNeuron);
            int fromLayerNumber = LayerCount - fromLayer - 1;
            int toLayerNumber = fromLayerNumber - 1;

            if (toLayerNumber < 0)
            {
                throw new NeuralNetworkError(
                    "The specified layer is not connected to another layer: "
                    + fromLayer);
            }

            int weightBaseIndex = _structure.Flat.WeightIndex[toLayerNumber];
            int count = _structure.Flat.LayerCounts[fromLayerNumber];
            int weightIndex = weightBaseIndex + fromNeuron
                              + (toNeuron * count);

            return _structure.Flat.Weights[weightIndex];
        }

        /// <summary>
        /// Generate a hash code.
        /// </summary>
        ///
        /// <returns>THe hash code.</returns>
        public override sealed int GetHashCode()
        {
            return base.GetHashCode();
        }

        public bool IsConnected(int layer, int fromNeuron,
                                int toNeuron)
        {
            /*
			 * if (!this.structure.isConnectionLimited()) { return true; } final
			 * double value = synapse.getMatrix().get(fromNeuron, toNeuron);
			 * 
			 * return (Math.abs(value) > this.structure.getConnectionLimit());
			 */
            return false;
        }


        public bool IsLayerBiased(int l)
        {
            _structure.RequireFlat();
            int layerNumber = LayerCount - l - 1;
            return _structure.Flat.LayerCounts[layerNumber] != _structure.Flat.LayerFeedCounts[layerNumber];
        }


        public void SetLayerBiasActivation(int l, double v)
        {
            if (!IsLayerBiased(l))
            {
                throw new NeuralNetworkError(
                    "Error, the specified layer does not have a bias: " + l);
            }

            _structure.RequireFlat();
            int layerNumber = LayerCount - l - 1;

            int layerOutputIndex = _structure.Flat.LayerIndex[layerNumber];
            int count = _structure.Flat.LayerCounts[layerNumber];
            _structure.Flat.LayerOutput[layerOutputIndex + count - 1] = v;
        }


        public void SetWeight(int fromLayer, int fromNeuron,
                              int toNeuron, double v)
        {
            _structure.RequireFlat();
            int fromLayerNumber = LayerCount - fromLayer - 1;
            int toLayerNumber = fromLayerNumber - 1;

            if (toLayerNumber < 0)
            {

            }

            int weightBaseIndex = _structure.Flat.WeightIndex[toLayerNumber];
            int count = _structure.Flat.LayerCounts[fromLayerNumber];
            int weightIndex = weightBaseIndex + fromNeuron
                              + (toNeuron * count);

            _structure.Flat.Weights[weightIndex] = v;
        }

        /// <summary>
        /// 
        /// </summary>
        ///
        public override sealed String ToString()
        {
            var builder = new StringBuilder();
            builder.Append("[BasicNetwork: Layers=");

            int layers = _structure.Flat == null ? _structure.Layers.Count : _structure.Flat.LayerCounts.Length;

            builder.Append(layers);
            builder.Append("]");
            return builder.ToString();
        }

        /// <summary>
        /// 
        /// </summary>
        ///
        public override sealed void UpdateProperties()
        {
            _structure.UpdateProperties();
        }

        /// <summary>
        /// Validate the the specified targetLayer and neuron are valid.
        /// </summary>
        ///
        /// <param name="targetLayer">The target layer.</param>
        /// <param name="neuron">The target neuron.</param>
        public void ValidateNeuron(int targetLayer, int neuron)
        {
            if ((targetLayer < 0) || (targetLayer >= LayerCount))
            {

            }

            if ((neuron < 0) || (neuron >= GetLayerTotalNeuronCount(targetLayer)))
            {

            }
        }

        /// <summary>
        /// Determine the winner for the specified input. This is the number of the
        /// winning neuron.
        /// </summary>
        ///
        /// <param name="input">The input patter to present to the neural network.</param>
        /// <returns>The winning neuron.</returns>
        public int Winner(IMLData input)
        {
            IMLData output = Compute(input);
            return EngineArray.MaxIndex(output.Data);
        }
    }

    public class BasicLayer : FlatLayer, ILayer
    {
        /// <summary>
        /// The network that this layer belongs to.
        /// </summary>
        ///
        private BasicNetwork _network;

        /// <summary>
        /// Construct this layer with a non-default activation function, also
        /// determine if a bias is desired or not.
        /// </summary>
        ///
        /// <param name="activationFunction">The activation function to use.</param>
        /// <param name="neuronCount">How many neurons in this layer.</param>
        /// <param name="hasBias">True if this layer has a bias.</param>
        public BasicLayer(IActivationFunction activationFunction,
                          bool hasBias, int neuronCount)
            : base(activationFunction, neuronCount, (hasBias) ? 1.0d : 0.0d)
        {
        }

        /// <summary>
        /// Construct this layer with a sigmoid activation function.
        /// </summary>
        public BasicLayer(int neuronCount) : this(new ActivationTANH(), true, neuronCount)
        {
        }

        #region Layer Members

        /// <summary>
        /// Set the network for this layer.
        /// </summary>
        public virtual BasicNetwork Network
        {
            get { return _network; }
            set { _network = value; }
        }

        /// <summary>
        /// THe neuron count.
        /// </summary>
        public virtual int NeuronCount
        {
            get { return Count; }
        }

        /// <summary>
        /// The activation function.
        /// </summary>
        public virtual IActivationFunction ActivationFunction
        {
            get { return Activation; }
        }

        #endregion
    }

    public class AnalyzeNetwork
    {
        /// <summary>
        /// All of the values in the neural network.
        /// </summary>
        ///
        private readonly double[] _allValues;

        /// <summary>
        /// The ranges of the bias values.
        /// </summary>
        ///
        private readonly NumericRange _bias;

        /// <summary>
        /// The bias values in the neural network.
        /// </summary>
        ///
        private readonly double[] _biasValues;

        /// <summary>
        /// The number of disabled connections.
        /// </summary>
        ///
        private readonly int _disabledConnections;

        /// <summary>
        /// The total number of connections.
        /// </summary>
        ///
        private readonly int _totalConnections;

        /// <summary>
        /// The weight values in the neural network.
        /// </summary>
        ///
        private readonly double[] _weightValues;

        /// <summary>
        /// The ranges of the weights.
        /// </summary>
        ///
        private readonly NumericRange _weights;

        /// <summary>
        /// The ranges of both the weights and biases.
        /// </summary>
        ///
        private readonly NumericRange _weightsAndBias;

        /// <summary>
        /// Construct a network analyze class. Analyze the specified network.
        /// </summary>
        ///
        /// <param name="network">The network to analyze.</param>
        public AnalyzeNetwork(BasicNetwork network)
        {
            int assignDisabled = 0;
            int assignedTotal = 0;
            IList<Double> biasList = new List<Double>();
            IList<Double> weightList = new List<Double>();
            IList<Double> allList = new List<Double>();

            for (int layerNumber = 0; layerNumber < network.LayerCount - 1; layerNumber++)
            {

                int fromCount = network.GetLayerNeuronCount(layerNumber);
                int fromBiasCount = network
                    .GetLayerTotalNeuronCount(layerNumber);
                int toCount = network.GetLayerNeuronCount(layerNumber + 1);

                // weights
                for (int fromNeuron = 0; fromNeuron < fromCount; fromNeuron++)
                {
                    for (int toNeuron = 0; toNeuron < toCount; toNeuron++)
                    {
                        double v = network.GetWeight(layerNumber, fromNeuron,
                                                     toNeuron);

                        if (network.Structure.ConnectionLimited)
                        {
                            if (Math.Abs(v) < network.Structure.ConnectionLimit)
                            {
                                assignDisabled++;
                            }
                        }

                        weightList.Add(v);
                        allList.Add(v);
                        assignedTotal++;
                    }
                }

                // bias
                if (fromCount != fromBiasCount)
                {
                    int biasNeuron = fromCount;
                    for (int toNeuron = 0; toNeuron < toCount; toNeuron++)
                    {
                        double v = network.GetWeight(layerNumber, biasNeuron,
                                                       toNeuron);
                        if (network.Structure.ConnectionLimited)
                        {
                            if (Math.Abs(v) < network.Structure.ConnectionLimit)
                            {
                                assignDisabled++;
                            }
                        }

                        biasList.Add(v);
                        allList.Add(v);
                        assignedTotal++;
                    }
                }
            }

            _disabledConnections = assignDisabled;
            _totalConnections = assignedTotal;
            _weights = new NumericRange(weightList);
            _bias = new NumericRange(biasList);
            _weightsAndBias = new NumericRange(allList);
            _weightValues = EngineArray.ListToDouble(weightList);
            _allValues = EngineArray.ListToDouble(allList);
            _biasValues = EngineArray.ListToDouble(biasList);
        }


        /// <value>All of the values in the neural network.</value>
        public double[] AllValues
        {
            get { return _allValues; }
        }


        /// <value>The numeric range of the bias values.</value>
        public NumericRange Bias
        {
            get { return _bias; }
        }


        /// <value>The bias values in the neural network.</value>
        public double[] BiasValues
        {
            get { return _biasValues; }
        }


        /// <value>The number of disabled connections in the network.</value>
        public int DisabledConnections
        {
            get { return _disabledConnections; }
        }


        /// <value>The total number of connections in the network.</value>
        public int TotalConnections
        {
            get { return _totalConnections; }
        }


        /// <value>The numeric range of the weights values.</value>
        public NumericRange Weights
        {
            get { return _weights; }
        }


        /// <value>The numeric range of the weights and bias values.</value>
        public NumericRange WeightsAndBias
        {
            get { return _weightsAndBias; }
        }


        /// <value>The weight values in the neural network.</value>
        public double[] WeightValues
        {
            get { return _weightValues; }
        }


        /// <inheritdoc/>
        public override sealed String ToString()
        {
            var result = new StringBuilder();
            result.Append("All Values : ");
            result.Append((_weightsAndBias.ToString()));
            result.Append("\n");
            result.Append("Bias : ");
            result.Append((_bias.ToString()));
            result.Append("\n");
            result.Append("Weights    : ");
            result.Append((_weights.ToString()));
            result.Append("\n");
            result.Append("Disabled   : ");
            result.Append(Format.FormatInteger(_disabledConnections));
            result.Append("\n");
            return result.ToString();
        }
    }

    public static class NetworkCODEC
    {
        /// <summary>
        /// Error message.
        /// </summary>
        ///
        private const String Error = "This machine learning method cannot be Syntesisd:";

        /// <summary>
        /// Use an array to populate the memory of the neural network.
        /// </summary>
        ///
        /// <param name="array">An array of doubles.</param>
        /// <param name="network">The network to Syntesis.</param>
        public static void ArrayToNetwork(double[] array,
                                          IMLMethod network)
        {
            if (network is IMLEncodable)
            {
                ((IMLEncodable)network).DecodeFromArray(array);
                return;
            }

        }

        /// <summary>
        /// Determine if the two neural networks are equal. Uses exact precision
        /// required by Arrays.equals.
        /// </summary>
        ///
        /// <param name="network1">The first network.</param>
        /// <param name="network2">The second network.</param>
        /// <returns>True if the two networks are equal.</returns>
        public static bool Equals(BasicNetwork network1,
                                  BasicNetwork network2)
        {
            return Equals(network1, network2, SyntFramework.DefaultPrecision);
        }

        /// <summary>
        /// Determine if the two neural networks are equal.
        /// </summary>
        ///
        /// <param name="network1">The first network.</param>
        /// <param name="network2">The second network.</param>
        /// <param name="precision">How many decimal places to check.</param>
        /// <returns>True if the two networks are equal.</returns>
        public static bool Equals(BasicNetwork network1,
                                  BasicNetwork network2, int precision)
        {
            double[] array1 = NetworkToArray(network1);
            double[] array2 = NetworkToArray(network2);

            if (array1.Length != array2.Length)
            {
                return false;
            }

            double test = Math.Pow(10.0d, precision);
            if (Double.IsInfinity(test) || (test > Int64.MaxValue))
            {
            }

            for (int i = 0; i < array1.Length; i++)
            {
                var l1 = (long)(array1[i] * test);
                var l2 = (long)(array2[i] * test);
                if (l1 != l2)
                {
                    return false;
                }
            }

            return true;
        }

        /// <summary>
        /// Determine the network size.
        /// </summary>
        ///
        /// <param name="network">The network.</param>
        /// <returns>The size.</returns>
        public static int NetworkSize(IMLMethod network)
        {
            if (network is IMLEncodable)
            {
                return ((IMLEncodable)network).SyntesisdArrayLength();
            }
            else return -1;

        }

        /// <summary>
        /// Convert to an array. This is used with some training Algos that
        /// require that the "memory" of the neuron(the weight and bias values) be
        /// expressed as a linear array.
        /// </summary>
        ///
        /// <param name="network">The network to Syntesis.</param>
        /// <returns>The memory of the neuron.</returns>
        public static double[] NetworkToArray(IMLMethod network)
        {
            int size = NetworkSize(network);

            if (network is IMLEncodable)
            {
                var Syntesisd = new double[size];
                ((IMLEncodable)network).SyntesisToArray(Syntesisd);
                return Syntesisd;
            }
            else return null;
        }
    }

    [Serializable]
    public class NeuralStructure
    {
        /// <summary>
        /// The layers in this neural network.
        /// </summary>
        ///
        private readonly IList<ILayer> _layers;

        /// <summary>
        /// The neural network this class belongs to.
        /// </summary>
        ///
        private readonly BasicNetwork _network;

        /// <summary>
        /// The limit, below which a connection is treated as zero.
        /// </summary>
        ///
        private double _connectionLimit;

        /// <summary>
        /// Are connections limited?
        /// </summary>
        ///
        private bool _connectionLimited;

        /// <summary>
        /// The flattened form of the network.
        /// </summary>
        ///
        private FlatNetwork _flat;

        /// <summary>
        /// Construct a structure object for the specified network.
        /// </summary>
        public NeuralStructure(BasicNetwork network)
        {
            _layers = new List<ILayer>();
            _network = network;
        }


        /// <value>The connection limit.</value>
        public double ConnectionLimit
        {
            get { return _connectionLimit; }
        }


        /// <summary>
        /// Set the flat network.
        /// </summary>
        public FlatNetwork Flat
        {
            get
            {
                RequireFlat();
                return _flat;
            }
            set { _flat = value; }
        }


        /// <value>The layers in this neural network.</value>
        public IList<ILayer> Layers
        {
            get { return _layers; }
        }


        /// <value>The network this structure belongs to.</value>
        public BasicNetwork Network
        {
            get { return _network; }
        }


        /// <value>True if this is not a fully connected feedforward network.</value>
        public bool ConnectionLimited
        {
            get { return _connectionLimited; }
        }

        /// <summary>
        /// Calculate the size that an array should be to hold all of the weights and
        /// bias values.
        /// </summary>
        ///
        /// <returns>The size of the calculated array.</returns>
        public int CalculateSize()
        {
            return NetworkCODEC.NetworkSize(_network);
        }

        /// <summary>
        /// Enforce that all connections are above the connection limit. Any
        /// connections below this limit will be severed.
        /// </summary>
        ///
        public void EnforceLimit()
        {
            if (!_connectionLimited)
            {
                return;
            }

            double[] weights = _flat.Weights;

            for (int i = 0; i < weights.Length; i++)
            {
                if (Math.Abs(weights[i]) < _connectionLimit)
                {
                    weights[i] = 0;
                }
            }
        }

        /// <summary>
        /// Parse/finalize the limit value for connections.
        /// </summary>
        ///
        public void FinalizeLimit()
        {
            // see if there is a connection limit imposed
            String limit = _network
                .GetPropertyString(BasicNetwork.TagLimit);
            if (limit != null)
            {
                try
                {
                    _connectionLimited = true;
                    _connectionLimit = CSVFormat.EgFormat.Parse(limit);
                    EnforceLimit();
                }
                catch (FormatException)
                {

                }
            }
            else
            {
                _connectionLimited = false;
                _connectionLimit = 0;
            }
        }

        /// <summary>
        /// Build the synapse and layer structure. This method should be called after
        /// you are done adding layers to a network, or change the network's logic
        /// property.
        /// </summary>
        ///
        public void FinalizeStructure()
        {
            if (_layers.Count < 2)
            {
            }

            var flatLayers = new FlatLayer[_layers.Count];

            for (int i = 0; i < _layers.Count; i++)
            {
                var layer = (BasicLayer)_layers[i];
                if (layer.Activation == null)
                {
                    layer.Activation = new ActivationLinear();
                }

                flatLayers[i] = layer;
            }

            _flat = new FlatNetwork(flatLayers);

            FinalizeLimit();
            _layers.Clear();
            EnforceLimit();
        }


        /// <summary>
        /// Throw an error if there is no flat network.
        /// </summary>
        ///
        public void RequireFlat()
        {
            if (_flat == null)
            {

            }
        }

        /// <summary>
        /// Update any properties from the property map.
        /// </summary>
        ///
        public void UpdateProperties()
        {
            if (_network.Properties.ContainsKey(BasicNetwork.TagLimit))
            {
                _connectionLimit = _network
                    .GetPropertyDouble(BasicNetwork.TagLimit);
                _connectionLimited = true;
            }
            else
            {
                _connectionLimited = false;
                _connectionLimit = 0;
            }

            if (_flat != null)
            {
                _flat.ConnectionLimit = _connectionLimit;
            }
        }
    }

    public class NeuralSimulatedAnnealing : BasicTraining
    {
        /// <summary>
        /// The cutoff for random data.
        /// </summary>
        ///
        public const double Cut = 0.5d;

        /// <summary>
        /// This class actually performs the training.
        /// </summary>
        ///
        private readonly NeuralSimulatedAnnealingHelper _anneal;

        /// <summary>
        /// Used to calculate the score.
        /// </summary>
        ///
        private readonly ICalculateScore _calculateScore;

        /// <summary>
        /// The neural network that is to be trained.
        /// </summary>
        ///
        private readonly BasicNetwork _network;

        /// <summary>
        /// Construct a simulated annleaing trainer for a feedforward neural network.
        /// </summary>
        ///
        /// <param name="network">The neural network to be trained.</param>
        /// <param name="calculateScore">Used to calculate the score for a neural network.</param>
        /// <param name="startTemp">The starting temperature.</param>
        /// <param name="stopTemp">The ending temperature.</param>
        /// <param name="cycles">The number of cycles in a training iteration.</param>
        public NeuralSimulatedAnnealing(BasicNetwork network,
                                        ICalculateScore calculateScore, double startTemp,
                                        double stopTemp, int cycles) : base(TrainingImplementationType.Iterative)
        {
            _network = network;
            _calculateScore = calculateScore;
            _anneal = new NeuralSimulatedAnnealingHelper(this)
            {
                Temperature = startTemp,
                StartTemperature = startTemp,
                StopTemperature = stopTemp,
                Cycles = cycles
            };
        }

        /// <inheritdoc />
        public override sealed bool CanContinue
        {
            get { return false; }
        }

        /// <summary>
        /// Get the network as an array of doubles.
        /// </summary>
        public double[] Array
        {
            get
            {
                return NetworkCODEC
                    .NetworkToArray(_network);
            }
        }


        /// <value>A copy of the annealing array.</value>
        public double[] ArrayCopy
        {
            get { return Array; }
        }


        /// <value>The object used to calculate the score.</value>
        public ICalculateScore CalculateScore
        {
            get { return _calculateScore; }
        }


        /// <inheritdoc/>
        public override IMLMethod Method
        {
            get { return _network; }
        }


        /// <summary>
        /// Perform one iteration of simulated annealing.
        /// </summary>
        ///
        public override sealed void Iteration()
        {
            SyntLogging.Log(SyntLogging.LevelInfo,
                             "Performing Simulated Annealing iteration.");
            PreIteration();
            _anneal.Iteration();
            Error = _anneal.PerformCalculateScore();
            PostIteration();
        }

        /// <inheritdoc/>
        public override TrainingContinuation Pause()
        {
            return null;
        }

        /// <summary>
        /// Convert an array of doubles to the current best network.
        /// </summary>
        ///
        /// <param name="array">An array.</param>
        public void PutArray(double[] array)
        {
            NetworkCODEC.ArrayToNetwork(array,
                                        _network);
        }

        /// <summary>
        /// Randomize the weights and bias values. This function does most of the
        /// work of the class. Each call to this class will randomize the data
        /// according to the current temperature. The higher the temperature the more
        /// randomness.
        /// </summary>
        ///
        public void Randomize()
        {
            double[] array = NetworkCODEC
                .NetworkToArray(_network);

            for (int i = 0; i < array.Length; i++)
            {
                double add = Cut - ThreadSafeRandom.NextDouble();
                add /= _anneal.StartTemperature;
                add *= _anneal.Temperature;
                array[i] = array[i] + add;
            }

            NetworkCODEC.ArrayToNetwork(array,
                                        _network);
        }

        /// <inheritdoc/>
        public override void Resume(TrainingContinuation state)
        {
        }
    }

    public class NeuralSimulatedAnnealingHelper : SimulatedAnnealing<Double>
    {
        /// <summary>
        /// The class that this class should report to.
        /// </summary>
        ///
        private readonly NeuralSimulatedAnnealing _owner;

        /// <summary>
        /// Constructs this object.
        /// </summary>
        ///
        /// <param name="owner">The owner of this class, that recieves all messages.</param>
        public NeuralSimulatedAnnealingHelper(NeuralSimulatedAnnealing owner)
        {
            _owner = owner;
            ShouldMinimize = _owner.CalculateScore.ShouldMinimize;
        }

        /// <summary>
        /// Used to pass the getArray call on to the parent object.
        /// </summary>
        public override double[] Array
        {
            get { return _owner.Array; }
        }


        /// <summary>
        /// Used to pass the getArrayCopy call on to the parent object.
        /// </summary>
        ///
        /// <value>The array copy created by the owner.</value>
        public override double[] ArrayCopy
        {
            get { return _owner.ArrayCopy; }
        }

        /// <summary>
        /// Used to pass the determineError call on to the parent object.
        /// </summary>
        ///
        /// <returns>The error returned by the owner.</returns>
        public override sealed double PerformCalculateScore()
        {
            return _owner.CalculateScore.CalculateScore(((BasicNetwork)_owner.Method));
        }


        /// <summary>
        /// Used to pass the putArray call on to the parent object.
        /// </summary>
        ///
        /// <param name="array">The array.</param>
        public override sealed void PutArray(double[] array)
        {
            _owner.PutArray(array);
        }

        /// <summary>
        /// Call the owner's randomize method.
        /// </summary>
        ///
        public override sealed void Randomize()
        {
            _owner.Randomize();
        }
    }

   

    public class NetworkFold
    {
        /// <summary>
        /// The output for this fold.
        /// </summary>
        ///
        private readonly double[] _output;

        /// <summary>
        /// The weights for this fold.
        /// </summary>
        ///
        private readonly double[] _weights;

        /// <summary>
        /// Construct a fold from the specified flat network.
        /// </summary>
        ///
        /// <param name="flat">THe flat network.</param>
        public NetworkFold(FlatNetwork flat)
        {
            _weights = EngineArray.ArrayCopy(flat.Weights);
            _output = EngineArray.ArrayCopy(flat.LayerOutput);
        }


        /// <value>The network weights.</value>
        public double[] Weights
        {
            get { return _weights; }
        }


        /// <value>The network output.</value>
        public double[] Output
        {
            get { return _output; }
        }

        /// <summary>
        /// Copy weights and output to the network.
        /// </summary>
        ///
        /// <param name="target">The network to copy to.</param>
        public void CopyToNetwork(FlatNetwork target)
        {
            EngineArray.ArrayCopy(_weights, target.Weights);
            EngineArray.ArrayCopy(_output, target.LayerOutput);
        }

        /// <summary>
        /// Copy the weights and output from the network.
        /// </summary>
        ///
        /// <param name="source">The network to copy from.</param>
        public void CopyFromNetwork(FlatNetwork source)
        {
            EngineArray.ArrayCopy(source.Weights, _weights);
            EngineArray.ArrayCopy(source.LayerOutput, _output);
        }
    }

    public class GScoreAdapter : ICalculateTScore
    {
        /// <summary>
        /// The calculate score object to use.
        /// </summary>
        ///
        private readonly ICalculateScore _calculateScore;

        /// <summary>
        /// Construct the adapter.
        /// </summary>
        ///
        /// <param name="calculateScore">The CalculateScore object to use.</param>
        public GScoreAdapter(ICalculateScore calculateScore)
        {
            _calculateScore = calculateScore;
        }

        #region ICalculateTScore Members

        /// <summary>
        /// Calculate the T's score.
        /// </summary>
        ///
        /// <param name="T">The T to calculate for.</param>
        /// <returns>The calculated score.</returns>
        public double CalculateScore(IT T)
        {
            var network = (IMLRegression)T.Organism;
            return _calculateScore.CalculateScore(network);
        }


        /// <returns>True, if the score should be minimized.</returns>
        public bool ShouldMinimize
        {
            get { return _calculateScore.ShouldMinimize; }
        }

        #endregion
    }

    [Serializable]
    public class BasicPopulation : IPopulation
    {
        /// <summary>
        /// Thed default old age penalty.
        /// </summary>
        ///
        public const double DefaultOldAgePenalty = 0.3d;

        /// <summary>
        /// The default old age threshold.
        /// </summary>
        ///
        public const int DefaultOldAgeThreshold = 50;

        /// <summary>
        /// The default survival rate.
        /// </summary>
        ///
        public const double DefaultSurvivalRate = 0.2d;

        /// <summary>
        /// The default youth penalty.
        /// </summary>
        ///
        public const double DefaultYouthBonus = 0.3d;

        /// <summary>
        /// The default youth threshold.
        /// </summary>
        ///
        public const int DefaultYouthThreshold = 10;

        /// <summary>
        /// Generate gene id's.
        /// </summary>
        ///
        private readonly IGenerateID _geneIDGenerate;

        /// <summary>
        /// Generate T id's.
        /// </summary>
        ///
        private readonly IGenerateID _TIDGenerate;

        /// <summary>
        /// The population.
        /// </summary>
        ///
        private readonly List<IT> _Ts;

        /// <summary>
        /// Generate innovation id's.
        /// </summary>
        ///
        private readonly IGenerateID _innovationIDGenerate;

        /// <summary>
        /// Generate species id's.
        /// </summary>
        ///
        private readonly IGenerateID _speciesIDGenerate;

        /// <summary>
        /// The young threshold.
        /// </summary>
        ///
        private int _youngBonusAgeThreshold;

        /// <summary>
        /// Construct an empty population.
        /// </summary>
        ///
        public BasicPopulation()
        {
            _geneIDGenerate = new BasicGenerateID();
            _TIDGenerate = new BasicGenerateID();
            _Ts = new List<IT>();
            _innovationIDGenerate = new BasicGenerateID();
            OldAgePenalty = DefaultOldAgePenalty;
            OldAgeThreshold = DefaultOldAgeThreshold;
            Species = new List<ISpecies>();
            _speciesIDGenerate = new BasicGenerateID();
            SurvivalRate = DefaultSurvivalRate;
            _youngBonusAgeThreshold = DefaultYouthThreshold;
            YoungScoreBonus = DefaultYouthBonus;
            PopulationSize = 0;
        }

        /// <summary>
        /// Construct a population.
        /// </summary>
        /// <param name="thePopulationSize">The population size.</param>
        public BasicPopulation(int thePopulationSize)
        {
            _geneIDGenerate = new BasicGenerateID();
            _TIDGenerate = new BasicGenerateID();
            _Ts = new List<IT>();
            _innovationIDGenerate = new BasicGenerateID();
            OldAgePenalty = DefaultOldAgePenalty;
            OldAgeThreshold = DefaultOldAgeThreshold;
            Species = new List<ISpecies>();
            _speciesIDGenerate = new BasicGenerateID();
            SurvivalRate = DefaultSurvivalRate;
            _youngBonusAgeThreshold = DefaultYouthThreshold;
            YoungScoreBonus = DefaultYouthBonus;
            PopulationSize = thePopulationSize;
        }

        /// <value>the geneIDGenerate</value>
        public IGenerateID GeneIDGenerate
        {
            get { return _geneIDGenerate; }
        }


        /// <value>the TIDGenerate</value>
        public IGenerateID TIDGenerate
        {
            get { return _TIDGenerate; }
        }

        /// <value>the innovationIDGenerate</value>
        public IGenerateID InnovationIDGenerate
        {
            get { return _innovationIDGenerate; }
        }

        /// <summary>
        /// Set the name.
        /// </summary>
        public String Name { get; set; }

        /// <value>the speciesIDGenerate</value>
        public IGenerateID SpeciesIDGenerate
        {
            get { return _speciesIDGenerate; }
        }

        #region IPopulation Members


        /// <inheritdoc/>
        public void Add(IT T)
        {
            _Ts.Add(T);
            T.Population = this;
        }

        /// <inheritdoc/>
        public long AssignGeneID()
        {
            return _geneIDGenerate.Generate();
        }

        /// <inheritdoc/>
        public long AssignTID()
        {
            return _TIDGenerate.Generate();
        }

        /// <inheritdoc/>
        public long AssignInnovationID()
        {
            return _innovationIDGenerate.Generate();
        }

        /// <inheritdoc/>
        public long AssignSpeciesID()
        {
            return _speciesIDGenerate.Generate();
        }

        /// <inheritdoc/>
        public void Claim(GAlgo ga)
        {
            foreach (IT T in _Ts)
            {
                T.GA = ga;
            }
        }

        /// <inheritdoc/>
        public void Clear()
        {
            _Ts.Clear();
        }

        /// <inheritdoc/>
        public IT Get(int i)
        {
            return _Ts[i];
        }

        /// <inheritdoc/>
        public IT Best
        {
            get { return _Ts.Count == 0 ? null : _Ts[0]; }
        }


        /// <inheritdoc/>
        public IList<IT> Ts
        {
            get { return _Ts; }
        }


        /// <inheritdoc/>
        public IInnovationList Innovations { get; set; }


        /// <inheritdoc/>
        public double OldAgePenalty { get; set; }


        /// <inheritdoc/>
        public int OldAgeThreshold { get; set; }


        /// <inheritdoc/>
        public int PopulationSize { get; set; }


        /// <inheritdoc/>
        public IList<ISpecies> Species { get; set; }


        /// <inheritdoc/>
        public double SurvivalRate { get; set; }


        /// <value>the youngBonusAgeThreshold to set</value>
        public int YoungBonusAgeThreshold
        {
            get { return _youngBonusAgeThreshold; }
            set { _youngBonusAgeThreshold = value; }
        }


        /// <inheritdoc/>
        public double YoungScoreBonus { get; set; }


        /// <inheritdoc/>
        public int YoungBonusAgeThreshhold
        {
            set { _youngBonusAgeThreshold = value; }
        }


        /// <inheritdoc/>
        public int Size()
        {
            return _Ts.Count;
        }

        /// <inheritdoc/>
        public void Sort()
        {
            _Ts.Sort();
        }

        #endregion
    }

    public class Splice : ICrossover
    {
        /// <summary>
        /// The cut length.
        /// </summary>
        ///
        private readonly int _cutLength;

        /// <summary>
        /// Create a slice crossover with the specified cut length.
        /// </summary>
        ///
        /// <param name="theCutLength">The cut length.</param>
        public Splice(int theCutLength)
        {
            _cutLength = theCutLength;
        }

        #region ICrossover Members

        /// <summary>
        /// Assuming this Q is the "mother" mate with the passed in
        /// "father".
        /// </summary>
        ///
        /// <param name="mother">The mother.</param>
        /// <param name="father">The father.</param>
        /// <param name="offspring1">Returns the first offspring</param>
        /// <param name="offspring2">Returns the second offspring.</param>
        public void Mate(Q mother, Q father,
                         Q offspring1, Q offspring2)
        {
            int geneLength = mother.Genes.Count;

            // the Q must be cut at two positions, determine them
            var cutpoint1 = (int)(ThreadSafeRandom.NextDouble() * (geneLength - _cutLength));
            int cutpoint2 = cutpoint1 + _cutLength;

            // handle cut section
            for (int i = 0; i < geneLength; i++)
            {
                if (!((i < cutpoint1) || (i > cutpoint2)))
                {
                    offspring1.GetGene(i).Copy(father.GetGene(i));
                    offspring2.GetGene(i).Copy(mother.GetGene(i));
                }
            }

            // handle outer sections
            for (int i = 0; i < geneLength; i++)
            {
                if ((i < cutpoint1) || (i > cutpoint2))
                {
                    offspring1.GetGene(i).Copy(mother.GetGene(i));
                    offspring2.GetGene(i).Copy(father.GetGene(i));
                }
            }
        }

        #endregion
    }

    public class MutatePerturb : IMutate
    {
        /// <summary>
        /// The amount to perturb by.
        /// </summary>
        ///
        private readonly double _perturbAmount;

        /// <summary>
        /// Construct a perturb mutation.
        /// </summary>
        ///
        /// <param name="thePerturbAmount">The amount to mutate by(percent).</param>
        public MutatePerturb(double thePerturbAmount)
        {
            _perturbAmount = thePerturbAmount;
        }

        #region IMutate Members

        /// <summary>
        /// Perform a perturb mutation on the specified Q.
        /// </summary>
        ///
        /// <param name="Q">The Q to mutate.</param>
        public void PerformMutation(Q Q)
        {
            foreach (IGene gene in Q.Genes)
            {
                if (gene is DoubleGene)
                {
                    var doubleGene = (DoubleGene)gene;
                    double v = doubleGene.Value;
                    v += (_perturbAmount - (ThreadSafeRandom.NextDouble() * _perturbAmount * 2));
                    doubleGene.Value = v;
                }
            }
        }

        #endregion
    }

    public class DoubleGene : BasicGene
    {
        /// <summary>
        /// The value of this gene.
        /// </summary>
        ///
        private double _value;

        /// <summary>
        /// Set the value of the gene.
        /// </summary>
        ///
        /// <value>The gene's value.</value>
        public double Value
        {
            get { return _value; }
            set { _value = value; }
        }

        /// <summary>
        /// Copy another gene to this one.
        /// </summary>
        ///
        /// <param name="gene">The other gene to copy.</param>
        public override sealed void Copy(IGene gene)
        {
            _value = ((DoubleGene)gene).Value;
        }


        /// <inheritdoc/>
        public override sealed String ToString()
        {
            return "" + _value;
        }
    }

    public class NeuralGAlgo : BasicTraining, IMultiThreadable
    {
        /// <summary>
        /// Construct a neural G Algo.
        /// </summary>
        ///
        /// <param name="network">The network to base this on.</param>
        /// <param name="randomizer">The randomizer used to create this initial population.</param>
        /// <param name="calculateScore">The score calculation object.</param>
        /// <param name="populationSize">The population size.</param>
        /// <param name="mutationPercent">The percent of offspring to mutate.</param>
        /// <param name="percentToMate">The percent of the population allowed to mate.</param>
        public NeuralGAlgo(BasicNetwork network,
                                      IRandomizer randomizer, ICalculateScore calculateScore,
                                      int populationSize, double mutationPercent,
                                      double percentToMate) : base(TrainingImplementationType.Iterative)
        {
            G = new NeuralGAlgoHelper
            {
                CalculateScore = new GScoreAdapter(calculateScore)
            };
            IPopulation population = new BasicPopulation(populationSize);
            G.MutationPercent = mutationPercent;
            G.MatingPopulation = percentToMate * 2;
            G.PercentToMate = percentToMate;
            G.Crossover = new Splice(network.Structure.CalculateSize() / 3);
            G.Mutate = new MutatePerturb(4.0d);
            G.Population = population;
            for (int i = 0; i < population.PopulationSize; i++)
            {
                var QNetwork = (BasicNetwork)(network
                                                           .Clone());
                randomizer.Randomize(QNetwork);

                var T = new NeuralT(QNetwork) { GA = G };
                G.PerformCalculateScore(T);
                G.Population.Add(T);
            }
            population.Sort();
        }

        /// <inheritdoc />
        public override sealed bool CanContinue
        {
            get { return false; }
        }

        /// <summary>
        /// Set the G helper class.
        /// </summary>
        public NeuralGAlgoHelper G { get; set; }


        /// <inheritdoc/>
        public override IMLMethod Method
        {
            get { return G.Method; }
        }


        /// <summary>
        /// Perform one training iteration.
        /// </summary>
        ///
        public override sealed void Iteration()
        {
            SyntLogging.Log(SyntLogging.LevelInfo,
                             "Performing G iteration.");
            PreIteration();
            G.Iteration();
            Error = G.Error;
            PostIteration();
        }

        /// <inheritdoc/>
        public override sealed TrainingContinuation Pause()
        {
            return null;
        }

        /// <inheritdoc/>
        public override sealed void Resume(TrainingContinuation state)
        {
        }



        #region Nested type: NeuralGAlgoHelper

        /// <summary>
        /// Very simple class that implements a G Algo.
        /// </summary>
        ///
        public class NeuralGAlgoHelper : BasicGAlgo
        {
            /// <value>The error from the last iteration.</value>
            public double Error
            {
                get
                {
                    IT T = Population.Best;
                    return T.Score;
                }
            }


            /// <summary>
            /// Get the current best neural network.
            /// </summary>
            public IMLMethod Method
            {
                get
                {
                    IT T = Population.Best;
                    return (BasicNetwork)T.Organism;
                }
            }
        }

        #endregion

        /// <inheritdoc/>
        public int ThreadCount
        {
            get
            {
                return this.G.ThreadCount;
            }
            set
            {
                this.G.ThreadCount = value;
            }
        }
    }

    public class NeuralT : BasicT
    {
        /// <summary>
        /// The Q.
        /// </summary>
        ///
        private readonly Q _networkQ;

        /// <summary>
        /// Construct a neural T.
        /// </summary>
        ///
        /// <param name="network">The network to use.</param>
        public NeuralT(BasicNetwork network)
        {
            Organism = network;

            _networkQ = new Q();

            // create an array of "double genes"
            int size = network.Structure.CalculateSize();
            for (int i = 0; i < size; i++)
            {
                IGene gene = new DoubleGene();
                _networkQ.Genes.Add(gene);
            }

            Qs.Add(_networkQ);

            Syntesis();
        }

        /// <summary>
        /// Decode the Ts into a neural network.
        /// </summary>
        ///
        public override sealed void Decode()
        {
            var net = new double[_networkQ.Genes.Count];
            for (int i = 0; i < net.Length; i++)
            {
                var gene = (DoubleGene)_networkQ.Genes[i];
                net[i] = gene.Value;
            }
            NetworkCODEC.ArrayToNetwork(net, (BasicNetwork)Organism);
        }

        /// <summary>
        /// Syntesis the neural network into genes.
        /// </summary>
        ///
        public override sealed void Syntesis()
        {
            double[] net = NetworkCODEC
                .NetworkToArray((BasicNetwork)Organism);

            for (int i = 0; i < net.Length; i++)
            {
                ((DoubleGene)_networkQ.GetGene(i)).Value = net[i];
            }
        }
    }

    public class LevenbergMarquardtTraining : BasicTraining, IMultiThreadable
    {
        /// <summary>
        /// The amount to scale the lambda by.
        /// </summary>
        public const double ScaleLambda = 10.0;

        /// <summary>
        /// The max amount for the LAMBDA.
        /// </summary>
        public const double LambdaMax = 1e25;

        /// <summary>
        /// The diagonal of the hessian.
        /// </summary>
        private readonly double[] _diagonal;

        /// <summary>
        /// Utility class to compute the Hessian.
        /// </summary>
        private readonly IComputeHessian _hessian;

        /// <summary>
        /// The training set that we are using to train.
        /// </summary>
        private readonly IMLDataSet _indexableTraining;

        /// <summary>
        /// The network that is to be trained.
        /// </summary>
        private readonly BasicNetwork _network;

        /// <summary>
        /// The training elements.
        /// </summary>
        private readonly IMLDataPair _pair;

        /// <summary>
        /// The training set length.
        /// </summary>
        private readonly int _trainingLength;

        /// <summary>
        /// How many weights are we dealing with?
        /// </summary>
        private readonly int _weightCount;

        /// <summary>
        /// The amount to change the weights by.
        /// </summary>
        private double[] _deltas;

        /// <summary>
        /// The lambda, or damping factor. This is increased until a desirable
        /// adjustment is found.
        /// </summary>
        private double _lambda;

        /// <summary>
        /// The neural network weights and bias values.
        /// </summary>
        private double[] _weights;

        /// <summary>
        /// Construct the LMA object. Use the chain rule for Hessian calc.
        /// </summary>
        /// <param name="network">The network to train. Must have a single output neuron.</param>
        /// <param name="training">The training data to use. Must be indexable.</param>
        public LevenbergMarquardtTraining(BasicNetwork network,
                                          IMLDataSet training)
            : this(network, training, new HessianCR())
        {
        }

        /// <summary>
        /// Construct the LMA object. 
        /// </summary>
        /// <param name="network">The network to train. Must have a single output neuron.</param>
        /// <param name="training">The training data to use. Must be indexable.</param>
        /// <param name="h">The Hessian calculator to use.</param>
        public LevenbergMarquardtTraining(BasicNetwork network,
                                          IMLDataSet training, IComputeHessian h)
            : base(TrainingImplementationType.Iterative)
        {
            ValidateNetwork.ValidateMethodToData(network, training);

            Training = training;
            _indexableTraining = Training;
            this._network = network;
            _trainingLength = (int)_indexableTraining.Count;
            _weightCount = this._network.Structure.CalculateSize();
            _lambda = 0.1;
            _deltas = new double[_weightCount];
            _diagonal = new double[_weightCount];

            var input = new BasicMLData(
                _indexableTraining.InputSize);
            var ideal = new BasicMLData(
                _indexableTraining.IdealSize);
            _pair = new BasicMLDataPair(input, ideal);

            _hessian = h;
            _hessian.Init(network, training);
        }

        /// <inheritdoc/>
        public override bool CanContinue
        {
            get { return false; }
        }

        /// <summary>
        /// The trained neural network.
        /// </summary>
        public override IMLMethod Method
        {
            get { return _network; }
        }

        /// <summary>
        /// The Hessian calculation method used.
        /// </summary>
        public IComputeHessian Hessian
        {
            get { return _hessian; }
        }

        #region IMultiThreadable Members

        /// <summary>
        /// The thread count, specify 0 for Synt to automatically select (default).  
        /// If the underlying Hessian calculator does not support multithreading, an error 
        /// will be thrown.  The default chain rule calc does support multithreading.
        /// </summary>
        public int ThreadCount
        {
            get
            {
                if (_hessian is IMultiThreadable)
                {
                    return ((IMultiThreadable)_hessian).ThreadCount;
                }
                throw new TrainingError("The Hessian object in use(" + _hessian.GetType().Name +
                                        ") does not support multi-threaded mode.");
            }
            set
            {
                if (_hessian is IMultiThreadable)
                {
                    ((IMultiThreadable)_hessian).ThreadCount = value;
                }
                else
                {
                    throw new TrainingError("The Hessian object in use(" + _hessian.GetType().Name +
                                            ") does not support multi-threaded mode.");
                }
            }
        }

        #endregion

        /// <summary>
        /// Save the diagonal of the Hessian.  Will be used to apply the lambda.
        /// </summary>
        private void SaveDiagonal()
        {
            double[][] h = _hessian.Hessian;
            for (int i = 0; i < _weightCount; i++)
            {
                _diagonal[i] = h[i][i];
            }
        }

        /// <summary>
        /// Calculate the SSE error.
        /// </summary>
        /// <returns>The SSE error with the current weights.</returns>
        private double CalculateError()
        {
            var result = new ErrorCalculation();

            for (int i = 0; i < _trainingLength; i++)
            {
                _indexableTraining.GetRecord(i, _pair);
                IMLData actual = _network.Compute(_pair.Input);
                result.UpdateError(actual.Data, _pair.Ideal.Data, _pair.Significance);
            }

            return result.CalculateSSE();
        }

        /// <summary>
        /// Apply the lambda, this will dampen the GNA.
        /// </summary>
        private void ApplyLambda()
        {
            double[][] h = _hessian.Hessian;
            for (int i = 0; i < _weightCount; i++)
            {
                h[i][i] = _diagonal[i] + _lambda;
            }
        }

        /// <summary>
        /// Perform one iteration.
        /// </summary>
        public override void Iteration()
        {
            LUDecomposition decomposition;
            PreIteration();

            _hessian.Clear();
            _weights = NetworkCODEC.NetworkToArray(_network);

            _hessian.Compute();
            double currentError = _hessian.SSE;
            SaveDiagonal();

            double startingError = currentError;
            bool done = false;

            while (!done)
            {
                ApplyLambda();
                decomposition = new LUDecomposition(_hessian.HessianMatrix);

                if (decomposition.IsNonsingular)
                {
                    _deltas = decomposition.Solve(_hessian.Gradients);

                    UpdateWeights();
                    currentError = CalculateError();

                    if (currentError < startingError)
                    {
                        _lambda /= LevenbergMarquardtTraining.ScaleLambda;
                        done = true;
                    }
                }

                if (!done)
                {
                    _lambda *= LevenbergMarquardtTraining.ScaleLambda;
                    if (_lambda > LevenbergMarquardtTraining.LambdaMax)
                    {
                        _lambda = LevenbergMarquardtTraining.LambdaMax;
                        done = true;
                    }
                }
            }

            Error = currentError;

            PostIteration();
        }

        /// <inheritdoc/>
        public override TrainingContinuation Pause()
        {
            return null;
        }

        /// <inheritdoc/>
        public override void Resume(TrainingContinuation state)
        {
        }

        /// <summary>
        /// Update the weights in the neural network.
        /// </summary>
        public void UpdateWeights()
        {
            var w = (double[])_weights.Clone();

            for (int i = 0; i < w.Length; i++)
            {
                w[i] += _deltas[i];
            }

            NetworkCODEC.ArrayToNetwork(w, _network);
        }
    }

    public class NelderMeadTraining : BasicTraining
    {
        private readonly int _konvge;

        /// <summary>
        /// The network to be trained.
        /// </summary>
        private readonly BasicNetwork _network;

        private readonly int _nn;
        private readonly double[] _p;
        private readonly double[] _p2Star;
        private readonly double[] _pbar;
        private readonly double[] _pstar;
        private readonly double _rq;
        private readonly double[] _start;
        private readonly double[] _step;
        private readonly double[] _trainedWeights;
        private readonly double[] _y;

        /// <summary>
        /// Used to calculate the centroid.
        /// </summary>
        private const double ccoeff = 0.5;

        /// <summary>
        /// True if the network has converged, and no further training is needed.
        /// </summary>
        private bool _converged;

        private double _del;
        private const double ecoeff = 2.0;
        private const double eps = 0.001;
        private int _ihi;
        private int _ilo;
        private int _jcount;
        private int _l;
        private const double rcoeff = 1.0;
        private double _y2Star;
        private double _ylo;

        /// <summary>
        /// The best error rate.
        /// </summary>
        private double _ynewlo;

        private double _ystar;
        private double _z;
        private BasicNetwork method;
        readonly IMLDataSet Training;
        public NelderMeadTraining(BasicNetwork network, IMLDataSet training)
            : this(network, training, 100)
        {
            this.method = network;
            Training = training;
        }

        /// <summary>
        /// Construct a Nelder Mead trainer with a step size of 100.
        /// </summary>
        /// <param name="network">The network to train.</param>
        /// <param name="training">The training set to use.</param>
        //public NelderMeadTraining(BasicNetwork network,IMLDataSet training): this(network, training, 100)
        //{
        //}

        /// <summary>
        /// Construct a Nelder Mead trainer with a definable step. 
        /// </summary>
        /// <param name="network">The network to train.</param>
        /// <param name="training">The training data to use.</param>
        /// <param name="stepValue">The step value. This value defines, to some degree the range
        /// of different weights that will be tried.</param>
        public NelderMeadTraining(BasicNetwork network,
                                  IMLDataSet training, double stepValue) :
                                      base(TrainingImplementationType.OnePass)
        {
            this._network = network;
            Training = training;

            _start = NetworkCODEC.NetworkToArray(network);
            _trainedWeights = NetworkCODEC.NetworkToArray(network);

            int n = _start.Length;

            _p = new double[n * (n + 1)];
            _pstar = new double[n];
            _p2Star = new double[n];
            _pbar = new double[n];
            _y = new double[n + 1];

            _nn = n + 1;
            _del = 1.0;
            _rq = SyntFramework.DefaultDoubleEqual * n;

            _step = new double[NetworkCODEC.NetworkSize(network)];
            _jcount = _konvge = 500;
            EngineArray.Fill(_step, stepValue);
        }

        ///// <inheritdoc/>
        public override bool CanContinue
        {
            get { return false; }
        }

        /// <inheritdoc/>
        public override IMLMethod Method
        {
            get { return _network; }
        }

        /// <inheritdoc/>
        public new bool TrainingDone
        {
            get
            {
                return _converged || base.TrainingDone;
            }
        }

        /// <summary>
        /// Calculate the error for the neural network with a given set of weights. 
        /// </summary>
        /// <param name="weights">The weights to use.</param>
        /// <returns>The current error.</returns>
        public double Fn(double[] weights)
        {
            NetworkCODEC.ArrayToNetwork(weights, _network);
            return _network.CalculateError(Training);
        }

        /// <inheritdoc/>
        public override void Iteration()
        {
            if (_converged)
            {
                return;
            }

            int n = _start.Length;

            for (int i = 0; i < n; i++)
            {
                _p[i + n * n] = _start[i];
            }
            _y[n] = Fn(_start);
            for (int j = 0; j < n; j++)
            {
                double x = _start[j];
                _start[j] = _start[j] + _step[j] * _del;
                for (int i = 0; i < n; i++)
                {
                    _p[i + j * n] = _start[i];
                }
                _y[j] = Fn(_start);
                _start[j] = x;
            }
            /*
             * The simplex construction is complete.
             * 
             * Find highest and lowest Y values. YNEWLO = Y(IHI) indicates the
             * vertex of the simplex to be replaced.
             */
            _ylo = _y[0];
            _ilo = 0;

            for (int i = 1; i < _nn; i++)
            {
                if (_y[i] < _ylo)
                {
                    _ylo = _y[i];
                    _ilo = i;
                }
            }
            /*
             * Inner loop.
             */
            for (; ; )
            {
                /*
                 * if (kcount <= icount) { break; }
                 */
                _ynewlo = _y[0];
                _ihi = 0;

                for (int i = 1; i < _nn; i++)
                {
                    if (_ynewlo < _y[i])
                    {
                        _ynewlo = _y[i];
                        _ihi = i;
                    }
                }
                /*
                 * Calculate PBAR, the centroid of the simplex vertices excepting
                 * the vertex with Y value YNEWLO.
                 */
                for (int i = 0; i < n; i++)
                {
                    _z = 0.0;
                    for (int j = 0; j < _nn; j++)
                    {
                        _z = _z + _p[i + j * n];
                    }
                    _z = _z - _p[i + _ihi * n];
                    _pbar[i] = _z / n;
                }
                /*
                 * Reflection through the centroid.
                 */
                for (int i = 0; i < n; i++)
                {
                    _pstar[i] = _pbar[i] + rcoeff
                               * (_pbar[i] - _p[i + _ihi * n]);
                }
                _ystar = Fn(_pstar);
                /*
                 * Successful reflection, so extension.
                 */
                if (_ystar < _ylo)
                {
                    for (int i = 0; i < n; i++)
                    {
                        _p2Star[i] = _pbar[i] + ecoeff
                                    * (_pstar[i] - _pbar[i]);
                    }
                    _y2Star = Fn(_p2Star);
                    /*
                     * Check extension.
                     */
                    if (_ystar < _y2Star)
                    {
                        for (int i = 0; i < n; i++)
                        {
                            _p[i + _ihi * n] = _pstar[i];
                        }
                        _y[_ihi] = _ystar;
                    }
                    /*
                 * Retain extension or contraction.
                 */
                    else
                    {
                        for (int i = 0; i < n; i++)
                        {
                            _p[i + _ihi * n] = _p2Star[i];
                        }
                        _y[_ihi] = _y2Star;
                    }
                }
                /*
             * No extension.
             */
                else
                {
                    _l = 0;
                    for (int i = 0; i < _nn; i++)
                    {
                        if (_ystar < _y[i])
                        {
                            _l = _l + 1;
                        }
                    }

                    if (1 < _l)
                    {
                        for (int i = 0; i < n; i++)
                        {
                            _p[i + _ihi * n] = _pstar[i];
                        }
                        _y[_ihi] = _ystar;
                    }
                    /*
                 * Contraction on the Y(IHI) side of the centroid.
                 */
                    else if (_l == 0)
                    {
                        for (int i = 0; i < n; i++)
                        {
                            _p2Star[i] = _pbar[i] + ccoeff
                                        * (_p[i + _ihi * n] - _pbar[i]);
                        }
                        _y2Star = Fn(_p2Star);
                        /*
                         * Contract the whole simplex.
                         */
                        if (_y[_ihi] < _y2Star)
                        {
                            for (int j = 0; j < _nn; j++)
                            {
                                for (int i = 0; i < n; i++)
                                {
                                    _p[i + j * n] = (_p[i + j * n] + _p[i
                                                                 + _ilo * n]) * 0.5;
                                    _trainedWeights[i] = _p[i + j * n];
                                }
                                _y[j] = Fn(_trainedWeights);
                            }
                            _ylo = _y[0];
                            _ilo = 0;

                            for (int i = 1; i < _nn; i++)
                            {
                                if (_y[i] < _ylo)
                                {
                                    _ylo = _y[i];
                                    _ilo = i;
                                }
                            }
                            continue;
                        }
                        /*
                     * Retain contraction.
                     */
                        for (int i = 0; i < n; i++)
                        {
                            _p[i + _ihi * n] = _p2Star[i];
                        }
                        _y[_ihi] = _y2Star;
                    }
                    /*
                 * Contraction on the reflection side of the centroid.
                 */
                    else if (_l == 1)
                    {
                        for (int i = 0; i < n; i++)
                        {
                            _p2Star[i] = _pbar[i] + ccoeff
                                        * (_pstar[i] - _pbar[i]);
                        }
                        _y2Star = Fn(_p2Star);
                        /*
                         * Retain reflection?
                         */
                        if (_y2Star <= _ystar)
                        {
                            for (int i = 0; i < n; i++)
                            {
                                _p[i + _ihi * n] = _p2Star[i];
                            }
                            _y[_ihi] = _y2Star;
                        }
                        else
                        {
                            for (int i = 0; i < n; i++)
                            {
                                _p[i + _ihi * n] = _pstar[i];
                            }
                            _y[_ihi] = _ystar;
                        }
                    }
                }
                /*
                 * Check if YLO improved.
                 */
                if (_y[_ihi] < _ylo)
                {
                    _ylo = _y[_ihi];
                    _ilo = _ihi;
                }
                _jcount = _jcount - 1;

                if (0 < _jcount)
                {
                    continue;
                }
                /*
                 * Check to see if minimum reached.
                 */
                // if (icount <= kcount)
                {
                    _jcount = _konvge;

                    _z = 0.0;
                    for (int i = 0; i < _nn; i++)
                    {
                        _z = _z + _y[i];
                    }
                    double x = _z / _nn;

                    _z = 0.0;
                    for (int i = 0; i < _nn; i++)
                    {
                        _z = _z + Math.Pow(_y[i] - x, 2);
                    }

                    if (_z <= _rq)
                    {
                        break;
                    }
                }
            }
            /*
             * Factorial tests to check that YNEWLO is a local minimum.
             */
            for (int i = 0; i < n; i++)
            {
                _trainedWeights[i] = _p[i + _ilo * n];
            }
            _ynewlo = _y[_ilo];

            bool fault = false;

            for (int i = 0; i < n; i++)
            {
                _del = _step[i] * eps;
                _trainedWeights[i] += _del;
                _z = Fn(_trainedWeights);
                if (_z < _ynewlo)
                {
                    fault = true;
                    break;
                }
                _trainedWeights[i] = _trainedWeights[i] - _del
                                    - _del;
                _z = Fn(_trainedWeights);
                if (_z < _ynewlo)
                {
                    fault = true;
                    break;
                }
                _trainedWeights[i] += _del;
            }

            if (!fault)
            {
                _converged = true;
            }
            else
            {
                /*
                 * Restart the procedure.
                 */
                for (int i = 0; i < n; i++)
                {
                    _start[i] = _trainedWeights[i];
                }
                _del = eps;
            }

            Error = _ynewlo;
            NetworkCODEC.ArrayToNetwork(_trainedWeights, _network);
        }

        /// <inheritdoc/>
        public override TrainingContinuation Pause()
        {
            return null;
        }

        /// <inheritdoc/>
        public override void Resume(TrainingContinuation state)
        {
        }
    }

    public class DeriveMinimum
    {


        public double Calculate(int maxIterations, double maxError,
                                double eps, double tol,
                                ICalculationCriteria network, int n, double[] x,
                                double ystart, double[] bs, double[] direc,
                                double[] g, double[] h, double[] deriv2)
        {
            var globalMinimum = new GlobalMinimumSearch();

            double fbest = network.CalcErrorWithMultipleSigma(x, direc, deriv2,
                                                              true);
            double prevBest = 1.0e30d;
            for (int i = 0; i < n; i++)
            {
                direc[i] = -direc[i];
            }

            EngineArray.ArrayCopy(direc, g);
            EngineArray.ArrayCopy(direc, h);

            int convergenceCounter = 0;
            int poorCj = 0;

            // Main loop
            for (int iteration = 0; iteration < maxIterations; iteration++)
            {
                if (fbest < maxError)
                {
                    break;
                }

                SyntLogging.Log(SyntLogging.LevelInfo,
                    "Beginning internal Iteration #" + iteration + ", currentError=" + fbest + ",target=" + maxError);

                // Check for convergence
                double toler;
                if (prevBest <= 1.0d)
                {
                    toler = tol;
                }
                else
                {
                    toler = tol * prevBest;
                }

                // Stop if there is little improvement
                if ((prevBest - fbest) <= toler)
                {
                    if (++convergenceCounter >= 3)
                    {
                        break;
                    }
                }
                else
                {
                    convergenceCounter = 0;
                }

                double dot2 = 0;
                double dlen = 0;
                double dot1 = dot2 = dlen = 0.0d;
                double high = 1.0e-4d;
                for (int i = 0; i < n; i++)
                {
                    bs[i] = x[i];
                    if (deriv2[i] > high)
                    {
                        high = deriv2[i];
                    }
                    dot1 += direc[i] * g[i]; // Directional first derivative
                    dot2 += direc[i] * direc[i] * deriv2[i]; // and second
                    dlen += direc[i] * direc[i]; // Length of search vector
                }

                double scale;

                if (Math.Abs(dot2) < SyntFramework.DefaultDoubleEqual)
                {
                    scale = 0;
                }
                else
                {
                    scale = dot1 / dot2;
                }
                high = 1.5d / high;
                if (high < 1.0e-4d)
                {
                    high = 1.0e-4d;
                }

                if (scale < 0.0d)
                {
                    scale = high;
                }
                else if (scale < 0.1d * high)
                {
                    scale = 0.1d * high;
                }
                else if (scale > 10.0d * high)
                {
                    scale = 10.0d * high;
                }

                prevBest = fbest;
                globalMinimum.Y2 = fbest;

                globalMinimum.FindBestRange(0.0d, 2.0d * scale, -3, false, maxError,
                                            network);

                if (globalMinimum.Y2 < maxError)
                {
                    if (globalMinimum.Y2 < fbest)
                    {
                        for (int i = 0; i < n; i++)
                        {
                            x[i] = bs[i] + globalMinimum.Y2 * direc[i];
                            if (x[i] < 1.0e-10d)
                            {
                                x[i] = 1.0e-10d;
                            }
                        }
                        fbest = globalMinimum.Y2;
                    }
                    else
                    {
                        for (int i = 0; i < n; i++)
                        {
                            x[i] = bs[i];
                        }
                    }
                    break;
                }

                if (convergenceCounter > 0)
                {
                    fbest = globalMinimum.Brentmin(20, maxError, eps, 1.0e-7d,
                                                   network, globalMinimum.Y2);
                }
                else
                {
                    fbest = globalMinimum.Brentmin(10, maxError, 1.0e-6d, 1.0e-5d,
                                                   network, globalMinimum.Y2);
                }

                for (int i = 0; i < n; i++)
                {
                    x[i] = bs[i] + globalMinimum.X2 * direc[i];
                    if (x[i] < 1.0e-10d)
                    {
                        x[i] = 1.0e-10d;
                    }
                }

                double improvement = (prevBest - fbest) / prevBest;

                if (fbest < maxError)
                {
                    break;
                }

                for (int i = 0; i < n; i++)
                {
                    direc[i] = -direc[i]; // negative gradient
                }

                double gam = Gamma(n, g, direc);

                if (gam < 0.0d)
                {
                    gam = 0.0d;
                }

                if (gam > 10.0d)
                {
                    gam = 10.0d;
                }

                if (improvement < 0.001d)
                {
                    ++poorCj;
                }
                else
                {
                    poorCj = 0;
                }

                if (poorCj >= 2)
                {
                    if (gam > 1.0d)
                    {
                        gam = 1.0d;
                    }
                }

                if (poorCj >= 6)
                {
                    poorCj = 0;
                    gam = 0.0d;
                }

                FindNewDir(n, gam, g, h, direc);
            }

            return fbest;
        }

        /// <summary>
        /// Find gamma.
        /// </summary>
        ///
        /// <param name="n">The number of variables.</param>
        /// <param name="gam">The gamma value.</param>
        /// <param name="g">The "g" value, used for CJ Algo.</param>
        /// <param name="h">The "h" value, used for CJ Algo.</param>
        /// <param name="grad">The gradients.</param>
        private static void FindNewDir(int n, double gam, double[] g,
                                double[] h, double[] grad)
        {
            int i;

            for (i = 0; i < n; i++)
            {
                g[i] = grad[i];
                grad[i] = h[i] = g[i] + gam * h[i];
            }
        }

        /// <summary>
        /// Find correction for next iteration.
        /// </summary>
        ///
        /// <param name="n">The number of variables.</param>
        /// <param name="g">The "g" value, used for CJ Algo.</param>
        /// <param name="grad">The gradients.</param>
        /// <returns>The correction for the next iteration.</returns>
        private static double Gamma(int n, double[] g, double[] grad)
        {
            int i;
            double denom;

            double numer = denom = 0.0d;

            for (i = 0; i < n; i++)
            {
                denom += g[i] * g[i];
                numer += (grad[i] - g[i]) * grad[i]; // Grad is neg gradient
            }

            if (denom == 0.0d)
            {
                return 0.0d;
            }
            return numer / denom;
        }
    }

    public class GlobalMinimumSearch
    {
        /// <summary>
        /// The golden section.
        /// </summary>
        ///
        public const double Cgold = 0.3819660d;

        /// <summary>
        /// A gamma to the left(lower) of the best(middle) gamma.
        /// </summary>
        ///
        private double _x1;

        /// <summary>
        /// The middle(best) gamma.
        /// </summary>
        ///
        private double _x2;

        /// <summary>
        /// A gamma to the right(higher) of the middle(best) gamma.
        /// </summary>
        ///
        private double _x3;

        /// <summary>
        /// The value y1 is the error for x1.
        /// </summary>
        ///
        private double _y1;

        /// <summary>
        /// The value y2 is the error for x2. This is the best(middle) error.
        /// </summary>
        ///
        private double _y2;

        /// <summary>
        /// The value y3 is the error for x3.
        /// </summary>
        ///
        private double _y3;


        /// <value></value>
        public double X1
        {
            get { return _x1; }
            set { _x1 = value; }
        }


        /// <value>Set X2, which is the middle(best) gamma.</value>
        public double X2
        {
            get { return _x2; }
            set { _x2 = value; }
        }


        /// <value>X3, which is a gamma to the right(higher) of the middle(best)
        /// gamma.</value>
        public double X3
        {
            get { return _x3; }
            set { _x3 = value; }
        }


        /// <value>Set Y1, which is the value y1 is the error for x1.</value>
        public double Y1
        {
            get { return _y1; }
            set { _y1 = value; }
        }


        /// <value>Y2, which is the value y2 is the error for x2. This is the
        /// best(middle) error.</value>
        public double Y2
        {
            get { return _y2; }
            set { _y2 = value; }
        }


        /// <value>Set Y3, which is the value y3 is the error for x3.</value>
        public double Y3
        {
            get { return _y3; }
            set { _y3 = value; }
        }

        /// <summary>
        /// Use the "Brent Method" to find a better minimum.
        /// </summary>
        ///
        /// <param name="maxIterations">THe maximum number of iterations.</param>
        /// <param name="maxError">We can stop if we reach this error.</param>
        /// <param name="eps">The approximate machine precision.</param>
        /// <param name="tol">Brent's tolerance, must be >= sqrt( eps )</param>
        /// <param name="network">The network to obtain the error from.</param>
        /// <param name="y">The error at x2.</param>
        /// <returns>The best error.</returns>
        public double Brentmin(int maxIterations, double maxError, double eps, double tol, ICalculationCriteria network, double y)
        {
            double prevdist = 0.0d;
            double step = 0.0d;

            // xBest is the minimum function ordinate thus far.
            // also keep 2nd and 3rd
            double xbest = _x2;
            double x2ndBest = _x2;
            double x3rdBest = _x2;
            // Keep the minimum bracketed between xlow and xhigh.

            // Get the low and high from our previous "crude" search.
            double xlow = _x1;
            double xhigh = _x3;

            double fbest = y;
            double fsecbest = y;
            double fthirdbest = y;

            // Main loop.
            // We will go up to the specified number of iterations.
            // Hopefully we will "break out" long before that happens!
            for (int iter = 0; iter < maxIterations; iter++)
            {
                // Have we reached an acceptable error?
                if (fbest < maxError)
                {
                    break;
                }

                double xmid = 0.5d * (xlow + xhigh);
                double tol1 = tol * (Math.Abs(xbest) + eps);
                double tol2 = 2.0 * tol1;

                // See if xlow is close relative to tol2,
                // Also, that that xbest is near the midpoint.
                if (Math.Abs(xbest - xmid) <= (tol2 - 0.5d * (xhigh - xlow)))
                {
                    break;
                }

                // Don't go to close to eps, the machine precision.
                if ((iter >= 2) && ((fthirdbest - fbest) < eps))
                {
                    break;
                }

                double xrecent = 0;

                // Try parabolic fit, if we moved far enough.
                if (Math.Abs(prevdist) > tol1)
                {
                    // Temps holders for the parabolic estimate
                    double t1 = (xbest - x2ndBest) * (fbest - fthirdbest);
                    double t2 = (xbest - x3rdBest) * (fbest - fsecbest);
                    double numer = (xbest - x3rdBest) * t2
                                   - (xbest - x2ndBest) * t1;
                    double denom = 2.0 * (t1 - t2);
                    double testdist = prevdist;
                    prevdist = step;
                    // This is the parabolic estimate to min.
                    if (denom != 0.0d)
                    {
                        step = numer / denom;
                    }
                    else
                    {
                        // test failed.
                        step = 1.0e30d;
                    }

                    // If shrinking, and within bounds, then use the parabolic
                    // estimate.
                    if ((Math.Abs(step) < Math.Abs(0.5d * testdist))
                        && (step + xbest > xlow) && (step + xbest < xhigh))
                    {
                        xrecent = xbest + step;
                        // If very close to known bounds.
                        if ((xrecent - xlow < tol2) || (xhigh - xrecent < tol2))
                        {
                            if (xbest < xmid)
                            {
                                step = tol1;
                            }
                            else
                            {
                                step = -tol1;
                            }
                        }
                    }
                    else
                    {
                        // Parabolic estimate poor, so use golden section
                        prevdist = (xbest >= xmid) ? xlow - xbest : xhigh - xbest;
                        step = Cgold * prevdist;
                    }
                }
                else
                {
                    // prevdist did not exceed tol1: we did not move far
                    // enough
                    // to justify a parabolic fit. Use golden section.
                    prevdist = (xbest >= xmid) ? xlow - xbest : xhigh - xbest;
                    step = .3819660d * prevdist;
                }

                if (Math.Abs(step) >= tol1)
                {
                    xrecent = xbest + step; // another trial we must move a
                }
                else
                {
                    // decent distance.
                    if (step > 0.0)
                    {
                        xrecent = xbest + tol1;
                    }
                    else
                    {
                        xrecent = xbest - tol1;
                    }
                }

                /*
				 * At long last we have a trial point 'xrecent'. Evaluate the
				 * function.
				 */

                double frecent = network.CalcErrorWithSingleSigma(xrecent);

                if (frecent < 0.0d)
                {
                    break;
                }

                if (frecent <= fbest)
                {
                    // If we improved...
                    if (xrecent >= xbest)
                    {
                        xlow = xbest; // replacing the appropriate endpoint
                    }
                    else
                    {
                        xhigh = xbest;
                    }
                    x3rdBest = x2ndBest; // Update x and f values for best,
                    x2ndBest = xbest; // second and third best
                    xbest = xrecent;
                    fthirdbest = fsecbest;
                    fsecbest = fbest;
                    fbest = frecent;
                }
                else
                {
                    // We did not improve
                    if (xrecent < xbest)
                    {
                        xlow = xrecent; // replacing the appropriate endpoint
                    }
                    else
                    {
                        xhigh = xrecent;
                    }

                    if ((frecent <= fsecbest) || (x2ndBest == xbest))
                    {
                        x3rdBest = x2ndBest;

                        x2ndBest = xrecent;
                        fthirdbest = fsecbest;
                        fsecbest = frecent;
                    }
                    else if ((frecent <= fthirdbest) || (x3rdBest == xbest)
                             || (x3rdBest == x2ndBest))
                    {
                        x3rdBest = xrecent;
                        fthirdbest = frecent;
                    }
                }
            }

            // update the three sigmas.

            _x1 = xlow;
            _x2 = xbest;
            _x3 = xhigh;

            // return the best.
            return fbest;
        }


        public void FindBestRange(double low, double high, int numberOfPoints, bool useLog, double minError, ICalculationCriteria network)
        {
            int i, ibest;
            double x, y, rate, previous;
            bool firstPointKnown;

            // if the number of points is negative, then
            // we already know the first point. Don't recalculate it.
            if (numberOfPoints < 0)
            {
                numberOfPoints = -numberOfPoints;
                firstPointKnown = true;
            }
            else
            {
                firstPointKnown = false;
            }

            // Set the rate to go from high to low. We are either advancing
            // logarithmically, or linear.
            if (useLog)
            {
                rate = Math.Exp(Math.Log(high / low) / (numberOfPoints - 1));
            }
            else
            {
                rate = (high - low) / (numberOfPoints - 1);
            }

            // Start the search at the low.
            x = low;
            previous = 0.0d;
            ibest = -1;

            // keep track of if the error is getting worse.
            bool gettingWorse = false;

            // Try the specified number of points, between high and low.
            for (i = 0; i < numberOfPoints; i++)
            {
                // Determine the error. If the first point is known, then us y2 as
                // the error.
                if ((i > 0) || !firstPointKnown)
                {
                    y = network.CalcErrorWithSingleSigma(x);
                }
                else
                {
                    y = _y2;
                }

                // Have we found a new best candidate point?
                if ((i == 0) || (y < _y2))
                {
                    // yes, we found a new candidate point!
                    ibest = i;
                    _x2 = x;
                    _y2 = y;
                    _y1 = previous; // Function value to its left
                    gettingWorse = false; // Flag that min is not yet bounded
                }
                else if (i == (ibest + 1))
                {
                    // Things are getting worse!
                    // Might be the right neighbor of the best found.
                    _y3 = y;
                    gettingWorse = true;
                }

                // Track the left neighbour of the best.
                previous = y;

                // Is this good enough? Might be able to stop early
                if ((_y2 <= minError) && (ibest > 0) && gettingWorse)
                {
                    break;
                }

                // Decrease the rate either linearly or
                if (useLog)
                {
                    x *= rate;
                }
                else
                {
                    x += rate;
                }
            }

            /*
			 * At this point we have a minimum (within low,high) at (x2,y2). Compute
			 * x1 and x3, its neighbors. We already know y1 and y3 (unless the
			 * minimum is at an endpoint!).
			 */

            // We have now located a minimum! Yeah!!
            // Lets calculate the neighbors. x1 and x3, which are the sigmas.
            // We should already have y1 and y3 calculated, these are the errors,
            // and are expensive to recalculate.
            if (useLog)
            {
                _x1 = _x2 / rate;
                _x3 = _x2 * rate;
            }
            else
            {
                _x1 = _x2 - rate;
                _x3 = _x2 + rate;
            }

            // We are really done at this point. But for "extra credit", we check to
            // see if things were "getting worse".
            //
            // If NOT, and things were getting better, the user probably cropped the
            // gamma range a bit short. After all, it is hard to guess at a good
            // gamma range.
            //
            // To try and get the best common gamma that we can, we will actually
            // slip off the right-hand high-range and search for an even better
            // gamma.

            if (!gettingWorse)
            {
                // Search as far as needed! (endless loop)
                for (; ; )
                {
                    // calculate at y3(the end point)
                    _y3 = network.CalcErrorWithSingleSigma(_x3);

                    // If we are not finding anything better, then stop!
                    // We are already outside the specified search range.
                    if (_y3 > _y2)
                    {
                        break;
                    }
                    if ((_y1 == _y2) && (_y2 == _y3))
                    {
                        break;
                    }

                    // Shift the points for the new range, as we have
                    // extended to the right.
                    _x1 = _x2;
                    _y1 = _y2;
                    _x2 = _x3;
                    _y2 = _y3;

                    // We want to step further each time. We can't search forever,
                    // and we are already outside of the area we were supposed to
                    // scan.
                    rate *= 3.0d;
                    if (useLog)
                    {
                        _x3 *= rate;
                    }
                    else
                    {
                        _x3 += rate;
                    }
                }
            }
            // We will also handle one more "bad situation", which results from a
            // bad gamma search range.
            //
            // What if the first gamma was tried, and that was the best it ever got?
            //
            // If this is the case, there MIGHT be better gammas to the left of the
            // search space. Lets try those.
            else if (ibest == 0)
            {
                // Search as far as needed! (endless loop)
                for (; ; )
                {
                    // Calculate at y3(the begin point)
                    _y1 = network.CalcErrorWithSingleSigma(_x1);

                    if (_y1 < 0.0d)
                    {
                        return;
                    }

                    // If we are not finding anything better, then stop!
                    // We are already outside the specified search range.
                    if (_y1 > _y2)
                    {
                        break;
                    }
                    if ((_y1 == _y2) && (_y2 == _y3))
                    {
                        break;
                    }

                    // Shift the points for the new range, as we have
                    // extended to the left.
                    _x3 = _x2;
                    _y3 = _y2;
                    _x2 = _x1;
                    _y2 = _y1;

                    // We want to step further each time. We can't search forever,
                    // and we are already outside of the area we were supposed to
                    // scan.
                    rate *= 3.0d;
                    if (useLog)
                    {
                        _x1 /= rate;
                    }
                    else
                    {
                        _x1 -= rate;
                    }
                }
            }
            return;
        }
    }

    public class BackProp : Prop, IMomentum,
                                 ILearningRate
    {
        /// <summary>
        /// The resume key for backProp.
        /// </summary>
        ///
        public const String PropertyLastDelta = "LAST_DELTA";

        /// <summary>
        /// The last delta values.
        /// </summary>
        ///
        private double[] _lastDelta;

        /// <summary>
        /// The learning rate.
        /// </summary>
        ///
        private double _learningRate;

        /// <summary>
        /// The momentum.
        /// </summary>
        ///
        private double _momentum;

        /// <summary>
        /// Create a class to train using backProp. Use auto learn rate and
        /// momentum. Use the CPU to train.
        /// </summary>
        ///
        /// <param name="network">The network that is to be trained.</param>
        /// <param name="training">The training data to be used for backProp.</param>
        public BackProp(BasicNetwork network, IMLDataSet training) : this(network, training, 0, 0)
        {
            AddStrategy(new SmartLearningRate());
            AddStrategy(new SmartMomentum());
        }


        /// <param name="network">The network that is to be trained</param>
        /// <param name="training">The training set</param>
        /// <param name="learnRate"></param>
        /// <param name="momentum"></param>
        public BackProp(BasicNetwork network,
                               IMLDataSet training, double learnRate,
                               double momentum) : base(network, training)
        {
            ValidateNetwork.ValidateMethodToData(network, training);
            _momentum = momentum;
            _learningRate = learnRate;
            _lastDelta = new double[Network.Flat.Weights.Length];
        }

        /// <inheritdoc />
        public override sealed bool CanContinue
        {
            get { return true; }
        }


        /// <value>Ther last delta values.</value>
        public double[] LastDelta
        {
            get { return _lastDelta; }
        }

        #region ILearningRate Members

        /// <summary>
        /// Set the learning rate, this is value is essentially a percent. It is the
        /// degree to which the gradients are applied to the weight matrix to allow
        /// learning.
        /// </summary>
        public virtual double LearningRate
        {
            get { return _learningRate; }
            set { _learningRate = value; }
        }

        #endregion

        #region IMomentum Members

        /// <summary>
        /// Set the momentum for training. This is the degree to which changes from
        /// which the previous training iteration will affect this training
        /// iteration. This can be useful to overcome local minima.
        /// </summary>
        public virtual double Momentum
        {
            get { return _momentum; }
            set { _momentum = value; }
        }

        #endregion

        /// <summary>
        /// Determine if the specified continuation object is valid to resume with.
        /// </summary>
        ///
        /// <param name="state">The continuation object to check.</param>
        /// <returns>True if the specified continuation object is valid for this
        /// training method and network.</returns>
        public bool IsValidResume(TrainingContinuation state)
        {
            if (!state.Contents.ContainsKey(PropertyLastDelta))
            {
                return false;
            }

            if (!state.TrainingType.Equals(GetType().Name))
            {
                return false;
            }

            var d = (double[])state.Get(PropertyLastDelta);
            return d.Length == ((IContainsFlat)Method).Flat.Weights.Length;
        }

        /// <summary>
        /// Pause the training.
        /// </summary>
        ///
        /// <returns>A training continuation object to continue with.</returns>
        public override sealed TrainingContinuation Pause()
        {
            var result = new TrainingContinuation { TrainingType = GetType().Name };
            result.Set(PropertyLastDelta, _lastDelta);
            return result;
        }

        /// <summary>
        /// Resume training.
        /// </summary>
        ///
        /// <param name="state">The training state to return to.</param>
        public override sealed void Resume(TrainingContinuation state)
        {
            if (!IsValidResume(state))
            {
                throw new TrainingError("Invalid training resume data length");
            }

            _lastDelta = (double[])state.Get(PropertyLastDelta);
        }

        /// <summary>
        /// Update a weight.
        /// </summary>
        ///
        /// <param name="gradients">The gradients.</param>
        /// <param name="lastGradient">The last gradients.</param>
        /// <param name="index">The index.</param>
        /// <returns>The weight delta.</returns>
        public override double UpdateWeight(double[] gradients,
                                                   double[] lastGradient, int index)
        {
            double delta = (gradients[index] * _learningRate)
                           + (_lastDelta[index] * _momentum);
            _lastDelta[index] = delta;
            return delta;
        }

        /// <summary>
        /// Not needed for this training type.
        /// </summary>
        public override void InitOthers()
        {
        }
    }

    public class ManhattanProp : Prop, ILearningRate
    {
        /// <summary>
        /// The default tolerance to determine of a number is close to zero.
        /// </summary>
        ///
        internal const double DefaultZeroTolerance = 0.001d;

        /// <summary>
        /// The zero tolerance to use.
        /// </summary>
        ///
        private readonly double _zeroTolerance;

        /// <summary>
        /// The learning rate.
        /// </summary>
        ///
        private double _learningRate;


        /// <summary>
        /// Construct a Manhattan Prop training object.
        /// </summary>
        ///
        /// <param name="network">The network to train.</param>
        /// <param name="training">The training data to use.</param>
        /// <param name="learnRate">The learning rate.</param>
        public ManhattanProp(BasicNetwork network,
                                    IMLDataSet training, double learnRate) : base(network, training)
        {
            _learningRate = learnRate;
            _zeroTolerance = RPROPConst.DefaultZeroTolerance;
        }


        /// <inheritdoc />
        public override sealed bool CanContinue
        {
            get { return false; }
        }

        #region ILearningRate Members

        /// <summary>
        /// Set the learning rate.
        /// </summary>
        public virtual double LearningRate
        {
            get { return _learningRate; }
            set { _learningRate = value; }
        }

        #endregion

        /// <summary>
        /// This training type does not support training continue.
        /// </summary>
        ///
        /// <returns>Always returns null.</returns>
        public override sealed TrainingContinuation Pause()
        {
            return null;
        }

        /// <summary>
        /// This training type does not support training continue.
        /// </summary>
        ///
        /// <param name="state">Not used.</param>
        public override sealed void Resume(TrainingContinuation state)
        {
        }

        /// <summary>
        /// Calculate the amount to change the weight by.
        /// </summary>
        ///
        /// <param name="gradients">The gradients.</param>
        /// <param name="lastGradient">The last gradients.</param>
        /// <param name="index">The index to update.</param>
        /// <returns>The amount to change the weight by.</returns>
        public override sealed double UpdateWeight(double[] gradients,
                                                   double[] lastGradient, int index)
        {
            if (Math.Abs(gradients[index]) < _zeroTolerance)
            {
                return 0;
            }
            else if (gradients[index] > 0)
            {
                return _learningRate;
            }
            else
            {
                return -_learningRate;
            }
        }

        /// <summary>
        /// Not needed for this training type.
        /// </summary>
        public override void InitOthers()
        {
        }

    }

    public sealed class QuickProp : Prop, ILearningRate
    {
        /// <summary>
        /// This factor times the current weight is added to the slope 
        /// at the start of each output epoch. Keeps weights from growing 
        /// too big.
        /// </summary>
        public double Decay { get; set; }

        /// <summary>
        /// Used to scale for the size of the training set.
        /// </summary>
        public double EPS { get; set; }

        /// <summary>
        /// The last deltas.
        /// </summary>
        public double[] LastDelta { get; set; }

        /// <summary>
        /// The learning rate.
        /// </summary>
        public double LearningRate { get; set; }

        /// <summary>
        /// Controls the amount of linear gradient descent 
        /// to use in updating output weights.
        /// </summary>
        public double OutputEpsilon { get; set; }

        /// <summary>
        /// Used in computing whether the proposed step is 
        /// too large.  Related to learningRate.
        /// </summary>
        public double Shrink { get; set; }


        /// <summary>
        /// Continuation tag for the last gradients.
        /// </summary>
        public const String LastGradients = "LAST_GRADIENTS";

        /// <summary>
        /// Construct a QPROP trainer for flat networks.  Uses a learning rate of 2.
        /// </summary>
        /// <param name="network">The network to train.</param>
        /// <param name="training">The training data.</param>
        public QuickProp(BasicNetwork network, IMLDataSet training) : this(network, training, 2.0)
        {
        }


        /// <summary>
        /// Construct a QPROP trainer for flat networks.
        /// </summary>
        /// <param name="network">The network to train.</param>
        /// <param name="training">The training data.</param>
        /// <param name="learnRate">The learning rate.  2 is a good suggestion as 
        ///            a learning rate to start with.  If it fails to converge, 
        ///            then drop it.  Just like backprop, except QPROP can 
        ///            take higher learning rates.</param>
        public QuickProp(BasicNetwork network,
                                IMLDataSet training, double learnRate) : base(network, training)
        {
            ValidateNetwork.ValidateMethodToData(network, training);
            LearningRate = learnRate;
        }

        /// <inheritdoc />
        public override bool CanContinue
        {
            get { return true; }
        }


        /// <summary>
        /// Determine if the specified continuation object is valid to resume with.
        /// </summary>
        /// <param name="state">The continuation object to check.</param>
        /// <returns>True if the specified continuation object is valid for this
        /// training method and network.</returns>
        public bool IsValidResume(TrainingContinuation state)
        {
            if (!state.Contents.ContainsKey(LastGradients))
            {
                return false;
            }

            if (!state.TrainingType.Equals(GetType().Name))
            {
                return false;
            }

            var d = (double[])state.Contents[LastGradients];
            return d.Length == ((IContainsFlat)Method).Flat.Weights.Length;
        }

        /// <summary>
        /// Pause the training.
        /// </summary>
        /// <returns>A training continuation object to continue with.</returns>
        public override TrainingContinuation Pause()
        {
            var result = new TrainingContinuation { TrainingType = (GetType().Name) };
            result.Contents[LastGradients] = LastGradient;
            return result;
        }

        /// <summary>
        /// Resume training.
        /// </summary>
        /// <param name="state">The training state to return to.</param>
        public override void Resume(TrainingContinuation state)
        {
            if (!IsValidResume(state))
            {
                throw new TrainingError("Invalid training resume data length");
            }

            var lastGradient = (double[])state.Contents[
                LastGradients];

            EngineArray.ArrayCopy(lastGradient, LastGradient);
        }

        /// <summary>
        /// Called to init the QPROP.
        /// </summary>
        public override void InitOthers()
        {
            EPS = OutputEpsilon / Training.Count;
            Shrink = LearningRate / (1.0 + LearningRate);
        }

        /// <summary>
        /// Update a weight.
        /// </summary>
        /// <param name="gradients">The gradients.</param>
        /// <param name="lastGradient">The last gradients.</param>
        /// <param name="index">The index.</param>
        /// <returns>The weight delta.</returns>
        public override double UpdateWeight(double[] gradients,
                                            double[] lastGradient, int index)
        {
            double w = Network.Flat.Weights[index];
            double d = LastDelta[index];
            double s = -Gradients[index] + Decay * w;
            double p = -lastGradient[index];
            double nextStep = 0.0;

            // The step must always be in direction opposite to the slope.
            if (d < 0.0)
            {
                // If last step was negative...
                if (s > 0.0)
                {
                    // Add in linear term if current slope is still positive.
                    nextStep -= EPS * s;
                }
                // If current slope is close to or larger than prev slope...
                if (s >= (Shrink * p))
                {
                    // Take maximum size negative step.
                    nextStep += LearningRate * d;
                }
                else
                {
                    // Else, use quadratic estimate.
                    nextStep += d * s / (p - s);
                }
            }
            else if (d > 0.0)
            {
                // If last step was positive...
                if (s < 0.0)
                {
                    // Add in linear term if current slope is still negative.
                    nextStep -= EPS * s;
                }
                // If current slope is close to or more neg than prev slope...
                if (s <= (Shrink * p))
                {
                    // Take maximum size negative step.
                    nextStep += LearningRate * d;
                }
                else
                {
                    // Else, use quadratic estimate.
                    nextStep += d * s / (p - s);
                }
            }
            else
            {
                // Last step was zero, so use only linear term. 
                nextStep -= EPS * s;
            }

            // update global data arrays
            LastDelta[index] = nextStep;
            LastGradient[index] = gradients[index];

            return nextStep;
        }

    }

    public class ResilientProp : Prop
    {
        /// <summary>
        /// Continuation tag for the last gradients.
        /// </summary>
        ///
        public const String LastGradientsConst = "LAST_GRADIENTS";

        /// <summary>
        /// Continuation tag for the last values.
        /// </summary>
        ///
        public const String UpdateValuesConst = "UPDATE_VALUES";

        /// <summary>
        /// The last deltas.
        /// </summary>
        private readonly double[] _lastDelta;

        /// <summary>
        /// The last weight changed.
        /// </summary>
        private readonly double[] _lastWeightChanged;

        /// <summary>
        /// The maximum step value for rprop.
        /// </summary>
        ///
        private readonly double _maxStep;

        /// <summary>
        /// The update values, for the weights and thresholds.
        /// </summary>
        ///
        private readonly double[] _updateValues;

        /// <summary>
        /// The zero tolerance.
        /// </summary>
        ///
        private readonly double _zeroTolerance;

        /// <summary>
        /// The last error.
        /// </summary>
        private double _lastError;


        /// <summary>
        /// Construct an RPROP trainer, allows an OpenCL device to be specified. Use
        /// the defaults for all training parameters. Usually this is the constructor
        /// to use as the resilient training Algo is designed for the default
        /// parameters to be acceptable for nearly all problems.
        /// </summary>
        ///
        /// <param name="network">The network to train.</param>
        /// <param name="training">The training data to use.</param>
        public ResilientProp(BasicNetwork network,
                                    IMLDataSet training)
            : this(network, training, RPROPConst.DefaultInitialUpdate, RPROPConst.DefaultMaxStep)
        {
        }

        /// <summary>
        /// Construct a resilient training object, allow the training parameters to
        /// be specified. Usually the default parameters are acceptable for the
        /// resilient training Algo. Therefore you should usually use the other
        /// constructor, that makes use of the default values.
        /// </summary>
        ///
        /// <param name="network">The network to train.</param>
        /// <param name="training">The training set to use.</param>
        /// <param name="initialUpdate"></param>
        /// <param name="maxStep">The maximum that a delta can reach.</param>
        public ResilientProp(IContainsFlat network,
                                    IMLDataSet training, double initialUpdate,
                                    double maxStep) : base(network, training)
        {
            _updateValues = new double[network.Flat.Weights.Length];
            _zeroTolerance = RPROPConst.DefaultZeroTolerance;
            _maxStep = maxStep;
            _lastWeightChanged = new double[Network.Flat.Weights.Length];
            _lastDelta = new double[Network.Flat.Weights.Length];

            for (int i = 0; i < _updateValues.Length; i++)
            {
                _updateValues[i] = initialUpdate;
            }
        }


        /// <inheritdoc />
        public override sealed bool CanContinue
        {
            get { return true; }
        }

        /// <summary>
        /// Determine if the specified continuation object is valid to resume with.
        /// </summary>
        ///
        /// <param name="state">The continuation object to check.</param>
        /// <returns>True if the specified continuation object is valid for this
        /// training method and network.</returns>
        public bool IsValidResume(TrainingContinuation state)
        {
            if (!state.Contents.ContainsKey(
                LastGradientsConst)
                || !state.Contents.ContainsKey(
                    UpdateValuesConst))
            {
                return false;
            }

            if (!state.TrainingType.Equals(GetType().Name))
            {
                return false;
            }

            var d = (double[])state.Get(LastGradientsConst);
            return d.Length == Network.Flat.Weights.Length;
        }

        /// <summary>
        /// Pause the training.
        /// </summary>
        ///
        /// <returns>A training continuation object to continue with.</returns>
        public override sealed TrainingContinuation Pause()
        {
            var result = new TrainingContinuation();

            result.TrainingType = GetType().Name;

            result.Set(LastGradientsConst, LastGradient);
            result.Set(UpdateValuesConst, _updateValues);

            return result;
        }

        /// <summary>
        /// Resume training.
        /// </summary>
        ///
        /// <param name="state">The training state to return to.</param>
        public override sealed void Resume(TrainingContinuation state)
        {
            if (!IsValidResume(state))
            {
                throw new TrainingError("Invalid training resume data length");
            }
            var lastGradient = (double[])state.Get(LastGradientsConst);
            var updateValues = (double[])state.Get(UpdateValuesConst);

            EngineArray.ArrayCopy(lastGradient, LastGradient);
            EngineArray.ArrayCopy(updateValues, _updateValues);
        }

        /// <summary>
        /// The type of RPROP to use.
        /// </summary>
        public RPROPType RType { get; set; }

        /// <value>The RPROP update values.</value>
        public double[] UpdateValues
        {
            get { return _updateValues; }
        }

        /// <summary>
        /// Determine the sign of the value.
        /// </summary>
        ///
        /// <param name="v">The value to check.</param>
        /// <returns>-1 if less than zero, 1 if greater, or 0 if zero.</returns>
        private int Sign(double v)
        {
            if (Math.Abs(v) < _zeroTolerance)
            {
                return 0;
            }
            if (v > 0)
            {
                return 1;
            }
            return -1;
        }

        /// <summary>
        /// Calculate the amount to change the weight by.
        /// </summary>
        ///
        /// <param name="gradients">The gradients.</param>
        /// <param name="lastGradient">The last gradients.</param>
        /// <param name="index">The index to update.</param>
        /// <returns>The amount to change the weight by.</returns>
        public override double UpdateWeight(double[] gradients,
                                            double[] lastGradient, int index)
        {
            double weightChange = 0;

            switch (RType)
            {
                case RPROPType.RPROPp:
                    weightChange = UpdateWeightPlus(gradients, lastGradient, index);
                    break;
                case RPROPType.RPROPm:
                    weightChange = UpdateWeightMinus(gradients, lastGradient, index);
                    break;
                case RPROPType.iRPROPp:
                    weightChange = UpdateiWeightPlus(gradients, lastGradient, index);
                    break;
                case RPROPType.iRPROPm:
                    weightChange = UpdateiWeightMinus(gradients, lastGradient, index);
                    break;
                default:
                    throw new TrainingError("Unknown RPROP type: " + RType);
            }

            _lastWeightChanged[index] = weightChange;
            return weightChange;
        }


        public double UpdateWeightPlus(double[] gradients,
                                       double[] lastGradient, int index)
        {
            // multiply the current and previous gradient, and take the
            // sign. We want to see if the gradient has changed its sign.
            int change = Sign(gradients[index] * lastGradient[index]);
            double weightChange = 0;

            // if the gradient has retained its sign, then we increase the
            // delta so that it will converge faster
            if (change > 0)
            {
                double delta = UpdateValues[index]
                               * RPROPConst.PositiveEta;
                delta = Math.Min(delta, _maxStep);
                weightChange = Sign(gradients[index]) * delta;
                UpdateValues[index] = delta;
                lastGradient[index] = gradients[index];
            }
            else if (change < 0)
            {
                // if change<0, then the sign has changed, and the last
                // delta was too big
                double delta = UpdateValues[index]
                               * RPROPConst.NegativeEta;
                delta = Math.Max(delta, RPROPConst.DeltaMin);
                UpdateValues[index] = delta;
                weightChange = -_lastWeightChanged[index];
                // set the previous gradent to zero so that there will be no
                // adjustment the next iteration
                lastGradient[index] = 0;
            }
            else if (change == 0)
            {
                // if change==0 then there is no change to the delta
                double delta = _updateValues[index];
                weightChange = Sign(gradients[index]) * delta;
                lastGradient[index] = gradients[index];
            }

            // apply the weight change, if any
            return weightChange;
        }

        public double UpdateWeightMinus(double[] gradients,
                                        double[] lastGradient, int index)
        {
            // multiply the current and previous gradient, and take the
            // sign. We want to see if the gradient has changed its sign.
            int change = Sign(gradients[index] * lastGradient[index]);
            double weightChange = 0;
            double delta;

            // if the gradient has retained its sign, then we increase the
            // delta so that it will converge faster
            if (change > 0)
            {
                delta = _lastDelta[index]
                        * RPROPConst.PositiveEta;
                delta = Math.Min(delta, _maxStep);
            }
            else
            {
                // if change<0, then the sign has changed, and the last
                // delta was too big
                delta = _lastDelta[index]
                        * RPROPConst.NegativeEta;
                delta = Math.Max(delta, RPROPConst.DeltaMin);
            }

            lastGradient[index] = gradients[index];
            weightChange = Sign(gradients[index]) * delta;
            _lastDelta[index] = delta;

            // apply the weight change, if any
            return weightChange;
        }

        public double UpdateiWeightPlus(double[] gradients,
                                        double[] lastGradient, int index)
        {
            // multiply the current and previous gradient, and take the
            // sign. We want to see if the gradient has changed its sign.
            int change = Sign(gradients[index] * lastGradient[index]);
            double weightChange = 0;

            // if the gradient has retained its sign, then we increase the
            // delta so that it will converge faster
            if (change > 0)
            {
                double delta = _updateValues[index]
                               * RPROPConst.PositiveEta;
                delta = Math.Min(delta, _maxStep);
                weightChange = Sign(gradients[index]) * delta;
                _updateValues[index] = delta;
                lastGradient[index] = gradients[index];
            }
            else if (change < 0)
            {
                // if change<0, then the sign has changed, and the last
                // delta was too big
                double delta = UpdateValues[index]
                               * RPROPConst.NegativeEta;
                delta = Math.Max(delta, RPROPConst.DeltaMin);
                UpdateValues[index] = delta;

                if (CurrentError > _lastError)
                {
                    weightChange = -_lastWeightChanged[index];
                }

                // set the previous gradent to zero so that there will be no
                // adjustment the next iteration
                lastGradient[index] = 0;
            }
            else if (change == 0)
            {
                // if change==0 then there is no change to the delta
                double delta = _updateValues[index];
                weightChange = Sign(gradients[index]) * delta;
                lastGradient[index] = gradients[index];
            }

            // apply the weight change, if any
            return weightChange;
        }

        public double UpdateiWeightMinus(double[] gradients,
                                         double[] lastGradient, int index)
        {
            // multiply the current and previous gradient, and take the
            // sign. We want to see if the gradient has changed its sign.
            int change = Sign(gradients[index] * lastGradient[index]);
            double weightChange = 0;
            double delta;

            // if the gradient has retained its sign, then we increase the
            // delta so that it will converge faster
            if (change > 0)
            {
                delta = _lastDelta[index]
                        * RPROPConst.PositiveEta;
                delta = Math.Min(delta, _maxStep);
            }
            else
            {
                // if change<0, then the sign has changed, and the last
                // delta was too big
                delta = _lastDelta[index]
                        * RPROPConst.NegativeEta;
                delta = Math.Max(delta, RPROPConst.DeltaMin);
                lastGradient[index] = 0;
            }

            lastGradient[index] = gradients[index];
            weightChange = Sign(gradients[index]) * delta;
            _lastDelta[index] = delta;

            // apply the weight change, if any
            return weightChange;
        }


        /// <summary>
        /// Not needed for this training type.
        /// </summary>
        public override void InitOthers()
        {
        }

    }

    public static class RPROPConst
    {
        /// <summary>
        /// The default zero tolerance.
        /// </summary>
        ///
        public const double DefaultZeroTolerance = 0.00000000000000001d;

        /// <summary>
        /// The POSITIVE ETA value. This is specified by the resilient Prop
        /// Algo. This is the percentage by which the deltas are increased by if
        /// the partial derivative is greater than zero.
        /// </summary>
        ///
        public const double PositiveEta = 1.2d;

        /// <summary>
        /// The NEGATIVE ETA value. This is specified by the resilient Prop
        /// Algo. This is the percentage by which the deltas are increased by if
        /// the partial derivative is less than zero.
        /// </summary>
        ///
        public const double NegativeEta = 0.5d;

        /// <summary>
        /// The minimum delta value for a weight matrix value.
        /// </summary>
        ///
        public const double DeltaMin = 1e-6d;

        /// <summary>
        /// The starting update for a delta.
        /// </summary>
        ///
        public const double DefaultInitialUpdate = 0.1d;

        /// <summary>
        /// The maximum amount a delta can reach.
        /// </summary>
        ///
        public const double DefaultMaxStep = 50;
    }

    public class ScaledConjugateGradient : Prop
    {
        /// <summary>
        /// The starting value for sigma.
        /// </summary>
        ///
        protected internal const double FirstSigma = 1.0E-4D;

        /// <summary>
        /// The starting value for lambda.
        /// </summary>
        ///
        protected internal const double FirstLambda = 1.0E-6D;

        /// <summary>
        /// The old gradients, used to compare.
        /// </summary>
        ///
        private readonly double[] _oldGradient;

        /// <summary>
        /// The old weight values, used to restore the neural network.
        /// </summary>
        ///
        private readonly double[] _oldWeights;

        /// <summary>
        /// Step direction vector.
        /// </summary>
        ///
        private readonly double[] _p;

        /// <summary>
        /// Step direction vector.
        /// </summary>
        ///
        private readonly double[] _r;

        /// <summary>
        /// The neural network weights.
        /// </summary>
        ///
        private readonly double[] _weights;

        /// <summary>
        /// The current delta.
        /// </summary>
        ///
        private double _delta;

        /// <summary>
        /// The number of iterations. The network will reset when this value
        /// increases over the number of weights in the network.
        /// </summary>
        ///
        private int _k;

        /// <summary>
        /// The first lambda value.
        /// </summary>
        ///
        private double _lambda;

        /// <summary>
        /// The second lambda value.
        /// </summary>
        ///
        private double _lambda2;

        /// <summary>
        /// The magnitude of p.
        /// </summary>
        ///
        private double _magP;

        /// <summary>
        /// Should the initial gradients be calculated.
        /// </summary>
        ///
        private bool _mustInit;

        /// <summary>
        /// The old error value, used to make sure an improvement happened.
        /// </summary>
        ///
        private double _oldError;

        /// <summary>
        /// Should we restart?
        /// </summary>
        ///
        private bool _restart;

        /// <summary>
        /// Tracks if the latest training cycle was successful.
        /// </summary>
        ///
        private bool _success;


        /// <summary>
        /// Construct a training class.
        /// </summary>
        ///
        /// <param name="network">The network to train.</param>
        /// <param name="training">The training data.</param>
        public ScaledConjugateGradient(BasicNetwork network,
                                       IMLDataSet training) : base(network, training)
        {
            _success = true;

            _success = true;
            _delta = 0;
            _lambda2 = 0;
            _lambda = FirstLambda;
            _oldError = 0;
            _magP = 0;
            _restart = false;

            _weights = EngineArray.ArrayCopy(network.Flat.Weights);
            int numWeights = _weights.Length;

            _oldWeights = new double[numWeights];
            _oldGradient = new double[numWeights];

            _p = new double[numWeights];
            _r = new double[numWeights];

            _mustInit = true;

        }

        /// <summary>
        /// This training type does not support training continue.
        /// </summary>
        ///
        /// <returns>Always returns false.</returns>
        public override sealed bool CanContinue
        {
            get { return false; }
        }

        /// <summary>
        /// This training type does not support training continue.
        /// </summary>
        ///
        /// <returns>Always returns null.</returns>
        public override sealed TrainingContinuation Pause()
        {
            return null;
        }

        /// <summary>
        /// This training type does not support training continue.
        /// </summary>
        ///
        /// <param name="state">Not used.</param>
        public override sealed void Resume(TrainingContinuation state)
        {
        }

        /// <summary>
        /// Calculate the gradients. They are normalized as well.
        /// </summary>
        ///
        public override void CalculateGradients()
        {
            int outCount = Network.Flat.OutputCount;

            base.CalculateGradients();

            // normalize

            double factor = -2D / Gradients.Length / outCount;

            for (int i = 0; i < Gradients.Length; i++)
            {
                Gradients[i] *= factor;
            }
        }

        /// <summary>
        /// Calculate the starting set of gradients.
        /// </summary>
        ///
        private void Init()
        {
            int numWeights = _weights.Length;

            CalculateGradients();

            _k = 1;

            for (int i = 0; i < numWeights; ++i)
            {
                _p[i] = _r[i] = -Gradients[i];
            }

            _mustInit = false;
        }

        /// <summary>
        /// Perform one iteration.
        /// </summary>
        ///
        public override void Iteration()
        {
            if (_mustInit)
            {
                Init();
            }
            RollIteration();
            int numWeights = _weights.Length;
            // Storage space for previous iteration values.

            if (_restart)
            {
                // First time through, set initial values for SCG parameters.
                _lambda = FirstLambda;
                _lambda2 = 0;
                _k = 1;
                _success = true;
                _restart = false;
            }

            // If an error reduction is possible, calculate 2nd order info.
            if (_success)
            {
                // If the search direction is small, stop.
                _magP = EngineArray.VectorProduct(_p, _p);

                double sigma = FirstSigma
                               / Math.Sqrt(_magP);

                // In order to compute the new step, we need a new gradient.
                // First, save off the old data.
                EngineArray.ArrayCopy(Gradients, _oldGradient);
                EngineArray.ArrayCopy(_weights, _oldWeights);
                _oldError = Error;

                // Now we move to the new point in weight space.
                for (int i = 0; i < numWeights; ++i)
                {
                    _weights[i] += sigma * _p[i];
                }

                EngineArray.ArrayCopy(_weights, Network.Flat.Weights);

                // And compute the new gradient.
                CalculateGradients();

                // Now we have the new gradient, and we continue the step
                // computation.
                _delta = 0;
                for (int i = 0; i < numWeights; ++i)
                {
                    double step = (Gradients[i] - _oldGradient[i])
                                  / sigma;
                    _delta += _p[i] * step;
                }
            }

            // Scale delta.
            _delta += (_lambda - _lambda2) * _magP;

            // If delta <= 0, make Hessian positive definite.
            if (_delta <= 0)
            {
                _lambda2 = 2 * (_lambda - _delta / _magP);
                _delta = _lambda * _magP - _delta;
                _lambda = _lambda2;
            }

            // Calculate step size.
            double mu = EngineArray.VectorProduct(_p, _r);
            double alpha = mu / _delta;

            // Calculate the comparison parameter.
            // We must compute a new gradient, but this time we do not
            // want to keep the old values. They were useful only for
            // approximating the Hessian.
            for (int i = 0; i < numWeights; ++i)
            {
                _weights[i] = _oldWeights[i] + alpha * _p[i];
            }

            EngineArray.ArrayCopy(_weights, Network.Flat.Weights);

            CalculateGradients();

            double gdelta = 2 * _delta * (_oldError - Error)
                            / (mu * mu);

            // If gdelta >= 0, a successful reduction in error is possible.
            if (gdelta >= 0)
            {
                // Product of r(k+1) by r(k)
                double rsum = 0;

                // Now r = r(k+1).
                for (int i = 0; i < numWeights; ++i)
                {
                    double tmp = -Gradients[i];
                    rsum += tmp * _r[i];
                    _r[i] = tmp;
                }
                _lambda2 = 0;
                _success = true;

                // Do we need to restart?
                if (_k >= numWeights)
                {
                    _restart = true;
                    EngineArray.ArrayCopy(_r, _p);
                }
                else
                {
                    // Compute new conjugate direction.
                    double beta = (EngineArray.VectorProduct(_r, _r) - rsum)
                                  / mu;

                    // Update direction vector.
                    for (int i = 0; i < numWeights; ++i)
                    {
                        _p[i] = _r[i] + beta * _p[i];
                    }

                    _restart = false;
                }

                if (gdelta >= 0.75D)
                {
                    _lambda *= 0.25D;
                }
            }
            else
            {
                // A reduction in error was not possible.
                // under_tolerance = false;

                // Go back to w(k) since w(k) + alpha*p(k) is not better.
                EngineArray.ArrayCopy(_oldWeights, _weights);
                CurrentError = _oldError;
                _lambda2 = _lambda;
                _success = false;
            }

            if (gdelta < 0.25D)
            {
                _lambda += _delta * (1 - gdelta) / _magP;
            }

            _lambda = BoundNumbers.Bound(_lambda);

            ++_k;

            EngineArray.ArrayCopy(_weights, Network.Flat.Weights);
        }

        /// <summary>
        /// Update the weights.
        /// </summary>
        ///
        /// <param name="gradients">The current gradients.</param>
        /// <param name="lastGradient">The last gradients.</param>
        /// <param name="index">The weight index being updated.</param>
        /// <returns>The new weight value.</returns>
        public override double UpdateWeight(double[] gradients,
                                            double[] lastGradient, int index)
        {
            return 0;
        }

        /// <summary>
        /// Not needed for this training type.
        /// </summary>
        public override void InitOthers()
        {
        }

    }

    public class GradientWorker : IEngineTask
    {
        /// <summary>
        /// The actual values from the neural network.
        /// </summary>
        ///
        private readonly double[] _actual;

        /// <summary>
        /// The error calculation method.
        /// </summary>
        ///
        private readonly ErrorCalculation _errorCalculation;

        /// <summary>
        /// The gradients.
        /// </summary>
        ///
        private readonly double[] _gradients;

        /// <summary>
        /// The low end of the training.
        /// </summary>
        ///
        private readonly int _high;

        /// <summary>
        /// The neuron counts, per layer.
        /// </summary>
        ///
        private readonly int[] _layerCounts;

        /// <summary>
        /// The deltas for each layer.
        /// </summary>
        ///
        private readonly double[] _layerDelta;

        /// <summary>
        /// The feed counts, per layer.
        /// </summary>
        ///
        private readonly int[] _layerFeedCounts;

        /// <summary>
        /// The layer indexes.
        /// </summary>
        ///
        private readonly int[] _layerIndex;

        /// <summary>
        /// The output from each layer.
        /// </summary>
        ///
        private readonly double[] _layerOutput;

        /// <summary>
        /// The sum from each layer.
        /// </summary>
        ///
        private readonly double[] _layerSums;

        /// <summary>
        /// The high end of the training data.
        /// </summary>
        ///
        private readonly int _low;

        /// <summary>
        /// The network to train.
        /// </summary>
        ///
        private readonly FlatNetwork _network;

        /// <summary>
        /// The owner.
        /// </summary>
        ///
        private readonly Prop _owner;

        /// <summary>
        /// The pair to use for training.
        /// </summary>
        ///
        private readonly IMLDataPair _pair;

        /// <summary>
        /// The training data.
        /// </summary>
        ///
        private readonly IMLDataSet _training;

        /// <summary>
        /// The index to each layer's weights and thresholds.
        /// </summary>
        ///
        private readonly int[] _weightIndex;

        /// <summary>
        /// The weights and thresholds.
        /// </summary>
        ///
        private readonly double[] _weights;

        /// <summary>
        /// Derivative add constant.  Used to combat flat spot.
        /// </summary>
        private readonly double[] _flatSpot;

        /// <summary>
        /// The error function.
        /// </summary>
        private readonly IErrorFunction _ef;


        /// <summary>
        /// Construct a gradient worker.
        /// </summary>
        ///
        /// <param name="theNetwork">The network to train.</param>
        /// <param name="theOwner">The owner that is doing the training.</param>
        /// <param name="theTraining">The training data.</param>
        /// <param name="theLow">The low index to use in the training data.</param>
        /// <param name="theHigh">The high index to use in the training data.</param>
        /// <param name="theFlatSpots">Holds an array of flat spot constants.</param>
        public GradientWorker(FlatNetwork theNetwork,
                                 Prop theOwner, IMLDataSet theTraining,
                                 int theLow, int theHigh, double[] theFlatSpots, IErrorFunction ef)
        {
            _errorCalculation = new ErrorCalculation();
            _network = theNetwork;
            _training = theTraining;
            _low = theLow;
            _high = theHigh;
            _owner = theOwner;
            _flatSpot = theFlatSpots;

            _layerDelta = new double[_network.LayerOutput.Length];
            _gradients = new double[_network.Weights.Length];
            _actual = new double[_network.OutputCount];

            _weights = _network.Weights;
            _layerIndex = _network.LayerIndex;
            _layerCounts = _network.LayerCounts;
            _weightIndex = _network.WeightIndex;
            _layerOutput = _network.LayerOutput;
            _layerSums = _network.LayerSums;
            _layerFeedCounts = _network.LayerFeedCounts;
            _ef = ef;

            _pair = BasicMLDataPair.CreatePair(_network.InputCount,
                                              _network.OutputCount);
        }

        #region FlatGradientWorker Members

        /// <inheritdoc/>
        public FlatNetwork Network
        {
            get { return _network; }
        }


        /// <value>The weights for this network.</value>
        public double[] Weights
        {
            get { return _weights; }
        }

        /// <summary>
        /// Perform the gradient calculation for the specified index range.
        /// </summary>
        ///
        public void Run()
        {
            try
            {
                _errorCalculation.Reset();
                for (int i = _low; i <= _high; i++)
                {
                    _training.GetRecord(i, _pair);
                    Process(_pair.InputArray, _pair.IdealArray, _pair.Significance);
                }
                double error = _errorCalculation.Calculate();
                _owner.Report(_gradients, error, null);
                EngineArray.Fill(_gradients, 0);
            }
            catch (Exception ex)
            {
                _owner.Report(null, 0, ex);
            }
        }

        #endregion

        /// <summary>
        /// Process one training set element.
        /// </summary>
        ///
        /// <param name="input">The network input.</param>
        /// <param name="ideal">The ideal values.</param>
        /// <param name="s">The significance of this error.</param>
        private void Process(double[] input, double[] ideal, double s)
        {
            _network.Compute(input, _actual);

            _errorCalculation.UpdateError(_actual, ideal, s);
            _ef.CalculateError(ideal, _actual, _layerDelta);

            for (int i = 0; i < _actual.Length; i++)
            {
                _layerDelta[i] = (_network.ActivationFunctions[0]
                                    .DerivativeFunction(_layerSums[i], _layerOutput[i]) + _flatSpot[0])
                                * _layerDelta[i] * s;
            }

            for (int i = _network.BeginTraining; i < _network.EndTraining; i++)
            {
                ProcessLevel(i);
            }
        }

        /// <summary>
        /// Process one level.
        /// </summary>
        ///
        /// <param name="currentLevel">The level.</param>
        private void ProcessLevel(int currentLevel)
        {
            int fromLayerIndex = _layerIndex[currentLevel + 1];
            int toLayerIndex = _layerIndex[currentLevel];
            int fromLayerSize = _layerCounts[currentLevel + 1];
            int toLayerSize = _layerFeedCounts[currentLevel];

            int index = _weightIndex[currentLevel];
            IActivationFunction activation = _network.ActivationFunctions[currentLevel + 1];
            double currentFlatSpot = _flatSpot[currentLevel + 1];

            // handle weights
            int yi = fromLayerIndex;
            for (int y = 0; y < fromLayerSize; y++)
            {
                double output = _layerOutput[yi];
                double sum = 0;
                int xi = toLayerIndex;
                int wi = index + y;
                for (int x = 0; x < toLayerSize; x++)
                {
                    _gradients[wi] += output * _layerDelta[xi];
                    sum += _weights[wi] * _layerDelta[xi];
                    wi += fromLayerSize;
                    xi++;
                }

                _layerDelta[yi] = sum
                                 * (activation.DerivativeFunction(_layerSums[yi], _layerOutput[yi]) + currentFlatSpot);
                yi++;
            }
        }
    }

    public class PersistTrainingContinuation : ISyntPersistor
    {
        #region SyntPersistor Members

        /// <summary>
        /// 
        /// </summary>
        ///
        public virtual int FileVersion
        {
            get { return 1; }
        }

        /// <inheritdoc/>
        public Type NativeType
        {
            get { return typeof(TrainingContinuation); }
        }

        /// <inheritdoc/>
        public virtual String PersistClassString
        {
            get { return "TrainingContinuation"; }
        }


        /// <inheritdoc/>
        public Object Read(Stream mask0)
        {
            var result = new TrainingContinuation();
            var ins0 = new SyntReadHelper(mask0);
            SyntFileSection section;

            while ((section = ins0.ReadNextSection()) != null)
            {
                if (section.SectionName.Equals("CONT")
                    && section.SubSectionName.Equals("PARAMS"))
                {
                    IDictionary<String, String> paras = section.ParseParams();

                    foreach (String key in paras.Keys)
                    {
                        if (key.Equals("type", StringComparison.InvariantCultureIgnoreCase))
                        {
                            result.TrainingType = paras[key];
                        }
                        else
                        {
                            double[] list = section.ParseDoubleArray(paras, key);
                            result.Put(key, list);
                        }
                    }
                }
            }

            return result;
        }

        /// <inheritdoc/>
        public void Save(Stream os, Object obj)
        {
            var xout = new SyntWriteHelper(os);
            var cont = (TrainingContinuation)obj;
            xout.AddSection("CONT");
            xout.AddSubSection("PARAMS");
            xout.WriteProperty("type", cont.TrainingType);

            foreach (String key in cont.Contents.Keys)
            {
                var list = (double[])cont.Get(key);
                xout.WriteProperty(key, list);
            }
            xout.Flush();
        }

        #endregion
    }

    [Serializable]
    public class TrainingContinuation
    {
        /// <summary>
        /// The contents of this object.
        /// </summary>
        ///
        private readonly IDictionary<String, Object> _contents;

        /// <summary>
        /// Construct the object.
        /// </summary>
        public TrainingContinuation()
        {
            _contents = new Dictionary<String, Object>();
        }


        /// <value>The contents.</value>
        public IDictionary<String, Object> Contents
        {
            get { return _contents; }
        }

        /// <value>the trainingType to set</value>
        public String TrainingType
        {
            get;
            set;
        }

        /// <summary>
        /// Get an object by name.
        /// </summary>
        ///
        /// <param name="name">The name of the object.</param>
        /// <returns>The object requested.</returns>
        public Object Get(String name)
        {
            return _contents[name];
        }


        /// <summary>
        /// Save a list of doubles.
        /// </summary>
        ///
        /// <param name="key">The key to save them under.</param>
        /// <param name="list">The list of doubles.</param>
        public void Put(String key, double[] list)
        {
            _contents[key] = list;
        }

        /// <summary>
        /// Set a value to a string.
        /// </summary>
        ///
        /// <param name="name">The value to set.</param>
        /// <param name="v">The value.</param>
        public void Set(String name, Object v)
        {
            _contents[name] = v;
        }
    }

    public class NeuralPSO : BasicTraining
    {
        public bool IsMultiThreaded { get; set; }
        protected VectorAlgebra m_va;
        protected ICalculateScore m_calculateScore;
        protected IRandomizer m_randomizer;

        /// <summary>
        /// Swarm state and memories.
        /// </summary>
        protected BasicNetwork[] m_networks;
        protected double[][] m_velocities;
        protected double[][] m_bestVectors;
        protected double[] m_bestErrors;
        protected int m_bestVectorIndex;

        /// <summary>
        /// Although this is redundant with m_bestVectors[m_bestVectorIndex],
        /// m_bestVectors[m_bestVectorIndex] is not thread safe.
        /// </summary>
        private double[] m_bestVector;
        BasicNetwork m_bestNetwork = null;

        /// <summary>
        /// Typical range is 20 - 40 for many problems. 
        /// More difficult problems may need much higher value. 
        /// Must be low enough to keep the training process 
        /// computationally efficient.
        /// </summary>
        protected int m_populationSize = 30;

        /// <summary>
        /// Determines the size of the search space. 
        /// The position components of particle will be bounded to 
        /// [-maxPos, maxPos]
        /// A well chosen range can improve the performance. 
        /// -1 is a special value that represents boundless search space.
        /// </summary>
        protected double m_maxPosition = -1;



        /// <summary>
        /// Maximum change one particle can take during one iteration.
        /// Imposes a limit on the maximum absolute value of the velocity 
        /// components of a particle. 
        /// Affects the granularity of the search.
        /// If too high, particle can fly past optimum solution.
        /// If too low, particle can get stuck in local minima.
        /// Usually set to a fraction of the dynamic range of the search
        /// space (10% was shown to be good for high dimensional problems).
        /// -1 is a special value that represents boundless velocities. 
        /// </summary>
        protected double m_maxVelocity = 2;

        /// <summary>
        /// c1, cognitive learning rate >= 0
        /// tendency to return to personal best position
        /// </summary>
        protected double m_c1 = 2.0;

        /// <summary>
        /// c2, social learning rate >= 0
        /// tendency to move towards the swarm best position
        /// </summary>
        protected double m_c2 = 2.0;

        /// <summary>
        /// w, inertia weight.
        /// Controls global (higher value) vs local exploration 
        /// of the search space. 
        /// Analogous to temperature in simulated annealing.
        /// Must be chosen carefully or gradually decreased over time.
        /// Value usually between 0 and 1.
        /// </summary>
        protected double m_inertiaWeight = 0.4;

        /// <summary>
        /// If true, the position of the previous global best position 
        /// can be updated *before* the other particles have been modified.
        /// </summary>
        private bool m_pseudoAsynchronousUpdate = false;

        /// <summary>
        /// Constructor. 
        /// </summary>
        /// <param name="network">an initialised Synt network. 
        ///                          The networks in the swarm will be created with 
        ///                          the same topology as this network.</param>
        /// <param name="randomizer">any type of Synt network weight initialisation
        ///                          object.</param>
        /// <param name="calculateScore">any type of Synt network scoring/fitness object.</param>
        /// <param name="populationSize">the swarm size.</param>
        public NeuralPSO(BasicNetwork network,
                IRandomizer randomizer, ICalculateScore calculateScore,
                int populationSize)
            : base(TrainingImplementationType.Iterative)
        {

            IsMultiThreaded = true;

            // initialisation of the member variables
            m_populationSize = populationSize;
            m_randomizer = randomizer;
            m_calculateScore = calculateScore;
            m_bestNetwork = network;

            m_networks = new BasicNetwork[m_populationSize];
            m_velocities = null;
            m_bestVectors = new double[m_populationSize][];
            m_bestErrors = new double[m_populationSize];
            m_bestVectorIndex = -1;

            // get a vector from the network.
            m_bestVector = NetworkCODEC.NetworkToArray(m_bestNetwork);

            m_va = new VectorAlgebra();
        }

        /// <summary>
        /// Initialise the particle positions and velocities, 
        /// personal and global bests.
        /// Only does this if they have not yet been initialised.
        /// </summary>
        public void InitPopulation()
        {
            if (m_velocities == null)
            {
                int dimensionality = m_bestVector.Length;
                m_velocities = EngineArray.AllocateDouble2D(m_populationSize, dimensionality);
                // run an initialisation iteration
                IterationPSO(true);
            }
        }

        /// <summary>
        /// Runs one PSO iteration over the whole population of networks.
        /// </summary>
        public override void Iteration()
        {
            InitPopulation();

            PreIteration();
            IterationPSO(false);
            PostIteration();
        }

        /// <summary>
        /// Internal method for the iteration of the swarm. 
        /// </summary>
        /// <param name="init">true if this is an initialisation iteration.</param>
        protected void IterationPSO(bool init)
        {
            TaskGroup group = EngineConcurrency.Instance.CreateTaskGroup();

            for (int i = 0; i < m_populationSize; i++)
            {
                NeuralPSOWorker worker = new NeuralPSOWorker(this, i, init);
                if (!init && IsMultiThreaded)
                {
                    EngineConcurrency.Instance.ProcessTask(worker, group);
                }
                else
                {
                    worker.Run();
                }
            }
            if (IsMultiThreaded)
            {
                group.WaitForComplete();
            }
            UpdateGlobalBestPosition();
        }

        /// <summary>
        /// Update the velocity, position and personal 
        /// best position of a particle.
        /// </summary>
        /// <param name="particleIndex">index of the particle in the swarm</param>
        /// <param name="init">if true, the position and velocity
        ///                          will be initialised. </param>
        public void UpdateParticle(int particleIndex, bool init)
        {
            int i = particleIndex;
            double[] particlePosition = null;
            if (init)
            {
                // Create a new particle with random values.
                // Except the first particle which has the same values 
                // as the network passed to the Algo.
                if (m_networks[i] == null)
                {
                    m_networks[i] = (BasicNetwork)m_bestNetwork.Clone();
                    if (i > 0) m_randomizer.Randomize(m_networks[i]);
                }
                particlePosition = GetNetworkState(i);
                m_bestVectors[i] = particlePosition;

                // randomise the velocity
                m_va.Randomise(m_velocities[i], m_maxVelocity);
            }
            else
            {
                particlePosition = GetNetworkState(i);
                UpdateVelocity(i, particlePosition);

                // velocity clamping
                m_va.ClampComponents(m_velocities[i], m_maxVelocity);

                // new position (Xt = Xt-1 + Vt)
                m_va.Add(particlePosition, m_velocities[i]);

                // pin the particle against the boundary of the search space.
                // (only for the components exceeding maxPosition)
                m_va.ClampComponents(particlePosition, m_maxPosition);

                SetNetworkState(i, particlePosition);
            }
            UpdatePersonalBestPosition(i, particlePosition);
        }

        /// <summary>
        /// Update the velocity of a particle  
        /// </summary>
        /// <param name="particleIndex">index of the particle in the swarm</param>
        /// <param name="particlePosition">the particle current position vector</param>
        protected void UpdateVelocity(int particleIndex, double[] particlePosition)
        {
            int i = particleIndex;
            double[] vtmp = new double[particlePosition.Length];

            // Standard PSO formula

            // inertia weight
            m_va.Mul(m_velocities[i], m_inertiaWeight);

            // cognitive term
            m_va.Copy(vtmp, m_bestVectors[i]);
            m_va.Sub(vtmp, particlePosition);
            m_va.MulRand(vtmp, m_c1);
            m_va.Add(m_velocities[i], vtmp);

            // social term
            if (i != m_bestVectorIndex)
            {
                m_va.Copy(vtmp, m_pseudoAsynchronousUpdate ? m_bestVectors[m_bestVectorIndex] : m_bestVector);
                m_va.Sub(vtmp, particlePosition);
                m_va.MulRand(vtmp, m_c2);
                m_va.Add(m_velocities[i], vtmp);
            }
        }

        /// <summary>
        /// Update the personal best position of a particle. 
        /// </summary>
        /// <param name="particleIndex">index of the particle in the swarm</param>
        /// <param name="particlePosition">the particle current position vector</param>
        protected void UpdatePersonalBestPosition(int particleIndex, double[] particlePosition)
        {
            // set the network weights and biases from the vector
            double score = m_calculateScore.CalculateScore(m_networks[particleIndex]);

            // update the best vectors (g and i)
            if ((m_bestErrors[particleIndex] == 0) || IsScoreBetter(score, m_bestErrors[particleIndex]))
            {
                m_bestErrors[particleIndex] = score;
                m_va.Copy(m_bestVectors[particleIndex], particlePosition);
            }
        }

        /// <summary>
        /// Update the swarm's best position
        /// </summary>
        protected void UpdateGlobalBestPosition()
        {
            bool bestUpdated = false;
            for (int i = 0; i < m_populationSize; i++)
            {
                if ((m_bestVectorIndex == -1) || IsScoreBetter(m_bestErrors[i], m_bestErrors[m_bestVectorIndex]))
                {
                    m_bestVectorIndex = i;
                    bestUpdated = true;
                }
            }
            if (bestUpdated)
            {
                m_va.Copy(m_bestVector, m_bestVectors[m_bestVectorIndex]);
                m_bestNetwork.DecodeFromArray(m_bestVector);
                Error = m_bestErrors[m_bestVectorIndex];
            }
        }

        /// <summary>
        /// Compares two scores. 
        /// </summary>
        /// <param name="score1">a score</param>
        /// <param name="score2">a score</param>
        /// <returns>true if score1 is better than score2</returns>
        bool IsScoreBetter(double score1, double score2)
        {
            return ((m_calculateScore.ShouldMinimize && (score1 < score2)) || ((!m_calculateScore.ShouldMinimize) && (score1 > score2)));
        }

        public override TrainingContinuation Pause()
        {
            return null;
        }

        public override bool CanContinue
        {
            get
            {
                return false;
            }
        }

        public override void Resume(TrainingContinuation state)
        {
        }

        /// <summary>
        /// Returns the state of a network in the swarm  
        /// </summary>
        /// <param name="particleIndex">index of the network in the swarm</param>
        /// <returns>an array of weights and biases for the given network</returns>
        protected double[] GetNetworkState(int particleIndex)
        {
            return NetworkCODEC.NetworkToArray(m_networks[particleIndex]);
        }

        /// <summary>
        /// Sets the state of the networks in the swarm
        /// </summary>
        /// <param name="particleIndex">index of the network in the swarm</param>
        /// <param name="state">an array of weights and biases</param>
        protected void SetNetworkState(int particleIndex, double[] state)
        {
            NetworkCODEC.ArrayToNetwork(state, m_networks[particleIndex]);
        }

        /// <summary>
        /// Set the swarm size.
        /// </summary>
        public int PopulationSize
        {
            get
            {
                return m_populationSize;
            }
            set
            {
                m_populationSize = value;
            }
        }

        /// <summary>
        /// Sets the maximum velocity.
        /// </summary>
        public double MaxVelocity
        {
            get
            {
                return m_maxVelocity;
            }
            set
            {
                m_maxVelocity = value;
            }
        }

        /// <summary>
        /// Set the boundary of the search space (Xmax)
        /// </summary>
        public double MaxPosition
        {
            get
            {
                return m_maxPosition;
            }
            set
            {
                m_maxPosition = value;
            }
        }

        /// <summary>
        /// Sets the cognition coefficient (c1).
        /// </summary>
        public double C1
        {
            get
            {
                return m_c1;
            }
            set
            {
                m_c1 = value;
            }
        }


        /// <summary>
        /// Set the social coefficient (c2).
        /// </summary>
        public double C2
        {
            get
            {
                return m_c2;
            }
            set
            {
                m_c2 = value;
            }
        }

        /// <summary>
        /// Get the inertia weight (w) 
        /// </summary>
        public double InertiaWeight
        {
            get
            {
                return m_inertiaWeight;
            }
            set
            {
                m_inertiaWeight = value;
            }
        }

        /// <summary>
        /// Get a description of all the current settings.
        /// </summary>
        public String Description
        {
            get
            {
                StringBuilder result = new StringBuilder();

                result.Append("pop = ");
                result.Append(m_populationSize);
                result.Append(", w = ");
                result.Append(Format.FormatDouble(m_inertiaWeight, 2));
                result.Append(", c1 = ");
                result.Append(Format.FormatDouble(m_c1, 2));
                result.Append(", c2 = ");
                result.Append(Format.FormatDouble(m_c2, 2));
                result.Append(", Xmax = ");
                result.Append(Format.FormatDouble(m_maxPosition, 2));
                result.Append(", Vmax = ");
                result.Append(Format.FormatDouble(m_maxVelocity, 2));
                return result.ToString();
            }

        }

        /// <summary>
        /// Keep a reference to the passed population of networks.
        /// This population is not copied, it will evolve during training.   
        /// </summary>
        /// <param name="initialPopulation"></param>
        public void SetInitialPopulation(BasicNetwork[] initialPopulation)
        {
            m_networks = initialPopulation;
        }

        public override IMLMethod Method
        {
            get { return m_bestNetwork; }
        }
    }

    public class NeuralPSOWorker : IEngineTask
    {
        private NeuralPSO m_neuralPSO;
        private int m_particleIndex;
        private bool m_init = false;

        /// <summary>
        /// Constructor. 
        /// </summary>
        /// <param name="neuralPSO">the training Algo</param>
        /// <param name="particleIndex">the index of the particle in the swarm</param>
        /// <param name="init">true for an initialisation iteration </param>
        public NeuralPSOWorker(NeuralPSO neuralPSO, int particleIndex, bool init)
        {
            m_neuralPSO = neuralPSO;
            m_particleIndex = particleIndex;
            m_init = init;
        }

        /// <summary>
        /// Update the particle velocity, position and personal best.
        /// </summary>
        public void Run()
        {
            m_neuralPSO.UpdateParticle(m_particleIndex, m_init);
        }

    }

    public class TrainAdaline : BasicTraining, ILearningRate
    {
        /// <summary>
        /// The network to train.
        /// </summary>
        ///
        private readonly BasicNetwork _network;

        /// <summary>
        /// The training data to use.
        /// </summary>
        ///
        private readonly IMLDataSet _training;

        /// <summary>
        /// The learning rate.
        /// </summary>
        ///
        private double _learningRate;

        /// <summary>
        /// Construct an ADALINE trainer.
        /// </summary>
        ///
        /// <param name="network">The network to train.</param>
        /// <param name="training">The training data.</param>
        /// <param name="learningRate">The learning rate.</param>
        public TrainAdaline(BasicNetwork network, IMLDataSet training,
                            double learningRate) : base(TrainingImplementationType.Iterative)
        {
            if (network.LayerCount > 2)
            {
                throw new NeuralNetworkError(
                    "An ADALINE network only has two layers.");
            }
            _network = network;

            _training = training;
            _learningRate = learningRate;
        }

        /// <inheritdoc />
        public override sealed bool CanContinue
        {
            get { return false; }
        }


        /// <inheritdoc/>
        public override IMLMethod Method
        {
            get { return _network; }
        }

        #region ILearningRate Members

        /// <summary>
        /// Set the learning rate.
        /// </summary>
        public double LearningRate
        {
            get { return _learningRate; }
            set { _learningRate = value; }
        }

        #endregion

        /// <inheritdoc/>
        public override sealed void Iteration()
        {
            var errorCalculation = new ErrorCalculation();


            foreach (IMLDataPair pair in _training)
            {
                // calculate the error
                IMLData output = _network.Compute(pair.Input);

                for (int currentAdaline = 0; currentAdaline < output.Count; currentAdaline++)
                {
                    double diff = pair.Ideal[currentAdaline]
                                  - output[currentAdaline];

                    // weights
                    for (int i = 0; i <= _network.InputCount; i++)
                    {
                        double input;

                        if (i == _network.InputCount)
                        {
                            input = 1.0d;
                        }
                        else
                        {
                            input = pair.Input[i];
                        }

                        _network.AddWeight(0, i, currentAdaline,
                                          _learningRate * diff * input);
                    }
                }

                errorCalculation.UpdateError(output.Data, pair.Ideal.Data, pair.Significance);
            }

            // set the global error
            Error = errorCalculation.Calculate();
        }

        /// <inheritdoc/>
        public override sealed TrainingContinuation Pause()
        {
            return null;
        }

        /// <inheritdoc/>
        public override void Resume(TrainingContinuation state)
        {
        }
    }

    public class SmartLearningRate : IStrategy
    {
        /// <summary>
        /// Learning decay rate.
        /// </summary>
        ///
        public const double LearningDecay = 0.99d;

        /// <summary>
        /// The current learning rate.
        /// </summary>
        ///
        private double _currentLearningRate;

        /// <summary>
        /// The error rate from the previous iteration.
        /// </summary>
        ///
        private double _lastError;

        /// <summary>
        /// Has one iteration passed, and we are now ready to start evaluation.
        /// </summary>
        ///
        private bool _ready;

        /// <summary>
        /// The class that is to have the learning rate set for.
        /// </summary>
        ///
        private ILearningRate _setter;

        /// <summary>
        /// The training Algo that is using this strategy.
        /// </summary>
        ///
        private IMLTrain _train;

        /// <summary>
        /// The training set size, this is used to pick an initial learning rate.
        /// </summary>
        ///
        private long _trainingSize;

        #region IStrategy Members

        /// <summary>
        /// Initialize this strategy.
        /// </summary>
        ///
        /// <param name="train">The training Algo.</param>
        public void Init(IMLTrain train)
        {
            _train = train;
            _ready = false;
            _setter = (ILearningRate)train;
            _trainingSize = train.Training.Count;
            _currentLearningRate = 1.0d / _trainingSize;
            SyntLogging.Log(SyntLogging.LevelDebug, "Starting learning rate: "
                                                       + _currentLearningRate);
            _setter.LearningRate = _currentLearningRate;
        }

        /// <summary>
        /// Called just after a training iteration.
        /// </summary>
        ///
        public void PostIteration()
        {
            if (_ready)
            {
                if (_train.Error > _lastError)
                {
                    _currentLearningRate *= LearningDecay;
                    _setter.LearningRate = _currentLearningRate;
                    SyntLogging.Log(SyntLogging.LevelDebug,
                                     "Adjusting learning rate to {}"
                                     + _currentLearningRate);
                }
            }
            else
            {
                _ready = true;
            }
        }

        /// <summary>
        /// Called just before a training iteration.
        /// </summary>
        ///
        public void PreIteration()
        {
            _lastError = _train.Error;
        }

        #endregion
    }

    public class SmartMomentum : IStrategy
    {
        /// <summary>
        /// The minimum improvement to adjust momentum.
        /// </summary>
        ///
        public const double MinImprovement = 0.0001d;

        /// <summary>
        /// The maximum value that momentum can go to.
        /// </summary>
        ///
        public const double MaxMomentum = 4;

        /// <summary>
        /// The starting momentum.
        /// </summary>
        ///
        public const double StartMomentum = 0.1d;

        /// <summary>
        /// How much to increase momentum by.
        /// </summary>
        ///
        public const double MomentumIncrease = 0.01d;

        /// <summary>
        /// How many cycles to accept before adjusting momentum.
        /// </summary>
        ///
        public const double MomentumCycles = 10;

        /// <summary>
        /// The current momentum.
        /// </summary>
        ///
        private double _currentMomentum;

        /// <summary>
        /// The error rate from the previous iteration.
        /// </summary>
        ///
        private double _lastError;

        /// <summary>
        /// The last improvement in error rate.
        /// </summary>
        ///
        private double _lastImprovement;

        /// <summary>
        /// The last momentum.
        /// </summary>
        ///
        private int _lastMomentum;

        /// <summary>
        /// Has one iteration passed, and we are now ready to start evaluation.
        /// </summary>
        ///
        private bool _ready;

        /// <summary>
        /// The setter used to change momentum.
        /// </summary>
        ///
        private IMomentum _setter;

        /// <summary>
        /// The training Algo that is using this strategy.
        /// </summary>
        ///
        private IMLTrain _train;

        #region IStrategy Members

        /// <summary>
        /// Initialize this strategy.
        /// </summary>
        ///
        /// <param name="train_0">The training Algo.</param>
        public void Init(IMLTrain train_0)
        {
            _train = train_0;
            _setter = (IMomentum)train_0;
            _ready = false;
            _setter.Momentum = 0.0d;
            _currentMomentum = 0;
        }

        /// <summary>
        /// Called just after a training iteration.
        /// </summary>
        ///
        public void PostIteration()
        {
            if (_ready)
            {
                double currentError = _train.Error;
                _lastImprovement = (currentError - _lastError)
                                  / _lastError;
                SyntLogging.Log(SyntLogging.LevelDebug, "Last improvement: "
                                                           + _lastImprovement);

                if ((_lastImprovement > 0)
                    || (Math.Abs(_lastImprovement) < MinImprovement))
                {
                    _lastMomentum++;

                    if (_lastMomentum > MomentumCycles)
                    {
                        _lastMomentum = 0;
                        if (((int)_currentMomentum) == 0)
                        {
                            _currentMomentum = StartMomentum;
                        }
                        _currentMomentum *= (1.0d + MomentumIncrease);
                        _setter.Momentum = _currentMomentum;
                        SyntLogging.Log(SyntLogging.LevelDebug,
                                         "Adjusting momentum: " + _currentMomentum);
                    }
                }
                else
                {
                    SyntLogging.Log(SyntLogging.LevelDebug,
                                     "Setting momentum back to zero.");

                    _currentMomentum = 0;
                    _setter.Momentum = 0;
                }
            }
            else
            {
                _ready = true;
            }
        }

        /// <summary>
        /// Called just before a training iteration.
        /// </summary>
        ///
        public void PreIteration()
        {
            _lastError = _train.Error;
        }

        #endregion
    }

    [Serializable]
    public class TrainingError : NeuralNetworkError
    {
        /// <summary>
        /// Construct a message exception.
        /// </summary>
        ///
        /// <param name="msg">The exception message.</param>
        public TrainingError(String msg) : base(msg)
        {
        }

        /// <summary>
        /// Construct an exception that holds another exception.
        /// </summary>
        ///
        /// <param name="t">The other exception.</param>
        public TrainingError(Exception t) : base(t)
        {
        }
    }

    public class TrainingSetScore : ICalculateScore
    {
        /// <summary>
        /// The training set.
        /// </summary>
        ///
        private readonly IMLDataSet _training;

        /// <summary>
        /// Construct a training set score calculation.
        /// </summary>
        ///
        /// <param name="training">The training data to use.</param>
        public TrainingSetScore(IMLDataSet training)
        {
            _training = training;
        }

        #region ICalculateScore Members

        /// <summary>
        /// Calculate the score for the network.
        /// </summary>
        ///
        /// <param name="method">The network to calculate for.</param>
        /// <returns>The score.</returns>
        public double CalculateScore(IMLRegression method)
        {
            return CalculateRegressionError.CalculateError(method, _training);
        }

        /// <summary>
        /// A training set based score should always seek to lower the error,
        /// as a result, this method always returns true.
        /// </summary>
        ///
        /// <returns>Returns true.</returns>
        public bool ShouldMinimize
        {
            get { return true; }
        }

        #endregion
    }

    public class NeuralDataMapping
    {
        /// <summary>
        /// Construct the neural data mapping class, with null values.
        /// </summary>
        ///
        public NeuralDataMapping()
        {
            From = null;
            To = null;
        }

        /// <summary>
        /// Construct the neural data mapping class with the specified values.
        /// </summary>
        ///
        /// <param name="f">The source data.</param>
        /// <param name="t">The target data.</param>
        public NeuralDataMapping(IMLData f, IMLData t)
        {
            From = f;
            To = t;
        }

        /// <summary>
        /// Set the from data.
        /// </summary>
        ///
        /// <value>The from data.</value>
        public IMLData From
        {
            get;
            set;
        }


        /// <summary>
        /// Set the target data.
        /// </summary>
        ///
        /// <value>The target data.</value>
        public IMLData To
        {
            get;
            set;
        }

        /// <summary>
        /// Copy from one object to the other.
        /// </summary>
        ///
        /// <param name="source">The source object.</param>
        /// <param name="target">The target object.</param>
        public static void Copy(NeuralDataMapping source,
                                NeuralDataMapping target)
        {
            for (int i = 0; i < source.From.Count; i++)
            {
                target.From[i] = source.From[i];
            }

            for (int i_0 = 0; i_0 < source.To.Count; i_0++)
            {
                target.To[i_0] = source.To[i_0];
            }
        }
    }

    public class PersistBasicNetwork : ISyntPersistor
    {
        #region SyntPersistor Members

        /// <summary>
        /// The file version.
        /// </summary>
        public virtual int FileVersion
        {
            get { return 1; }
        }


        /// <summary>
        /// The persist class string.
        /// </summary>
        public virtual String PersistClassString
        {
            get { return "BasicNetwork"; }
        }


        /// <summary>
        /// Read an object.
        /// </summary>
        ///
        public Object Read(Stream mask0)
        {
            var result = new BasicNetwork();
            var flat = new FlatNetwork();
            var ins0 = new SyntReadHelper(mask0);
            SyntFileSection section;

            while ((section = ins0.ReadNextSection()) != null)
            {
                if (section.SectionName.Equals("BASIC")
                    && section.SubSectionName.Equals("PARAMS"))
                {
                    IDictionary<String, String> paras = section.ParseParams();
                    EngineArray.PutAll(paras, result.Properties);
                }
                if (section.SectionName.Equals("BASIC")
                    && section.SubSectionName.Equals("NETWORK"))
                {
                    IDictionary<String, String> p = section.ParseParams();

                    flat.BeginTraining = SyntFileSection.ParseInt(p,
                                                                   BasicNetwork.TagBeginTraining);
                    flat.ConnectionLimit = SyntFileSection.ParseDouble(p,
                                                                        BasicNetwork.TagConnectionLimit);
                    flat.ContextTargetOffset = SyntFileSection.ParseIntArray(
                        p, BasicNetwork.TagContextTargetOffset);
                    flat.ContextTargetSize = SyntFileSection.ParseIntArray(
                        p, BasicNetwork.TagContextTargetSize);
                    flat.EndTraining = SyntFileSection.ParseInt(p,
                                                                 BasicNetwork.TagEndTraining);
                    flat.HasContext = SyntFileSection.ParseBoolean(p,
                                                                    BasicNetwork.TagHasContext);
                    flat.InputCount = SyntFileSection.ParseInt(p,
                                                                PersistConst.InputCount);
                    flat.LayerCounts = SyntFileSection.ParseIntArray(p,
                                                                      BasicNetwork.TagLayerCounts);
                    flat.LayerFeedCounts = SyntFileSection.ParseIntArray(p,
                                                                          BasicNetwork.TagLayerFeedCounts);
                    flat.LayerContextCount = SyntFileSection.ParseIntArray(
                        p, BasicNetwork.TagLayerContextCount);
                    flat.LayerIndex = SyntFileSection.ParseIntArray(p,
                                                                     BasicNetwork.TagLayerIndex);
                    flat.LayerOutput = section.ParseDoubleArray(p, PersistConst.Output);
                    flat.LayerSums = new double[flat.LayerOutput.Length];
                    flat.OutputCount = SyntFileSection.ParseInt(p,
                                                                 PersistConst.OutputCount);
                    flat.WeightIndex = SyntFileSection.ParseIntArray(p,
                                                                      BasicNetwork.TagWeightIndex);
                    flat.Weights = section.ParseDoubleArray(p, PersistConst.Weights);
                    flat.BiasActivation = section.ParseDoubleArray(p, BasicNetwork.TagBiasActivation);
                }
                else if (section.SectionName.Equals("BASIC")
                         && section.SubSectionName.Equals("ACTIVATION"))
                {
                    int index = 0;

                    flat.ActivationFunctions = new IActivationFunction[flat.LayerCounts.Length];


                    foreach (String line in section.Lines)
                    {
                        IActivationFunction af;
                        IList<String> cols = SyntFileSection
                            .SplitColumns(line);
                        String name = ReflectionUtil.AfPath
                                      + cols[0];
                        try
                        {
                            af = (IActivationFunction)ReflectionUtil.LoadObject(name);
                        }
                        catch (TypeLoadException e)
                        {
                            throw new PersistError(e);
                        }
                        catch (TargetException e)
                        {
                            throw new PersistError(e);
                        }
                        catch (MemberAccessException e)
                        {
                            throw new PersistError(e);
                        }

                        for (int i = 0; i < af.ParamNames.Length; i++)
                        {
                            af.Params[i] =
                                        CSVFormat.EgFormat.Parse(cols[i + 1]);
                        }

                        flat.ActivationFunctions[index++] = af;
                    }
                }
            }

            result.Structure.Flat = flat;

            return result;
        }

        /// <inheritdoc/>
        public void Save(Stream os, Object obj)
        {
            var xout = new SyntWriteHelper(os);
            var net = (BasicNetwork)obj;
            FlatNetwork flat = net.Structure.Flat;
            xout.AddSection("BASIC");
            xout.AddSubSection("PARAMS");
            xout.AddProperties(net.Properties);
            xout.AddSubSection("NETWORK");

            xout.WriteProperty(BasicNetwork.TagBeginTraining,
                               flat.BeginTraining);
            xout.WriteProperty(BasicNetwork.TagConnectionLimit,
                               flat.ConnectionLimit);
            xout.WriteProperty(BasicNetwork.TagContextTargetOffset,
                               flat.ContextTargetOffset);
            xout.WriteProperty(BasicNetwork.TagContextTargetSize,
                               flat.ContextTargetSize);
            xout.WriteProperty(BasicNetwork.TagEndTraining, flat.EndTraining);
            xout.WriteProperty(BasicNetwork.TagHasContext, flat.HasContext);
            xout.WriteProperty(PersistConst.InputCount, flat.InputCount);
            xout.WriteProperty(BasicNetwork.TagLayerCounts, flat.LayerCounts);
            xout.WriteProperty(BasicNetwork.TagLayerFeedCounts,
                               flat.LayerFeedCounts);
            xout.WriteProperty(BasicNetwork.TagLayerContextCount,
                               flat.LayerContextCount);
            xout.WriteProperty(BasicNetwork.TagLayerIndex, flat.LayerIndex);
            xout.WriteProperty(PersistConst.Output, flat.LayerOutput);
            xout.WriteProperty(PersistConst.OutputCount, flat.OutputCount);
            xout.WriteProperty(BasicNetwork.TagWeightIndex, flat.WeightIndex);
            xout.WriteProperty(PersistConst.Weights, flat.Weights);
            xout.WriteProperty(BasicNetwork.TagBiasActivation,
                               flat.BiasActivation);
            xout.AddSubSection("ACTIVATION");

            foreach (IActivationFunction af in flat.ActivationFunctions)
            {
                xout.AddColumn(af.GetType().Name);
                for (int i = 0; i < af.Params.Length; i++)
                {
                    xout.AddColumn(af.Params[i]);
                }
                xout.WriteLine();
            }

            xout.Flush();
        }

        /// <inheritdoc/>
        public Type NativeType
        {
            get { return typeof(BasicNetwork); }
        }

        #endregion
    }

    public class ADALINEPattern : INeuralNetworkPattern
    {
        /// <summary>
        /// The number of neurons in the input layer.
        /// </summary>
        ///
        private int _inputNeurons;

        /// <summary>
        /// The number of neurons in the output layer.
        /// </summary>
        ///
        private int _outputNeurons;

        #region NeuralNetworkPattern Members

        /// <summary>
        /// Not used, the ADALINE has no hidden layers, this will throw an error.
        /// </summary>
        ///
        /// <param name="count">The neuron count.</param>
        public void AddHiddenLayer(int count)
        {

        }

        /// <summary>
        /// Clear out any parameters.
        /// </summary>
        ///
        public void Clear()
        {
            _inputNeurons = 0;
            _outputNeurons = 0;
        }

        /// <summary>
        /// Generate the network.
        /// </summary>
        public IMLMethod Generate()
        {
            var network = new BasicNetwork();

            ILayer inputLayer = new BasicLayer(new ActivationLinear(), true,
                                              _inputNeurons);
            ILayer outputLayer = new BasicLayer(new ActivationLinear(), false,
                                               _outputNeurons);

            network.AddLayer(inputLayer);
            network.AddLayer(outputLayer);
            network.Structure.FinalizeStructure();

            (new RangeRandomizer(-0.5d, 0.5d)).Randomize(network);

            return network;
        }

        /// <summary>
        /// Not used, ADALINE does not use custom activation functions.
        /// </summary>
        public IActivationFunction ActivationFunction
        {
            set
            {
            }
        }


        /// <summary>
        /// Set the input neurons.
        /// </summary>
        public int InputNeurons
        {
            set { _inputNeurons = value; }
        }


        /// <summary>
        /// Set the output neurons.
        /// </summary>
        public int OutputNeurons
        {
            set { _outputNeurons = value; }
        }

        #endregion
    }

    public class ART1Pattern : INeuralNetworkPattern
    {
        /// <summary>
        /// A parameter for F1 layer.
        /// </summary>
        ///
        private double _a1;

        /// <summary>
        /// B parameter for F1 layer.
        /// </summary>
        ///
        private double _b1;

        /// <summary>
        /// C parameter for F1 layer.
        /// </summary>
        ///
        private double _c1;

        /// <summary>
        /// D parameter for F1 layer.
        /// </summary>
        ///
        private double _d1;

        /// <summary>
        /// The number of input neurons.
        /// </summary>
        ///
        private int _inputNeurons;

        /// <summary>
        /// L parameter for net.
        /// </summary>
        ///
        private double _l;

        /// <summary>
        /// The number of output neurons.
        /// </summary>
        ///
        private int _outputNeurons;

        /// <summary>
        /// The vigilance parameter.
        /// </summary>
        ///
        private double _vigilance;

        /// <summary>
        /// Construct the object.
        /// </summary>
        public ART1Pattern()
        {
            _a1 = 1;
            _b1 = 1.5d;
            _c1 = 5;
            _d1 = 0.9d;
            _l = 3;
            _vigilance = 0.9d;
        }

        /// <summary>
        /// Set the A1 parameter.
        /// </summary>
        public double A1
        {
            get { return _a1; }
            set { _a1 = value; }
        }


        /// <summary>
        /// Set the B1 parameter.
        /// </summary>
        public double B1
        {
            get { return _b1; }
            set { _b1 = value; }
        }


        /// <summary>
        /// Set the C1 parameter.
        /// </summary>
        public double C1
        {
            get { return _c1; }
            set { _c1 = value; }
        }


        /// <summary>
        /// Set the D1 parameter.
        /// </summary>
        public double D1
        {
            get { return _d1; }
            set { _d1 = value; }
        }


        /// <summary>
        /// Set the L parameter.
        /// </summary>
        ///
        /// <value>The new value.</value>
        public double L
        {
            get { return _l; }
            set { _l = value; }
        }


        /// <summary>
        /// Set the vigilance for the network.
        /// </summary>
        public double Vigilance
        {
            get { return _vigilance; }
            set { _vigilance = value; }
        }

        #region NeuralNetworkPattern Members

        /// <summary>
        /// This will fail, hidden layers are not supported for this type of network.
        /// </summary>
        ///
        /// <param name="count">Not used.</param>
        public void AddHiddenLayer(int count)
        {
            throw new PatternError("A ART1 network has no hidden layers.");
        }

        /// <summary>
        /// Clear any properties set for this network.
        /// </summary>
        ///
        public void Clear()
        {
            _inputNeurons = 0;
            _outputNeurons = 0;
        }

        /// <summary>
        /// Generate the neural network.
        /// </summary>
        ///
        /// <returns>The generated neural network.</returns>
        public IMLMethod Generate()
        {
            var art = new ART1(_inputNeurons, _outputNeurons)
            {
                A1 = _a1,
                B1 = _b1,
                C1 = _c1,
                D1 = _d1,
                L = _l,
                Vigilance = _vigilance
            };
            return art;
        }


        /// <summary>
        /// This method will throw an error, you can't set the activation function
        /// for an ART1. type network.
        /// </summary>
        public IActivationFunction ActivationFunction
        {
            set { throw new PatternError("Can't set the activation function for an ART1."); }
        }


        /// <summary>
        /// Set the input neuron (F1 layer) count.
        /// </summary>
        public int InputNeurons
        {
            set { _inputNeurons = value; }
        }


        /// <summary>
        /// Set the output neuron (F2 layer) count.
        /// </summary>
        public int OutputNeurons
        {
            set { _outputNeurons = value; }
        }

        #endregion
    }

    [Serializable]
    public class BAMNetwork : BasicML
    {
        /// <summary>
        /// Neurons in the F1 layer.
        /// </summary>
        ///
        private int _f1Count;

        /// <summary>
        /// Neurons in the F2 layer.
        /// </summary>
        ///
        private int _f2Count;

        /// <summary>
        /// The weights between the F1 and F2 layers.
        /// </summary>
        ///
        private Matrix _weightsF1ToF2;

        /// <summary>
        /// The weights between the F1 and F2 layers.
        /// </summary>
        ///
        private Matrix _weightsF2ToF1;

        /// <summary>
        /// Default constructor, used mainly for persistence.
        /// </summary>
        ///
        public BAMNetwork()
        {
        }

        /// <summary>
        /// Construct the BAM network.
        /// </summary>
        ///
        /// <param name="theF1Count">The F1 count.</param>
        /// <param name="theF2Count">The F2 count.</param>
        public BAMNetwork(int theF1Count, int theF2Count)
        {
            _f1Count = theF1Count;
            _f2Count = theF2Count;

            _weightsF1ToF2 = new Matrix(_f1Count, _f2Count);
            _weightsF2ToF1 = new Matrix(_f2Count, _f1Count);
        }

        /// <summary>
        /// Set the F1 neuron count.
        /// </summary>
        public int F1Count
        {
            get { return _f1Count; }
            set { _f1Count = value; }
        }


        /// <summary>
        /// Set the F2 neuron count.
        /// </summary>
        public int F2Count
        {
            get { return _f2Count; }
            set { _f2Count = value; }
        }

        /// <summary>
        /// Set the weights for F1 to F2.
        /// </summary>
        public Matrix WeightsF1ToF2
        {
            get { return _weightsF1ToF2; }
            set { _weightsF1ToF2 = value; }
        }


        /// <summary>
        /// Set the weights for F2 to F1.
        /// </summary>
        public Matrix WeightsF2ToF1
        {
            get { return _weightsF2ToF1; }
            set { _weightsF2ToF1 = value; }
        }

        /// <summary>
        /// Add a pattern to the neural network.
        /// </summary>
        ///
        /// <param name="inputPattern">The input pattern.</param>
        /// <param name="outputPattern">The output pattern(for this input).</param>
        public void AddPattern(IMLData inputPattern,
                               IMLData outputPattern)
        {
            for (int i = 0; i < _f1Count; i++)
            {
                for (int j = 0; j < _f2Count; j++)
                {
                    var weight = (int)(inputPattern[i] * outputPattern[j]);
                    _weightsF1ToF2.Add(i, j, weight);
                    _weightsF2ToF1.Add(j, i, weight);
                }
            }
        }

        /// <summary>
        /// Clear any connection weights.
        /// </summary>
        ///
        public void Clear()
        {
            _weightsF1ToF2.Clear();
            _weightsF2ToF1.Clear();
        }

        /// <summary>
        /// Setup the network logic, read parameters from the network. NOT USED, call
        /// compute(NeuralInputData).
        /// </summary>
        ///
        /// <param name="input">NOT USED</param>
        /// <returns>NOT USED</returns>
        public IMLData Compute(IMLData input)
        {
            throw new NeuralNetworkError(
                "Compute on BasicNetwork cannot be used, rather call"
                + " the compute(NeuralData) method on the BAMLogic.");
        }

        /// <summary>
        /// Compute the network for the specified input.
        /// </summary>
        ///
        /// <param name="input">The input to the network.</param>
        /// <returns>The output from the network.</returns>
        public NeuralDataMapping Compute(NeuralDataMapping input)
        {
            bool stable1;
            bool stable2;

            do
            {
                stable1 = PropagateLayer(_weightsF1ToF2, input.From,
                                         input.To);
                stable2 = PropagateLayer(_weightsF2ToF1, input.To,
                                         input.From);
            } while (!stable1 && !stable2);
            return null;
        }


        /// <summary>
        /// Get the specified weight.
        /// </summary>
        ///
        /// <param name="matrix">The matrix to use.</param>
        /// <param name="input">The input, to obtain the size from.</param>
        /// <param name="x"></param>
        /// <param name="y"></param>
        /// <returns>The value from the matrix.</returns>
        private static double GetWeight(Matrix matrix, IMLData input,
                                 int x, int y)
        {
            if (matrix.Rows != input.Count)
            {
                return matrix[x, y];
            }
            return matrix[y, x];
        }


        /// <summary>
        /// Propagate the layer.
        /// </summary>
        ///
        /// <param name="matrix">The matrix for this layer.</param>
        /// <param name="input">The input pattern.</param>
        /// <param name="output">The output pattern.</param>
        /// <returns>True if the network has become stable.</returns>
        private static bool PropagateLayer(Matrix matrix, IMLData input,
                                    IMLData output)
        {
            int i;

            bool stable = true;

            for (i = 0; i < output.Count; i++)
            {
                double sum = 0; // **FIX** ?? int ??
                int j;
                for (j = 0; j < input.Count; j++)
                {
                    sum += GetWeight(matrix, input, i, j) * input[j];
                }
                if (sum != 0)
                {
                    int xout;
                    if (sum < 0)
                    {
                        xout = -1;
                    }
                    else
                    {
                        xout = 1;
                    }
                    if (xout != (int)output[i])
                    {
                        stable = false;
                        output[i] = xout;
                    }
                }
            }
            return stable;
        }

        /// <summary>
        /// 
        /// </summary>
        ///
        public override void UpdateProperties()
        {
            // TODO Auto-generated method stub
        }
    }

    public class BAMPattern : INeuralNetworkPattern
    {
        /// <summary>
        /// The number of neurons in the first layer.
        /// </summary>
        ///
        private int _f1Neurons;

        /// <summary>
        /// The number of neurons in the second layer.
        /// </summary>
        ///
        private int _f2Neurons;

        /// <summary>
        /// Set the F1 neurons. The BAM really does not have an input and output
        /// layer, so this is simply setting the number of neurons that are in the
        /// first layer.
        /// </summary>
        ///
        /// <value>The number of neurons in the first layer.</value>
        public int F1Neurons
        {
            set { _f1Neurons = value; }
        }


        /// <summary>
        /// Set the output neurons. The BAM really does not have an input and output
        /// layer, so this is simply setting the number of neurons that are in the
        /// second layer.
        /// </summary>
        public int F2Neurons
        {
            set { _f2Neurons = value; }
        }

        #region NeuralNetworkPattern Members

        /// <summary>
        /// Unused, a BAM has no hidden layers.
        /// </summary>
        ///
        /// <param name="count">Not used.</param>
        public void AddHiddenLayer(int count)
        {
            throw new PatternError("A BAM network has no hidden layers.");
        }

        /// <summary>
        /// Clear any settings on the pattern.
        /// </summary>
        public void Clear()
        {
            _f1Neurons = 0;
            _f2Neurons = 0;
        }


        /// <returns>The generated network.</returns>
        public IMLMethod Generate()
        {
            var bam = new BAMNetwork(_f1Neurons, _f2Neurons);
            return bam;
        }

        /// <summary>
        /// Not used, the BAM uses a bipoloar activation function.
        /// </summary>
        public IActivationFunction ActivationFunction
        {
            set
            {
                throw new PatternError(
                    "A BAM network can't specify a custom activation function.");
            }
        }


        /// <summary>
        /// Set the number of input neurons.
        /// </summary>
        public int InputNeurons
        {
            set
            {
                throw new PatternError(
                    "A BAM network has no input layer, consider setting F1 layer.");
            }
        }


        /// <summary>
        /// Set the number of output neurons.
        /// </summary>
        public int OutputNeurons
        {
            set
            {
                throw new PatternError(
                    "A BAM network has no output layer, consider setting F2 layer.");
            }
        }

        #endregion
    }

    public class BoltzmannPattern : INeuralNetworkPattern
    {
        /// <summary>
        /// The number of annealing cycles per run.
        /// </summary>
        ///
        private int _annealCycles;

        /// <summary>
        /// The number of neurons in the Boltzmann network.
        /// </summary>
        ///
        private int _neuronCount;

        /// <summary>
        /// The number of cycles per run.
        /// </summary>
        ///
        private int _runCycles;

        /// <summary>
        /// The current temperature.
        /// </summary>
        ///
        private double _temperature;

        /// <summary>
        /// Construct the object.
        /// </summary>
        public BoltzmannPattern()
        {
            _annealCycles = 100;
            _runCycles = 1000;
            _temperature = 0.0d;
        }

        /// <summary>
        /// Set the number of annealing cycles per run.
        /// </summary>
        public int AnnealCycles
        {
            get { return _annealCycles; }
            set { _annealCycles = value; }
        }


        /// <summary>
        /// Set the number of cycles per run.
        /// </summary>
        public int RunCycles
        {
            get { return _runCycles; }
            set { _runCycles = value; }
        }


        /// <summary>
        /// Set the temperature.
        /// </summary>
        public double Temperature
        {
            get { return _temperature; }
            set { _temperature = value; }
        }

        #region NeuralNetworkPattern Members

        /// <summary>
        /// Not supported, will throw an exception, Boltzmann networks have no hidden
        /// layers.
        /// </summary>
        ///
        /// <param name="count">Not used.</param>
        public void AddHiddenLayer(int count)
        {
            throw new PatternError("A Boltzmann network has no hidden layers.");
        }

        /// <summary>
        /// Clear any properties set on this network.
        /// </summary>
        ///
        public void Clear()
        {
            _neuronCount = 0;
        }

        /// <summary>
        /// Generate the network.
        /// </summary>
        public IMLMethod Generate()
        {
            var boltz = new BoltzmannMachine(_neuronCount);
            boltz.Temperature = _temperature;
            boltz.RunCycles = _runCycles;
            boltz.AnnealCycles = _annealCycles;
            return boltz;
        }


        /// <summary>
        /// Not used, will throw an exception.
        /// </summary>
        ///
        /// <value>Not used.</value>
        public IActivationFunction ActivationFunction
        {
            set
            {
                throw new PatternError(
                    "A Boltzmann network will use the BiPolar activation "
                    + "function, no activation function needs to be specified.");
            }
        }


        /// <summary>
        /// Set the number of input neurons. This is the same as the number of output
        /// neurons.
        /// </summary>
        ///
        /// <value>The number of input neurons.</value>
        public int InputNeurons
        {
            set { _neuronCount = value; }
        }


        /// <summary>
        /// Set the number of output neurons. This is the same as the number of input
        /// neurons.
        /// </summary>
        public int OutputNeurons
        {
            set { _neuronCount = value; }
        }

        #endregion
    }

    [Serializable]
    public class CPNNetwork : BasicML, IMLRegression, IMLResettable, IMLError
    {
        /// <summary>
        /// The number of neurons in the input layer.
        /// </summary>
        ///
        private readonly int _inputCount;

        /// <summary>
        /// The number of neurons in the instar, or hidden, layer.
        /// </summary>
        ///
        private readonly int _instarCount;

        /// <summary>
        /// The number of neurons in the outstar, or output, layer.
        /// </summary>
        ///
        private readonly int _outstarCount;

        /// <summary>
        /// The weights from the input to the instar layer.
        /// </summary>
        ///
        private readonly Matrix _weightsInputToInstar;

        /// <summary>
        /// The weights from the instar to the outstar layer.
        /// </summary>
        ///
        private readonly Matrix _weightsInstarToOutstar;

        /// <summary>
        /// The number of winning neurons.
        /// </summary>
        ///
        private readonly int _winnerCount;

        /// <summary>
        /// Construct the counterProp neural network.
        /// </summary>
        ///
        /// <param name="theInputCount">The number of input neurons.</param>
        /// <param name="theInstarCount">The number of instar neurons.</param>
        /// <param name="theOutstarCount">The number of outstar neurons.</param>
        /// <param name="theWinnerCount">The winner count.</param>
        public CPNNetwork(int theInputCount, int theInstarCount,
                          int theOutstarCount, int theWinnerCount)
        {
            _inputCount = theInputCount;
            _instarCount = theInstarCount;
            _outstarCount = theOutstarCount;

            _weightsInputToInstar = new Matrix(_inputCount, _instarCount);
            _weightsInstarToOutstar = new Matrix(_instarCount, _outstarCount);
            _winnerCount = theWinnerCount;
        }


        /// <value>The instar count, same as the input count.</value>
        public int InstarCount
        {
            get { return _instarCount; }
        }


        /// <value>The outstar count, same as the output count.</value>
        public int OutstarCount
        {
            get { return _outstarCount; }
        }


        /// <value>The weights between the input and instar.</value>
        public Matrix WeightsInputToInstar
        {
            get { return _weightsInputToInstar; }
        }


        /// <value>The weights between the instar and outstar.</value>
        public Matrix WeightsInstarToOutstar
        {
            get { return _weightsInstarToOutstar; }
        }


        /// <value>The winner count.</value>
        public int WinnerCount
        {
            get { return _winnerCount; }
        }

        #region MLError Members

        /// <summary>
        /// Calculate the error for this neural network.
        /// </summary>
        ///
        /// <param name="data">The training set.</param>
        /// <returns>The error percentage.</returns>
        public double CalculateError(IMLDataSet data)
        {
            return SyntUtility.CalculateRegressionError(this, data);
        }

        #endregion

        #region MLRegression Members

        /// <inheritdoc/>
        public IMLData Compute(IMLData input)
        {
            IMLData temp = ComputeInstar(input);
            return ComputeOutstar(temp);
        }

        /// <inheritdoc/>
        public int InputCount
        {
            get { return _inputCount; }
        }

        /// <inheritdoc/>
        public int OutputCount
        {
            get { return _outstarCount; }
        }

        #endregion

        #region MLResettable Members

        /// <summary>
        /// 
        /// </summary>
        ///
        public void Reset()
        {
            Reset(0);
        }

        /// <summary>
        /// 
        /// </summary>
        ///
        public void Reset(int seed)
        {
            var randomize = new ConsistentRandomizer(-1, 1,
                                                     seed);
            randomize.Randomize(_weightsInputToInstar);
            randomize.Randomize(_weightsInstarToOutstar);
        }

        #endregion

        /// <summary>
        /// Compute the instar layer.
        /// </summary>
        ///
        /// <param name="input">The input.</param>
        /// <returns>The output.</returns>
        public IMLData ComputeInstar(IMLData input)
        {
            IMLData result = new BasicMLData(_instarCount);
            int w, i;
            int winner = 0;
            var winners = new bool[_instarCount];

            for (i = 0; i < _instarCount; i++)
            {
                double sum = 0;
                int j;
                for (j = 0; j < _inputCount; j++)
                {
                    sum += _weightsInputToInstar[j, i] * input[j];
                }
                result[i] = sum;
                winners[i] = false;
            }
            double sumWinners = 0;
            for (w = 0; w < _winnerCount; w++)
            {
                double maxOut = Double.MinValue;
                for (i = 0; i < _instarCount; i++)
                {
                    if (!winners[i] && (result[i] > maxOut))
                    {
                        winner = i;
                        maxOut = result[winner];
                    }
                }
                winners[winner] = true;
                sumWinners += result[winner];
            }
            for (i = 0; i < _instarCount; i++)
            {
                if (winners[i]
                    && (Math.Abs(sumWinners) > SyntFramework.DefaultDoubleEqual))
                {
                    result.Data[i] /= sumWinners;
                }
                else
                {
                    result.Data[i] = 0;
                }
            }

            return result;
        }

        /// <summary>
        /// Compute the outstar layer.
        /// </summary>
        ///
        /// <param name="input">The input.</param>
        /// <returns>The output.</returns>
        public IMLData ComputeOutstar(IMLData input)
        {
            IMLData result = new BasicMLData(_outstarCount);

            for (int i = 0; i < _outstarCount; i++)
            {
                double sum = 0;
                for (int j = 0; j < _instarCount; j++)
                {
                    sum += _weightsInstarToOutstar[j, i] * input[j];
                }
                result[i] = sum;
            }
            return result;
        }

        /// <summary>
        /// 
        /// </summary>
        ///
        public override void UpdateProperties()
        {
            // unneeded
        }
    }

    public class CPNPattern : INeuralNetworkPattern
    {
        /// <summary>
        /// The tag for the INSTAR layer.
        /// </summary>
        ///
        public const String TagInstar = "INSTAR";

        /// <summary>
        /// The tag for the OUTSTAR layer.
        /// </summary>
        ///
        public const String TagOutstar = "OUTSTAR";

        /// <summary>
        /// The number of neurons in the hidden layer.
        /// </summary>
        ///
        private int _inputCount;

        /// <summary>
        /// The number of neurons in the instar layer.
        /// </summary>
        ///
        private int _instarCount;

        /// <summary>
        /// The number of neurons in the outstar layer.
        /// </summary>
        ///
        private int _outstarCount;

        /// <summary>
        /// Set the number of neurons in the instar layer. This level is essentially
        /// a hidden layer.
        /// </summary>
        public int InstarCount
        {
            set { _instarCount = value; }
        }

        /// <summary>
        /// Set the number of neurons in the outstar level, this level is mapped to
        /// the "output" level.
        /// </summary>
        public int OutstarCount
        {
            set { _outstarCount = value; }
        }

        #region NeuralNetworkPattern Members

        /// <summary>
        /// Not used, will throw an error. CPN networks already have a predefined
        /// hidden layer called the instar layer.
        /// </summary>
        ///
        /// <param name="count">NOT USED</param>
        public void AddHiddenLayer(int count)
        {
            throw new PatternError(
                "A CPN already has a predefined hidden layer.  No additional"
                + "specification is needed.");
        }

        /// <summary>
        /// Clear any parameters that were set.
        /// </summary>
        ///
        public void Clear()
        {
            _inputCount = 0;
            _instarCount = 0;
            _outstarCount = 0;
        }

        /// <summary>
        /// Generate the network.
        /// </summary>
        ///
        /// <returns>The generated network.</returns>
        public IMLMethod Generate()
        {
            return new CPNNetwork(_inputCount, _instarCount, _outstarCount, 1);
        }

        /// <summary>
        /// This method will throw an error. The CPN network uses predefined
        /// activation functions.
        /// </summary>
        public IActivationFunction ActivationFunction
        {
            set
            {
                throw new PatternError(
                    "A CPN network will use the BiPolar & competitive activation "
                    + "functions, no activation function needs to be specified.");
            }
        }


        /// <summary>
        /// Set the number of input neurons.
        /// </summary>
        public int InputNeurons
        {
            set { _inputCount = value; }
        }


        /// <summary>
        /// Set the number of output neurons. Calling this method maps to setting the
        /// number of neurons in the outstar layer.
        /// </summary>
        public int OutputNeurons
        {
            set { _outstarCount = value; }
        }

        #endregion
    }

    public class ElmanPattern : INeuralNetworkPattern
    {
        /// <summary>
        /// The activation function.
        /// </summary>
        ///
        private IActivationFunction _activation;

        /// <summary>
        /// The number of hidden neurons.
        /// </summary>
        ///
        private int _hiddenNeurons;

        /// <summary>
        /// The number of input neurons.
        /// </summary>
        ///
        private int _inputNeurons;

        /// <summary>
        /// The number of output neurons.
        /// </summary>
        ///
        private int _outputNeurons;

        /// <summary>
        /// Create an object to generate Elman neural networks.
        /// </summary>
        ///
        public ElmanPattern()
        {
            _inputNeurons = -1;
            _outputNeurons = -1;
            _hiddenNeurons = -1;
        }

        #region NeuralNetworkPattern Members

        /// <summary>
        /// Add a hidden layer with the specified number of neurons.
        /// </summary>
        ///
        /// <param name="count">The number of neurons in this hidden layer.</param>
        public void AddHiddenLayer(int count)
        {
            if (_hiddenNeurons != -1)
            {
                throw new PatternError(
                    "An Elman neural network should have only one hidden layer.");
            }

            _hiddenNeurons = count;
        }

        /// <summary>
        /// Clear out any hidden neurons.
        /// </summary>
        ///
        public void Clear()
        {
            _hiddenNeurons = -1;
        }

        /// <summary>
        /// Generate the Elman neural network.
        /// </summary>
        ///
        /// <returns>The Elman neural network.</returns>
        public IMLMethod Generate()
        {
            BasicLayer hidden, input;

            var network = new BasicNetwork();
            network.AddLayer(input = new BasicLayer(_activation, true,
                                                    _inputNeurons));
            network.AddLayer(hidden = new BasicLayer(_activation, true,
                                                     _hiddenNeurons));
            network.AddLayer(new BasicLayer(null, false, _outputNeurons));
            input.ContextFedBy = hidden;
            network.Structure.FinalizeStructure();
            network.Reset();
            return network;
        }

        /// <summary>
        /// Set the activation function to use on each of the layers.
        /// </summary>
        public IActivationFunction ActivationFunction
        {
            set { _activation = value; }
        }


        /// <summary>
        /// Set the number of input neurons.
        /// </summary>
        public int InputNeurons { set { _inputNeurons = value; } }


        /// <summary>
        /// Set the number of output neurons.
        /// </summary>
        public int OutputNeurons
        {

            set { _outputNeurons = value; }
        }

        #endregion
    }

    public class FeedForwardPattern : INeuralNetworkPattern
    {
        /// <summary>
        /// The number of hidden neurons.
        /// </summary>
        ///
        private readonly IList<Int32> _hidden;

        /// <summary>
        /// The activation function.
        /// </summary>
        ///
        private IActivationFunction _activationHidden;

        /// <summary>
        /// The activation function.
        /// </summary>
        ///
        private IActivationFunction _activationOutput;

        /// <summary>
        /// The number of input neurons.
        /// </summary>
        ///
        private int _inputNeurons;

        /// <summary>
        /// The number of output neurons.
        /// </summary>
        ///
        private int _outputNeurons;

        /// <summary>
        /// Construct the object.
        /// </summary>
        public FeedForwardPattern()
        {
            _hidden = new List<Int32>();
        }

        /// <value>the activationOutput to set</value>
        public IActivationFunction ActivationOutput
        {
            get { return _activationOutput; }
            set { _activationOutput = value; }
        }

        #region NeuralNetworkPattern Members

        /// <summary>
        /// Add a hidden layer, with the specified number of neurons.
        /// </summary>
        public void AddHiddenLayer(int count)
        {
            _hidden.Add(count);
        }

        /// <summary>
        /// Clear out any hidden neurons.
        /// </summary>
        ///
        public void Clear()
        {
            _hidden.Clear();
        }

        /// <summary>
        /// Generate the feedforward neural network.
        /// </summary>
        public IMLMethod Generate()
        {
            if (_activationOutput == null)
                _activationOutput = _activationHidden;

            ILayer input = new BasicLayer(null, true, _inputNeurons);

            var result = new BasicNetwork();
            result.AddLayer(input);


            foreach (Int32 count in _hidden)
            {
                ILayer hidden = new BasicLayer(_activationHidden, true,
                                                (count));

                result.AddLayer(hidden);
            }

            ILayer output = new BasicLayer(_activationOutput, false,
                                          _outputNeurons);
            result.AddLayer(output);

            result.Structure.FinalizeStructure();
            result.Reset();

            return result;
        }

        /// <summary>
        /// Set the activation function to use on each of the layers.
        /// </summary>
        public IActivationFunction ActivationFunction
        {
            set { _activationHidden = value; }
        }


        /// <summary>
        /// Set the number of input neurons.
        /// </summary>
        public int InputNeurons
        {
            set { _inputNeurons = value; }
        }


        /// <summary>
        /// Set the number of output neurons.
        /// </summary>
        public int OutputNeurons
        {
            set { _outputNeurons = value; }
        }

        #endregion
    }

    public class HopfieldPattern : INeuralNetworkPattern
    {
        /// <summary>
        /// How many neurons in the Hopfield network. Default to -1, which is
        /// invalid. Therefore this value must be set.
        /// </summary>
        ///
        private int _neuronCount;

        /// <summary>
        /// Construct the object.
        /// </summary>
        public HopfieldPattern()
        {
            _neuronCount = -1;
        }

        #region NeuralNetworkPattern Members

        /// <summary>
        /// Add a hidden layer. This will throw an error, because the Hopfield neural
        /// network has no hidden layers.
        /// </summary>
        ///
        /// <param name="count">The number of neurons.</param>
        public void AddHiddenLayer(int count)
        {

        }

        /// <summary>
        /// Nothing to clear.
        /// </summary>
        ///
        public virtual void Clear()
        {
        }

        /// <summary>
        /// Generate the Hopfield neural network.
        /// </summary>
        ///
        /// <returns>The generated network.</returns>
        public IMLMethod Generate()
        {
            var logic = new HopfieldNetwork(_neuronCount);
            return logic;
        }

        /// <summary>
        /// Set the activation function to use. This function will throw an error,
        /// because the Hopfield network must use the BiPolar activation function.
        /// </summary>
        public IActivationFunction ActivationFunction
        {
            set
            {

            }
        }


        /// <summary>
        /// Set the number of input neurons, this must match the output neurons.
        /// </summary>
        public int InputNeurons
        {
            set { _neuronCount = value; }
        }


        /// <summary>
        /// Set the number of output neurons, should not be used with a hopfield
        /// neural network, because the number of input neurons defines the number of
        /// output neurons.
        /// </summary>
        public int OutputNeurons
        {
            set
            {

            }
        }

        #endregion
    }

    public class JordanPattern : INeuralNetworkPattern
    {
        /// <summary>
        /// The activation function.
        /// </summary>
        ///
        private IActivationFunction _activation;

        /// <summary>
        /// The number of hidden neurons.
        /// </summary>
        ///
        private int _hiddenNeurons;

        /// <summary>
        /// The number of input neurons.
        /// </summary>
        ///
        private int _inputNeurons;

        /// <summary>
        /// The number of output neurons.
        /// </summary>
        ///
        private int _outputNeurons;

        /// <summary>
        /// Construct an object to create a Jordan type neural network.
        /// </summary>
        ///
        public JordanPattern()
        {
            _inputNeurons = -1;
            _outputNeurons = -1;
            _hiddenNeurons = -1;
        }

        #region NeuralNetworkPattern Members

        /// <summary>
        /// Add a hidden layer, there should be only one.
        /// </summary>
        ///
        /// <param name="count">The number of neurons in this hidden layer.</param>
        public void AddHiddenLayer(int count)
        {
            if (_hiddenNeurons != -1)
            {

            }

            _hiddenNeurons = count;
        }

        /// <summary>
        /// Clear out any hidden neurons.
        /// </summary>
        ///
        public void Clear()
        {
            _hiddenNeurons = -1;
        }

        /// <summary>
        /// Generate a Jordan neural network.
        /// </summary>
        ///
        /// <returns>A Jordan neural network.</returns>
        public IMLMethod Generate()
        {
            BasicLayer hidden, output;

            var network = new BasicNetwork();
            network.AddLayer(new BasicLayer(null, true,
                                            _inputNeurons));
            network.AddLayer(hidden = new BasicLayer(_activation, true,
                                                     _hiddenNeurons));
            network.AddLayer(output = new BasicLayer(_activation, false,
                                                     _outputNeurons));
            hidden.ContextFedBy = output;
            network.Structure.FinalizeStructure();
            network.Reset();
            return network;
        }

        /// <summary>
        /// Set the activation function to use on each of the layers.
        /// </summary>
        public IActivationFunction ActivationFunction
        {
            set { _activation = value; }
        }


        /// <summary>
        /// Set the number of input neurons.
        /// </summary>
        public int InputNeurons
        {
            set { _inputNeurons = value; }
        }


        /// <summary>
        /// Set the number of output neurons.
        /// </summary>
        public int OutputNeurons
        {
            set { _outputNeurons = value; }
        }

        #endregion
    }

    [Serializable]
    public class PatternError : NeuralNetworkError
    {
        /// <summary>
        /// Construct a message exception.
        /// </summary>
        ///
        /// <param name="msg">The exception message.</param>
        public PatternError(String msg) : base(msg)
        {
        }

        /// <summary>
        /// Construct an exception that holds another exception.
        /// </summary>
        ///
        /// <param name="t">The other exception.</param>
        public PatternError(Exception t) : base(t)
        {
        }
    }

    public class PNNPattern : INeuralNetworkPattern
    {
        /// <summary>
        /// The number of input neurons.
        /// </summary>
        ///
        private int _inputNeurons;

        /// <summary>
        /// The kernel type.
        /// </summary>
        ///
        private PNNKernelType _kernel;

        /// <summary>
        /// The output model.
        /// </summary>
        ///
        private PNNOutputMode _outmodel;

        /// <summary>
        /// The number of output neurons.
        /// </summary>
        ///
        private int _outputNeurons;

        /// <summary>
        /// Construct the object.
        /// </summary>
        public PNNPattern()
        {
            _kernel = PNNKernelType.Gaussian;
            _outmodel = PNNOutputMode.Regression;
        }

        /// <summary>
        /// Set the kernel type.
        /// </summary>
        public PNNKernelType Kernel
        {
            get { return _kernel; }
            set { _kernel = value; }
        }


        /// <summary>
        /// Set the output model.
        /// </summary>
        public PNNOutputMode Outmodel
        {
            get { return _outmodel; }
            set { _outmodel = value; }
        }

        #region NeuralNetworkPattern Members

        /// <summary>
        /// Add a hidden layer. PNN networks do not have hidden layers, so this will
        /// throw an error.
        /// </summary>
        ///
        /// <param name="count">The number of hidden neurons.</param>
        public void AddHiddenLayer(int count)
        {


        }

        /// <summary>
        /// Clear out any hidden neurons.
        /// </summary>
        ///
        public virtual void Clear()
        {
        }

        /// <summary>
        /// Generate the RSOM network.
        /// </summary>
        ///
        /// <returns>The neural network.</returns>
        public IMLMethod Generate()
        {
            var pnn = new BasicPNN(_kernel, _outmodel,
                                   _inputNeurons, _outputNeurons);
            return pnn;
        }

        /// <summary>
        /// Set the input neuron count.
        /// </summary>
        public int InputNeurons
        {
            get { return _inputNeurons; }
            set { _inputNeurons = value; }
        }


        /// <summary>
        /// Set the output neuron count.
        /// </summary>
        ///
        /// <value>The number of neurons.</value>
        public int OutputNeurons
        {
            get { return _outputNeurons; }
            set { _outputNeurons = value; }
        }


        /// <summary>
        /// Set the activation function. A PNN uses a linear activation function, so
        /// this method throws an error.
        /// </summary>
        public IActivationFunction ActivationFunction
        {
            set
            {

            }
        }

        #endregion
    }

    public class RadialBasisPattern : INeuralNetworkPattern
    {
        /// <summary>
        /// The number of hidden neurons to use. Must be set, default to invalid -1
        /// value.
        /// </summary>
        ///
        private int _hiddenNeurons;

        /// <summary>
        /// The number of input neurons to use. Must be set, default to invalid -1
        /// value.
        /// </summary>
        ///
        private int _inputNeurons;

        /// <summary>
        /// The number of hidden neurons to use. Must be set, default to invalid -1
        /// value.
        /// </summary>
        ///
        private int _outputNeurons;

        /// <summary>
        /// The RBF type.
        /// </summary>
        private RBFEnum _rbfType;

        /// <summary>
        /// Construct the object.
        /// </summary>
        public RadialBasisPattern()
        {
            _rbfType = RBFEnum.Gaussian;
            _inputNeurons = -1;
            _outputNeurons = -1;
            _hiddenNeurons = -1;
        }

        /// <summary>
        /// The RBF type.
        /// </summary>
        public RBFEnum RBF
        {
            set { _rbfType = value; }
        }

        #region NeuralNetworkPattern Members

        /// <summary>
        /// Add the hidden layer, this should be called once, as a RBF has a single
        /// hidden layer.
        /// </summary>
        ///
        /// <param name="count">The number of neurons in the hidden layer.</param>
        public void AddHiddenLayer(int count)
        {
            if (_hiddenNeurons != -1)
            {

            }
            _hiddenNeurons = count;
        }

        /// <summary>
        /// Clear out any hidden neurons.
        /// </summary>
        ///
        public void Clear()
        {
            _hiddenNeurons = -1;
        }

        /// <summary>
        /// Generate the RBF network.
        /// </summary>
        ///
        /// <returns>The neural network.</returns>
        public IMLMethod Generate()
        {
            var result = new RBFNetwork(_inputNeurons, _hiddenNeurons,
                                        _outputNeurons, _rbfType);
            return result;
        }

        /// <summary>
        /// Set the activation function, this is an error. The activation function
        /// may not be set on a RBF layer.
        /// </summary>
        public IActivationFunction ActivationFunction
        {
            set
            {

            }
        }


        /// <summary>
        /// Set the number of input neurons.
        /// </summary>
        public int InputNeurons
        {
            set { _inputNeurons = value; }
        }


        /// <summary>
        /// Set the number of output neurons.
        /// </summary>
        public int OutputNeurons
        {
            set { _outputNeurons = value; }
        }

        #endregion
    }

    public class SOMPattern : INeuralNetworkPattern
    {
        /// <summary>
        /// The number of input neurons.
        /// </summary>
        ///
        private int _inputNeurons;

        /// <summary>
        /// The number of output neurons.
        /// </summary>
        ///
        private int _outputNeurons;

        #region NeuralNetworkPattern Members

        /// <summary>
        /// Add a hidden layer. SOM networks do not have hidden layers, so this will
        /// throw an error.
        /// </summary>
        public void AddHiddenLayer(int count)
        {
            throw new PatternError("A SOM network does not have hidden layers.");
        }

        /// <summary>
        /// Clear out any hidden neurons.
        /// </summary>
        ///
        public virtual void Clear()
        {
        }

        /// <summary>
        /// Generate the RSOM network.
        /// </summary>
        public IMLMethod Generate()
        {
            var som = new SOMNetwork(_inputNeurons, _outputNeurons);
            som.Reset();
            return som;
        }

        /// <summary>
        /// Set the activation function. A SOM uses a linear activation function, so
        /// this method throws an error.
        /// </summary>
        public IActivationFunction ActivationFunction
        {
            set
            {
                throw new PatternError(
                    "A SOM network can't define an activation function.");
            }
        }


        /// <summary>
        /// Set the input neuron count.
        /// </summary>
        public int InputNeurons
        {
            set { _inputNeurons = value; }
        }


        /// <summary>
        /// Set the output neuron count.
        /// </summary>
        public int OutputNeurons
        {
            set { _outputNeurons = value; }
        }

        #endregion
    }

    internal class Cache
    {
        //UPGRADE_NOTE: Final was removed from the declaration of 'l '. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1003_3"'

        //UPGRADE_NOTE: Final was removed from the declaration of 'head '. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1003_3"'
        private readonly head_t[] head;
        private readonly int l;
        private readonly head_t lru_head;
        private int size;

        internal Cache(int l_, int size_)
        {
            l = l_;
            size = size_;
            head = new head_t[l];
            for (int i = 0; i < l; i++)
                head[i] = new head_t(this);
            size /= 4;
            size -= l * (16 / 4); // sizeof(head_t) == 16
            lru_head = new head_t(this);
            lru_head.next = lru_head.prev = lru_head;
        }

        private void lru_delete(head_t h)
        {
            // delete from current location
            h.prev.next = h.next;
            h.next.prev = h.prev;
        }

        private void lru_insert(head_t h)
        {
            // insert to last position
            h.next = lru_head;
            h.prev = lru_head.prev;
            h.prev.next = h;
            h.next.prev = h;
        }

        // request data [0,len)
        // return some position p where [p,len) need to be filled
        // (p >= len if nothing needs to be filled)
        // java: simulate pointer using single-element array
        internal virtual int get_data(int index, float[][] data, int len)
        {
            head_t h = head[index];
            if (h.len > 0)
                lru_delete(h);
            int more = len - h.len;

            if (more > 0)
            {
                // free old space
                while (size < more)
                {
                    head_t old = lru_head.next;
                    lru_delete(old);
                    size += old.len;
                    old.data = null;
                    old.len = 0;
                }

                // allocate new space
                var new_data = new float[len];
                if (h.data != null)
                    Array.Copy(h.data, 0, new_data, 0, h.len);
                h.data = new_data;
                size -= more;
                do
                {
                    int _ = h.len;
                    h.len = len;
                    len = _;
                } while (false);
            }

            lru_insert(h);
            data[0] = h.data;
            return len;
        }

        internal virtual void swap_index(int i, int j)
        {
            if (i == j)
                return;

            if (head[i].len > 0)
                lru_delete(head[i]);
            if (head[j].len > 0)
                lru_delete(head[j]);
            do
            {
                float[] _ = head[i].data;
                head[i].data = head[j].data;
                head[j].data = _;
            } while (false);
            do
            {
                int _ = head[i].len;
                head[i].len = head[j].len;
                head[j].len = _;
            } while (false);
            if (head[i].len > 0)
                lru_insert(head[i]);
            if (head[j].len > 0)
                lru_insert(head[j]);

            if (i > j)
                do
                {
                    int _ = i;
                    i = j;
                    j = _;
                } while (false);
            for (head_t h = lru_head.next; h != lru_head; h = h.next)
            {
                if (h.len > i)
                {
                    if (h.len > j)
                        do
                        {
                            float _ = h.data[i];
                            h.data[i] = h.data[j];
                            h.data[j] = _;
                        } while (false);
                    else
                    {
                        // give up
                        lru_delete(h);
                        size += h.len;
                        h.data = null;
                        h.len = 0;
                    }
                }
            }
        }

        #region Nested type: head_t

        private sealed class head_t
        {
            internal float[] data;
            private Cache enclosingInstance;
            internal int len; // data[0,len) is cached in this entry
            internal head_t next; // a cicular list
            internal head_t prev; // a cicular list

            public head_t(Cache enclosingInstance)
            {
                InitBlock(enclosingInstance);
            }

            public Cache Enclosing_Instance
            {
                get { return enclosingInstance; }
            }

            private void InitBlock(Cache enclosingInstance)
            {
                this.enclosingInstance = enclosingInstance;
            }
        }

        #endregion
    }

    internal abstract class Kernel
    {
        //UPGRADE_NOTE: Final was removed from the declaration of 'degree '. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1003_3"'
        private readonly double coef0;
        private readonly double degree;
        //UPGRADE_NOTE: Final was removed from the declaration of 'gamma '. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1003_3"'
        private readonly double gamma;
        private readonly int kernel_type;
        private readonly svm_node[][] x;
        //UPGRADE_NOTE: Final was removed from the declaration of 'x_square '. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1003_3"'
        private readonly double[] x_square;

        internal Kernel(int l, svm_node[][] x_, svm_parameter param)
        {
            kernel_type = param.kernel_type;
            degree = param.degree;
            gamma = param.gamma;
            coef0 = param.coef0;

            x = (svm_node[][])x_.Clone();

            if (kernel_type == svm_parameter.RBF)
            {
                x_square = new double[l];
                for (int i = 0; i < l; i++)
                    x_square[i] = dot(x[i], x[i]);
            }
            else
                x_square = null;
        }

        //UPGRADE_NOTE: Final was removed from the declaration of 'coef0 '. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1003_3"'

        internal abstract float[] get_Q(int column, int len);

        internal virtual void swap_index(int i, int j)
        {
            do
            {
                svm_node[] _ = x[i];
                x[i] = x[j];
                x[j] = _;
            } while (false);
            if (x_square != null)
                do
                {
                    double _ = x_square[i];
                    x_square[i] = x_square[j];
                    x_square[j] = _;
                } while (false);
        }

        private static double tanh(double x)
        {
            double e = Math.Exp(x);
            return 1.0 - 2.0 / (e * e + 1);
        }

        internal virtual double kernel_function(int i, int j)
        {
            switch (kernel_type)
            {
                case svm_parameter.LINEAR:
                    return dot(x[i], x[j]);

                case svm_parameter.POLY:
                    return Math.Pow(gamma * dot(x[i], x[j]) + coef0, degree);

                case svm_parameter.RBF:
                    return Math.Exp((-gamma) * (x_square[i] + x_square[j] - 2 * dot(x[i], x[j])));

                case svm_parameter.SIGMOID:
                    return tanh(gamma * dot(x[i], x[j]) + coef0);

                default:
                    return 0; // java
            }
        }

        internal static double dot(svm_node[] x, svm_node[] y)
        {
            double sum = 0;
            int xlen = x.Length;
            int ylen = y.Length;
            int i = 0;
            int j = 0;
            while (i < xlen && j < ylen)
            {
                if (x[i].index == y[j].index)
                    sum += x[i++].value_Renamed * y[j++].value_Renamed;
                else
                {
                    if (x[i].index > y[j].index)
                        ++j;
                    else
                        ++i;
                }
            }
            return sum;
        }

        internal static double k_function(svm_node[] x, svm_node[] y, svm_parameter param)
        {
            switch (param.kernel_type)
            {
                case svm_parameter.LINEAR:
                    return dot(x, y);

                case svm_parameter.POLY:
                    return Math.Pow(param.gamma * dot(x, y) + param.coef0, param.degree);

                case svm_parameter.RBF:
                    {
                        double sum = 0;
                        int xlen = x.Length;
                        int ylen = y.Length;
                        int i = 0;
                        int j = 0;
                        while (i < xlen && j < ylen)
                        {
                            if (x[i].index == y[j].index)
                            {
                                double d = x[i++].value_Renamed - y[j++].value_Renamed;
                                sum += d * d;
                            }
                            else if (x[i].index > y[j].index)
                            {
                                sum += y[j].value_Renamed * y[j].value_Renamed;
                                ++j;
                            }
                            else
                            {
                                sum += x[i].value_Renamed * x[i].value_Renamed;
                                ++i;
                            }
                        }

                        while (i < xlen)
                        {
                            sum += x[i].value_Renamed * x[i].value_Renamed;
                            ++i;
                        }

                        while (j < ylen)
                        {
                            sum += y[j].value_Renamed * y[j].value_Renamed;
                            ++j;
                        }

                        return Math.Exp((-param.gamma) * sum);
                    }

                case svm_parameter.SIGMOID:
                    return tanh(param.gamma * dot(x, y) + param.coef0);

                default:
                    return 0; // java
            }
        }
    }

    internal class Solver
    {
        internal const sbyte LOWER_BOUND = 0;
        internal const sbyte UPPER_BOUND = 1;
        internal const sbyte FREE = 2;
        internal static readonly double INF = Double.PositiveInfinity;
        internal double Cn;
        internal double Cp;
        internal double[] G; // gradient of objective function
        internal double[] G_bar; // gradient, if we treat free variables as 0
        internal Kernel Q;
        internal int[] active_set;
        internal int active_size;
        internal double[] alpha;
        internal sbyte[] alpha_status; // LOWER_BOUND, UPPER_BOUND, FREE
        internal double[] b;
        internal double eps;
        internal int l;
        internal bool unshrinked; // XXX
        internal sbyte[] y;

        //UPGRADE_NOTE: Final was removed from the declaration of 'INF '. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1003_3"'

        internal virtual double get_C(int i)
        {
            return (y[i] > 0) ? Cp : Cn;
        }

        internal virtual void update_alpha_status(int i)
        {
            if (alpha[i] >= get_C(i))
                alpha_status[i] = UPPER_BOUND;
            else if (alpha[i] <= 0)
                alpha_status[i] = LOWER_BOUND;
            else
                alpha_status[i] = FREE;
        }

        internal virtual bool is_upper_bound(int i)
        {
            return alpha_status[i] == UPPER_BOUND;
        }

        internal virtual bool is_lower_bound(int i)
        {
            return alpha_status[i] == LOWER_BOUND;
        }

        internal virtual bool is_free(int i)
        {
            return alpha_status[i] == FREE;
        }

        // java: information about solution except alpha,
        // because we cannot return multiple values otherwise...

        internal virtual void swap_index(int i, int j)
        {
            Q.swap_index(i, j);
            do
            {
                sbyte _ = y[i];
                y[i] = y[j];
                y[j] = _;
            } while (false);
            do
            {
                double _ = G[i];
                G[i] = G[j];
                G[j] = _;
            } while (false);
            do
            {
                sbyte _ = alpha_status[i];
                alpha_status[i] = alpha_status[j];
                alpha_status[j] = _;
            } while (false);
            do
            {
                double _ = alpha[i];
                alpha[i] = alpha[j];
                alpha[j] = _;
            } while (false);
            do
            {
                double _ = b[i];
                b[i] = b[j];
                b[j] = _;
            } while (false);
            do
            {
                int _ = active_set[i];
                active_set[i] = active_set[j];
                active_set[j] = _;
            } while (false);
            do
            {
                double _ = G_bar[i];
                G_bar[i] = G_bar[j];
                G_bar[j] = _;
            } while (false);
        }

        internal virtual void reconstruct_gradient()
        {
            // reconstruct inactive elements of G from G_bar and free variables

            if (active_size == l)
                return;

            int i;
            for (i = active_size; i < l; i++)
                G[i] = G_bar[i] + b[i];

            for (i = 0; i < active_size; i++)
                if (is_free(i))
                {
                    float[] Q_i = Q.get_Q(i, l);
                    double alpha_i = alpha[i];
                    for (int j = active_size; j < l; j++)
                        G[j] += alpha_i * Q_i[j];
                }
        }

        internal virtual void Solve(int l, Kernel Q, double[] b_, sbyte[] y_, double[] alpha_, double Cp, double Cn,
                                    double eps, SolutionInfo si, int shrinking)
        {
            this.l = l;
            this.Q = Q;
            b = new double[b_.Length];
            b_.CopyTo(b, 0);
            y = new sbyte[y_.Length];
            y_.CopyTo(y, 0);
            alpha = new double[alpha_.Length];
            alpha_.CopyTo(alpha, 0);
            this.Cp = Cp;
            this.Cn = Cn;
            this.eps = eps;
            unshrinked = false;

            // initialize alpha_status
            {
                alpha_status = new sbyte[l];
                for (int i = 0; i < l; i++)
                    update_alpha_status(i);
            }

            // initialize active set (for shrinking)
            {
                active_set = new int[l];
                for (int i = 0; i < l; i++)
                    active_set[i] = i;
                active_size = l;
            }

            // initialize gradient
            {
                G = new double[l];
                G_bar = new double[l];
                int i;
                for (i = 0; i < l; i++)
                {
                    G[i] = b[i];
                    G_bar[i] = 0;
                }
                for (i = 0; i < l; i++)
                    if (!is_lower_bound(i))
                    {
                        float[] Q_i = Q.get_Q(i, l);
                        double alpha_i = alpha[i];
                        int j;
                        for (j = 0; j < l; j++)
                            G[j] += alpha_i * Q_i[j];
                        if (is_upper_bound(i))
                            for (j = 0; j < l; j++)
                                G_bar[j] += get_C(i) * Q_i[j];
                    }
            }

            // optimization step

            int iter = 0;
            int counter = Math.Min(l, 1000) + 1;
            var working_set = new int[2];

            while (true)
            {
                // max iterations?
                if (iter > 10000)
                    break;
                // show progress and do shrinking

                if (--counter == 0)
                {
                    counter = Math.Min(l, 1000);
                    if (shrinking != 0)
                        do_shrinking();
                    //Console.Error.Write(".");
                }

                if (select_working_set(working_set) != 0)
                {
                    // reconstruct the whole gradient
                    reconstruct_gradient();
                    // reset active set size and check
                    active_size = l;
                    //Console.Error.Write("*");
                    if (select_working_set(working_set) != 0)
                        break;
                    else
                        counter = 1; // do shrinking next iteration
                }

                int i = working_set[0];
                int j = working_set[1];

                ++iter;

                // update alpha[i] and alpha[j], handle bounds carefully

                float[] Q_i = Q.get_Q(i, active_size);
                float[] Q_j = Q.get_Q(j, active_size);

                double C_i = get_C(i);
                double C_j = get_C(j);

                double old_alpha_i = alpha[i];
                double old_alpha_j = alpha[j];

                if (y[i] != y[j])
                {
                    double delta = (-G[i] - G[j]) / Math.Max(Q_i[i] + Q_j[j] + 2 * Q_i[j], 0);
                    double diff = alpha[i] - alpha[j];
                    alpha[i] += delta;
                    alpha[j] += delta;

                    if (diff > 0)
                    {
                        if (alpha[j] < 0)
                        {
                            alpha[j] = 0;
                            alpha[i] = diff;
                        }
                    }
                    else
                    {
                        if (alpha[i] < 0)
                        {
                            alpha[i] = 0;
                            alpha[j] = -diff;
                        }
                    }
                    if (diff > C_i - C_j)
                    {
                        if (alpha[i] > C_i)
                        {
                            alpha[i] = C_i;
                            alpha[j] = C_i - diff;
                        }
                    }
                    else
                    {
                        if (alpha[j] > C_j)
                        {
                            alpha[j] = C_j;
                            alpha[i] = C_j + diff;
                        }
                    }
                }
                else
                {
                    double delta = (G[i] - G[j]) / Math.Max(Q_i[i] + Q_j[j] - 2 * Q_i[j], 0);
                    double sum = alpha[i] + alpha[j];
                    alpha[i] -= delta;
                    alpha[j] += delta;
                    if (sum > C_i)
                    {
                        if (alpha[i] > C_i)
                        {
                            alpha[i] = C_i;
                            alpha[j] = sum - C_i;
                        }
                    }
                    else
                    {
                        if (alpha[j] < 0)
                        {
                            alpha[j] = 0;
                            alpha[i] = sum;
                        }
                    }
                    if (sum > C_j)
                    {
                        if (alpha[j] > C_j)
                        {
                            alpha[j] = C_j;
                            alpha[i] = sum - C_j;
                        }
                    }
                    else
                    {
                        if (alpha[i] < 0)
                        {
                            alpha[i] = 0;
                            alpha[j] = sum;
                        }
                    }
                }

                // update G

                double delta_alpha_i = alpha[i] - old_alpha_i;
                double delta_alpha_j = alpha[j] - old_alpha_j;

                for (int k = 0; k < active_size; k++)
                {
                    G[k] += Q_i[k] * delta_alpha_i + Q_j[k] * delta_alpha_j;
                }

                // update alpha_status and G_bar

                {
                    bool ui = is_upper_bound(i);
                    bool uj = is_upper_bound(j);
                    update_alpha_status(i);
                    update_alpha_status(j);
                    int k;
                    if (ui != is_upper_bound(i))
                    {
                        Q_i = Q.get_Q(i, l);
                        if (ui)
                            for (k = 0; k < l; k++)
                                G_bar[k] -= C_i * Q_i[k];
                        else
                            for (k = 0; k < l; k++)
                                G_bar[k] += C_i * Q_i[k];
                    }

                    if (uj != is_upper_bound(j))
                    {
                        Q_j = Q.get_Q(j, l);
                        if (uj)
                            for (k = 0; k < l; k++)
                                G_bar[k] -= C_j * Q_j[k];
                        else
                            for (k = 0; k < l; k++)
                                G_bar[k] += C_j * Q_j[k];
                    }
                }
            }

            // calculate rho

            si.rho = calculate_rho();

            // calculate objective value
            {
                double v = 0;
                int i;
                for (i = 0; i < l; i++)
                    v += alpha[i] * (G[i] + b[i]);

                si.obj = v / 2;
            }

            // put back the solution
            {
                for (int i = 0; i < l; i++)
                    alpha_[active_set[i]] = alpha[i];
            }

            si.upper_bound_p = Cp;
            si.upper_bound_n = Cn;

            //Console.Out.Write("\noptimization finished, #iter = " + iter + "\n");
        }

        // return 1 if already optimal, return 0 otherwise
        internal virtual int select_working_set(int[] working_set)
        {
            // return i,j which maximize -grad(f)^T d , under constraint
            // if alpha_i == C, d != +1
            // if alpha_i == 0, d != -1

            double Gmax1 = -INF; // max { -grad(f)_i * d | y_i*d = +1 }
            int Gmax1_idx = -1;

            double Gmax2 = -INF; // max { -grad(f)_i * d | y_i*d = -1 }
            int Gmax2_idx = -1;

            for (int i = 0; i < active_size; i++)
            {
                if (y[i] == +1)
                // y = +1
                {
                    if (!is_upper_bound(i))
                    // d = +1
                    {
                        if (-G[i] > Gmax1)
                        {
                            Gmax1 = -G[i];
                            Gmax1_idx = i;
                        }
                    }
                    if (!is_lower_bound(i))
                    // d = -1
                    {
                        if (G[i] > Gmax2)
                        {
                            Gmax2 = G[i];
                            Gmax2_idx = i;
                        }
                    }
                }
                // y = -1
                else
                {
                    if (!is_upper_bound(i))
                    // d = +1
                    {
                        if (-G[i] > Gmax2)
                        {
                            Gmax2 = -G[i];
                            Gmax2_idx = i;
                        }
                    }
                    if (!is_lower_bound(i))
                    // d = -1
                    {
                        if (G[i] > Gmax1)
                        {
                            Gmax1 = G[i];
                            Gmax1_idx = i;
                        }
                    }
                }
            }

            if (Gmax1 + Gmax2 < eps)
                return 1;

            working_set[0] = Gmax1_idx;
            working_set[1] = Gmax2_idx;
            return 0;
        }

        internal virtual void do_shrinking()
        {
            int i, j, k;
            var working_set = new int[2];
            if (select_working_set(working_set) != 0)
                return;
            i = working_set[0];
            j = working_set[1];
            double Gm1 = (-y[j]) * G[j];
            double Gm2 = y[i] * G[i];

            // shrink

            for (k = 0; k < active_size; k++)
            {
                if (is_lower_bound(k))
                {
                    if (y[k] == +1)
                    {
                        if (-G[k] >= Gm1)
                            continue;
                    }
                    else if (-G[k] >= Gm2)
                        continue;
                }
                else if (is_upper_bound(k))
                {
                    if (y[k] == +1)
                    {
                        if (G[k] >= Gm2)
                            continue;
                    }
                    else if (G[k] >= Gm1)
                        continue;
                }
                else
                    continue;

                --active_size;
                swap_index(k, active_size);
                --k; // look at the newcomer
            }

            // unshrink, check all variables again before final iterations

            if (unshrinked || -(Gm1 + Gm2) > eps * 10)
                return;

            unshrinked = true;
            reconstruct_gradient();

            for (k = l - 1; k >= active_size; k--)
            {
                if (is_lower_bound(k))
                {
                    if (y[k] == +1)
                    {
                        if (-G[k] < Gm1)
                            continue;
                    }
                    else if (-G[k] < Gm2)
                        continue;
                }
                else if (is_upper_bound(k))
                {
                    if (y[k] == +1)
                    {
                        if (G[k] < Gm2)
                            continue;
                    }
                    else if (G[k] < Gm1)
                        continue;
                }
                else
                    continue;

                swap_index(k, active_size);
                active_size++;
                ++k; // look at the newcomer
            }
        }

        internal virtual double calculate_rho()
        {
            double r;
            int nr_free = 0;
            double ub = INF, lb = -INF, sum_free = 0;
            for (int i = 0; i < active_size; i++)
            {
                double yG = y[i] * G[i];

                if (is_lower_bound(i))
                {
                    if (y[i] > 0)
                        ub = Math.Min(ub, yG);
                    else
                        lb = Math.Max(lb, yG);
                }
                else if (is_upper_bound(i))
                {
                    if (y[i] < 0)
                        ub = Math.Min(ub, yG);
                    else
                        lb = Math.Max(lb, yG);
                }
                else
                {
                    ++nr_free;
                    sum_free += yG;
                }
            }

            if (nr_free > 0)
                r = sum_free / nr_free;
            else
                r = (ub + lb) / 2;

            return r;
        }

        #region Nested type: SolutionInfo

        internal class SolutionInfo
        {
            internal double obj;
            internal double r; // for Solver_NU
            internal double rho;
            internal double upper_bound_n;
            internal double upper_bound_p;
        }

        #endregion
    }
    
    internal sealed class Solver_NU : Solver
    {
        private SolutionInfo si;

        internal override void Solve(int l, Kernel Q, double[] b, sbyte[] y, double[] alpha, double Cp, double Cn,
                                     double eps, SolutionInfo si, int shrinking)
        {
            this.si = si;
            base.Solve(l, Q, b, y, alpha, Cp, Cn, eps, si, shrinking);
        }

        internal override int select_working_set(int[] working_set)
        {
            // return i,j which maximize -grad(f)^T d , under constraint
            // if alpha_i == C, d != +1
            // if alpha_i == 0, d != -1

            double Gmax1 = -INF; // max { -grad(f)_i * d | y_i = +1, d = +1 }
            int Gmax1_idx = -1;

            double Gmax2 = -INF; // max { -grad(f)_i * d | y_i = +1, d = -1 }
            int Gmax2_idx = -1;

            double Gmax3 = -INF; // max { -grad(f)_i * d | y_i = -1, d = +1 }
            int Gmax3_idx = -1;

            double Gmax4 = -INF; // max { -grad(f)_i * d | y_i = -1, d = -1 }
            int Gmax4_idx = -1;

            for (int i = 0; i < active_size; i++)
            {
                if (y[i] == +1)
                // y == +1
                {
                    if (!is_upper_bound(i))
                    // d = +1
                    {
                        if (-G[i] > Gmax1)
                        {
                            Gmax1 = -G[i];
                            Gmax1_idx = i;
                        }
                    }
                    if (!is_lower_bound(i))
                    // d = -1
                    {
                        if (G[i] > Gmax2)
                        {
                            Gmax2 = G[i];
                            Gmax2_idx = i;
                        }
                    }
                }
                // y == -1
                else
                {
                    if (!is_upper_bound(i))
                    // d = +1
                    {
                        if (-G[i] > Gmax3)
                        {
                            Gmax3 = -G[i];
                            Gmax3_idx = i;
                        }
                    }
                    if (!is_lower_bound(i))
                    // d = -1
                    {
                        if (G[i] > Gmax4)
                        {
                            Gmax4 = G[i];
                            Gmax4_idx = i;
                        }
                    }
                }
            }

            if (Math.Max(Gmax1 + Gmax2, Gmax3 + Gmax4) < eps)
                return 1;

            if (Gmax1 + Gmax2 > Gmax3 + Gmax4)
            {
                working_set[0] = Gmax1_idx;
                working_set[1] = Gmax2_idx;
            }
            else
            {
                working_set[0] = Gmax3_idx;
                working_set[1] = Gmax4_idx;
            }
            return 0;
        }

        internal override void do_shrinking()
        {
            double Gmax1 = -INF; // max { -grad(f)_i * d | y_i = +1, d = +1 }
            double Gmax2 = -INF; // max { -grad(f)_i * d | y_i = +1, d = -1 }
            double Gmax3 = -INF; // max { -grad(f)_i * d | y_i = -1, d = +1 }
            double Gmax4 = -INF; // max { -grad(f)_i * d | y_i = -1, d = -1 }

            int k;
            for (k = 0; k < active_size; k++)
            {
                if (!is_upper_bound(k))
                {
                    if (y[k] == +1)
                    {
                        if (-G[k] > Gmax1)
                            Gmax1 = -G[k];
                    }
                    else if (-G[k] > Gmax3)
                        Gmax3 = -G[k];
                }
                if (!is_lower_bound(k))
                {
                    if (y[k] == +1)
                    {
                        if (G[k] > Gmax2)
                            Gmax2 = G[k];
                    }
                    else if (G[k] > Gmax4)
                        Gmax4 = G[k];
                }
            }

            double Gm1 = -Gmax2;
            double Gm2 = -Gmax1;
            double Gm3 = -Gmax4;
            double Gm4 = -Gmax3;

            for (k = 0; k < active_size; k++)
            {
                if (is_lower_bound(k))
                {
                    if (y[k] == +1)
                    {
                        if (-G[k] >= Gm1)
                            continue;
                    }
                    else if (-G[k] >= Gm3)
                        continue;
                }
                else if (is_upper_bound(k))
                {
                    if (y[k] == +1)
                    {
                        if (G[k] >= Gm2)
                            continue;
                    }
                    else if (G[k] >= Gm4)
                        continue;
                }
                else
                    continue;

                --active_size;
                swap_index(k, active_size);
                --k; // look at the newcomer
            }

            // unshrink, check all variables again before final iterations

            if (unshrinked || Math.Max(-(Gm1 + Gm2), -(Gm3 + Gm4)) > eps * 10)
                return;

            unshrinked = true;
            reconstruct_gradient();

            for (k = l - 1; k >= active_size; k--)
            {
                if (is_lower_bound(k))
                {
                    if (y[k] == +1)
                    {
                        if (-G[k] < Gm1)
                            continue;
                    }
                    else if (-G[k] < Gm3)
                        continue;
                }
                else if (is_upper_bound(k))
                {
                    if (y[k] == +1)
                    {
                        if (G[k] < Gm2)
                            continue;
                    }
                    else if (G[k] < Gm4)
                        continue;
                }
                else
                    continue;

                swap_index(k, active_size);
                active_size++;
                ++k; // look at the newcomer
            }
        }

        internal override double calculate_rho()
        {
            int nr_free1 = 0, nr_free2 = 0;
            double ub1 = INF, ub2 = INF;
            double lb1 = -INF, lb2 = -INF;
            double sum_free1 = 0, sum_free2 = 0;

            for (int i = 0; i < active_size; i++)
            {
                if (y[i] == +1)
                {
                    if (is_lower_bound(i))
                        ub1 = Math.Min(ub1, G[i]);
                    else if (is_upper_bound(i))
                        lb1 = Math.Max(lb1, G[i]);
                    else
                    {
                        ++nr_free1;
                        sum_free1 += G[i];
                    }
                }
                else
                {
                    if (is_lower_bound(i))
                        ub2 = Math.Min(ub2, G[i]);
                    else if (is_upper_bound(i))
                        lb2 = Math.Max(lb2, G[i]);
                    else
                    {
                        ++nr_free2;
                        sum_free2 += G[i];
                    }
                }
            }

            double r1, r2;
            if (nr_free1 > 0)
                r1 = sum_free1 / nr_free1;
            else
                r1 = (ub1 + lb1) / 2;

            if (nr_free2 > 0)
                r2 = sum_free2 / nr_free2;
            else
                r2 = (ub2 + lb2) / 2;

            si.r = (r1 + r2) / 2;
            return (r1 - r2) / 2;
        }
    }

    internal class SVC_Q : Kernel
    {
        //UPGRADE_NOTE: Final was removed from the declaration of 'y '. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1003_3"'
        //UPGRADE_NOTE: Final was removed from the declaration of 'cache '. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1003_3"'
        private readonly Cache cache;
        private readonly sbyte[] y;

        internal SVC_Q(svm_problem prob, svm_parameter param, sbyte[] y_) : base(prob.l, prob.x, param)
        {
            y = new sbyte[y_.Length];
            y_.CopyTo(y, 0);
            //UPGRADE_WARNING: Data types in Visual C# might be different.  Verify the accuracy of narrowing conversions. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1042_3"'
            cache = new Cache(prob.l, (int)(param.cache_size * (1 << 20)));
        }

        internal override float[] get_Q(int i, int len)
        {
            var data = new float[1][];
            int start;
            if ((start = cache.get_data(i, data, len)) < len)
            {
                for (int j = start; j < len; j++)
                {
                    //UPGRADE_WARNING: Data types in Visual C# might be different.  Verify the accuracy of narrowing conversions. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1042_3"'
                    data[0][j] = (float)(y[i] * y[j] * kernel_function(i, j));
                }
            }
            return data[0];
        }

        internal override void swap_index(int i, int j)
        {
            cache.swap_index(i, j);
            base.swap_index(i, j);
            do
            {
                sbyte _ = y[i];
                y[i] = y[j];
                y[j] = _;
            } while (false);
        }
    }

    internal class ONE_CLASS_Q : Kernel
    {
        //UPGRADE_NOTE: Final was removed from the declaration of 'cache '. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1003_3"'
        private readonly Cache cache;

        internal ONE_CLASS_Q(svm_problem prob, svm_parameter param) : base(prob.l, prob.x, param)
        {
            //UPGRADE_WARNING: Data types in Visual C# might be different.  Verify the accuracy of narrowing conversions. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1042_3"'
            cache = new Cache(prob.l, (int)(param.cache_size * (1 << 20)));
        }

        internal override float[] get_Q(int i, int len)
        {
            var data = new float[1][];
            int start;
            if ((start = cache.get_data(i, data, len)) < len)
            {
                for (int j = start; j < len; j++)
                {
                    //UPGRADE_WARNING: Data types in Visual C# might be different.  Verify the accuracy of narrowing conversions. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1042_3"'
                    data[0][j] = (float)kernel_function(i, j);
                }
            }
            return data[0];
        }

        internal override void swap_index(int i, int j)
        {
            cache.swap_index(i, j);
            base.swap_index(i, j);
        }
    }

    internal class SVR_Q : Kernel
    {
        //UPGRADE_NOTE: Final was removed from the declaration of 'l '. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1003_3"'
        //UPGRADE_NOTE: Final was removed from the declaration of 'cache '. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1003_3"'
        private readonly float[][] buffer;
        private readonly Cache cache;
        //UPGRADE_NOTE: Final was removed from the declaration of 'sign '. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1003_3"'
        //UPGRADE_NOTE: Final was removed from the declaration of 'index '. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1003_3"'
        private readonly int[] index;
        private readonly int l;
        private readonly sbyte[] sign;
        private int next_buffer;

        internal SVR_Q(svm_problem prob, svm_parameter param) : base(prob.l, prob.x, param)
        {
            l = prob.l;
            //UPGRADE_WARNING: Data types in Visual C# might be different.  Verify the accuracy of narrowing conversions. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1042_3"'
            cache = new Cache(l, (int)(param.cache_size * (1 << 20)));
            sign = new sbyte[2 * l];
            index = new int[2 * l];
            for (int k = 0; k < l; k++)
            {
                sign[k] = 1;
                sign[k + l] = -1;
                index[k] = k;
                index[k + l] = k;
            }
            buffer = new float[2][];
            for (int i = 0; i < 2; i++)
            {
                buffer[i] = new float[2 * l];
            }
            next_buffer = 0;
        }

        internal override void swap_index(int i, int j)
        {
            do
            {
                sbyte _ = sign[i];
                sign[i] = sign[j];
                sign[j] = _;
            } while (false);
            do
            {
                int _ = index[i];
                index[i] = index[j];
                index[j] = _;
            } while (false);
        }

        internal override float[] get_Q(int i, int len)
        {
            var data = new float[1][];
            int real_i = index[i];
            if (cache.get_data(real_i, data, l) < l)
            {
                for (int j = 0; j < l; j++)
                {
                    //UPGRADE_WARNING: Data types in Visual C# might be different.  Verify the accuracy of narrowing conversions. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1042_3"'
                    data[0][j] = (float)kernel_function(real_i, j);
                }
            }

            // reorder and copy
            float[] buf = buffer[next_buffer];
            next_buffer = 1 - next_buffer;
            sbyte si = sign[i];
            for (int j = 0; j < len; j++)
                buf[j] = si * sign[j] * data[0][index[j]];
            return buf;
        }
    }

    public class svm
    {
        //
        // construct and solve various formulations
        //
        private static void solve_c_svc(svm_problem prob, svm_parameter param, double[] alpha, Solver.SolutionInfo si,
                                        double Cp, double Cn)
        {
            int l = prob.l;
            var minus_ones = new double[l];
            var y = new sbyte[l];

            int i;

            for (i = 0; i < l; i++)
            {
                alpha[i] = 0;
                minus_ones[i] = -1;
                if (prob.y[i] > 0)
                    y[i] = (+1);
                else
                    y[i] = -1;
            }

            var s = new Solver();
            s.Solve(l, new SVC_Q(prob, param, y), minus_ones, y, alpha, Cp, Cn, param.eps, si, param.shrinking);

            double sum_alpha = 0;
            for (i = 0; i < l; i++)
                sum_alpha += alpha[i];

            /*if (Cp == Cn)
                Console.Out.Write("nu = " + sum_alpha/(Cp*prob.l) + "\n");*/

            for (i = 0; i < l; i++)
                alpha[i] *= y[i];
        }

        private static void solve_nu_svc(svm_problem prob, svm_parameter param, double[] alpha, Solver.SolutionInfo si)
        {
            int i;
            int l = prob.l;
            double nu = param.nu;

            var y = new sbyte[l];

            for (i = 0; i < l; i++)
                if (prob.y[i] > 0)
                    y[i] = (+1);
                else
                    y[i] = -1;

            double sum_pos = nu * l / 2;
            double sum_neg = nu * l / 2;

            for (i = 0; i < l; i++)
                if (y[i] == +1)
                {
                    alpha[i] = Math.Min(1.0, sum_pos);
                    sum_pos -= alpha[i];
                }
                else
                {
                    alpha[i] = Math.Min(1.0, sum_neg);
                    sum_neg -= alpha[i];
                }

            var zeros = new double[l];

            for (i = 0; i < l; i++)
                zeros[i] = 0;

            var s = new Solver_NU();
            s.Solve(l, new SVC_Q(prob, param, y), zeros, y, alpha, 1.0, 1.0, param.eps, si, param.shrinking);
            double r = si.r;

            //Console.Out.Write("C = " + 1/r + "\n");

            for (i = 0; i < l; i++)
                alpha[i] *= y[i] / r;

            si.rho /= r;
            si.obj /= (r * r);
            si.upper_bound_p = 1 / r;
            si.upper_bound_n = 1 / r;
        }

        private static void solve_one_class(svm_problem prob, svm_parameter param, double[] alpha,
                                            Solver.SolutionInfo si)
        {
            int l = prob.l;
            var zeros = new double[l];
            var ones = new sbyte[l];
            int i;

            //UPGRADE_WARNING: Data types in Visual C# might be different.  Verify the accuracy of narrowing conversions. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1042_3"'
            var n = (int)(param.nu * prob.l); // # of alpha's at upper bound

            for (i = 0; i < n; i++)
                alpha[i] = 1;
            alpha[n] = param.nu * prob.l - n;
            for (i = n + 1; i < l; i++)
                alpha[i] = 0;

            for (i = 0; i < l; i++)
            {
                zeros[i] = 0;
                ones[i] = 1;
            }

            var s = new Solver();
            s.Solve(l, new ONE_CLASS_Q(prob, param), zeros, ones, alpha, 1.0, 1.0, param.eps, si, param.shrinking);
        }

        private static void solve_epsilon_svr(svm_problem prob, svm_parameter param, double[] alpha,
                                              Solver.SolutionInfo si)
        {
            int l = prob.l;
            var alpha2 = new double[2 * l];
            var linear_term = new double[2 * l];
            var y = new sbyte[2 * l];
            int i;

            for (i = 0; i < l; i++)
            {
                alpha2[i] = 0;
                linear_term[i] = param.p - prob.y[i];
                y[i] = 1;

                alpha2[i + l] = 0;
                linear_term[i + l] = param.p + prob.y[i];
                y[i + l] = -1;
            }

            var s = new Solver();
            s.Solve(2 * l, new SVR_Q(prob, param), linear_term, y, alpha2, param.C, param.C, param.eps, si,
                    param.shrinking);

            double sum_alpha = 0;
            for (i = 0; i < l; i++)
            {
                alpha[i] = alpha2[i] - alpha2[i + l];
                sum_alpha += Math.Abs(alpha[i]);
            }
            //Console.Out.Write("nu = " + sum_alpha/(param.C*l) + "\n");
        }

        private static void solve_nu_svr(svm_problem prob, svm_parameter param, double[] alpha, Solver.SolutionInfo si)
        {
            int l = prob.l;
            double C = param.C;
            var alpha2 = new double[2 * l];
            var linear_term = new double[2 * l];
            var y = new sbyte[2 * l];
            int i;

            double sum = C * param.nu * l / 2;
            for (i = 0; i < l; i++)
            {
                alpha2[i] = alpha2[i + l] = Math.Min(sum, C);
                sum -= alpha2[i];

                linear_term[i] = -prob.y[i];
                y[i] = 1;

                linear_term[i + l] = prob.y[i];
                y[i + l] = -1;
            }

            var s = new Solver_NU();
            s.Solve(2 * l, new SVR_Q(prob, param), linear_term, y, alpha2, C, C, param.eps, si, param.shrinking);

            //Console.Out.Write("epsilon = " + (- si.r) + "\n");

            for (i = 0; i < l; i++)
                alpha[i] = alpha2[i] - alpha2[i + l];
        }

        //
        // decision_function
        //
        internal class decision_function
        {
            internal double[] alpha;
            internal double rho;
        }
        public class SupportClass
        {
            /// <summary>
            /// Provides access to a static System.Random class instance
            /// </summary>
            public static Random Random = new Random();

            /*******************************/

            #region Nested type: Tokenizer

            /// <summary>
            /// The class performs token processing in strings
            /// </summary>
            public class Tokenizer : IEnumerator
            {
                /// Char representation of the String to tokenize.
                private readonly char[] chars;

                /// Include demiliters in the results.
                private readonly bool includeDelims;

                /// Position over the string
                private long currentPos;

                //The tokenizer uses the default delimiter set: the space character, the tab character, the newline character, and the carriage-return character and the form-feed character
                private string delimiters = " \t\n\r\f";

                /// <summary>
                /// Initializes a new class instance with a specified string to process
                /// </summary>
                /// <param name="source">String to tokenize</param>
                public Tokenizer(String source)
                {
                    chars = source.ToCharArray();
                }

                /// <summary>
                /// Initializes a new class instance with a specified string to process
                /// and the specified token delimiters to use
                /// </summary>
                /// <param name="source">String to tokenize</param>
                /// <param name="delimiters">String containing the delimiters</param>
                public Tokenizer(String source, String delimiters)
                    : this(source)
                {
                    this.delimiters = delimiters;
                }


                /// <summary>
                /// Initializes a new class instance with a specified string to process, the specified token 
                /// delimiters to use, and whether the delimiters must be included in the results.
                /// </summary>
                /// <param name="source">String to tokenize</param>
                /// <param name="delimiters">String containing the delimiters</param>
                /// <param name="includeDelims">Determines if delimiters are included in the results.</param>
                public Tokenizer(String source, String delimiters, bool includeDelims)
                    : this(source, delimiters)
                {
                    this.includeDelims = includeDelims;
                }


                /// <summary>
                /// Remaining tokens count
                /// </summary>
                public int Count
                {
                    get
                    {
                        //keeping the current pos
                        long pos = currentPos;
                        int i = 0;

                        try
                        {
                            while (true)
                            {
                                NextToken();
                                i++;
                            }
                        }
                        catch (ArgumentOutOfRangeException)
                        {
                            currentPos = pos;
                            return i;
                        }
                    }
                }

                #region IEnumerator Members

                /// <summary>
                ///  Performs the same action as NextToken.
                /// </summary>
                public Object Current
                {
                    get { return NextToken(); }
                }

                /// <summary>
                ///  Performs the same action as HasMoreTokens.
                /// </summary>
                /// <returns>True or false, depending if there are more tokens</returns>
                public bool MoveNext()
                {
                    return HasMoreTokens();
                }

                /// <summary>
                /// Does nothing.
                /// </summary>
                public void Reset()
                {
                    ;
                }

                #endregion

                /// <summary>
                /// Returns the next token from the token list
                /// </summary>
                /// <returns>The string value of the token</returns>
                public String NextToken()
                {
                    return NextToken(delimiters);
                }

                /// <summary>
                /// Returns the next token from the source string, using the provided
                /// token delimiters
                /// </summary>
                /// <param name="delimiters">String containing the delimiters to use</param>
                /// <returns>The string value of the token</returns>
                public String NextToken(String delimiters)
                {
                    //According to documentation, the usage of the received delimiters should be temporary (only for this call).
                    //However, it seems it is not true, so the following line is necessary.
                    this.delimiters = delimiters;

                    //at the end 
                    if (currentPos == chars.Length)
                        throw new ArgumentOutOfRangeException();
                    //if over a delimiter and delimiters must be returned
                    else if ((Array.IndexOf(delimiters.ToCharArray(), chars[currentPos]) != -1)
                             && includeDelims)
                        return "" + chars[currentPos++];
                    //need to get the token wo delimiters.
                    else
                        return nextToken(delimiters.ToCharArray());
                }

                //Returns the nextToken wo delimiters
                private String nextToken(char[] delimiters)
                {
                    string token = "";
                    long pos = currentPos;

                    //skip possible delimiters
                    while (Array.IndexOf(delimiters, chars[currentPos]) != -1)
                        //The last one is a delimiter (i.e there is no more tokens)
                        if (++currentPos == chars.Length)
                        {
                            currentPos = pos;
                            throw new ArgumentOutOfRangeException();
                        }

                    //getting the token
                    while (Array.IndexOf(delimiters, chars[currentPos]) == -1)
                    {
                        token += chars[currentPos];
                        //the last one is not a delimiter
                        if (++currentPos == chars.Length)
                            break;
                    }
                    return token;
                }


                /// <summary>
                /// Determines if there are more tokens to return from the source string
                /// </summary>
                /// <returns>True or false, depending if there are more tokens</returns>
                public bool HasMoreTokens()
                {
                    //keeping the current pos
                    long pos = currentPos;

                    try
                    {
                        NextToken();
                    }
                    catch (ArgumentOutOfRangeException)
                    {
                        return false;
                    }
                    finally
                    {
                        currentPos = pos;
                    }
                    return true;
                }
            }

            #endregion
        }

        internal static decision_function svm_train_one(svm_problem prob, svm_parameter param, double Cp, double Cn)
        {
            var alpha = new double[prob.l];
            var si = new Solver.SolutionInfo();
            switch (param.svm_type)
            {
                case svm_parameter.C_SVC:
                    solve_c_svc(prob, param, alpha, si, Cp, Cn);
                    break;

                case svm_parameter.NU_SVC:
                    solve_nu_svc(prob, param, alpha, si);
                    break;

                case svm_parameter.ONE_CLASS:
                    solve_one_class(prob, param, alpha, si);
                    break;

                case svm_parameter.EPSILON_SVR:
                    solve_epsilon_svr(prob, param, alpha, si);
                    break;

                case svm_parameter.NU_SVR:
                    solve_nu_svr(prob, param, alpha, si);
                    break;
            }

            //Console.Out.Write("obj = " + si.obj + ", rho = " + si.rho + "\n");

            // output SVs

            int nSV = 0;
            int nBSV = 0;
            for (int i = 0; i < prob.l; i++)
            {
                if (Math.Abs(alpha[i]) > 0)
                {
                    ++nSV;
                    if (prob.y[i] > 0)
                    {
                        if (Math.Abs(alpha[i]) >= si.upper_bound_p)
                            ++nBSV;
                    }
                    else
                    {
                        if (Math.Abs(alpha[i]) >= si.upper_bound_n)
                            ++nBSV;
                    }
                }
            }

            //Console.Out.Write("nSV = " + nSV + ", nBSV = " + nBSV + "\n");

            var f = new decision_function();
            f.alpha = alpha;
            f.rho = si.rho;
            return f;
        }

        // Platt's binary SVM Probablistic Output: an improvement from Lin et al.
        private static void sigmoid_train(int l, double[] dec_values, double[] labels, double[] probAB)
        {
            double A, B;
            double prior1 = 0, prior0 = 0;
            int i;

            for (i = 0; i < l; i++)
                if (labels[i] > 0)
                    prior1 += 1;
                else
                    prior0 += 1;

            int max_iter = 100; // Maximal number of iterations
            double min_step = 1e-10; // Minimal step taken in line search
            double sigma = 1e-3; // For numerically strict PD of Hessian
            double eps = 1e-5;
            double hiTarget = (prior1 + 1.0) / (prior1 + 2.0);
            double loTarget = 1 / (prior0 + 2.0);
            var t = new double[l];
            double fApB, p, q, h11, h22, h21, g1, g2, det, dA, dB, gd, stepsize;
            double newA, newB, newf, d1, d2;
            int iter;

            // Initial Point and Initial Fun Value
            A = 0.0;
            B = Math.Log((prior0 + 1.0) / (prior1 + 1.0));
            double fval = 0.0;

            for (i = 0; i < l; i++)
            {
                if (labels[i] > 0)
                    t[i] = hiTarget;
                else
                    t[i] = loTarget;
                fApB = dec_values[i] * A + B;
                if (fApB >= 0)
                    fval += t[i] * fApB + Math.Log(1 + Math.Exp(-fApB));
                else
                    fval += (t[i] - 1) * fApB + Math.Log(1 + Math.Exp(fApB));
            }
            for (iter = 0; iter < max_iter; iter++)
            {
                // Update Gradient and Hessian (use H' = H + sigma I)
                h11 = sigma; // numerically ensures strict PD
                h22 = sigma;
                h21 = 0.0;
                g1 = 0.0;
                g2 = 0.0;
                for (i = 0; i < l; i++)
                {
                    fApB = dec_values[i] * A + B;
                    if (fApB >= 0)
                    {
                        p = Math.Exp(-fApB) / (1.0 + Math.Exp(-fApB));
                        q = 1.0 / (1.0 + Math.Exp(-fApB));
                    }
                    else
                    {
                        p = 1.0 / (1.0 + Math.Exp(fApB));
                        q = Math.Exp(fApB) / (1.0 + Math.Exp(fApB));
                    }
                    d2 = p * q;
                    h11 += dec_values[i] * dec_values[i] * d2;
                    h22 += d2;
                    h21 += dec_values[i] * d2;
                    d1 = t[i] - p;
                    g1 += dec_values[i] * d1;
                    g2 += d1;
                }

                // Stopping Criteria
                if (Math.Abs(g1) < eps && Math.Abs(g2) < eps)
                    break;

                // Finding Newton direction: -inv(H') * g
                det = h11 * h22 - h21 * h21;
                dA = (-(h22 * g1 - h21 * g2)) / det;
                dB = (-((-h21) * g1 + h11 * g2)) / det;
                gd = g1 * dA + g2 * dB;


                stepsize = 1; // Line Search
                while (stepsize >= min_step)
                {
                    newA = A + stepsize * dA;
                    newB = B + stepsize * dB;

                    // New function value
                    newf = 0.0;
                    for (i = 0; i < l; i++)
                    {
                        fApB = dec_values[i] * newA + newB;
                        if (fApB >= 0)
                            newf += t[i] * fApB + Math.Log(1 + Math.Exp(-fApB));
                        else
                            newf += (t[i] - 1) * fApB + Math.Log(1 + Math.Exp(fApB));
                    }
                    // Check sufficient decrease
                    if (newf < fval + 0.0001 * stepsize * gd)
                    {
                        A = newA;
                        B = newB;
                        fval = newf;
                        break;
                    }
                    else
                        stepsize = stepsize / 2.0;
                }

                if (stepsize < min_step)
                {
                    //Console.Error.Write("Line search fails in two-class probability estimates\n");
                    break;
                }
            }

            /*if (iter >= max_iter)
                Console.Error.Write("Reaching maximal iterations in two-class probability estimates\n");*/
            probAB[0] = A;
            probAB[1] = B;
        }

        private static double sigmoid_predict(double decision_value, double A, double B)
        {
            double fApB = decision_value * A + B;
            if (fApB >= 0)
                return Math.Exp(-fApB) / (1.0 + Math.Exp(-fApB));
            else
                return 1.0 / (1 + Math.Exp(fApB));
        }

        // Method 2 from the multiclass_prob paper by Wu, Lin, and Weng
        private static void multiclass_probability(int k, double[][] r, double[] p)
        {
            int t;
            int iter = 0, max_iter = 100;
            var Q = new double[k][];
            for (int i = 0; i < k; i++)
            {
                Q[i] = new double[k];
            }
            var Qp = new double[k];
            double pQp, eps = 0.001;

            for (t = 0; t < k; t++)
            {
                p[t] = 1.0 / k; // Valid if k = 1
                Q[t][t] = 0;
                for (int j = 0; j < t; j++)
                {
                    Q[t][t] += r[j][t] * r[j][t];
                    Q[t][j] = Q[j][t];
                }
                for (int j = t + 1; j < k; j++)
                {
                    Q[t][t] += r[j][t] * r[j][t];
                    Q[t][j] = (-r[j][t]) * r[t][j];
                }
            }
            for (iter = 0; iter < max_iter; iter++)
            {
                // stopping condition, recalculate QP,pQP for numerical accuracy
                pQp = 0;
                for (t = 0; t < k; t++)
                {
                    Qp[t] = 0;
                    for (int j = 0; j < k; j++)
                        Qp[t] += Q[t][j] * p[j];
                    pQp += p[t] * Qp[t];
                }
                double max_error = 0;
                for (t = 0; t < k; t++)
                {
                    double error = Math.Abs(Qp[t] - pQp);
                    if (error > max_error)
                        max_error = error;
                }
                if (max_error < eps)
                    break;

                for (t = 0; t < k; t++)
                {
                    double diff = (-Qp[t] + pQp) / Q[t][t];
                    p[t] += diff;
                    pQp = (pQp + diff * (diff * Q[t][t] + 2 * Qp[t])) / (1 + diff) / (1 + diff);
                    for (int j = 0; j < k; j++)
                    {
                        Qp[j] = (Qp[j] + diff * Q[t][j]) / (1 + diff);
                        p[j] /= (1 + diff);
                    }
                }
            }
            /*if (iter >= max_iter)
                Console.Error.Write("Exceeds max_iter in multiclass_prob\n");*/
        }

        // Cross-validation decision values for probability estimates
        private static void svm_binary_svc_probability(svm_problem prob, svm_parameter param, double Cp, double Cn,
                                                       double[] probAB)
        {
            int i;
            int nr_fold = 5;
            var perm = new int[prob.l];
            var dec_values = new double[prob.l];

            // random shuffle
            for (i = 0; i < prob.l; i++)
                perm[i] = i;
            for (i = 0; i < prob.l; i++)
            {
                //UPGRADE_WARNING: Data types in Visual C# might be different.  Verify the accuracy of narrowing conversions. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1042_3"'
                int j = i + (int)(SupportClass.Random.NextDouble() * (prob.l - i));
                do
                {
                    int _ = perm[i];
                    perm[i] = perm[j];
                    perm[j] = _;
                } while (false);
            }
            for (i = 0; i < nr_fold; i++)
            {
                int begin = i * prob.l / nr_fold;
                int end = (i + 1) * prob.l / nr_fold;
                int j, k;
                var subprob = new svm_problem();

                subprob.l = prob.l - (end - begin);
                subprob.x = new svm_node[subprob.l][];
                subprob.y = new double[subprob.l];

                k = 0;
                for (j = 0; j < begin; j++)
                {
                    subprob.x[k] = prob.x[perm[j]];
                    subprob.y[k] = prob.y[perm[j]];
                    ++k;
                }
                for (j = end; j < prob.l; j++)
                {
                    subprob.x[k] = prob.x[perm[j]];
                    subprob.y[k] = prob.y[perm[j]];
                    ++k;
                }
                int p_count = 0, n_count = 0;
                for (j = 0; j < k; j++)
                    if (subprob.y[j] > 0)
                        p_count++;
                    else
                        n_count++;

                if (p_count == 0 && n_count == 0)
                    for (j = begin; j < end; j++)
                        dec_values[perm[j]] = 0;
                else if (p_count > 0 && n_count == 0)
                    for (j = begin; j < end; j++)
                        dec_values[perm[j]] = 1;
                else if (p_count == 0 && n_count > 0)
                    for (j = begin; j < end; j++)
                        dec_values[perm[j]] = -1;
                else
                {
                    var subparam = (svm_parameter)param.Clone();
                    subparam.probability = 0;
                    subparam.C = 1.0;
                    subparam.nr_weight = 2;
                    subparam.weight_label = new int[2];
                    subparam.weight = new double[2];
                    subparam.weight_label[0] = +1;
                    subparam.weight_label[1] = -1;
                    subparam.weight[0] = Cp;
                    subparam.weight[1] = Cn;
                    svm_model submodel = svm_train(subprob, subparam);
                    for (j = begin; j < end; j++)
                    {
                        var dec_value = new double[1];
                        svm_predict_values(submodel, prob.x[perm[j]], dec_value);
                        dec_values[perm[j]] = dec_value[0];
                        // ensure +1 -1 order; reason not using CV subroutine
                        dec_values[perm[j]] *= submodel.label[0];
                    }
                }
            }
            sigmoid_train(prob.l, dec_values, prob.y, probAB);
        }

        // Return parameter of a Laplace distribution 
        private static double svm_svr_probability(svm_problem prob, svm_parameter param)
        {
            int i;
            int nr_fold = 5;
            var ymv = new double[prob.l];
            double mae = 0;

            var newparam = (svm_parameter)param.Clone();
            newparam.probability = 0;
            svm_cross_validation(prob, newparam, nr_fold, ymv);
            for (i = 0; i < prob.l; i++)
            {
                ymv[i] = prob.y[i] - ymv[i];
                mae += Math.Abs(ymv[i]);
            }
            mae /= prob.l;
            double std = Math.Sqrt(2 * mae * mae);
            int count = 0;
            mae = 0;
            for (i = 0; i < prob.l; i++)
                if (Math.Abs(ymv[i]) > 5 * std)
                    count = count + 1;
                else
                    mae += Math.Abs(ymv[i]);
            mae /= (prob.l - count);
            /*Console.Error.Write(
                "Prob. model for test data: target value = predicted value + z,\nz: Laplace distribution e^(-|z|/sigma)/(2sigma),sigma=" +
                mae + "\n");*/
            return mae;
        }

        //
        // Interface functions
        //
        public static svm_model svm_train(svm_problem prob, svm_parameter param)
        {
            var model = new svm_model();
            model.param = param;

            if (param.svm_type == svm_parameter.ONE_CLASS || param.svm_type == svm_parameter.EPSILON_SVR ||
                param.svm_type == svm_parameter.NU_SVR)
            {
                // regression or one-class-svm
                model.nr_class = 2;
                model.label = null;
                model.nSV = null;
                model.probA = null;
                model.probB = null;
                model.sv_coef = new double[1][];

                if (param.probability == 1 &&
                    (param.svm_type == svm_parameter.EPSILON_SVR || param.svm_type == svm_parameter.NU_SVR))
                {
                    model.probA = new double[1];
                    model.probA[0] = svm_svr_probability(prob, param);
                }

                decision_function f = svm_train_one(prob, param, 0, 0);
                model.rho = new double[1];
                model.rho[0] = f.rho;

                int nSV = 0;
                int i;
                for (i = 0; i < prob.l; i++)
                    if (Math.Abs(f.alpha[i]) > 0)
                        ++nSV;
                model.l = nSV;
                model.SV = new svm_node[nSV][];
                model.sv_coef[0] = new double[nSV];
                int j = 0;
                for (i = 0; i < prob.l; i++)
                    if (Math.Abs(f.alpha[i]) > 0)
                    {
                        model.SV[j] = prob.x[i];
                        model.sv_coef[0][j] = f.alpha[i];
                        ++j;
                    }
            }
            else
            {
                // classification
                // find out the number of classes
                int l = prob.l;
                int max_nr_class = 16;
                int nr_class = 0;
                var label = new int[max_nr_class];
                var count = new int[max_nr_class];
                var index = new int[l];

                int i;
                for (i = 0; i < l; i++)
                {
                    //UPGRADE_WARNING: Data types in Visual C# might be different.  Verify the accuracy of narrowing conversions. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1042_3"'
                    var this_label = (int)prob.y[i];
                    int j;
                    for (j = 0; j < nr_class; j++)
                        if (this_label == label[j])
                        {
                            ++count[j];
                            break;
                        }
                    index[i] = j;
                    if (j == nr_class)
                    {
                        if (nr_class == max_nr_class)
                        {
                            max_nr_class *= 2;
                            var new_data = new int[max_nr_class];
                            Array.Copy(label, 0, new_data, 0, label.Length);
                            label = new_data;

                            new_data = new int[max_nr_class];
                            Array.Copy(count, 0, new_data, 0, count.Length);
                            count = new_data;
                        }
                        label[nr_class] = this_label;
                        count[nr_class] = 1;
                        ++nr_class;
                    }
                }

                // group training data of the same class

                var start = new int[nr_class];
                start[0] = 0;
                for (i = 1; i < nr_class; i++)
                    start[i] = start[i - 1] + count[i - 1];

                var x = new svm_node[l][];

                for (i = 0; i < l; i++)
                {
                    x[start[index[i]]] = prob.x[i];
                    ++start[index[i]];
                }

                start[0] = 0;
                for (i = 1; i < nr_class; i++)
                    start[i] = start[i - 1] + count[i - 1];

                // calculate weighted C

                var weighted_C = new double[nr_class];
                for (i = 0; i < nr_class; i++)
                    weighted_C[i] = param.C;
                for (i = 0; i < param.nr_weight; i++)
                {
                    int j;
                    for (j = 0; j < nr_class; j++)
                        if (param.weight_label[i] == label[j])
                            break;
                    if (j == nr_class) ;
                    /*Console.Error.Write("warning: class label " + param.weight_label[i] +
                                        " specified in weight is not found\n");*/
                    else
                        weighted_C[j] *= param.weight[i];
                }

                // train k*(k-1)/2 models

                var nonzero = new bool[l];
                for (i = 0; i < l; i++)
                    nonzero[i] = false;
                var f = new decision_function[nr_class * (nr_class - 1) / 2];

                double[] probA = null, probB = null;
                if (param.probability == 1)
                {
                    probA = new double[nr_class * (nr_class - 1) / 2];
                    probB = new double[nr_class * (nr_class - 1) / 2];
                }

                int p = 0;
                for (i = 0; i < nr_class; i++)
                    for (int j = i + 1; j < nr_class; j++)
                    {
                        var sub_prob = new svm_problem();
                        int si = start[i], sj = start[j];
                        int ci = count[i], cj = count[j];
                        sub_prob.l = ci + cj;
                        sub_prob.x = new svm_node[sub_prob.l][];
                        sub_prob.y = new double[sub_prob.l];
                        int k;
                        for (k = 0; k < ci; k++)
                        {
                            sub_prob.x[k] = x[si + k];
                            sub_prob.y[k] = +1;
                        }
                        for (k = 0; k < cj; k++)
                        {
                            sub_prob.x[ci + k] = x[sj + k];
                            sub_prob.y[ci + k] = -1;
                        }

                        if (param.probability == 1)
                        {
                            var probAB = new double[2];
                            svm_binary_svc_probability(sub_prob, param, weighted_C[i], weighted_C[j], probAB);
                            probA[p] = probAB[0];
                            probB[p] = probAB[1];
                        }

                        f[p] = svm_train_one(sub_prob, param, weighted_C[i], weighted_C[j]);
                        for (k = 0; k < ci; k++)
                            if (!nonzero[si + k] && Math.Abs(f[p].alpha[k]) > 0)
                                nonzero[si + k] = true;
                        for (k = 0; k < cj; k++)
                            if (!nonzero[sj + k] && Math.Abs(f[p].alpha[ci + k]) > 0)
                                nonzero[sj + k] = true;
                        ++p;
                    }

                // build output

                model.nr_class = nr_class;

                model.label = new int[nr_class];
                for (i = 0; i < nr_class; i++)
                    model.label[i] = label[i];

                model.rho = new double[nr_class * (nr_class - 1) / 2];
                for (i = 0; i < nr_class * (nr_class - 1) / 2; i++)
                    model.rho[i] = f[i].rho;

                if (param.probability == 1)
                {
                    model.probA = new double[nr_class * (nr_class - 1) / 2];
                    model.probB = new double[nr_class * (nr_class - 1) / 2];
                    for (i = 0; i < nr_class * (nr_class - 1) / 2; i++)
                    {
                        model.probA[i] = probA[i];
                        model.probB[i] = probB[i];
                    }
                }
                else
                {
                    model.probA = null;
                    model.probB = null;
                }

                int nnz = 0;
                var nz_count = new int[nr_class];
                model.nSV = new int[nr_class];
                for (i = 0; i < nr_class; i++)
                {
                    int nSV = 0;
                    for (int j = 0; j < count[i]; j++)
                        if (nonzero[start[i] + j])
                        {
                            ++nSV;
                            ++nnz;
                        }
                    model.nSV[i] = nSV;
                    nz_count[i] = nSV;
                }

                //Console.Out.Write("Total nSV = " + nnz + "\n");

                model.l = nnz;
                model.SV = new svm_node[nnz][];
                p = 0;
                for (i = 0; i < l; i++)
                    if (nonzero[i])
                        model.SV[p++] = x[i];

                var nz_start = new int[nr_class];
                nz_start[0] = 0;
                for (i = 1; i < nr_class; i++)
                    nz_start[i] = nz_start[i - 1] + nz_count[i - 1];

                model.sv_coef = new double[nr_class - 1][];
                for (i = 0; i < nr_class - 1; i++)
                    model.sv_coef[i] = new double[nnz];

                p = 0;
                for (i = 0; i < nr_class; i++)
                    for (int j = i + 1; j < nr_class; j++)
                    {
                        // classifier (i,j): coefficients with
                        // i are in sv_coef[j-1][nz_start[i]...],
                        // j are in sv_coef[i][nz_start[j]...]

                        int si = start[i];
                        int sj = start[j];
                        int ci = count[i];
                        int cj = count[j];

                        int q = nz_start[i];
                        int k;
                        for (k = 0; k < ci; k++)
                            if (nonzero[si + k])
                                model.sv_coef[j - 1][q++] = f[p].alpha[k];
                        q = nz_start[j];
                        for (k = 0; k < cj; k++)
                            if (nonzero[sj + k])
                                model.sv_coef[i][q++] = f[p].alpha[ci + k];
                        ++p;
                    }
            }
            return model;
        }

        public static void svm_cross_validation(svm_problem prob, svm_parameter param, int nr_fold, double[] target)
        {
            int i;
            var perm = new int[prob.l];

            // random shuffle
            for (i = 0; i < prob.l; i++)
                perm[i] = i;
            for (i = 0; i < prob.l; i++)
            {
                //UPGRADE_WARNING: Data types in Visual C# might be different.  Verify the accuracy of narrowing conversions. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1042_3"'
                int j = i + (int)(SupportClass.Random.NextDouble() * (prob.l - i));
                do
                {
                    int _ = perm[i];
                    perm[i] = perm[j];
                    perm[j] = _;
                } while (false);
            }
            for (i = 0; i < nr_fold; i++)
            {
                int begin = i * prob.l / nr_fold;
                int end = (i + 1) * prob.l / nr_fold;
                int j, k;
                var subprob = new svm_problem();

                subprob.l = prob.l - (end - begin);
                subprob.x = new svm_node[subprob.l][];
                subprob.y = new double[subprob.l];

                k = 0;
                for (j = 0; j < begin; j++)
                {
                    subprob.x[k] = prob.x[perm[j]];
                    subprob.y[k] = prob.y[perm[j]];
                    ++k;
                }
                for (j = end; j < prob.l; j++)
                {
                    subprob.x[k] = prob.x[perm[j]];
                    subprob.y[k] = prob.y[perm[j]];
                    ++k;
                }
                svm_model submodel = svm_train(subprob, param);
                if (param.probability == 1 &&
                    (param.svm_type == svm_parameter.C_SVC || param.svm_type == svm_parameter.NU_SVC))
                {
                    var prob_estimates = new double[svm_get_nr_class(submodel)];
                    for (j = begin; j < end; j++)
                        target[perm[j]] = svm_predict_probability(submodel, prob.x[perm[j]], prob_estimates);
                }
                else
                    for (j = begin; j < end; j++)
                        target[perm[j]] = svm_predict(submodel, prob.x[perm[j]]);
            }
        }

        public static int svm_get_svm_type(svm_model model)
        {
            return model.param.svm_type;
        }

        public static int svm_get_nr_class(svm_model model)
        {
            return model.nr_class;
        }

        public static void svm_get_labels(svm_model model, int[] label)
        {
            if (model.label != null)
                for (int i = 0; i < model.nr_class; i++)
                    label[i] = model.label[i];
        }

        public static double svm_get_svr_probability(svm_model model)
        {
            if ((model.param.svm_type == svm_parameter.EPSILON_SVR || model.param.svm_type == svm_parameter.NU_SVR) &&
                model.probA != null)
                return model.probA[0];
            else
            {
                //Console.Error.Write("Model doesn't contain information for SVR probability inference\n");
                return 0;
            }
        }

        public static void svm_predict_values(svm_model model, svm_node[] x, double[] dec_values)
        {
            if (model.param.svm_type == svm_parameter.ONE_CLASS || model.param.svm_type == svm_parameter.EPSILON_SVR ||
                model.param.svm_type == svm_parameter.NU_SVR)
            {
                double[] sv_coef = model.sv_coef[0];
                double sum = 0;
                for (int i = 0; i < model.l; i++)
                    sum += sv_coef[i] * Kernel.k_function(x, model.SV[i], model.param);
                sum -= model.rho[0];
                dec_values[0] = sum;
            }
            else
            {
                int i;
                int nr_class = model.nr_class;
                int l = model.l;

                var kvalue = new double[l];
                for (i = 0; i < l; i++)
                    kvalue[i] = Kernel.k_function(x, model.SV[i], model.param);

                var start = new int[nr_class];
                start[0] = 0;
                for (i = 1; i < nr_class; i++)
                    start[i] = start[i - 1] + model.nSV[i - 1];

                int p = 0;
                int pos = 0;
                for (i = 0; i < nr_class; i++)
                    for (int j = i + 1; j < nr_class; j++)
                    {
                        double sum = 0;
                        int si = start[i];
                        int sj = start[j];
                        int ci = model.nSV[i];
                        int cj = model.nSV[j];

                        int k;
                        double[] coef1 = model.sv_coef[j - 1];
                        double[] coef2 = model.sv_coef[i];
                        for (k = 0; k < ci; k++)
                            sum += coef1[si + k] * kvalue[si + k];
                        for (k = 0; k < cj; k++)
                            sum += coef2[sj + k] * kvalue[sj + k];
                        sum -= model.rho[p++];
                        dec_values[pos++] = sum;
                    }
            }
        }

        public static double svm_predict(svm_model model, svm_node[] x)
        {
            if (model.param.svm_type == svm_parameter.ONE_CLASS || model.param.svm_type == svm_parameter.EPSILON_SVR ||
                model.param.svm_type == svm_parameter.NU_SVR)
            {
                var res = new double[1];
                svm_predict_values(model, x, res);

                if (model.param.svm_type == svm_parameter.ONE_CLASS)
                    return (res[0] > 0) ? 1 : -1;
                else
                    return res[0];
            }
            else
            {
                int i;
                int nr_class = model.nr_class;
                var dec_values = new double[nr_class * (nr_class - 1) / 2];
                svm_predict_values(model, x, dec_values);

                var vote = new int[nr_class];
                for (i = 0; i < nr_class; i++)
                    vote[i] = 0;
                int pos = 0;
                for (i = 0; i < nr_class; i++)
                    for (int j = i + 1; j < nr_class; j++)
                    {
                        if (dec_values[pos++] > 0)
                            ++vote[i];
                        else
                            ++vote[j];
                    }

                int vote_max_idx = 0;
                for (i = 1; i < nr_class; i++)
                    if (vote[i] > vote[vote_max_idx])
                        vote_max_idx = i;
                return model.label[vote_max_idx];
            }
        }

        public static double svm_predict_probability(svm_model model, svm_node[] x, double[] prob_estimates)
        {
            if ((model.param.svm_type == svm_parameter.C_SVC || model.param.svm_type == svm_parameter.NU_SVC) &&
                model.probA != null && model.probB != null)
            {
                int i;
                int nr_class = model.nr_class;
                var dec_values = new double[nr_class * (nr_class - 1) / 2];
                svm_predict_values(model, x, dec_values);

                double min_prob = 1e-7;
                var tmpArray = new double[nr_class][];
                for (int i2 = 0; i2 < nr_class; i2++)
                {
                    tmpArray[i2] = new double[nr_class];
                }
                double[][] pairwise_prob = tmpArray;

                int k = 0;
                for (i = 0; i < nr_class; i++)
                    for (int j = i + 1; j < nr_class; j++)
                    {
                        pairwise_prob[i][j] =
                            Math.Min(
                                Math.Max(sigmoid_predict(dec_values[k], model.probA[k], model.probB[k]), min_prob),
                                1 - min_prob);
                        pairwise_prob[j][i] = 1 - pairwise_prob[i][j];
                        k++;
                    }
                multiclass_probability(nr_class, pairwise_prob, prob_estimates);

                int prob_max_idx = 0;
                for (i = 1; i < nr_class; i++)
                    if (prob_estimates[i] > prob_estimates[prob_max_idx])
                        prob_max_idx = i;
                return model.label[prob_max_idx];
            }
            else
                return svm_predict(model, x);
        }

        //UPGRADE_NOTE: Final was removed from the declaration of 'svm_type_table'. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1003_3"'
        internal static readonly String[] svm_type_table = new[]
                                                               {"c_svc", "nu_svc", "one_class", "epsilon_svr", "nu_svr"};

        //UPGRADE_NOTE: Final was removed from the declaration of 'kernel_type_table'. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1003_3"'
        internal static readonly String[] kernel_type_table = new[] { "linear", "polynomial", "rbf", "sigmoid" };

        public static void svm_save_model(StreamWriter fp, svm_model model)
        {
            svm_parameter param = model.param;

            fp.Write("svm_type " + svm_type_table[param.svm_type] + "\n");
            fp.Write("kernel_type " + kernel_type_table[param.kernel_type] + "\n");

            if (param.kernel_type == svm_parameter.POLY)
                fp.Write("degree " + param.degree + "\n");

            if (param.kernel_type == svm_parameter.POLY || param.kernel_type == svm_parameter.RBF ||
                param.kernel_type == svm_parameter.SIGMOID)
                fp.Write("gamma " + param.gamma + "\n");

            if (param.kernel_type == svm_parameter.POLY || param.kernel_type == svm_parameter.SIGMOID)
                fp.Write("coef0 " + param.coef0 + "\n");

            int nr_class = model.nr_class;
            int l = model.l;
            fp.Write("nr_class " + nr_class + "\n");
            fp.Write("total_sv " + l + "\n");

            {
                fp.Write("rho");
                for (int i = 0; i < nr_class * (nr_class - 1) / 2; i++)
                    fp.Write(" " + model.rho[i]);
                fp.Write("\n");
            }

            if (model.label != null)
            {
                fp.Write("label");
                for (int i = 0; i < nr_class; i++)
                    fp.Write(" " + model.label[i]);
                fp.Write("\n");
            }

            if (model.probA != null)
            // regression has probA only
            {
                fp.Write("probA");
                for (int i = 0; i < nr_class * (nr_class - 1) / 2; i++)
                    fp.Write(" " + model.probA[i]);
                fp.Write("\n");
            }
            if (model.probB != null)
            {
                fp.Write("probB");
                for (int i = 0; i < nr_class * (nr_class - 1) / 2; i++)
                    fp.Write(" " + model.probB[i]);
                fp.Write("\n");
            }

            if (model.nSV != null)
            {
                fp.Write("nr_sv");
                for (int i = 0; i < nr_class; i++)
                    fp.Write(" " + model.nSV[i]);
                fp.Write("\n");
            }

            fp.Write("SV\n");
            double[][] sv_coef = model.sv_coef;
            svm_node[][] SV = model.SV;

            for (int i = 0; i < l; i++)
            {
                for (int j = 0; j < nr_class - 1; j++)
                    fp.Write(sv_coef[j][i] + " ");

                svm_node[] p = SV[i];
                for (int j = 0; j < p.Length; j++)
                    fp.Write(p[j].index + ":" + p[j].value_Renamed + " ");
                fp.Write("\n");
            }

            fp.Close();
        }

        private static double atof(String s)
        {
            return Double.Parse(s);
        }

        private static int atoi(String s)
        {
            return Int32.Parse(s);
        }

        public static svm_model svm_load_model(StringReader fp)
        {
            // read parameters

            var model = new svm_model();
            var param = new svm_parameter();
            model.param = param;
            model.rho = null;
            model.probA = null;
            model.probB = null;
            model.label = null;
            model.nSV = null;

            while (true)
            {
                String cmd = fp.ReadLine();
                String arg = cmd.Substring(cmd.IndexOf(' ') + 1);

                if (cmd.StartsWith("svm_type"))
                {
                    int i;
                    for (i = 0; i < svm_type_table.Length; i++)
                    {
                        if (arg.IndexOf(svm_type_table[i]) != -1)
                        {
                            param.svm_type = i;
                            break;
                        }
                    }
                    if (i == svm_type_table.Length)
                    {
                        //Console.Error.Write("unknown svm type.\n");
                        return null;
                    }
                }
                else if (cmd.StartsWith("kernel_type"))
                {
                    int i;
                    for (i = 0; i < kernel_type_table.Length; i++)
                    {
                        if (arg.IndexOf(kernel_type_table[i]) != -1)
                        {
                            param.kernel_type = i;
                            break;
                        }
                    }
                    if (i == kernel_type_table.Length)
                    {
                        //Console.Error.Write("unknown kernel function.\n");
                        return null;
                    }
                }
                else if (cmd.StartsWith("degree"))
                    param.degree = atof(arg);
                else if (cmd.StartsWith("gamma"))
                    param.gamma = atof(arg);
                else if (cmd.StartsWith("coef0"))
                    param.coef0 = atof(arg);
                else if (cmd.StartsWith("nr_class"))
                    model.nr_class = atoi(arg);
                else if (cmd.StartsWith("total_sv"))
                    model.l = atoi(arg);
                else if (cmd.StartsWith("rho"))
                {
                    int n = model.nr_class * (model.nr_class - 1) / 2;
                    model.rho = new double[n];
                    var st = new SupportClass.Tokenizer(arg);
                    for (int i = 0; i < n; i++)
                        model.rho[i] = atof(st.NextToken());
                }
                else if (cmd.StartsWith("label"))
                {
                    int n = model.nr_class;
                    model.label = new int[n];
                    var st = new SupportClass.Tokenizer(arg);
                    for (int i = 0; i < n; i++)
                        model.label[i] = atoi(st.NextToken());
                }
                else if (cmd.StartsWith("probA"))
                {
                    int n = model.nr_class * (model.nr_class - 1) / 2;
                    model.probA = new double[n];
                    var st = new SupportClass.Tokenizer(arg);
                    for (int i = 0; i < n; i++)
                        model.probA[i] = atof(st.NextToken());
                }
                else if (cmd.StartsWith("probB"))
                {
                    int n = model.nr_class * (model.nr_class - 1) / 2;
                    model.probB = new double[n];
                    var st = new SupportClass.Tokenizer(arg);
                    for (int i = 0; i < n; i++)
                        model.probB[i] = atof(st.NextToken());
                }
                else if (cmd.StartsWith("nr_sv"))
                {
                    int n = model.nr_class;
                    model.nSV = new int[n];
                    var st = new SupportClass.Tokenizer(arg);
                    for (int i = 0; i < n; i++)
                        model.nSV[i] = atoi(st.NextToken());
                }
                else if (cmd.StartsWith("SV"))
                {
                    break;
                }
                else
                {
                    //Console.Error.Write("unknown text in model file\n");
                    return null;
                }
            }

            // read sv_coef and SV

            int m = model.nr_class - 1;
            int l = model.l;
            model.sv_coef = new double[m][];
            for (int i = 0; i < m; i++)
            {
                model.sv_coef[i] = new double[l];
            }
            model.SV = new svm_node[l][];

            for (int i = 0; i < l; i++)
            {
                String line = fp.ReadLine();
                var st = new SupportClass.Tokenizer(line, " \t\n\r\f:");

                for (int k = 0; k < m; k++)
                    model.sv_coef[k][i] = atof(st.NextToken());
                int n = st.Count / 2;
                model.SV[i] = new svm_node[n];
                for (int j = 0; j < n; j++)
                {
                    model.SV[i][j] = new svm_node();
                    model.SV[i][j].index = atoi(st.NextToken());
                    model.SV[i][j].value_Renamed = atof(st.NextToken());
                }
            }

            return model;
        }

        public static String svm_check_parameter(svm_problem prob, svm_parameter param)
        {
            // svm_type

            int svm_type = param.svm_type;
            if (svm_type != svm_parameter.C_SVC && svm_type != svm_parameter.NU_SVC &&
                svm_type != svm_parameter.ONE_CLASS && svm_type != svm_parameter.EPSILON_SVR &&
                svm_type != svm_parameter.NU_SVR)
                return "unknown svm type";

            // kernel_type

            int kernel_type = param.kernel_type;
            if (kernel_type != svm_parameter.LINEAR && kernel_type != svm_parameter.POLY &&
                kernel_type != svm_parameter.RBF && kernel_type != svm_parameter.SIGMOID)
                return "unknown kernel type";

            // cache_size,eps,C,nu,p,shrinking

            if (param.cache_size <= 0)
                return "cache_size <= 0";

            if (param.eps <= 0)
                return "eps <= 0";

            if (svm_type == svm_parameter.C_SVC || svm_type == svm_parameter.EPSILON_SVR ||
                svm_type == svm_parameter.NU_SVR)
                if (param.C <= 0)
                    return "C <= 0";

            if (svm_type == svm_parameter.NU_SVC || svm_type == svm_parameter.ONE_CLASS ||
                svm_type == svm_parameter.NU_SVR)
                if (param.nu < 0 || param.nu > 1)
                    return "nu < 0 or nu > 1";

            if (svm_type == svm_parameter.EPSILON_SVR)
                if (param.p < 0)
                    return "p < 0";

            if (param.shrinking != 0 && param.shrinking != 1)
                return "shrinking != 0 and shrinking != 1";

            if (param.probability != 0 && param.probability != 1)
                return "probability != 0 and probability != 1";

            if (param.probability == 1 && svm_type == svm_parameter.ONE_CLASS)
                return "one-class SVM probability output not supported yet";

            // check whether nu-svc is feasible

            if (svm_type == svm_parameter.NU_SVC)
            {
                int l = prob.l;
                int max_nr_class = 16;
                int nr_class = 0;
                var label = new int[max_nr_class];
                var count = new int[max_nr_class];

                int i;
                for (i = 0; i < l; i++)
                {
                    //UPGRADE_WARNING: Data types in Visual C# might be different.  Verify the accuracy of narrowing conversions. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1042_3"'
                    var this_label = (int)prob.y[i];
                    int j;
                    for (j = 0; j < nr_class; j++)
                        if (this_label == label[j])
                        {
                            ++count[j];
                            break;
                        }

                    if (j == nr_class)
                    {
                        if (nr_class == max_nr_class)
                        {
                            max_nr_class *= 2;
                            var new_data = new int[max_nr_class];
                            Array.Copy(label, 0, new_data, 0, label.Length);
                            label = new_data;

                            new_data = new int[max_nr_class];
                            Array.Copy(count, 0, new_data, 0, count.Length);
                            count = new_data;
                        }
                        label[nr_class] = this_label;
                        count[nr_class] = 1;
                        ++nr_class;
                    }
                }

                for (i = 0; i < nr_class; i++)
                {
                    int n1 = count[i];
                    for (int j = i + 1; j < nr_class; j++)
                    {
                        int n2 = count[j];
                        if (param.nu * (n1 + n2) / 2 > Math.Min(n1, n2))
                            return "specified nu is infeasible";
                    }
                }
            }

            return null;
        }

        public static int svm_check_probability_model(svm_model model)
        {
            if (((model.param.svm_type == svm_parameter.C_SVC || model.param.svm_type == svm_parameter.NU_SVC) &&
                 model.probA != null && model.probB != null) ||
                ((model.param.svm_type == svm_parameter.EPSILON_SVR || model.param.svm_type == svm_parameter.NU_SVR) &&
                 model.probA != null))
                return 1;
            else
                return 0;
        }
    }

    [Serializable]
    public class SupportVectorMachine : BasicML, IMLRegression, IMLClassification,
                                     IMLError
    {
        /// <summary>
        /// The default degree.
        /// </summary>
        ///
        public const int DefaultDegree = 3;

        /// <summary>
        /// The default COEF0.
        /// </summary>
        ///
        public const int DefaultCoef0 = 0;

        /// <summary>
        /// The default NU.
        /// </summary>
        ///
        public const double DefaultNu = 0.5d;

        /// <summary>
        /// The default cache size.
        /// </summary>
        ///
        public const int DefaultCacheSize = 100;

        /// <summary>
        /// The default C.
        /// </summary>
        ///
        public const int DefaultC = 1;

        /// <summary>
        /// The default EPS.
        /// </summary>
        ///
        public const double DefaultEps = 1e-3d;

        /// <summary>
        /// The default P.
        /// </summary>
        ///
        public const double DefaultP = 0.1d;

        /// <summary>
        /// The params for the model.
        /// </summary>
        ///
        private readonly svm_parameter _paras;

        /// <summary>
        /// The input count.
        /// </summary>
        ///
        private int _inputCount;

        /// <summary>
        /// The SVM model to use.
        /// </summary>
        ///
        private svm_model _model;

        /// <summary>
        /// Construct the SVM.
        /// </summary>
        ///
        public SupportVectorMachine()
        {
            _paras = new svm_parameter();
        }

        /// <summary>
        /// Construct an SVM network. For regression it will use an epsilon support
        /// vector. Both types will use an RBF kernel.
        /// </summary>
        ///
        /// <param name="theInputCount">The input count.</param>
        /// <param name="regression">True if this network is used for regression.</param>
        public SupportVectorMachine(int theInputCount, bool regression)
            : this(
                theInputCount,
                (regression) ? SVMType.EpsilonSupportVectorRegression : SVMType.SupportVectorClassification,
                KernelType.RadialBasisFunction)
        {
        }

        /// <summary>
        /// Construct a SVM network.
        /// </summary>
        ///
        /// <param name="theInputCount">The input count.</param>
        /// <param name="svmType">The type of SVM.</param>
        /// <param name="kernelType">The SVM kernal type.</param>
        public SupportVectorMachine(int theInputCount, SVMType svmType,
                                    KernelType kernelType)
        {
            _inputCount = theInputCount;

            _paras = new svm_parameter();

            switch (svmType)
            {
                case SVMType.SupportVectorClassification:
                    _paras.svm_type = svm_parameter.C_SVC;
                    break;
                case SVMType.NewSupportVectorClassification:
                    _paras.svm_type = svm_parameter.NU_SVC;
                    break;
                case SVMType.SupportVectorOneClass:
                    _paras.svm_type = svm_parameter.ONE_CLASS;
                    break;
                case SVMType.EpsilonSupportVectorRegression:
                    _paras.svm_type = svm_parameter.EPSILON_SVR;
                    break;
                case SVMType.NewSupportVectorRegression:
                    _paras.svm_type = svm_parameter.NU_SVR;
                    break;
                default:
                    throw new NeuralNetworkError("Invalid svm type");
            }

            switch (kernelType)
            {
                case KernelType.Linear:
                    _paras.kernel_type = svm_parameter.LINEAR;
                    break;
                case KernelType.Poly:
                    _paras.kernel_type = svm_parameter.POLY;
                    break;
                case KernelType.RadialBasisFunction:
                    _paras.kernel_type = svm_parameter.RBF;
                    break;
                case KernelType.Sigmoid:
                    _paras.kernel_type = svm_parameter.SIGMOID;
                    break;
                /*case Synt.ML.SVM.KernelType.Precomputed:
            this.paras.kernel_type = Synt.MathUtil.LIBSVM.svm_parameter.PRECOMPUTED;
            break;*/
                default:
                    throw new NeuralNetworkError("Invalid kernel type");
            }

            // params[i].kernel_type = svm_parameter.RBF;
            _paras.degree = DefaultDegree;
            _paras.coef0 = 0;
            _paras.nu = DefaultNu;
            _paras.cache_size = DefaultCacheSize;
            _paras.C = 1;
            _paras.eps = DefaultEps;
            _paras.p = DefaultP;
            _paras.shrinking = 1;
            _paras.probability = 0;
            _paras.nr_weight = 0;
            _paras.weight_label = new int[0];
            _paras.weight = new double[0];
            _paras.gamma = 1.0d / _inputCount;
        }

        /// <summary>
        /// Construct a SVM from a model.
        /// </summary>
        ///
        /// <param name="theModel">The model.</param>
        public SupportVectorMachine(svm_model theModel)
        {
            _model = theModel;
            _paras = _model.param;
            _inputCount = 0;


            // determine the input count
            foreach (var element in _model.SV)
            {
                foreach (svm_node t in element)
                {
                    _inputCount = Math.Max(t.index, _inputCount);
                }
            }

            //
        }


        /// <value>The kernel type.</value>
        public KernelType KernelType
        {
            get
            {
                switch (_paras.kernel_type)
                {
                    case svm_parameter.LINEAR:
                        return KernelType.Linear;
                    case svm_parameter.POLY:
                        return KernelType.Poly;
                    case svm_parameter.RBF:
                        return KernelType.RadialBasisFunction;
                    case svm_parameter.SIGMOID:
                        return KernelType.Sigmoid;
                    /*                case Synt.MathUtil.LIBSVM.svm_parameter.PRECOMPUTED:
                                        return Synt.ML.SVM.KernelType.Precomputed;*/
                    default:
                        return default(KernelType) /* was: null */;
                }
            }
        }


        /// <summary>
        /// Set the model.
        /// </summary>
        public svm_model Model
        {
            get { return _model; }
            set { _model = value; }
        }


        /// <value>The SVM params for each of the outputs.</value>
        public svm_parameter Params
        {
            get { return _paras; }
        }


        /// <value>The SVM type.</value>
        public SVMType SVMType
        {
            get
            {
                switch (_paras.svm_type)
                {
                    case svm_parameter.C_SVC:
                        return SVMType.SupportVectorClassification;
                    case svm_parameter.NU_SVC:
                        return SVMType.NewSupportVectorClassification;
                    case svm_parameter.ONE_CLASS:
                        return SVMType.SupportVectorOneClass;
                    case svm_parameter.EPSILON_SVR:
                        return SVMType.EpsilonSupportVectorRegression;
                    case svm_parameter.NU_SVR:
                        return SVMType.NewSupportVectorRegression;
                    default:
                        return default(SVMType) /* was: null */;
                }
            }
        }

        #region MLClassification Members

        /// <inheritdoc/>
        public int Classify(IMLData input)
        {
            if (_model == null)
            {
                throw new SyntError(
                    "Can't use the SVM yet, it has not been trained, "
                    + "and no model exists.");
            }

            svm_node[] formattedInput = MakeSparse(input);
            return (int)svm.svm_predict(_model, formattedInput);
        }

        #endregion

        #region MLError Members

        /// <summary>
        /// Calculate the error for this SVM.
        /// </summary>
        ///
        /// <param name="data">The training set.</param>
        /// <returns>The error percentage.</returns>
        public double CalculateError(IMLDataSet data)
        {
            switch (SVMType)
            {
                case SVMType.SupportVectorClassification:
                case SVMType.NewSupportVectorClassification:
                case SVMType.SupportVectorOneClass:
                    return SyntUtility.CalculateClassificationError(this, data);
                case SVMType.EpsilonSupportVectorRegression:
                case SVMType.NewSupportVectorRegression:
                    return SyntUtility.CalculateRegressionError(this, data);
                default:
                    return SyntUtility.CalculateRegressionError(this, data);
            }
        }

        #endregion

        #region MLRegression Members

        /// <summary>
        /// Compute the output for the given input.
        /// </summary>
        ///
        /// <param name="input">The input to the SVM.</param>
        /// <returns>The results from the SVM.</returns>
        public IMLData Compute(IMLData input)
        {
            if (_model == null)
            {
                throw new SyntError(
                    "Can't use the SVM yet, it has not been trained, "
                    + "and no model exists.");
            }

            IMLData result = new BasicMLData(1);

            svm_node[] formattedInput = MakeSparse(input);

            double d = svm.svm_predict(_model, formattedInput);
            result[0] = d;

            return result;
        }

        /// <summary>
        /// Set the input count.
        /// </summary>
        ///
        /// <value>The new input count.</value>
        public int InputCount
        {
            get { return _inputCount; }
            set { _inputCount = value; }
        }

        /// <value>For a SVM, the output count is always one.</value>
        public int OutputCount
        {
            get { return 1; }
        }

        #endregion

        /// <summary>
        /// Convert regular Synt MLData into the "sparse" data needed by an SVM.
        /// </summary>
        ///
        /// <param name="data">The data to convert.</param>
        /// <returns>The SVM sparse data.</returns>
        public svm_node[] MakeSparse(IMLData data)
        {
            var result = new svm_node[data.Count];
            for (int i = 0; i < data.Count; i++)
            {
                result[i] = new svm_node { index = i + 1, value_Renamed = data[i] };
            }

            return result;
        }

        /// <summary>
        /// Not needed, no properties to update.
        /// </summary>
        ///
        public override void UpdateProperties()
        {
            // unneeded
        }
    }

    public class SVMPattern : INeuralNetworkPattern
    {
        /// <summary>
        /// The number of neurons in the first layer.
        /// </summary>
        ///
        private int _inputNeurons;

        /// <summary>
        /// The kernel type.
        /// </summary>
        ///
        private KernelType _kernelType;

        /// <summary>
        /// The number of neurons in the second layer.
        /// </summary>
        ///
        private int _outputNeurons;

        /// <summary>
        /// The SVM type.
        /// </summary>
        ///
        private SVMType _svmType;

        /// <summary>
        /// Construct the object.
        /// </summary>
        public SVMPattern()
        {
            Regression = true;
            _kernelType = KernelType.RadialBasisFunction;
            _svmType = SVMType.EpsilonSupportVectorRegression;
        }

        /// <summary>
        /// Set if regression is used.
        /// </summary>
        public bool Regression { get; set; }

        /// <summary>
        /// Set the kernel type.
        /// </summary>
        public KernelType KernelType
        {
            set { _kernelType = value; }
        }


        /// <summary>
        /// Set the SVM type.
        /// </summary>
        public SVMType SVMType
        {
            set { _svmType = value; }
        }

        #region NeuralNetworkPattern Members

        /// <summary>
        /// Unused, a BAM has no hidden layers.
        /// </summary>
        ///
        /// <param name="count">Not used.</param>
        public void AddHiddenLayer(int count)
        {
            throw new PatternError("A SVM network has no hidden layers.");
        }

        /// <summary>
        /// Clear any settings on the pattern.
        /// </summary>
        ///
        public void Clear()
        {
            _inputNeurons = 0;
            _outputNeurons = 0;
        }


        /// <returns>The generated network.</returns>
        public IMLMethod Generate()
        {
            if (_outputNeurons != 1)
            {
                throw new PatternError("A SVM may only have one output.");
            }
            var network = new SupportVectorMachine(_inputNeurons, _svmType,
                                                   _kernelType);
            return network;
        }

        /// <summary>
        /// Set the number of input neurons.
        /// </summary>
        public int InputNeurons
        {
            get { return _inputNeurons; }
            set { _inputNeurons = value; }
        }


        /// <summary>
        /// Set the number of output neurons.
        /// </summary>
        public int OutputNeurons
        {
            get { return _outputNeurons; }
            set { _outputNeurons = value; }
        }


        /// <summary>
        /// Not used, the BAM uses a bipoloar activation function.
        /// </summary>
        public IActivationFunction ActivationFunction
        {
            set
            {
                throw new PatternError(
                    "A SVM network can't specify a custom activation function.");
            }
        }

        #endregion
    }

    [Serializable]
    public class svm_parameter
      : ICloneable
    {
        /* svm_type */
        public const int C_SVC = 0;
        public const int NU_SVC = 1;
        public const int ONE_CLASS = 2;
        public const int EPSILON_SVR = 3;
        public const int NU_SVR = 4;

        /* kernel_type */
        public const int LINEAR = 0;
        public const int POLY = 1;
        public const int RBF = 2;
        public const int SIGMOID = 3;

        public int svm_type;
        public int kernel_type;
        public double degree; // for poly
        public double gamma; // for poly/rbf/sigmoid
        public double coef0; // for poly/sigmoid

        // these are for training only
        public double cache_size; // in MB
        public double eps; // stopping criteria
        public double C; // for C_SVC, EPSILON_SVR and NU_SVR
        public int nr_weight; // for C_SVC
        public int[] weight_label; // for C_SVC
        public double[] weight; // for C_SVC
        public double nu; // for NU_SVC, ONE_CLASS, and NU_SVR
        public double p; // for EPSILON_SVR
        public int shrinking; // use the shrinking heuristics
        public int probability; // do probability estimates

        public virtual Object Clone()
        {
            try
            {
                return base.MemberwiseClone();
            }
            //UPGRADE_NOTE: Exception 'java.lang.CloneNotSupportedException' was converted to 'System.Exception' which has different behavior. 'ms-help://MS.VSCC.2003/commoner/redir/redirect.htm?keyword="jlca1100_3"'
            catch (Exception)
            {
                return null;
            }
        }
    }

    [Serializable]
    public class svm_model
    {
        internal svm_parameter param; // parameter
        internal int nr_class; // number of classes, = 2 in regression/one class svm
        internal int l; // total #SV
        public svm_node[][] SV; // SVs (SV[l])
        internal double[][] sv_coef; // coefficients for SVs in decision functions (sv_coef[n-1][l])
        internal double[] rho; // constants in decision functions (rho[n*(n-1)/2])
        internal double[] probA; // pariwise probability information
        internal double[] probB;

        // for classification only

        internal int[] label; // label of each class (label[n])
        internal int[] nSV; // number of SVs for each class (nSV[n])
        // nSV[0] + nSV[1] + ... + nSV[n-1] = l
    }

    [Serializable]
    public class svm_node
    {
        public int index;
        public double value_Renamed;
    }

    [Serializable]
    public class BasicPNN : AbstractPNN, IMLRegression, IMLClassification, IMLError
    {
        /// <summary>
        /// The sigma's specify the widths of each kernel used.
        /// </summary>
        ///
        private readonly double[] _sigma;

        /// <summary>
        /// Used for classification, the number of cases in each class.
        /// </summary>
        ///
        private int[] _countPer;

        /// <summary>
        /// The prior probability weights.
        /// </summary>
        ///
        private double[] _priors;

        /// <summary>
        /// The training samples that form the memory of this network.
        /// </summary>
        ///
        private BasicMLDataSet _samples;

        /// <summary>
        /// Construct a BasicPNN network.
        /// </summary>
        ///
        /// <param name="kernel">The kernel to use.</param>
        /// <param name="outmodel">The output model for this network.</param>
        /// <param name="inputCount">The number of inputs in this network.</param>
        /// <param name="outputCount">The number of outputs in this network.</param>
        public BasicPNN(PNNKernelType kernel, PNNOutputMode outmodel,
                        int inputCount, int outputCount) : base(kernel, outmodel, inputCount, outputCount)
        {
            SeparateClass = false;

            _sigma = new double[inputCount];
        }


        /// <value>the countPer</value>
        public int[] CountPer
        {
            get { return _countPer; }
        }


        /// <value>the priors</value>
        public double[] Priors
        {
            get { return _priors; }
        }


        /// <value>the samples to set</value>
        public BasicMLDataSet Samples
        {
            get { return _samples; }
            set
            {
                _samples = value;

                // update counts per
                if (OutputMode == PNNOutputMode.Classification)
                {
                    _countPer = new int[OutputCount];
                    _priors = new double[OutputCount];


                    foreach (IMLDataPair pair in value)
                    {
                        var i = (int)pair.Ideal[0];
                        if (i >= _countPer.Length)
                        {
                            throw new NeuralNetworkError(
                                "Training data contains more classes than neural network has output neurons to hold.");
                        }
                        _countPer[i]++;
                    }

                    for (int i = 0; i < _priors.Length; i++)
                    {
                        _priors[i] = -1;
                    }
                }
            }
        }


        /// <value>the sigma</value>
        public double[] Sigma
        {
            get { return _sigma; }
        }

        /// <summary>
        /// Compute the output from this network.
        /// </summary>
        ///
        /// <param name="input">The input to the network.</param>
        /// <returns>The output from the network.</returns>
        public override sealed IMLData Compute(IMLData input)
        {
            var xout = new double[OutputCount];

            double psum = 0.0d;

            int r = -1;

            foreach (IMLDataPair pair in _samples)
            {
                r++;

                if (r == Exclude)
                {
                    continue;
                }

                double dist = 0.0d;
                for (int i = 0; i < InputCount; i++)
                {
                    double diff = input[i] - pair.Input[i];
                    diff /= _sigma[i];
                    dist += diff * diff;
                }

                if (Kernel == PNNKernelType.Gaussian)
                {
                    dist = Math.Exp(-dist);
                }
                else if (Kernel == PNNKernelType.Reciprocal)
                {
                    dist = 1.0d / (1.0d + dist);
                }

                if (dist < 1.0e-40d)
                {
                    dist = 1.0e-40d;
                }

                if (OutputMode == PNNOutputMode.Classification)
                {
                    var pop = (int)pair.Ideal[0];
                    xout[pop] += dist;
                }
                else if (OutputMode == PNNOutputMode.Unsupervised)
                {
                    for (int i = 0; i < InputCount; i++)
                    {
                        xout[i] += dist * pair.Input[i];
                    }
                    psum += dist;
                }
                else if (OutputMode == PNNOutputMode.Regression)
                {
                    for (int i = 0; i < OutputCount; i++)
                    {
                        xout[i] += dist * pair.Ideal[i];
                    }

                    psum += dist;
                }
            }

            if (OutputMode == PNNOutputMode.Classification)
            {
                psum = 0.0d;
                for (int i = 0; i < OutputCount; i++)
                {
                    if (_priors[i] >= 0.0d)
                    {
                        xout[i] *= _priors[i] / _countPer[i];
                    }
                    psum += xout[i];
                }

                if (psum < 1.0e-40d)
                {
                    psum = 1.0e-40d;
                }

                for (int i = 0; i < OutputCount; i++)
                {
                    xout[i] /= psum;
                }
            }
            else if (OutputMode == PNNOutputMode.Unsupervised)
            {
                for (int i = 0; i < InputCount; i++)
                {
                    xout[i] /= psum;
                }
            }
            else if (OutputMode == PNNOutputMode.Regression)
            {
                for (int i = 0; i < OutputCount; i++)
                {
                    xout[i] /= psum;
                }
            }

            return new BasicMLData(xout);
        }

        /// <inheritdoc/>
        public override void UpdateProperties()
        {
            // unneeded
        }


        /// <inheritdoc/>
        public double CalculateError(IMLDataSet data)
        {
            if (OutputMode == PNNOutputMode.Classification)
            {
                return SyntUtility.CalculateClassificationError(this, data);
            }
            else
            {
                return SyntUtility.CalculateRegressionError(this, data);
            }
        }

        /// <inheritdoc/>
        public int Classify(IMLData input)
        {
            IMLData output = Compute(input);
            return EngineArray.MaxIndex(output.Data);
        }
    }

    public class PersistBasicPNN : ISyntPersistor
    {
        /// <summary>
        /// The output mode property.
        /// </summary>
        ///
        public const String PropertyOutputMode = "outputMode";

        /// <summary>
        /// File version.
        /// </summary>
        public virtual int FileVersion
        {
            get { return 1; }
        }


        /// <summary>
        /// File version.
        /// </summary>
        public virtual String PersistClassString
        {
            get { return "BasicPNN"; }
        }


        /// <summary>
        /// Read an object.
        /// </summary>
        public Object Read(Stream mask0)
        {
            var ins0 = new SyntReadHelper(mask0);
            SyntFileSection section;
            var samples = new BasicMLDataSet();
            IDictionary<String, String> networkParams = null;
            PNNKernelType kernel = default(PNNKernelType) /* was: null */;
            PNNOutputMode outmodel = default(PNNOutputMode) /* was: null */;
            int inputCount = 0;
            int outputCount = 0;
            double error = 0;
            double[] sigma = null;

            while ((section = ins0.ReadNextSection()) != null)
            {
                if (section.SectionName.Equals("PNN")
                    && section.SubSectionName.Equals("PARAMS"))
                {
                    networkParams = section.ParseParams();
                }
                if (section.SectionName.Equals("PNN")
                    && section.SubSectionName.Equals("NETWORK"))
                {
                    IDictionary<String, String> paras = section.ParseParams();
                    inputCount = SyntFileSection.ParseInt(paras,
                                                           PersistConst.InputCount);
                    outputCount = SyntFileSection.ParseInt(paras,
                                                            PersistConst.OutputCount);
                    kernel = StringToKernel(paras[PersistConst.Kernel]);
                    outmodel = StringToOutputMode(paras[PropertyOutputMode]);
                    error = SyntFileSection
                        .ParseDouble(paras, PersistConst.Error);
                    sigma = section.ParseDoubleArray(paras, PersistConst.Sigma);
                }
                if (section.SectionName.Equals("PNN")
                    && section.SubSectionName.Equals("SAMPLES"))
                {
                    foreach (String line in section.Lines)
                    {
                        IList<String> cols = SyntFileSection
                            .SplitColumns(line);
                        int index = 0;
                        IMLData inputData = new BasicMLData(inputCount);
                        for (int i = 0; i < inputCount; i++)
                        {
                            inputData[i] =
                                CSVFormat.EgFormat.Parse(cols[index++]);
                        }
                        IMLData idealData = new BasicMLData(inputCount);

                        idealData[0] = CSVFormat.EgFormat.Parse(cols[index++]);

                        IMLDataPair pair = new BasicMLDataPair(inputData,
                                                              idealData);
                        samples.Add(pair);
                    }
                }
            }

            var result = new BasicPNN(kernel, outmodel, inputCount,
                                      outputCount);
            if (networkParams != null)
            {
                EngineArray.PutAll(networkParams, result.Properties);
            }
            result.Samples = samples;
            result.Error = error;
            if (sigma != null)
            {
                EngineArray.ArrayCopy(sigma, result.Sigma);
            }

            return result;
        }

        /// <summary>
        /// 
        /// </summary>
        ///
        public void Save(Stream os, Object obj)
        {
            var xout = new SyntWriteHelper(os);
            var pnn = (BasicPNN)obj;
            xout.AddSection("PNN");
            xout.AddSubSection("PARAMS");
            xout.AddProperties(pnn.Properties);
            xout.AddSubSection("NETWORK");

            xout.WriteProperty(PersistConst.Error, pnn.Error);
            xout.WriteProperty(PersistConst.InputCount, pnn.InputCount);
            xout.WriteProperty(PersistConst.Kernel,
                               KernelToString(pnn.Kernel));
            xout.WriteProperty(PersistConst.OutputCount, pnn.OutputCount);
            xout.WriteProperty(PropertyOutputMode,
                               OutputModeToString(pnn.OutputMode));
            xout.WriteProperty(PersistConst.Sigma, pnn.Sigma);

            xout.AddSubSection("SAMPLES");

            if (pnn.Samples != null)
            {
                foreach (IMLDataPair pair in pnn.Samples)
                {
                    for (int i = 0; i < pair.Input.Count; i++)
                    {
                        xout.AddColumn(pair.Input[i]);
                    }

                    for (int i = 0; i < pair.Ideal.Count; i++)
                    {
                        xout.AddColumn(pair.Ideal[i]);
                    }
                    xout.WriteLine();
                }
            }
            xout.Flush();
        }

        /// <summary>
        /// Convert a kernel type to a string.
        /// </summary>
        ///
        /// <param name="k">The kernel type.</param>
        /// <returns>The string.</returns>
        public static String KernelToString(PNNKernelType k)
        {
            switch (k)
            {
                case PNNKernelType.Gaussian:
                    return "gaussian";
                case PNNKernelType.Reciprocal:
                    return "reciprocal";
                default:
                    return null;
            }
        }

        /// <summary>
        /// Convert output mode to string.
        /// </summary>
        ///
        /// <param name="mode">The output mode.</param>
        /// <returns>The string.</returns>
        public static String OutputModeToString(PNNOutputMode mode)
        {
            switch (mode)
            {
                case PNNOutputMode.Regression:
                    return "regression";
                case PNNOutputMode.Unsupervised:
                    return "unsupervised";
                case PNNOutputMode.Classification:
                    return "classification";
                default:
                    return null;
            }
        }

        /// <summary>
        /// Convert a string to a PNN kernel.
        /// </summary>
        ///
        /// <param name="k">The string.</param>
        /// <returns>The kernel.</returns>
        public static PNNKernelType StringToKernel(String k)
        {
            if (k.Equals("gaussian", StringComparison.InvariantCultureIgnoreCase))
            {
                return PNNKernelType.Gaussian;
            }
            if (k.Equals("reciprocal", StringComparison.InvariantCultureIgnoreCase))
            {
                return PNNKernelType.Reciprocal;
            }
            return default(PNNKernelType) /* was: null */;
        }

        /// <summary>
        /// Convert a string to a PNN output mode.
        /// </summary>
        ///
        /// <param name="mode">The string.</param>
        /// <returns>The output ndoe.</returns>
        public static PNNOutputMode StringToOutputMode(String mode)
        {
            if (mode.Equals("regression", StringComparison.InvariantCultureIgnoreCase))
            {
                return PNNOutputMode.Regression;
            }
            if (mode.Equals("unsupervised", StringComparison.InvariantCultureIgnoreCase))
            {
                return PNNOutputMode.Unsupervised;
            }
            if (mode.Equals("classification", StringComparison.InvariantCultureIgnoreCase))
            {
                return PNNOutputMode.Classification;
            }
            return default(PNNOutputMode) /* was: null */;
        }

        /// <inheritdoc/>
        public Type NativeType
        {
            get { return typeof(BasicPNN); }
        }
    }

    public class HiddenLayerParams
    {
        /// <summary>
        /// The maximum number of neurons on this layer.
        /// </summary>
        ///
        private readonly int _max;

        /// <summary>
        /// The minimum number of neurons on this layer.
        /// </summary>
        ///
        private readonly int _min;

        /// <summary>
        /// Construct a hidden layer param object with the specified min and max
        /// values.
        /// </summary>
        ///
        /// <param name="min">The minimum number of neurons.</param>
        /// <param name="max">The maximum number of neurons.</param>
        public HiddenLayerParams(int min, int max)
        {
            _min = min;
            _max = max;
        }


        /// <value>The maximum number of neurons.</value>
        public int Max
        {
            get { return _max; }
        }


        /// <value>The minimum number of neurons.</value>
        public int Min
        {
            get { return _min; }
        }
    }

    public class PruneIncremental : ConcurrentJob
    {
        /// <summary>
        /// The ranges for the hidden layers.
        /// </summary>
        ///
        private readonly IList<HiddenLayerParams> _hidden;

        /// <summary>
        /// The number if training iterations that should be tried for each network.
        /// </summary>
        ///
        private readonly int _iterations;

        /// <summary>
        /// The pattern for which type of neural network we would like to create.
        /// </summary>
        ///
        private readonly INeuralNetworkPattern _pattern;

        /// <summary>
        /// The object that status should be reported to.
        /// </summary>
        ///
        private readonly IStatusReportable _report;

        /// <summary>
        /// An array of the top errors.
        /// </summary>
        ///
        private readonly double[] _topErrors;

        /// <summary>
        /// An array of the top networks.
        /// </summary>
        ///
        private readonly BasicNetwork[] _topNetworks;

        /// <summary>
        /// The training set to use as different neural networks are evaluated.
        /// </summary>
        ///
        private readonly IMLDataSet _training;

        /// <summary>
        /// The number of tries with random weights.
        /// </summary>
        ///
        private readonly int _weightTries;

        /// <summary>
        /// The best network found so far.
        /// </summary>
        ///
        private BasicNetwork _bestNetwork;

        /// <summary>
        /// How many networks have been tried so far?
        /// </summary>
        ///
        private int _currentTry;

        /// <summary>
        /// Are we done?
        /// </summary>
        ///
        private bool _done;

        /// <summary>
        /// The size of the first hidden layer.
        /// </summary>
        ///
        private int _hidden1Size;

        /// <summary>
        /// The size of the second hidden layer.
        /// </summary>
        ///
        private int _hidden2Size;

        /// <summary>
        /// Keeps track of how many neurons in each hidden layer as training the
        /// evaluation progresses.
        /// </summary>
        ///
        private int[] _hiddenCounts;

        /// <summary>
        /// The current highest error.
        /// </summary>
        ///
        private double _high;

        /// <summary>
        /// The current lowest error.
        /// </summary>
        ///
        private double _low;

        /// <summary>
        /// The results in a 2d array.
        /// </summary>
        ///
        private double[][] _results;

        /// <summary>
        /// Construct an object to determine the optimal number of hidden layers and
        /// neurons for the specified training data and pattern.
        /// </summary>
        ///
        /// <param name="training">The training data to use.</param>
        /// <param name="pattern">The network pattern to use to solve this data.</param>
        /// <param name="iterations">How many iterations to try per network.</param>
        /// <param name="weightTries">The number of random weights to use.</param>
        /// <param name="numTopResults"></param>
        /// <param name="report">Object used to report status to.</param>
        public PruneIncremental(IMLDataSet training,
                                INeuralNetworkPattern pattern, int iterations,
                                int weightTries, int numTopResults,
                                IStatusReportable report) : base(report)
        {
            _done = false;
            _hidden = new List<HiddenLayerParams>();
            _training = training;
            _pattern = pattern;
            _iterations = iterations;
            _report = report;
            _weightTries = weightTries;
            _topNetworks = new BasicNetwork[numTopResults];
            _topErrors = new double[numTopResults];
        }


        /// <value>The network being processed.</value>
        public BasicNetwork BestNetwork
        {
            get { return _bestNetwork; }
        }


        /// <value>The hidden layer max and min.</value>
        public IList<HiddenLayerParams> Hidden
        {
            get { return _hidden; }
        }


        /// <value>The size of the first hidden layer.</value>
        public int Hidden1Size
        {
            get { return _hidden1Size; }
        }


        /// <value>The size of the second hidden layer.</value>
        public int Hidden2Size
        {
            get { return _hidden2Size; }
        }


        /// <value>The higest error so far.</value>
        public double High
        {
            get { return _high; }
        }


        /// <value>The number of training iterations to try for each network.</value>
        public int Iterations
        {
            get { return _iterations; }
        }


        /// <value>The lowest error so far.</value>
        public double Low
        {
            get { return _low; }
        }


        /// <value>The network pattern to use.</value>
        public INeuralNetworkPattern Pattern
        {
            get { return _pattern; }
        }


        /// <value>The error results.</value>
        public double[][] Results
        {
            get { return _results; }
        }


        /// <value>the topErrors</value>
        public double[] TopErrors
        {
            get { return _topErrors; }
        }


        /// <value>the topNetworks</value>
        public BasicNetwork[] TopNetworks
        {
            get { return _topNetworks; }
        }


        /// <value>The training set to use.</value>
        public IMLDataSet Training
        {
            get { return _training; }
        }

        /// <summary>
        /// Format the network as a human readable string that lists the hidden
        /// layers.
        /// </summary>
        ///
        /// <param name="network">The network to format.</param>
        /// <returns>A human readable string.</returns>
        public static String NetworkToString(BasicNetwork network)
        {
            if (network != null)
            {
                var result = new StringBuilder();
                int num = 1;

                // display only hidden layers
                for (int i = 1; i < network.LayerCount - 1; i++)
                {
                    if (result.Length > 0)
                    {
                        result.Append(",");
                    }
                    result.Append("H");
                    result.Append(num++);
                    result.Append("=");
                    result.Append(network.GetLayerNeuronCount(i));
                }

                return result.ToString();
            }
            else
            {
                return "N/A";
            }
        }

        /// <summary>
        /// Add a hidden layer's min and max. Call this once per hidden layer.
        /// Specify a zero min if it is possible to remove this hidden layer.
        /// </summary>
        ///
        /// <param name="min">The minimum number of neurons for this layer.</param>
        /// <param name="max">The maximum number of neurons for this layer.</param>
        public void AddHiddenLayer(int min, int max)
        {
            var param = new HiddenLayerParams(min, max);
            _hidden.Add(param);
        }

        /// <summary>
        /// Generate a network according to the current hidden layer counts.
        /// </summary>
        ///
        /// <returns>The network based on current hidden layer counts.</returns>
        private BasicNetwork GenerateNetwork()
        {
            _pattern.Clear();


            foreach (int element in _hiddenCounts)
            {
                if (element > 0)
                {
                    _pattern.AddHiddenLayer(element);
                }
            }

            return (BasicNetwork)_pattern.Generate();
        }


        /// <summary>
        /// Increase the hidden layer counts according to the hidden layer
        /// parameters. Increase the first hidden layer count by one, if it is maxed
        /// out, then set it to zero and increase the next hidden layer.
        /// </summary>
        ///
        /// <returns>False if no more increases can be done, true otherwise.</returns>
        private bool IncreaseHiddenCounts()
        {
            int i = 0;
            do
            {
                HiddenLayerParams param = _hidden[i];
                _hiddenCounts[i]++;

                // is this hidden layer still within the range?
                if (_hiddenCounts[i] <= param.Max)
                {
                    return true;
                }

                // increase the next layer if we've maxed out this one
                _hiddenCounts[i] = param.Min;
                i++;
            } while (i < _hiddenCounts.Length);

            // can't increase anymore, we're done!

            return false;
        }

        /// <summary>
        /// Init for prune.
        /// </summary>
        ///
        public void Init()
        {
            // handle display for one layer
            if (_hidden.Count == 1)
            {
                _hidden1Size = (_hidden[0].Max - _hidden[0].Min) + 1;
                _hidden2Size = 0;
                _results = EngineArray.AllocateDouble2D(_hidden1Size, 1);
            }
            else if (_hidden.Count == 2)
            {
                // handle display for two layers
                _hidden1Size = (_hidden[0].Max - _hidden[0].Min) + 1;
                _hidden2Size = (_hidden[1].Max - _hidden[1].Min) + 1;
                _results = EngineArray.AllocateDouble2D(_hidden1Size, _hidden2Size);
            }
            else
            {
                // we don't handle displays for more than two layers
                _hidden1Size = 0;
                _hidden2Size = 0;
                _results = null;
            }

            // reset min and max
            _high = Double.NegativeInfinity;
            _low = Double.PositiveInfinity;
        }

        /// <summary>
        /// Get the next workload. This is the number of hidden neurons. This is the
        /// total amount of work to be processed.
        /// </summary>
        ///
        /// <returns>The amount of work to be processed by this.</returns>
        public override sealed int LoadWorkload()
        {
            int result = 1;


            foreach (HiddenLayerParams param in _hidden)
            {
                result *= (param.Max - param.Min) + 1;
            }

            Init();

            return result;
        }

        /// <summary>
        /// Perform an individual job unit, which is a single network to train and
        /// evaluate.
        /// </summary>
        ///
        /// <param name="context">Contains information about the job unit.</param>
        public override sealed void PerformJobUnit(JobUnitContext context)
        {
            var network = (BasicNetwork)context.JobUnit;
            BufferedMLDataSet buffer = null;
            IMLDataSet useTraining = _training;

            if (_training is BufferedMLDataSet)
            {
                buffer = (BufferedMLDataSet)_training;
                useTraining = (buffer.OpenAdditional());
            }

            // train the neural network

            double error = Double.PositiveInfinity;
            for (int z = 0; z < _weightTries; z++)
            {
                network.Reset();
                Prop train = new ResilientProp(network,
                                                             useTraining);
                var strat = new StopTrainingStrategy(0.001d,
                                                     5);

                train.AddStrategy(strat);
                train.ThreadCount = 1; // force single thread mode

                for (int i = 0;
                     (i < _iterations) && !ShouldStop
                     && !strat.ShouldStop();
                     i++)
                {
                    train.Iteration();
                }

                error = Math.Min(error, train.Error);
            }

            if (buffer != null)
            {
                buffer.Close();
            }

            if (!ShouldStop)
            {
                // update min and max

                _high = Math.Max(_high, error);
                _low = Math.Min(_low, error);

                if (_hidden1Size > 0)
                {
                    int networkHidden1Count;
                    int networkHidden2Count;

                    if (network.LayerCount > 3)
                    {
                        networkHidden2Count = network.GetLayerNeuronCount(2);
                        networkHidden1Count = network.GetLayerNeuronCount(1);
                    }
                    else
                    {
                        networkHidden2Count = 0;
                        networkHidden1Count = network.GetLayerNeuronCount(1);
                    }

                    int row, col;

                    if (_hidden2Size == 0)
                    {
                        row = networkHidden1Count - _hidden[0].Min;
                        col = 0;
                    }
                    else
                    {
                        row = networkHidden1Count - _hidden[0].Min;
                        col = networkHidden2Count - _hidden[1].Min;
                    }

                    if ((row < 0) || (col < 0))
                    {
                        Console.Out.WriteLine("STOP");
                    }
                    _results[row][col] = error;
                }

                // report status
                _currentTry++;

                UpdateBest(network, error);
                ReportStatus(
                    context,
                    "Current: "
                    + NetworkToString(network)
                    + "; Best: "
                    + NetworkToString(_bestNetwork));
            }
        }

        /// <summary>
        /// Begin the prune process.
        /// </summary>
        ///
        public override sealed void Process()
        {
            if (_hidden.Count == 0)
            {


            }

            _hiddenCounts = new int[_hidden.Count];

            // set the best network
            _bestNetwork = null;

            // set to minimums
            int i = 0;

            foreach (HiddenLayerParams parm in _hidden)
            {
                _hiddenCounts[i++] = parm.Min;
            }

            // make sure hidden layer 1 has at least one neuron
            if (_hiddenCounts[0] == 0)
            {
                throw new SyntError(
                    "To calculate the optimal hidden size, at least "
                    + "one neuron must be the minimum for the first hidden layer.");
            }

            base.Process();
        }

        /// <summary>
        /// Request the next task. This is the next network to attempt to train.
        /// </summary>
        ///
        /// <returns>The next network to train.</returns>
        public override sealed Object RequestNextTask()
        {
            if (_done || ShouldStop)
            {
                return null;
            }

            BasicNetwork network = GenerateNetwork();

            if (!IncreaseHiddenCounts())
            {
                _done = true;
            }

            return network;
        }

        /// <summary>
        /// Update the best network.
        /// </summary>
        ///
        /// <param name="network">The network to consider.</param>
        /// <param name="error">The error for this network.</param>
        [MethodImpl(MethodImplOptions.Synchronized)]
        private void UpdateBest(BasicNetwork network,
                                double error)
        {
            _high = Math.Max(_high, error);
            _low = Math.Min(_low, error);

            int selectedIndex = -1;

            // find a place for this in the top networks, if it is a top network
            for (int i = 0; i < _topNetworks.Length; i++)
            {
                if (_topNetworks[i] == null)
                {
                    selectedIndex = i;
                    break;
                }
                else if (_topErrors[i] > error)
                {
                    // this network might be worth replacing, see if the one
                    // already selected is a better option.
                    if ((selectedIndex == -1)
                        || (_topErrors[selectedIndex] < _topErrors[i]))
                    {
                        selectedIndex = i;
                    }
                }
            }

            // replace the selected index
            if (selectedIndex != -1)
            {
                _topErrors[selectedIndex] = error;
                _topNetworks[selectedIndex] = network;
            }

            // now select the best network, which is the most simple of the
            // top networks.

            BasicNetwork choice = null;


            foreach (BasicNetwork n in _topNetworks)
            {
                if (n == null)
                {
                    continue;
                }

                if (choice == null)
                {
                    choice = n;
                }
                else
                {
                    if (n.Structure.CalculateSize() < choice.Structure
                                                          .CalculateSize())
                    {
                        choice = n;
                    }
                }
            }

            if (choice != _bestNetwork)
            {
                _bestNetwork = choice;
                SyntLogging.Log(SyntLogging.LevelDebug,
                                 "Prune found new best network: error=" + error
                                 + ", network=" + choice);
            }
        }
    }

    public class PruneSelective
    {
        /// <summary>
        /// The network to prune.
        /// </summary>
        ///
        private readonly BasicNetwork _network;

        /// <summary>
        /// Construct an object prune the neural network.
        /// </summary>
        ///
        /// <param name="network">The network to prune.</param>
        public PruneSelective(BasicNetwork network)
        {
            _network = network;
        }

        /// <value>The network that is being processed.</value>
        public BasicNetwork Network
        {
            get { return _network; }
        }

        /// <summary>
        /// Change the neuron count for the network. If the count is increased then a
        /// zero-weighted neuron is added, which will not affect the output of the
        /// neural network. If the neuron count is decreased, then the weakest neuron
        /// will be removed.
        /// This method cannot be used to remove a bias neuron.
        /// </summary>
        ///
        /// <param name="layer">The layer to adjust.</param>
        /// <param name="neuronCount">The new neuron count for this layer.</param>
        public void ChangeNeuronCount(int layer, int neuronCount)
        {
            if (neuronCount == 0)
            {
                throw new NeuralNetworkError("Can't decrease to zero neurons.");
            }

            int currentCount = _network.GetLayerNeuronCount(layer);

            // is there anything to do?
            if (neuronCount == currentCount)
            {
                return;
            }

            if (neuronCount > currentCount)
            {
                IncreaseNeuronCount(layer, neuronCount);
            }
            else
            {
                DecreaseNeuronCount(layer, neuronCount);
            }
        }

        /// <summary>
        /// Internal function to decrease the neuron count of a layer.
        /// </summary>
        ///
        /// <param name="layer">The layer to affect.</param>
        /// <param name="neuronCount">The new neuron count.</param>
        private void DecreaseNeuronCount(int layer,
                                         int neuronCount)
        {
            // create an array to hold the least significant neurons, which will be
            // removed

            int lostNeuronCount = _network.GetLayerNeuronCount(layer)
                                  - neuronCount;
            int[] lostNeuron = FindWeakestNeurons(layer, lostNeuronCount);

            // finally, actually prune the neurons that the previous steps
            // determined to remove
            for (int i = 0; i < lostNeuronCount; i++)
            {
                Prune(layer, lostNeuron[i] - i);
            }
        }

        /// <summary>
        /// Determine the significance of the neuron. The higher the return value,
        /// the more significant the neuron is.
        /// </summary>
        ///
        /// <param name="layer">The layer to query.</param>
        /// <param name="neuron">The neuron to query.</param>
        /// <returns>How significant is this neuron.</returns>
        public double DetermineNeuronSignificance(int layer,
                                                  int neuron)
        {
            _network.ValidateNeuron(layer, neuron);

            // calculate the bias significance
            double result = 0;

            // calculate the inbound significance
            if (layer > 0)
            {
                int prevLayer = layer - 1;
                int prevCount = _network
                    .GetLayerTotalNeuronCount(prevLayer);
                for (int i = 0; i < prevCount; i++)
                {
                    result += _network.GetWeight(prevLayer, i, neuron);
                }
            }

            // calculate the outbound significance
            if (layer < _network.LayerCount - 1)
            {
                int nextLayer = layer + 1;
                int nextCount = _network.GetLayerNeuronCount(nextLayer);
                for (int i = 0; i < nextCount; i++)
                {
                    result += _network.GetWeight(layer, neuron, i);
                }
            }

            return Math.Abs(result);
        }

        /// <summary>
        /// Find the weakest neurons on a layer. Considers both weight and bias.
        /// </summary>
        ///
        /// <param name="layer">The layer to search.</param>
        /// <param name="count">The number of neurons to find.</param>
        /// <returns>An array of the indexes of the weakest neurons.</returns>
        private int[] FindWeakestNeurons(int layer, int count)
        {
            // create an array to hold the least significant neurons, which will be
            // returned
            var lostNeuronSignificance = new double[count];
            var lostNeuron = new int[count];

            // init the potential lost neurons to the first ones, we will find
            // better choices if we can
            for (int i = 0; i < count; i++)
            {
                lostNeuron[i] = i;
                lostNeuronSignificance[i] = DetermineNeuronSignificance(layer, i);
            }

            // now loop over the remaining neurons and see if any are better ones to
            // remove
            for (int i = count; i < _network.GetLayerNeuronCount(layer); i++)
            {
                double significance = DetermineNeuronSignificance(layer, i);

                // is this neuron less significant than one already chosen?
                for (int j = 0; j < count; j++)
                {
                    if (lostNeuronSignificance[j] > significance)
                    {
                        lostNeuron[j] = i;
                        lostNeuronSignificance[j] = significance;
                        break;
                    }
                }
            }

            return lostNeuron;
        }


        /// <summary>
        /// Internal function to increase the neuron count. This will add a
        /// zero-weight neuron to this layer.
        /// </summary>
        ///
        /// <param name="targetLayer">The layer to increase.</param>
        /// <param name="neuronCount">The new neuron count.</param>
        private void IncreaseNeuronCount(int targetLayer,
                                         int neuronCount)
        {
            // check for errors
            if (targetLayer > _network.LayerCount)
            {
                throw new NeuralNetworkError("Invalid layer " + targetLayer);
            }

            if (neuronCount <= 0)
            {
                throw new NeuralNetworkError("Invalid neuron count " + neuronCount);
            }

            int oldNeuronCount = _network
                .GetLayerNeuronCount(targetLayer);
            int increaseBy = neuronCount - oldNeuronCount;

            if (increaseBy <= 0)
            {
                throw new NeuralNetworkError(
                    "New neuron count is either a decrease or no change: "
                    + neuronCount);
            }

            // access the flat network
            FlatNetwork flat = _network.Structure.Flat;
            double[] oldWeights = flat.Weights;

            // first find out how many connections there will be after this prune.
            int connections = oldWeights.Length;

            // are connections added from the previous layer?
            if (targetLayer > 0)
            {
                int inBoundConnections = _network
                    .GetLayerTotalNeuronCount(targetLayer - 1);
                connections += inBoundConnections * increaseBy;
            }

            // are there connections added from the next layer?
            if (targetLayer < (_network.LayerCount - 1))
            {
                int outBoundConnections = _network
                    .GetLayerNeuronCount(targetLayer + 1);
                connections += outBoundConnections * increaseBy;
            }

            // increase layer count
            int flatLayer = _network.LayerCount - targetLayer - 1;
            flat.LayerCounts[flatLayer] += increaseBy;
            flat.LayerFeedCounts[flatLayer] += increaseBy;

            // allocate new weights now that we know how big the new weights will be
            var newWeights = new double[connections];

            // construct the new weights
            int weightsIndex = 0;
            int oldWeightsIndex = 0;

            for (int fromLayer = flat.LayerCounts.Length - 2; fromLayer >= 0; fromLayer--)
            {
                int fromNeuronCount = _network
                    .GetLayerTotalNeuronCount(fromLayer);
                int toNeuronCount = _network
                    .GetLayerNeuronCount(fromLayer + 1);
                int toLayer = fromLayer + 1;

                for (int toNeuron = 0; toNeuron < toNeuronCount; toNeuron++)
                {
                    for (int fromNeuron = 0; fromNeuron < fromNeuronCount; fromNeuron++)
                    {
                        if ((toLayer == targetLayer)
                            && (toNeuron >= oldNeuronCount))
                        {
                            newWeights[weightsIndex++] = 0;
                        }
                        else if ((fromLayer == targetLayer)
                                 && (fromNeuron > oldNeuronCount))
                        {
                            newWeights[weightsIndex++] = 0;
                        }
                        else
                        {
                            newWeights[weightsIndex++] = _network.Flat.Weights[oldWeightsIndex++];
                        }
                    }
                }
            }

            // swap in the new weights
            flat.Weights = newWeights;

            // reindex
            ReindexNetwork();
        }

        /// <summary>
        /// Prune one of the neurons from this layer. Remove all entries in this
        /// weight matrix and other layers. This method cannot be used to remove a
        /// bias neuron.
        /// </summary>
        ///
        /// <param name="targetLayer">The neuron to prune. Zero specifies the first neuron.</param>
        /// <param name="neuron">The neuron to prune.</param>
        public void Prune(int targetLayer, int neuron)
        {
            // check for errors
            _network.ValidateNeuron(targetLayer, neuron);

            // don't empty a layer
            if (_network.GetLayerNeuronCount(targetLayer) <= 1)
            {

            }

            // access the flat network
            FlatNetwork flat = _network.Structure.Flat;
            double[] oldWeights = flat.Weights;

            // first find out how many connections there will be after this prune.
            int connections = oldWeights.Length;

            // are connections removed from the previous layer?
            if (targetLayer > 0)
            {
                int inBoundConnections = _network
                    .GetLayerTotalNeuronCount(targetLayer - 1);
                connections -= inBoundConnections;
            }

            // are there connections removed from the next layer?
            if (targetLayer < (_network.LayerCount - 1))
            {
                int outBoundConnections = _network
                    .GetLayerNeuronCount(targetLayer + 1);
                connections -= outBoundConnections;
            }

            // allocate new weights now that we know how big the new weights will be
            var newWeights = new double[connections];

            // construct the new weights
            int weightsIndex = 0;

            for (int fromLayer = flat.LayerCounts.Length - 2; fromLayer >= 0; fromLayer--)
            {
                int fromNeuronCount = _network
                    .GetLayerTotalNeuronCount(fromLayer);
                int toNeuronCount = _network
                    .GetLayerNeuronCount(fromLayer + 1);
                int toLayer = fromLayer + 1;

                for (int toNeuron = 0; toNeuron < toNeuronCount; toNeuron++)
                {
                    for (int fromNeuron = 0; fromNeuron < fromNeuronCount; fromNeuron++)
                    {
                        bool skip = false;
                        if ((toLayer == targetLayer) && (toNeuron == neuron))
                        {
                            skip = true;
                        }
                        else if ((fromLayer == targetLayer)
                                 && (fromNeuron == neuron))
                        {
                            skip = true;
                        }

                        if (!skip)
                        {
                            newWeights[weightsIndex++] = _network.GetWeight(
                                fromLayer, fromNeuron, toNeuron);
                        }
                    }
                }
            }

            // swap in the new weights
            flat.Weights = newWeights;

            // decrease layer count
            int flatLayer = _network.LayerCount - targetLayer - 1;
            flat.LayerCounts[flatLayer]--;
            flat.LayerFeedCounts[flatLayer]--;

            // reindex
            ReindexNetwork();
        }


        /// <param name="low">The low-end of the range.</param>
        /// <param name="high">The high-end of the range.</param>
        /// <param name="targetLayer">The target layer.</param>
        /// <param name="neuron">The target neuron.</param>
        public void RandomizeNeuron(double low, double high,
                                    int targetLayer, int neuron)
        {
            RandomizeNeuron(targetLayer, neuron, true, low, high, false, 0.0d);
        }

        /// <summary>
        /// Assign random values to the network. The range will be the min/max of
        /// existing neurons.
        /// </summary>
        ///
        /// <param name="targetLayer">The target layer.</param>
        /// <param name="neuron">The target neuron.</param>
        public void RandomizeNeuron(int targetLayer, int neuron)
        {
            FlatNetwork flat = _network.Structure.Flat;
            double low = EngineArray.Min(flat.Weights);
            double high = EngineArray.Max(flat.Weights);
            RandomizeNeuron(targetLayer, neuron, true, low, high, false, 0.0d);
        }

        /// <summary>
        /// Used internally to randomize a neuron. Usually called from
        /// randomizeNeuron or stimulateNeuron.
        /// </summary>
        ///
        /// <param name="targetLayer">The target layer.</param>
        /// <param name="neuron">The target neuron.</param>
        /// <param name="useRange">True if range randomization should be used.</param>
        /// <param name="low">The low-end of the range.</param>
        /// <param name="high">The high-end of the range.</param>
        /// <param name="usePercent">True if percent stimulation should be used.</param>
        /// <param name="percent">The percent to stimulate by.</param>
        private void RandomizeNeuron(int targetLayer, int neuron,
                                     bool useRange, double low, double high,
                                     bool usePercent, double percent)
        {
            IRandomizer d;

            if (useRange)
            {
             d  = (IRandomizer)(new RangeRandomizer(low, high));
            }
            else
            {
                d = (IRandomizer)(new Distort(percent));
            }

            // check for errors
            _network.ValidateNeuron(targetLayer, neuron);

            // access the flat network
            FlatNetwork flat = _network.Structure.Flat;

            // allocate new weights now that we know how big the new weights will be
            var newWeights = new double[flat.Weights.Length];

            // construct the new weights
            int weightsIndex = 0;

            for (int fromLayer = flat.LayerCounts.Length - 2; fromLayer >= 0; fromLayer--)
            {
                int fromNeuronCount = _network
                    .GetLayerTotalNeuronCount(fromLayer);
                int toNeuronCount = _network
                    .GetLayerNeuronCount(fromLayer + 1);
                int toLayer = fromLayer + 1;

                for (int toNeuron = 0; toNeuron < toNeuronCount; toNeuron++)
                {
                    for (int fromNeuron = 0; fromNeuron < fromNeuronCount; fromNeuron++)
                    {
                        bool randomize = false;
                        if ((toLayer == targetLayer) && (toNeuron == neuron))
                        {
                            randomize = true;
                        }
                        else if ((fromLayer == targetLayer)
                                 && (fromNeuron == neuron))
                        {
                            randomize = true;
                        }

                        double weight = _network.GetWeight(fromLayer,
                                                          fromNeuron, toNeuron);

                        if (randomize)
                        {
                            weight = d.Randomize(weight);
                        }

                        newWeights[weightsIndex++] = weight;
                    }
                }
            }

            // swap in the new weights
            flat.Weights = newWeights;
        }

        /// <summary>
        /// Creat new index values for the network.
        /// </summary>
        ///
        private void ReindexNetwork()
        {
            FlatNetwork flat = _network.Structure.Flat;

            int neuronCount = 0;
            int weightCount = 0;
            for (int i = 0; i < flat.LayerCounts.Length; i++)
            {
                if (i > 0)
                {
                    int from = flat.LayerFeedCounts[i - 1];
                    int to = flat.LayerCounts[i];
                    weightCount += from * to;
                }
                flat.LayerIndex[i] = neuronCount;
                flat.WeightIndex[i] = weightCount;
                neuronCount += flat.LayerCounts[i];
            }

            flat.LayerOutput = new double[neuronCount];
            flat.LayerSums = new double[neuronCount];
            flat.ClearContext();

            flat.InputCount = flat.LayerFeedCounts[flat.LayerCounts.Length - 1];
            flat.OutputCount = flat.LayerFeedCounts[0];
        }

        /// <summary>
        /// Stimulate the specified neuron by the specified percent. This is used to
        /// randomize the weights and bias values for weak neurons.
        /// </summary>
        ///
        /// <param name="percent">The percent to randomize by.</param>
        /// <param name="targetLayer">The layer that the neuron is on.</param>
        /// <param name="neuron">The neuron to randomize.</param>
        public void StimulateNeuron(double percent,
                                    int targetLayer, int neuron)
        {
            RandomizeNeuron(targetLayer, neuron, false, 0, 0, true, percent);
        }

        /// <summary>
        /// Stimulate weaker neurons on a layer. Find the weakest neurons and then
        /// randomize them by the specified percent.
        /// </summary>
        ///
        /// <param name="layer">The layer to stimulate.</param>
        /// <param name="count">The number of weak neurons to stimulate.</param>
        /// <param name="percent">The percent to stimulate by.</param>
        public void StimulateWeakNeurons(int layer, int count,
                                         double percent)
        {
            int[] weak = FindWeakestNeurons(layer, count);

            foreach (int element in weak)
            {
                StimulateNeuron(percent, layer, element);
            }
        }
    }

    public class SVD
    {
        /// <summary>
        /// Perform a SVD fit.
        /// </summary>
        /// <param name="x">The X matrix.</param>
        /// <param name="y">The Y matrix.</param>
        /// <param name="a">The A matrix.</param>
        /// <param name="funcs">The RBF functions.</param>
        /// <returns>The fit.</returns>
        public static double Svdfit(double[][] x, double[][] y, double[][] a,
                                    IRadialBasisFunction[] funcs)
        {
            int i, j, k;
            double wmax, tmp, thresh, sum, TOL = 1e-13d;

            //Allocated memory for svd matrices
            double[][] u = EngineArray.AllocateDouble2D(x.Length, funcs.Length);
            double[][] v = EngineArray.AllocateDouble2D(funcs.Length, funcs.Length);
            var w = new double[funcs.Length];

            //Fill input matrix with values based on fitting functions and input coordinates 
            for (i = 0; i < x.Length; i++)
            {
                for (j = 0; j < funcs.Length; j++)
                    u[i][j] = funcs[j].Calculate(x[i]);
            }

            //Perform decomposition
            Svdcmp(u, w, v);

            //Check for w values that are close to zero and replace them with zeros such that they are ignored in backsub
            wmax = 0;
            for (j = 0; j < funcs.Length; j++)
                if (w[j] > wmax)
                    wmax = w[j];

            thresh = TOL * wmax;

            for (j = 0; j < funcs.Length; j++)
                if (w[j] < thresh)
                    w[j] = 0;

            //Perform back substitution to get result
            Svdbksb(u, w, v, y, a);

            //Calculate chi squared for the fit
            double chisq = 0;
            for (k = 0; k < y[0].Length; k++)
            {
                for (i = 0; i < y.Length; i++)
                {
                    sum = 0.0d;
                    for (j = 0; j < funcs.Length; j++)
                        sum += a[j][k] * funcs[j].Calculate(x[i]);
                    tmp = (y[i][k] - sum);
                    chisq += tmp * tmp;
                }
            }

            return Math.Sqrt(chisq / (y.Length * y[0].Length));
        }

        public static void Svdbksb(double[][] u, double[] w, double[][] v,
                                   double[][] b, double[][] x)
        {
            int jj, j, i, m, n, k;
            double s;

            m = u.Length;
            n = u[0].Length;

            var temp = new double[n];

            for (k = 0; k < b[0].Length; k++)
            {
                for (j = 0; j < n; j++)
                {
                    s = 0;

                    if (w[j] != 0)
                    {
                        for (i = 0; i < m; i++)
                            s += u[i][j] * b[i][k];
                        s /= w[j];
                    }
                    temp[j] = s;
                }

                for (j = 0; j < n; j++)
                {
                    s = 0;
                    for (jj = 0; jj < n; jj++)
                        s += v[j][jj] * temp[jj];
                    x[j][k] = s;
                }
            }
        }

        /// <summary>
        /// Given a matrix a[1..m][1..n], this routine computes its singular value
        /// decomposition, A = U.W.VT.  The matrix U replaces a on output.  The diagonal
        /// matrix of singular values W is output as a vector w[1..n].  The matrix V (not
        /// the transpose VT) is output as v[1..n][1..n].
        /// </summary>
        /// <param name="a"></param>
        /// <param name="w"></param>
        /// <param name="v"></param>
        public static void Svdcmp(double[][] a, double[] w, double[][] v)
        {
            bool flag;
            int i, its, j, jj, k, l = 0, nm = 0;
            double anorm, c, f, g, h, s, scale, x, y, z;

            int m = a.Length;
            int n = a[0].Length;
            var rv1 = new double[n];
            g = scale = anorm = 0.0d;
            for (i = 0; i < n; i++)
            {
                l = i + 2;
                rv1[i] = scale * g;
                g = s = scale = 0.0d;
                if (i < m)
                {
                    for (k = i; k < m; k++)
                        scale += Math.Abs(a[k][i]);
                    if (scale != 0.0d)
                    {
                        for (k = i; k < m; k++)
                        {
                            a[k][i] /= scale;
                            s += a[k][i] * a[k][i];
                        }
                        f = a[i][i];
                        g = -SIGN(Math.Sqrt(s), f);
                        h = f * g - s;
                        a[i][i] = f - g;
                        for (j = l - 1; j < n; j++)
                        {
                            for (s = 0.0d, k = i; k < m; k++)
                                s += a[k][i] * a[k][j];
                            f = s / h;
                            for (k = i; k < m; k++)
                                a[k][j] += f * a[k][i];
                        }
                        for (k = i; k < m; k++)
                            a[k][i] *= scale;
                    }
                }
                w[i] = scale * g;
                g = s = scale = 0.0d;
                if (i + 1 <= m && i + 1 != n)
                {
                    for (k = l - 1; k < n; k++)
                        scale += Math.Abs(a[i][k]);
                    if (scale != 0.0d)
                    {
                        for (k = l - 1; k < n; k++)
                        {
                            a[i][k] /= scale;
                            s += a[i][k] * a[i][k];
                        }
                        f = a[i][l - 1];
                        g = -SIGN(Math.Sqrt(s), f);
                        h = f * g - s;
                        a[i][l - 1] = f - g;
                        for (k = l - 1; k < n; k++)
                            rv1[k] = a[i][k] / h;
                        for (j = l - 1; j < m; j++)
                        {
                            for (s = 0.0d, k = l - 1; k < n; k++)
                                s += a[j][k] * a[i][k];
                            for (k = l - 1; k < n; k++)
                                a[j][k] += s * rv1[k];
                        }
                        for (k = l - 1; k < n; k++)
                            a[i][k] *= scale;
                    }
                }
                anorm = MAX(anorm, (Math.Abs(w[i]) + Math.Abs(rv1[i])));
            }
            for (i = n - 1; i >= 0; i--)
            {
                if (i < n - 1)
                {
                    if (g != 0.0d)
                    {
                        for (j = l; j < n; j++)
                            v[j][i] = (a[i][j] / a[i][l]) / g;
                        for (j = l; j < n; j++)
                        {
                            for (s = 0.0d, k = l; k < n; k++)
                                s += a[i][k] * v[k][j];
                            for (k = l; k < n; k++)
                                v[k][j] += s * v[k][i];
                        }
                    }
                    for (j = l; j < n; j++)
                        v[i][j] = v[j][i] = 0.0d;
                }
                v[i][i] = 1.0d;
                g = rv1[i];
                l = i;
            }
            for (i = MIN(m, n) - 1; i >= 0; i--)
            {
                l = i + 1;
                g = w[i];
                for (j = l; j < n; j++)
                    a[i][j] = 0.0d;
                if (g != 0.0d)
                {
                    g = 1.0d / g;
                    for (j = l; j < n; j++)
                    {
                        for (s = 0.0d, k = l; k < m; k++)
                            s += a[k][i] * a[k][j];
                        f = (s / a[i][i]) * g;
                        for (k = i; k < m; k++)
                            a[k][j] += f * a[k][i];
                    }
                    for (j = i; j < m; j++)
                        a[j][i] *= g;
                }
                else
                    for (j = i; j < m; j++)
                        a[j][i] = 0.0d;
                ++a[i][i];
            }
            for (k = n - 1; k >= 0; k--)
            {
                for (its = 0; its < 30; its++)
                {
                    flag = true;
                    for (l = k; l >= 0; l--)
                    {
                        nm = l - 1;
                        if (Math.Abs(rv1[l]) + anorm == anorm)
                        {
                            flag = false;
                            break;
                        }
                        if (Math.Abs(w[nm]) + anorm == anorm)
                            break;
                    }
                    if (flag)
                    {
                        c = 0.0d;
                        s = 1.0d;
                        for (i = l; i < k + 1; i++)
                        {
                            f = s * rv1[i];
                            rv1[i] = c * rv1[i];
                            if (Math.Abs(f) + anorm == anorm)
                                break;
                            g = w[i];
                            h = Pythag(f, g);
                            w[i] = h;
                            h = 1.0d / h;
                            c = g * h;
                            s = -f * h;
                            for (j = 0; j < m; j++)
                            {
                                y = a[j][nm];
                                z = a[j][i];
                                a[j][nm] = y * c + z * s;
                                a[j][i] = z * c - y * s;
                            }
                        }
                    }
                    z = w[k];
                    if (l == k)
                    {
                        if (z < 0.0d)
                        {
                            w[k] = -z;
                            for (j = 0; j < n; j++)
                                v[j][k] = -v[j][k];
                        }
                        break;
                    }
                    if (its == 29)
                    {
                        //	Debug.Print("no convergence in 30 svdcmp iterations");
                    }
                    x = w[l];
                    nm = k - 1;
                    y = w[nm];
                    g = rv1[nm];
                    h = rv1[k];
                    f = ((y - z) * (y + z) + (g - h) * (g + h)) / (2.0d * h * y);
                    g = Pythag(f, 1.0d);
                    f = ((x - z) * (x + z) + h * ((y / (f + SIGN(g, f))) - h)) / x;
                    c = s = 1.0d;
                    for (j = l; j <= nm; j++)
                    {
                        i = j + 1;
                        g = rv1[i];
                        y = w[i];
                        h = s * g;
                        g = c * g;
                        z = Pythag(f, h);
                        rv1[j] = z;
                        c = f / z;
                        s = h / z;
                        f = x * c + g * s;
                        g = g * c - x * s;
                        h = y * s;
                        y *= c;
                        for (jj = 0; jj < n; jj++)
                        {
                            x = v[jj][j];
                            z = v[jj][i];
                            v[jj][j] = x * c + z * s;
                            v[jj][i] = z * c - x * s;
                        }
                        z = Pythag(f, h);
                        w[j] = z;
                        if (z != 0)
                        {
                            z = 1.0d / z;
                            c = f * z;
                            s = h * z;
                        }
                        f = c * g + s * y;
                        x = c * y - s * g;
                        for (jj = 0; jj < m; jj++)
                        {
                            y = a[jj][j];
                            z = a[jj][i];
                            a[jj][j] = y * c + z * s;
                            a[jj][i] = z * c - y * s;
                        }
                    }
                    rv1[l] = 0.0d;
                    rv1[k] = f;
                    w[k] = x;
                }
            }
        }

        /// <summary>
        /// Take the min of two numbers.
        /// </summary>
        /// <param name="m">First number.</param>
        /// <param name="n">Second number.</param>
        /// <returns>The min.</returns>
        public static int MIN(int m, int n)
        {
            return (m < n) ? m : n;
        }

        /// <summary>
        /// Take the max of two numbers.
        /// </summary>
        /// <param name="a">The first number.</param>
        /// <param name="b">The second number.</param>
        /// <returns>The max.</returns>
        public static double MAX(double a, double b)
        {
            return (a > b) ? a : b;
        }

        /// <summary>
        /// Take the sign of two numbers.
        /// </summary>
        /// <param name="a">The first number.</param>
        /// <param name="b">The second number.</param>
        /// <returns></returns>
        public static double SIGN(double a, double b)
        {
            return (((b) >= 0.0d) ? Math.Abs(a) : -Math.Abs(a));
        }

        /// <summary>
        /// Compute the pythag distance of two numbers.
        /// </summary>
        /// <param name="a">The first number.</param>
        /// <param name="b">The second number.</param>
        /// <returns>The result.</returns>
        public static double Pythag(double a, double b)
        {
            double absa, absb;
            absa = Math.Abs(a);
            absb = Math.Abs(b);
            if (absa > absb)
                return absa * Math.Sqrt(1.0d + (absb / absa) * (absb / absa));
            else
                return ((absb == 0.0d)
                            ? 0.0d
                            : absb
                              * Math.Sqrt(1.0d + (absa / absb) * (absa / absb)));
        }
    }

    public class SVDTraining : BasicTraining
    {
        /// <summary>
        /// The network that is to be trained.
        /// </summary>
        ///
        private readonly RBFNetwork network;

        /// <summary>
        /// Construct the training object.
        /// </summary>
        ///
        /// <param name="network_0">The network to train. Must have a single output neuron.</param>
        /// <param name="training">The training data to use. Must be indexable.</param>
        public SVDTraining(RBFNetwork network_0, IMLDataSet training) : base(TrainingImplementationType.OnePass)
        {
            if (network_0.OutputCount != 1)
            {


            }

            Training = training;
            network = network_0;
        }

        /// <inheritdoc />
        public override sealed bool CanContinue
        {
            get { return false; }
        }

        /// <inheritdoc/>
        public override IMLMethod Method
        {
            get { return network; }
        }

        /// <summary>
        /// Convert a flat network to a matrix.
        /// </summary>
        /// <param name="flat">The flat network to convert.</param>
        /// <param name="start">The starting point.</param>
        /// <param name="matrix">The matrix to convert to.</param>
        public void FlatToMatrix(double[] flat, int start,
                                 double[][] matrix)
        {
            int rows = matrix.Length;
            int cols = matrix[0].Length;

            int index = start;

            for (int r = 0; r < rows; r++)
            {
                for (int c = 0; c < cols; c++)
                {
                    matrix[r][c] = flat[index++];
                }
            }
        }


        /// <summary>
        /// Perform one iteration.
        /// </summary>
        ///
        public override sealed void Iteration()
        {
            int length = network.RBF.Length;

            var funcs = new IRadialBasisFunction[length];

            // Iteration over neurons and determine the necessaries
            for (int i = 0; i < length; i++)
            {
                IRadialBasisFunction basisFunc = network.RBF[i];

                funcs[i] = basisFunc;

                // This is the value that is changed using other training methods.
                // weights[i] =
                // network.Structure.Synapses[0].WeightMatrix.Data[i][j];
            }

            ObjectPair<double[][], double[][]> data = TrainingSetUtil
                .TrainingToArray(Training);

            double[][] matrix = EngineArray.AllocateDouble2D(length, network.OutputCount);

            FlatToMatrix(network.Flat.Weights, 0, matrix);
            Error = SVD.Svdfit(data.A, data.B, matrix, funcs);
            MatrixToFlat(matrix, network.Flat.Weights, 0);
        }

        /// <summary>
        /// Convert the matrix to flat.
        /// </summary>
        ///
        /// <param name="matrix">The matrix.</param>
        /// <param name="flat">Flat array.</param>
        /// <param name="start">WHere to start.</param>
        public void MatrixToFlat(double[][] matrix, double[] flat,
                                 int start)
        {
            int rows = matrix.Length;
            int cols = matrix[0].Length;

            int index = start;

            for (int r = 0; r < rows; r++)
            {
                for (int c = 0; c < cols; c++)
                {
                    flat[index++] = matrix[r][c];
                }
            }
        }

        /// <inheritdoc/>
        public override TrainingContinuation Pause()
        {
            return null;
        }

        /// <inheritdoc/>
        public override void Resume(TrainingContinuation state)
        {
        }
    }

    public class PersistRBFNetwork : ISyntPersistor
    {
        #region SyntPersistor Members

        /// <inheritdoc/>
        public virtual int FileVersion
        {
            get { return 1; }
        }


        /// <inheritdoc/>
        public virtual String PersistClassString
        {
            get { return "RBFNetwork"; }
        }


        /// <inheritdoc/>
        public Object Read(Stream mask0)
        {
            var result = new RBFNetwork();
            var flat = (FlatNetworkRBF)result.Flat;

            var ins0 = new SyntReadHelper(mask0);
            SyntFileSection section;

            while ((section = ins0.ReadNextSection()) != null)
            {
                if (section.SectionName.Equals("RBF-NETWORK")
                    && section.SubSectionName.Equals("PARAMS"))
                {
                    IDictionary<String, String> paras = section.ParseParams();
                    EngineArray.PutAll(paras, result.Properties);
                }
                if (section.SectionName.Equals("RBF-NETWORK")
                    && section.SubSectionName.Equals("NETWORK"))
                {
                    IDictionary<String, String> p = section.ParseParams();

                    flat.BeginTraining = SyntFileSection.ParseInt(p,
                                                                   BasicNetwork.TagBeginTraining);
                    flat.ConnectionLimit = SyntFileSection.ParseDouble(p,
                                                                        BasicNetwork.TagConnectionLimit);
                    flat.ContextTargetOffset = SyntFileSection.ParseIntArray(
                        p, BasicNetwork.TagContextTargetOffset);
                    flat.ContextTargetSize = SyntFileSection.ParseIntArray(
                        p, BasicNetwork.TagContextTargetSize);
                    flat.EndTraining = SyntFileSection.ParseInt(p,
                                                                 BasicNetwork.TagEndTraining);
                    flat.HasContext = SyntFileSection.ParseBoolean(p,
                                                                    BasicNetwork.TagHasContext);
                    flat.InputCount = SyntFileSection.ParseInt(p,
                                                                PersistConst.InputCount);
                    flat.LayerCounts = SyntFileSection.ParseIntArray(p,
                                                                      BasicNetwork.TagLayerCounts);
                    flat.LayerFeedCounts = SyntFileSection.ParseIntArray(p,
                                                                          BasicNetwork.TagLayerFeedCounts);
                    flat.LayerContextCount = SyntFileSection.ParseIntArray(p, BasicNetwork.TagLayerContextCount);
                    flat.LayerIndex = SyntFileSection.ParseIntArray(p,
                                                                     BasicNetwork.TagLayerIndex);
                    flat.LayerOutput = section.ParseDoubleArray(p,
                                                                         PersistConst.Output);
                    flat.LayerSums = new double[flat.LayerOutput.Length];
                    flat.OutputCount = SyntFileSection.ParseInt(p, PersistConst.OutputCount);
                    flat.WeightIndex = SyntFileSection.ParseIntArray(p,
                                                                      BasicNetwork.TagWeightIndex);
                    flat.Weights = section.ParseDoubleArray(p,
                                                                     PersistConst.Weights);
                    flat.BiasActivation = section.ParseDoubleArray(p, BasicNetwork.TagBiasActivation);
                }
                else if (section.SectionName.Equals("RBF-NETWORK")
                         && section.SubSectionName.Equals("ACTIVATION"))
                {
                    int index = 0;

                    flat.ActivationFunctions = new IActivationFunction[flat.LayerCounts.Length];


                    foreach (String line in section.Lines)
                    {
                        IActivationFunction af;
                        IList<String> cols = SyntFileSection
                            .SplitColumns(line);
                        String name = ReflectionUtil.AfPath
                                      + cols[0];
                        try
                        {
                            af = (IActivationFunction)ReflectionUtil.LoadObject(name);
                        }
                        catch (Exception e)
                        {
                            throw new PersistError(e);
                        }
                        for (int i = 0; i < af.ParamNames.Length; i++)
                        {
                            af.Params[i] = CSVFormat.EgFormat.Parse(cols[i + 1]);
                        }

                        flat.ActivationFunctions[index++] = af;
                    }
                }
                else if (section.SectionName.Equals("RBF-NETWORK")
                         && section.SubSectionName.Equals("RBF"))
                {
                    int index = 0;

                    int hiddenCount = flat.LayerCounts[1];
                    int inputCount = flat.LayerCounts[2];

                    flat.RBF = new IRadialBasisFunction[hiddenCount];


                    foreach (String line in section.Lines)
                    {
                        IRadialBasisFunction rbf;
                        IList<String> cols = SyntFileSection
                            .SplitColumns(line);
                        String name = ReflectionUtil.RBFPath + cols[0];
                        try
                        {
                            rbf = (IRadialBasisFunction)ReflectionUtil.LoadObject(name);
                        }
                        catch (TypeLoadException ex)
                        {
                            throw new PersistError(ex);
                        }
                        catch (TargetException ex)
                        {
                            throw new PersistError(ex);
                        }
                        catch (MemberAccessException ex)
                        {
                            throw new PersistError(ex);
                        }

                        rbf.Width = CSVFormat.EgFormat.Parse(cols[1]);
                        rbf.Peak = CSVFormat.EgFormat.Parse(cols[2]);
                        rbf.Centers = new double[inputCount];

                        for (int i = 0; i < inputCount; i++)
                        {
                            rbf.Centers[i] = CSVFormat.EgFormat.Parse(cols[i + 3]);
                        }

                        flat.RBF[index++] = rbf;
                    }
                }
            }

            return result;
        }

        /// <inheritdoc/>
        public void Save(Stream os, Object obj)
        {
            var xout = new SyntWriteHelper(os);
            var net = (RBFNetwork)obj;
            var flat = (FlatNetworkRBF)net.Flat;
            xout.AddSection("RBF-NETWORK");
            xout.AddSubSection("PARAMS");
            xout.AddProperties(net.Properties);
            xout.AddSubSection("NETWORK");
            xout.WriteProperty(BasicNetwork.TagBeginTraining,
                               flat.BeginTraining);
            xout.WriteProperty(BasicNetwork.TagConnectionLimit,
                               flat.ConnectionLimit);
            xout.WriteProperty(BasicNetwork.TagContextTargetOffset,
                               flat.ContextTargetOffset);
            xout.WriteProperty(BasicNetwork.TagContextTargetSize,
                               flat.ContextTargetSize);
            xout.WriteProperty(BasicNetwork.TagEndTraining, flat.EndTraining);
            xout.WriteProperty(BasicNetwork.TagHasContext, flat.HasContext);
            xout.WriteProperty(PersistConst.InputCount, flat.InputCount);
            xout.WriteProperty(BasicNetwork.TagLayerCounts, flat.LayerCounts);
            xout.WriteProperty(BasicNetwork.TagLayerFeedCounts,
                               flat.LayerFeedCounts);
            xout.WriteProperty(BasicNetwork.TagLayerContextCount,
                               flat.LayerContextCount);
            xout.WriteProperty(BasicNetwork.TagLayerIndex, flat.LayerIndex);
            xout.WriteProperty(PersistConst.Output, flat.LayerOutput);
            xout.WriteProperty(PersistConst.OutputCount, flat.OutputCount);
            xout.WriteProperty(BasicNetwork.TagWeightIndex, flat.WeightIndex);
            xout.WriteProperty(PersistConst.Weights, flat.Weights);
            xout.WriteProperty(BasicNetwork.TagBiasActivation,
                               flat.BiasActivation);
            xout.AddSubSection("ACTIVATION");

            foreach (IActivationFunction af in flat.ActivationFunctions)
            {
                xout.AddColumn(af.GetType().Name);
                foreach (double t in af.Params)
                {
                    xout.AddColumn(t);
                }
                xout.WriteLine();
            }
            xout.AddSubSection("RBF");

            foreach (IRadialBasisFunction rbf in flat.RBF)
            {
                xout.AddColumn(rbf.GetType().Name);
                xout.AddColumn(rbf.Width);
                xout.AddColumn(rbf.Peak);
                foreach (double t in rbf.Centers)
                {
                    xout.AddColumn(t);
                }
                xout.WriteLine();
            }

            xout.Flush();
        }

        /// <inheritdoc/>
        public Type NativeType
        {
            get { return typeof(RBFNetwork); }
        }

        #endregion
    }

    public class SOMClusterCopyTraining : BasicTraining
    {
        /// <summary>
        /// The SOM to train.
        /// </summary>
        ///
        private readonly SOMNetwork _network;

        /// <summary>
        /// Construct the object.
        /// </summary>
        ///
        /// <param name="network">The network to train.</param>
        /// <param name="training">The training data.</param>
        public SOMClusterCopyTraining(SOMNetwork network, IMLDataSet training)
            : base(TrainingImplementationType.OnePass)
        {
            _network = network;
            Training = training;
            if (_network.OutputCount < training.Count)
            {
                throw new NeuralNetworkError(
                        "To use cluster copy training you must have at least as many output neurons as training elements.");
            }
        }

        /// <inheritdoc />
        public override sealed bool CanContinue
        {
            get { return false; }
        }

        /// <inheritdoc/>
        public override IMLMethod Method
        {
            get { return _network; }
        }

        /// <summary>
        /// Copy the specified input pattern to the weight matrix. This causes an
        /// output neuron to learn this pattern "exactly". This is useful when a
        /// winner is to be forced.
        /// </summary>
        ///
        /// <param name="outputNeuron">The output neuron to set.</param>
        /// <param name="input">The input pattern to copy.</param>
        private void CopyInputPattern(int outputNeuron, IMLData input)
        {
            for (int inputNeuron = 0; inputNeuron < _network.InputCount; inputNeuron++)
            {
                _network.Weights[inputNeuron, outputNeuron] = input[inputNeuron];
            }
        }


        /// <summary>
        /// 
        /// </summary>
        ///
        public override sealed void Iteration()
        {
            int outputNeuron = 0;

            foreach (IMLDataPair pair in Training)
            {
                CopyInputPattern(outputNeuron++, pair.Input);
            }
        }

        /// <summary>
        /// 
        /// </summary>
        ///
        public override sealed TrainingContinuation Pause()
        {
            return null;
        }

        /// <summary>
        /// 
        /// </summary>
        ///
        public override void Resume(TrainingContinuation state)
        {
        }
    }

    public class BasicTrainSOM : BasicTraining, ILearningRate
    {
        /// <summary>
        /// Utility class used to determine the BMU.
        /// </summary>
        private readonly BestMatchingUnit _bmuUtil;

        /// <summary>
        /// Holds the corrections for any matrix being trained.
        /// </summary>
        private readonly Matrix _correctionMatrix;

        /// <summary>
        /// How many neurons in the input layer.
        /// </summary>
        private readonly int _inputNeuronCount;

        /// <summary>
        /// The neighborhood function to use to determine to what degree a neuron
        /// should be "trained".
        /// </summary>
        private readonly INeighborhoodFunction _neighborhood;

        /// <summary>
        /// The network being trained.
        /// </summary>
        private readonly SOMNetwork _network;

        /// <summary>
        /// How many neurons in the output layer.
        /// </summary>
        private readonly int _outputNeuronCount;

        /// <summary>
        /// This is the current autodecay radius.
        /// </summary>
        private double _autoDecayRadius;

        /// <summary>
        /// This is the current autodecay learning rate.
        /// </summary>
        private double _autoDecayRate;

        /// <summary>
        /// When used with autodecay, this is the ending radius.
        /// </summary>
        private double _endRadius;

        /// <summary>
        /// When used with autodecay, this is the ending learning rate.
        /// </summary>
        private double _endRate;

        /// <summary>
        /// The current radius.
        /// </summary>
        private double _radius;

        /// <summary>
        /// When used with autodecay, this is the starting radius.
        /// </summary>
        private double _startRadius;

        /// <summary>
        /// When used with autodecay, this is the starting learning rate.
        /// </summary>
        private double _startRate;

        /// <summary>
        /// Create an instance of competitive training.
        /// </summary>
        /// <param name="network">The network to train.</param>
        /// <param name="learningRate">The learning rate, how much to apply per iteration.</param>
        /// <param name="training">The training set (unsupervised).</param>
        /// <param name="neighborhood">The neighborhood function to use.</param>
        public BasicTrainSOM(SOMNetwork network, double learningRate,
                             IMLDataSet training, INeighborhoodFunction neighborhood)
            : base(TrainingImplementationType.Iterative)
        {
            _neighborhood = neighborhood;
            Training = training;
            LearningRate = learningRate;
            _network = network;
            _inputNeuronCount = network.InputCount;
            _outputNeuronCount = network.OutputCount;
            ForceWinner = false;

            // setup the correction matrix
            _correctionMatrix = new Matrix(_outputNeuronCount, _inputNeuronCount);

            // create the BMU class
            _bmuUtil = new BestMatchingUnit(network);
        }

        /// <summary>
        /// True is a winner is to be forced, see class description, or forceWinners
        /// method. By default, this is true.
        /// </summary>
        public bool ForceWinner { get; set; }

        /// <inheritdoc/>
        public override bool CanContinue
        {
            get { return false; }
        }

        /// <summary>
        /// The input neuron count.
        /// </summary>
        public int InputNeuronCount
        {
            get { return _inputNeuronCount; }
        }

        /// <inheritdoc/>
        public override IMLMethod Method
        {
            get { return _network; }
        }

        /// <summary>
        /// The network neighborhood function.
        /// </summary>
        public INeighborhoodFunction Neighborhood
        {
            get { return _neighborhood; }
        }

        /// <summary>
        /// The output neuron count.
        /// </summary>
        public int OutputNeuronCount
        {
            get { return _outputNeuronCount; }
        }

        #region ILearningRate Members

        /// <summary>
        /// The learning rate. To what degree should changes be applied.
        /// </summary>
        public double LearningRate { get; set; }

        #endregion

        /// <summary>
        /// Loop over the synapses to be trained and apply any corrections that were
        /// determined by this training iteration.
        /// </summary>
        private void ApplyCorrection()
        {
            _network.Weights.Set(_correctionMatrix);
        }

        /// <summary>
        /// Should be called each iteration if autodecay is desired.
        /// </summary>
        public void AutoDecay()
        {
            if (_radius > _endRadius)
            {
                _radius += _autoDecayRadius;
            }

            if (LearningRate > _endRate)
            {
                LearningRate += _autoDecayRate;
            }
            _neighborhood.Radius = _radius;
        }


        /// <summary>
        /// Copy the specified input pattern to the weight matrix. This causes an
        /// output neuron to learn this pattern "exactly". This is useful when a
        /// winner is to be forced.
        /// </summary>
        /// <param name="matrix">The matrix that is the target of the copy.</param>
        /// <param name="outputNeuron">The output neuron to set.</param>
        /// <param name="input">The input pattern to copy.</param>
        private void CopyInputPattern(Matrix matrix, int outputNeuron,
                                      IMLData input)
        {
            for (int inputNeuron = 0; inputNeuron < _inputNeuronCount; inputNeuron++)
            {
                matrix.Data[outputNeuron][inputNeuron] = input[inputNeuron];
            }
        }

        /// <summary>
        /// Called to decay the learning rate and radius by the specified amount.
        /// </summary>
        /// <param name="d">The percent to decay by.</param>
        public void Decay(double d)
        {
            _radius *= (1.0 - d);
            LearningRate *= (1.0 - d);
        }

        /// <summary>
        /// Decay the learning rate and radius by the specified amount.
        /// </summary>
        /// <param name="decayRate">The percent to decay the learning rate by.</param>
        /// <param name="decayRadius">The percent to decay the radius by.</param>
        public void Decay(double decayRate, double decayRadius)
        {
            _radius *= (1.0 - decayRadius);
            LearningRate *= (1.0 - decayRate);
            _neighborhood.Radius = _radius;
        }

        /// <summary>
        /// Determine the weight adjustment for a single neuron during a training
        /// iteration.
        /// </summary>
        /// <param name="weight">The starting weight.</param>
        /// <param name="input">The input to this neuron.</param>
        /// <param name="currentNeuron">The neuron who's weight is being updated.</param>
        /// <param name="bmu">The neuron that "won", the best matching unit.</param>
        /// <returns>The new weight value.</returns>
        private double DetermineNewWeight(double weight, double input,
                                          int currentNeuron, int bmu)
        {
            double newWeight = weight
                               + (_neighborhood.Function(currentNeuron, bmu)
                                  * LearningRate * (input - weight));
            return newWeight;
        }

        /// <summary>
        /// Force any neurons that did not win to off-load patterns from overworked
        /// neurons.
        /// </summary>
        /// <param name="matrix">The synapse to modify.</param>
        /// <param name="won">An array that specifies how many times each output neuron has "won".</param>
        /// <param name="leastRepresented">The training pattern that is the least represented by this neural network.</param>
        /// <returns>True if a winner was forced.</returns>
        private bool ForceWinners(Matrix matrix, int[] won,
                                  IMLData leastRepresented)
        {
            double maxActivation = Double.NegativeInfinity;
            int maxActivationNeuron = -1;

            IMLData output = Compute(_network, leastRepresented);

            // Loop over all of the output neurons. Consider any neurons that were
            // not the BMU (winner) for any pattern. Track which of these
            // non-winning neurons had the highest activation.
            for (int outputNeuron = 0; outputNeuron < won.Length; outputNeuron++)
            {
                // Only consider neurons that did not "win".
                if (won[outputNeuron] == 0)
                {
                    if ((maxActivationNeuron == -1)
                        || (output[outputNeuron] > maxActivation))
                    {
                        maxActivation = output[outputNeuron];
                        maxActivationNeuron = outputNeuron;
                    }
                }
            }

            // If a neurons was found that did not activate for any patterns, then
            // force it to "win" the least represented pattern.
            if (maxActivationNeuron != -1)
            {
                CopyInputPattern(matrix, maxActivationNeuron, leastRepresented);
                return true;
            }
            return false;
        }


        /// <summary>
        /// Perform one training iteration.
        /// </summary>
        public override void Iteration()
        {
            SyntLogging.Log(SyntLogging.LevelInfo,
                             "Performing SOM Training iteration.");

            PreIteration();

            // Reset the BMU and begin this iteration.
            _bmuUtil.Reset();
            var won = new int[_outputNeuronCount];
            double leastRepresentedActivation = Double.PositiveInfinity;
            IMLData leastRepresented = null;

            // Reset the correction matrix for this synapse and iteration.
            _correctionMatrix.Clear();

            // Determine the BMU for each training element.
            foreach (IMLDataPair pair in Training)
            {
                IMLData input = pair.Input;

                int bmu = _bmuUtil.CalculateBMU(input);
                won[bmu]++;

                // If we are to force a winner each time, then track how many
                // times each output neuron becomes the BMU (winner).
                if (ForceWinner)
                {
                    // Get the "output" from the network for this pattern. This
                    // gets the activation level of the BMU.
                    IMLData output = Compute(_network, pair.Input);

                    // Track which training entry produces the least BMU. This
                    // pattern is the least represented by the network.
                    if (output[bmu] < leastRepresentedActivation)
                    {
                        leastRepresentedActivation = output[bmu];
                        leastRepresented = pair.Input;
                    }
                }

                Train(bmu, _network.Weights, input);

                if (ForceWinner)
                {
                    // force any non-winning neurons to share the burden somewhat\
                    if (!ForceWinners(_network.Weights, won,
                                      leastRepresented))
                    {
                        ApplyCorrection();
                    }
                }
                else
                {
                    ApplyCorrection();
                }
            }

            // update the error
            Error = _bmuUtil.WorstDistance / 100.0;

            PostIteration();
        }

        /// <inheritdoc/>
        public override TrainingContinuation Pause()
        {
            return null;
        }

        /// <inheritdoc/>
        public override void Resume(TrainingContinuation state)
        {
        }

        /// <summary>
        /// Setup autodecay. This will decrease the radius and learning rate from the
        /// start values to the end values.
        /// </summary>
        /// <param name="plannedIterations">The number of iterations that are planned. This allows the
        /// decay rate to be determined.</param>
        /// <param name="startRate">The starting learning rate.</param>
        /// <param name="endRate">The ending learning rate.</param>
        /// <param name="startRadius">The starting radius.</param>
        /// <param name="endRadius">The ending radius.</param>
        public void SetAutoDecay(int plannedIterations,
                                 double startRate, double endRate,
                                 double startRadius, double endRadius)
        {
            _startRate = startRate;
            _endRate = endRate;
            _startRadius = startRadius;
            _endRadius = endRadius;
            _autoDecayRadius = (endRadius - startRadius) / plannedIterations;
            _autoDecayRate = (endRate - startRate) / plannedIterations;
            SetParams(_startRate, _startRadius);
        }

        /// <summary>
        /// Set the learning rate and radius.
        /// </summary>
        /// <param name="rate">The new learning rate.</param>
        /// <param name="radius">The new radius.</param>
        public void SetParams(double rate, double radius)
        {
            _radius = radius;
            LearningRate = rate;
            _neighborhood.Radius = radius;
        }

        /// <inheritdoc/>
        public override String ToString()
        {
            var result = new StringBuilder();
            result.Append("Rate=");
            result.Append(Format.FormatPercent(LearningRate));
            result.Append(", Radius=");
            result.Append(Format.FormatDouble(_radius, 2));
            return result.ToString();
        }

        /// <summary>
        /// Train for the specified synapse and BMU.
        /// </summary>
        /// <param name="bmu">The best matching unit for this input.</param>
        /// <param name="matrix">The synapse to train.</param>
        /// <param name="input">The input to train for.</param>
        private void Train(int bmu, Matrix matrix, IMLData input)
        {
            // adjust the weight for the BMU and its neighborhood
            for (int outputNeuron = 0; outputNeuron < _outputNeuronCount; outputNeuron++)
            {
                TrainPattern(matrix, input, outputNeuron, bmu);
            }
        }

        /// <summary>
        /// Train for the specified pattern.
        /// </summary>
        /// <param name="matrix">The synapse to train.</param>
        /// <param name="input">The input pattern to train for.</param>
        /// <param name="current">The current output neuron being trained.</param>
        /// <param name="bmu">The best matching unit, or winning output neuron.</param>
        private void TrainPattern(Matrix matrix, IMLData input,
                                  int current, int bmu)
        {
            for (int inputNeuron = 0; inputNeuron < _inputNeuronCount; inputNeuron++)
            {
                double currentWeight = matrix.Data[current][inputNeuron];
                double inputValue = input[inputNeuron];

                double newWeight = DetermineNewWeight(currentWeight,
                                                      inputValue, current, bmu);

                _correctionMatrix.Data[current][inputNeuron] = newWeight;
            }
        }

        /// <summary>
        /// Train the specified pattern. Find a winning neuron and adjust all neurons
        /// according to the neighborhood function.
        /// </summary>
        /// <param name="pattern">The pattern to train.</param>
        public void TrainPattern(IMLData pattern)
        {
            IMLData input = pattern;
            int bmu = _bmuUtil.CalculateBMU(input);
            Train(bmu, _network.Weights, input);
            ApplyCorrection();
        }

        /// <summary>
        /// Calculate the output of the SOM, for each output neuron.  Typically,
        /// you will use the classify method instead of calling this method.
        /// </summary>
        /// <param name="som">The SOM to use.</param>
        /// <param name="input">The input.</param>
        /// <returns>The output.</returns>
        private static IMLData Compute(SOMNetwork som, IMLData input)
        {
            IMLData result = new BasicMLData(som.OutputCount);

            for (int i = 0; i < som.OutputCount; i++)
            {
                Matrix optr = som.Weights.GetRow(i);
                Matrix inputMatrix = Matrix.CreateRowMatrix(input.Data);
                result[i] = MatrixMath.DotProduct(inputMatrix, optr);
            }

            return result;
        }
    }

    public class BestMatchingUnit
    {
        /// <summary>
        /// The owner of this class.
        /// </summary>
        ///
        private readonly SOMNetwork _som;

        /// <summary>
        /// What is the worst BMU distance so far, this becomes the error for the
        /// entire SOM.
        /// </summary>
        ///
        private double _worstDistance;

        /// <summary>
        /// Construct a BestMatchingUnit class.  The training class must be provided.
        /// </summary>
        ///
        /// <param name="som">The SOM to evaluate.</param>
        public BestMatchingUnit(SOMNetwork som)
        {
            _som = som;
        }

        /// <value>What is the worst BMU distance so far, this becomes the error 
        /// for the entire SOM.</value>
        public double WorstDistance
        {
            get { return _worstDistance; }
        }

        /// <summary>
        /// Calculate the best matching unit (BMU). This is the output neuron that
        /// has the lowest Euclidean distance to the input vector.
        /// </summary>
        ///
        /// <param name="input">The input vector.</param>
        /// <returns>The output neuron number that is the BMU.</returns>
        public int CalculateBMU(IMLData input)
        {
            int result = 0;

            // Track the lowest distance so far.
            double lowestDistance = Double.MaxValue;

            for (int i = 0; i < _som.OutputCount; i++)
            {
                double distance = CalculateEuclideanDistance(
                    _som.Weights, input, i);

                // Track the lowest distance, this is the BMU.
                if (distance < lowestDistance)
                {
                    lowestDistance = distance;
                    result = i;
                }
            }

            // Track the worst distance, this is the error for the entire network.
            if (lowestDistance > _worstDistance)
            {
                _worstDistance = lowestDistance;
            }

            return result;
        }

        /// <summary>
        /// Calculate the Euclidean distance for the specified output neuron and the
        /// input vector.  This is the square root of the squares of the differences
        /// between the weight and input vectors.
        /// </summary>
        ///
        /// <param name="matrix">The matrix to get the weights from.</param>
        /// <param name="input">The input vector.</param>
        /// <param name="outputNeuron">The neuron we are calculating the distance for.</param>
        /// <returns>The Euclidean distance.</returns>
        public double CalculateEuclideanDistance(Matrix matrix,
                                                 IMLData input, int outputNeuron)
        {
            double result = 0;

            // Loop over all input data.
            for (int i = 0; i < input.Count; i++)
            {
                double diff = input[i] - matrix[outputNeuron, i];
                result += diff * diff;
            }
            return BoundMath.Sqrt(result);
        }


        /// <summary>
        /// Reset the "worst distance" back to a minimum value.  This should be
        /// called for each training iteration.
        /// </summary>
        ///
        public void Reset()
        {
            _worstDistance = Double.MinValue;
        }
    }

    public class NeighborhoodBubble : INeighborhoodFunction
    {
        /// <summary>
        /// The radius of the bubble.
        /// </summary>
        ///
        private double _radius;

        /// <summary>
        /// Create a bubble neighborhood function that will return 1.0 (full update)
        /// for any neuron that is plus or minus the width distance from the winning
        /// neuron.
        /// </summary>
        ///
        /// <param name="radius">bubble, is actually two times this parameter.</param>
        public NeighborhoodBubble(int radius)
        {
            _radius = radius;
        }

        #region INeighborhoodFunction Members

        /// <summary>
        /// Determine how much the current neuron should be affected by training
        /// based on its proximity to the winning neuron.
        /// </summary>
        ///
        /// <param name="currentNeuron">THe current neuron being evaluated.</param>
        /// <param name="bestNeuron">The winning neuron.</param>
        /// <returns>The ratio for this neuron's adjustment.</returns>
        public double Function(int currentNeuron, int bestNeuron)
        {
            int distance = Math.Abs(bestNeuron - currentNeuron);
            if (distance <= _radius)
            {
                return 1.0d;
            }
            return 0.0d;
        }

        /// <summary>
        /// Set the radius.
        /// </summary>
        public virtual double Radius
        {
            get { return _radius; }
            set { _radius = value; }
        }

        #endregion
    }

    public class NeighborhoodRBF : INeighborhoodFunction
    {
        /// <summary>
        /// The radial basis function to use.
        /// </summary>
        ///
        private readonly IRadialBasisFunction _rbf;

        /// <summary>
        /// The size of each dimension.
        /// </summary>
        ///
        private readonly int[] _size;

        /// <summary>
        /// The displacement of each dimension, when mapping the dimensions
        /// to a 1d array.
        /// </summary>
        ///
        private int[] _displacement;

        /// <summary>
        /// Construct a 2d neighborhood function based on the sizes for the
        /// x and y dimensions.
        /// </summary>
        ///
        /// <param name="type">The RBF type to use.</param>
        /// <param name="x">The size of the x-dimension.</param>
        /// <param name="y">The size of the y-dimension.</param>
        public NeighborhoodRBF(RBFEnum type, int x, int y)
        {
            var size = new int[2];
            size[0] = x;
            size[1] = y;

            var centerArray = new double[2];
            centerArray[0] = 0;
            centerArray[1] = 0;

            var widthArray = new double[2];
            widthArray[0] = 1;
            widthArray[1] = 1;

            switch (type)
            {
                case RBFEnum.Gaussian:
                    _rbf = new GaussianFunction(2);
                    break;
                case RBFEnum.InverseMultiquadric:
                    _rbf = new InverseMultiquadricFunction(2);
                    break;
                case RBFEnum.Multiquadric:
                    _rbf = new MultiquadricFunction(2);
                    break;
                case RBFEnum.MexicanHat:
                    _rbf = new MexicanHatFunction(2);
                    break;
            }

            _rbf.Width = 1;
            EngineArray.ArrayCopy(centerArray, _rbf.Centers);

            _size = size;

            CalculateDisplacement();
        }

        /// <summary>
        /// Construct a multi-dimensional neighborhood function.
        /// </summary>
        ///
        /// <param name="size">The sizes of each dimension.</param>
        /// <param name="type">The RBF type to use.</param>
        public NeighborhoodRBF(int[] size, RBFEnum type)
        {
            switch (type)
            {
                case RBFEnum.Gaussian:
                    _rbf = new GaussianFunction(2);
                    break;
                case RBFEnum.InverseMultiquadric:
                    _rbf = new InverseMultiquadricFunction(2);
                    break;
                case RBFEnum.Multiquadric:
                    _rbf = new MultiquadricFunction(2);
                    break;
                case RBFEnum.MexicanHat:
                    _rbf = new MexicanHatFunction(2);
                    break;
            }
            _size = size;
            CalculateDisplacement();
        }

        /// <value>The RBF to use.</value>
        public IRadialBasisFunction RBF
        {
            get { return _rbf; }
        }

        #region INeighborhoodFunction Members

        /// <summary>
        /// Calculate the value for the multi RBF function.
        /// </summary>
        ///
        /// <param name="currentNeuron">The current neuron.</param>
        /// <param name="bestNeuron">The best neuron.</param>
        /// <returns>A percent that determines the amount of training the current
        /// neuron should get.  Usually 100% when it is the bestNeuron.</returns>
        public virtual double Function(int currentNeuron, int bestNeuron)
        {
            var vector = new double[_displacement.Length];
            int[] vectorCurrent = TranslateCoordinates(currentNeuron);
            int[] vectorBest = TranslateCoordinates(bestNeuron);
            for (int i = 0; i < vectorCurrent.Length; i++)
            {
                vector[i] = vectorCurrent[i] - vectorBest[i];
            }
            return _rbf.Calculate(vector);
        }

        /// <summary>
        /// Set the radius.
        /// </summary>
        public virtual double Radius
        {
            get { return _rbf.Width; }
            set { _rbf.Width = value; }
        }

        #endregion

        /// <summary>
        /// Calculate all of the displacement values.
        /// </summary>
        ///
        private void CalculateDisplacement()
        {
            _displacement = new int[_size.Length];
            for (int i = 0; i < _size.Length; i++)
            {
                int v;

                if (i == 0)
                {
                    v = 0;
                }
                else if (i == 1)
                {
                    v = _size[0];
                }
                else
                {
                    v = _displacement[i - 1] * _size[i - 1];
                }

                _displacement[i] = v;
            }
        }


        /// <summary>
        /// Translate the specified index into a set of multi-dimensional
        /// coordinates that represent the same index.  This is how the
        /// multi-dimensional coordinates are translated into a one dimensional
        /// index for the input neurons.
        /// </summary>
        ///
        /// <param name="index">The index to translate.</param>
        /// <returns>The multi-dimensional coordinates.</returns>
        private int[] TranslateCoordinates(int index)
        {
            var result = new int[_displacement.Length];
            int countingIndex = index;

            for (int i = _displacement.Length - 1; i >= 0; i--)
            {
                int v;
                if (_displacement[i] > 0)
                {
                    v = countingIndex / _displacement[i];
                }
                else
                {
                    v = countingIndex;
                }

                countingIndex -= _displacement[i] * v;
                result[i] = v;
            }

            return result;
        }
    }

    public class NeighborhoodRBF1D : INeighborhoodFunction
    {
        /// <summary>
        /// The radial basis function (RBF) to use to calculate the training falloff
        /// from the best neuron.
        /// </summary>
        ///
        private readonly IRadialBasisFunction _radial;

        /// <summary>
        /// Construct the neighborhood function with the specified radial function.
        /// Generally this will be a Gaussian function but any RBF should do.
        /// </summary>
        ///
        /// <param name="radial">The radial basis function to use.</param>
        public NeighborhoodRBF1D(IRadialBasisFunction radial)
        {
            _radial = radial;
        }

        /// <summary>
        /// Construct a 1d neighborhood function.
        /// </summary>
        ///
        /// <param name="type">The RBF type to use.</param>
        public NeighborhoodRBF1D(RBFEnum type)
        {
            switch (type)
            {
                case RBFEnum.Gaussian:
                    _radial = new GaussianFunction(1);
                    break;
                case RBFEnum.InverseMultiquadric:
                    _radial = new InverseMultiquadricFunction(1);
                    break;
                case RBFEnum.Multiquadric:
                    _radial = new MultiquadricFunction(1);
                    break;
                case RBFEnum.MexicanHat:
                    _radial = new MexicanHatFunction(1);
                    break;
                default:
                    throw new NeuralNetworkError("Unknown RBF type: " + type);
            }

            _radial.Width = 1.0d;
        }

        #region INeighborhoodFunction Members

        /// <summary>
        /// Compute the RBF function.
        /// </summary>
        /// <param name="currentNeuron">The current neuron.</param>
        /// <param name="bestNeuron">The best neuron.</param>
        /// <returns>The distance.</returns>
        public virtual double Function(int currentNeuron, int bestNeuron)
        {
            var d = new double[1];
            d[0] = currentNeuron - bestNeuron;
            return _radial.Calculate(d);
        }

        /// <summary>
        /// Set the radius.
        /// </summary>
        ///
        /// <value>The new radius.</value>
        public virtual double Radius
        {
            get { return _radial.Width; }
            set { _radial.Width = value; }
        }

        #endregion
    }

    public class NeighborhoodSingle : INeighborhoodFunction
    {
        #region INeighborhoodFunction Members

        /// <summary>
        /// Determine how much the current neuron should be affected by training
        /// based on its proximity to the winning neuron.
        /// </summary>
        ///
        /// <param name="currentNeuron">THe current neuron being evaluated.</param>
        /// <param name="bestNeuron">The winning neuron.</param>
        /// <returns>The ratio for this neuron's adjustment.</returns>
        public virtual double Function(int currentNeuron, int bestNeuron)
        {
            if (currentNeuron == bestNeuron)
            {
                return 1.0d;
            }
            return 0.0d;
        }

        /// <summary>
        /// Set the radius.  This type does not use a radius, so this has no effect.
        /// </summary>
        ///
        /// <value>The radius.</value>
        public virtual double Radius
        {
            get { return 1; }
            set
            {
                // no effect on this type
            }
        }

        #endregion
    }

    public class PersistSOM : ISyntPersistor
    {
        /**
	 * {@inheritDoc}
	 */

        #region ISyntPersistor Members

        public int FileVersion
        {
            get { return 1; }
        }

        /**
	 * {@inheritDoc}
	 */

        public String PersistClassString
        {
            get { return "SOMNetwork"; }
        }


        /**
	 * {@inheritDoc}
	 */

        public Object Read(Stream istream)
        {
            var result = new SOMNetwork();
            var reader = new SyntReadHelper(istream);
            SyntFileSection section;

            while ((section = reader.ReadNextSection()) != null)
            {
                if (section.SectionName.Equals("SOM")
                    && section.SubSectionName.Equals("PARAMS"))
                {
                    IDictionary<String, String> p = section.ParseParams();
                    EngineArray.PutAll(p, result.Properties);
                }
                if (section.SectionName.Equals("SOM")
                    && section.SubSectionName.Equals("NETWORK"))
                {
                    IDictionary<String, String> p = section.ParseParams();
                    result.Weights = SyntFileSection.ParseMatrix(p,
                                                                  PersistConst.Weights)
                        ;
                }
            }

            return result;
        }

        /**
	 * {@inheritDoc}
	 */

        public void Save(Stream os, Object obj)
        {
            var writer = new SyntWriteHelper(os);
            var som = (SOMNetwork)obj;
            writer.AddSection("SOM");
            writer.AddSubSection("PARAMS");
            writer.AddProperties(som.Properties);
            writer.AddSubSection("NETWORK");
            writer.WriteProperty(PersistConst.Weights, som.Weights);
            writer.WriteProperty(PersistConst.InputCount, som.InputCount);
            writer.WriteProperty(PersistConst.OutputCount, som.OutputCount);
            writer.Flush();
        }


        public Type NativeType
        {
            get { return typeof(SOMNetwork); }
        }

        #endregion
    }

    [Serializable]
    public class SOMNetwork : BasicML, IMLClassification, IMLResettable,
                             IMLError
    {
        /// <summary>
        /// The weights of the output neurons base on the input from the input
	    /// neurons.
        /// </summary>
        private Matrix _weights;

        /// <summary>
        /// Default constructor.
        /// </summary>
        public SOMNetwork()
        {
        }

        /// <summary>
        /// The constructor.
        /// </summary>
        /// <param name="inputCount">Number of input neurons</param>
        /// <param name="outputCount">Number of output neurons</param>
        public SOMNetwork(int inputCount, int outputCount)
        {
            _weights = new Matrix(outputCount, inputCount);
        }

        /// <summary>
        /// The weights.
        /// </summary>
        public Matrix Weights
        {
            get { return _weights; }
            set { _weights = value; }
        }

        /// <summary>
        /// Classify the input into one of the output clusters.
        /// </summary>
        /// <param name="input">The input.</param>
        /// <returns>The cluster it was clasified into.</returns>
        public int Classify(IMLData input)
        {
            if (input.Count > InputCount)
            {
                throw new NeuralNetworkError(
                    "Can't classify SOM with input size of " + InputCount
                    + " with input data of count " + input.Count);
            }

            double[][] m = _weights.Data;
            double[] inputData = input.Data;
            double minDist = Double.PositiveInfinity;
            int result = -1;

            for (int i = 0; i < OutputCount; i++)
            {
                double dist = EngineArray.EuclideanDistance(inputData, m[i]);
                if (dist < minDist)
                {
                    minDist = dist;
                    result = i;
                }
            }

            return result;
        }

        /// <inheritdoc/>
        public int InputCount
        {
            get { return _weights.Cols; }
        }

        /// <inheritdoc/>
        public int OutputCount
        {
            get { return _weights.Rows; }
        }

        /// <summary>
        /// Calculate the error for the specified data set. The error is the largest distance.
        /// </summary>
        /// <param name="data">The data set to check.</param>
        /// <returns>The error.</returns>
        public double CalculateError(IMLDataSet data)
        {
            var bmu = new BestMatchingUnit(this);

            bmu.Reset();

            // Determine the BMU for each training element.
            foreach (IMLDataPair pair in data)
            {
                IMLData input = pair.Input;
                bmu.CalculateBMU(input);
            }

            // update the error
            return bmu.WorstDistance / 100.0;
        }

        /// <summary>
        /// Randomize the network.
        /// </summary>
        public void Reset()
        {
            _weights.Randomize(-1, 1);
        }

        /// <summary>
        /// Randomize the network.
        /// </summary>
        /// <param name="seed">Not used.</param>
        public void Reset(int seed)
        {
            Reset();
        }

        /// <summary>
        /// Not used.
        /// </summary>
        public override void UpdateProperties()
        {
            // unneeded
        }

        /// <summary>
        /// An alias for the classify method, kept for compatibility 
	    /// with earlier versions of Synt.
        /// </summary>
        /// <param name="input">The input pattern.</param>
        /// <returns>The winning neuron.</returns>
        public int Winner(IMLData input)
        {
            return Classify(input);
        }
    }

    [Serializable]
    public class BoltzmannMachine : ThermalNetwork
    {
        /// <summary>
        /// The property for run cycles.
        /// </summary>
        ///
        public const String ParamRunCycles = "runCycles";

        /// <summary>
        /// The property for anneal cycles.
        /// </summary>
        ///
        public const String ParamAnnealCycles = "annealCycles";

        /// <summary>
        /// The number of cycles to anneal for.
        /// </summary>
        ///
        private int _annealCycles;

        /// <summary>
        /// Count used to internally determine if a neuron is "off".
        /// </summary>
        [NonSerialized]
        private int[] _off;

        /// <summary>
        /// Count used to internally determine if a neuron is "on".
        /// </summary>
        [NonSerialized]
        private int[] _on;

        /// <summary>
        /// The number of cycles to run the network through before annealing.
        /// </summary>
        ///
        private int _runCycles;

        /// <summary>
        /// The current temperature of the neural network. The higher the
        /// temperature, the more random the network will behave.
        /// </summary>
        ///
        private double _temperature;

        /// <summary>
        /// The thresholds.
        /// </summary>
        ///
        private double[] _threshold;

        /// <summary>
        /// Default constructors.
        /// </summary>
        ///
        public BoltzmannMachine()
        {
            _annealCycles = 100;
            _runCycles = 1000;
        }

        /// <summary>
        /// Construct a Boltzmann machine with the specified number of neurons.
        /// </summary>
        public BoltzmannMachine(int neuronCount) : base(neuronCount)
        {
            _annealCycles = 100;
            _runCycles = 1000;

            _threshold = new double[neuronCount];
        }


        /// <value>the annealCycles to set</value>
        public int AnnealCycles
        {
            get { return _annealCycles; }
            set { _annealCycles = value; }
        }


        /// <inheritdoc/>
        public override int InputCount
        {
            get { return NeuronCount; }
        }



        /// <inheritdoc/>
        public override int OutputCount
        {
            get { return NeuronCount; }
        }


        /// <value>the runCycles to set</value>
        public int RunCycles
        {
            get { return _runCycles; }
            set { _runCycles = value; }
        }


        /// <summary>
        /// Set the network temperature.
        /// </summary>
        public double Temperature
        {
            get { return _temperature; }
            set { _temperature = value; }
        }


        /// <summary>
        /// Set the thresholds.
        /// </summary>
        public double[] Threshold
        {
            get { return _threshold; }
            set { _threshold = value; }
        }

        /// <summary>
        /// Note: for Boltzmann networks, you will usually want to call the "run"
        /// method to compute the output.
        /// This method can be used to copy the input data to the current state. A
        /// single iteration is then run, and the new current state is returned.
        /// </summary>
        ///
        /// <param name="input">The input pattern.</param>
        /// <returns>The new current state.</returns>
        public override sealed IMLData Compute(IMLData input)
        {
            var result = new BiPolarMLData(input.Count);
            EngineArray.ArrayCopy(input.Data, CurrentState.Data);
            Run();
            EngineArray.ArrayCopy(CurrentState.Data, result.Data);
            return result;
        }

        /// <summary>
        /// Decrease the temperature by the specified amount.
        /// </summary>
        ///
        /// <param name="d">The amount to decrease by.</param>
        public void DecreaseTemperature(double d)
        {
            _temperature *= d;
        }

        /// <summary>
        /// Run the network until thermal equilibrium is established.
        /// </summary>
        ///
        public void EstablishEquilibrium()
        {
            int count = NeuronCount;

            if (_on == null)
            {
                _on = new int[count];
                _off = new int[count];
            }

            for (int i = 0; i < count; i++)
            {
                _on[i] = 0;
                _off[i] = 0;
            }

            for (int n = 0; n < _runCycles * count; n++)
            {
                Run((int)RangeRandomizer.Randomize(0, count - 1));
            }
            for (int n = 0; n < _annealCycles * count; n++)
            {
                var i = (int)RangeRandomizer.Randomize(0, count - 1);
                Run(i);
                if (CurrentState.GetBoolean(i))
                {
                    _on[i]++;
                }
                else
                {
                    _off[i]++;
                }
            }

            for (int i = 0; i < count; i++)
            {
                CurrentState.SetBoolean(i, _on[i] > _off[i]);
            }
        }


        /// <summary>
        /// Run the network for all neurons present.
        /// </summary>
        ///
        public void Run()
        {
            int count = NeuronCount;
            for (int i = 0; i < count; i++)
            {
                Run(i);
            }
        }

        /// <summary>
        /// Run the network for the specified neuron.
        /// </summary>
        ///
        /// <param name="i">The neuron to run for.</param>
        public void Run(int i)
        {
            int j;

            int count = NeuronCount;

            double sum = 0;
            for (j = 0; j < count; j++)
            {
                sum += GetWeight(i, j) * ((CurrentState.GetBoolean(j)) ? 1 : 0);
            }
            sum -= _threshold[i];
            double probability = 1 / (1 + BoundMath.Exp(-sum / _temperature));
            CurrentState.SetBoolean(i, RangeRandomizer.Randomize(0, 1) <= probability);
        }

        /// <summary>
        /// 
        /// </summary>
        ///
        public override void UpdateProperties()
        {
            // nothing needed here
        }
    }

    [Serializable]
    public class HopfieldNetwork : ThermalNetwork
    {
        /// <summary>
        /// Default constructor.
        /// </summary>
        ///
        public HopfieldNetwork()
        {
        }

        /// <summary>
        /// Construct a Hopfield with the specified neuron count.
        /// </summary>
        ///
        /// <param name="neuronCount">The neuron count.</param>
        public HopfieldNetwork(int neuronCount) : base(neuronCount)
        {
        }

        /// <inheritdoc/>
        public override int InputCount
        {
            get { return NeuronCount; }
        }


        /// <inheritdoc/>
        public override int OutputCount
        {
            get { return NeuronCount; }
        }

        /// <summary>
        /// Train the neural network for the specified pattern. The neural network
        /// can be trained for more than one pattern. To do this simply call the
        /// train method more than once.
        /// </summary>
        ///
        /// <param name="pattern">The pattern to train for.</param>
        public void AddPattern(IMLData pattern)
        {
            if (pattern.Count != NeuronCount)
            {
                throw new NeuralNetworkError("Network with " + NeuronCount
                                             + " neurons, cannot learn a pattern of size "
                                             + pattern.Count);
            }

            // Create a row matrix from the input, convert boolean to bipolar
            Matrix m2 = Matrix.CreateRowMatrix(pattern.Data);
            // Transpose the matrix and multiply by the original input matrix
            Matrix m1 = MatrixMath.Transpose(m2);
            Matrix m3 = MatrixMath.Multiply(m1, m2);

            // matrix 3 should be square by now, so create an identity
            // matrix of the same size.
            Matrix identity = MatrixMath.Identity(m3.Rows);

            // subtract the identity matrix
            Matrix m4 = MatrixMath.Subtract(m3, identity);

            // now add the calculated matrix, for this pattern, to the
            // existing weight matrix.
            ConvertHopfieldMatrix(m4);
        }

        /// <summary>
        /// Note: for Hopfield networks, you will usually want to call the "run"
        /// method to compute the output.
        /// This method can be used to copy the input data to the current state. A
        /// single iteration is then run, and the new current state is returned.
        /// </summary>
        ///
        /// <param name="input">The input pattern.</param>
        /// <returns>The new current state.</returns>
        public override sealed IMLData Compute(IMLData input)
        {
            var result = new BiPolarMLData(input.Count);
            EngineArray.ArrayCopy(input.Data, CurrentState.Data);
            Run();

            for (int i = 0; i < CurrentState.Count; i++)
            {
                result.SetBoolean(i,
                                  BiPolarUtil.Double2bipolar(CurrentState[i]));
            }
            EngineArray.ArrayCopy(CurrentState.Data, result.Data);
            return result;
        }

        /// <summary>
        /// Update the Hopfield weights after training.
        /// </summary>
        ///
        /// <param name="delta">The amount to change the weights by.</param>
        private void ConvertHopfieldMatrix(Matrix delta)
        {
            // add the new weight matrix to what is there already
            for (int row = 0; row < delta.Rows; row++)
            {
                for (int col = 0; col < delta.Rows; col++)
                {
                    AddWeight(row, col, delta[row, col]);
                }
            }
        }


        /// <summary>
        /// Perform one Hopfield iteration.
        /// </summary>
        ///
        public void Run()
        {
            for (int toNeuron = 0; toNeuron < NeuronCount; toNeuron++)
            {
                double sum = 0;
                for (int fromNeuron = 0; fromNeuron < NeuronCount; fromNeuron++)
                {
                    sum += CurrentState[fromNeuron]
                           * GetWeight(fromNeuron, toNeuron);
                }
                CurrentState[toNeuron] = sum;
            }
        }

        /// <summary>
        /// Run the network until it becomes stable and does not change from more
        /// runs.
        /// </summary>
        ///
        /// <param name="max">The maximum number of cycles to run before giving up.</param>
        /// <returns>The number of cycles that were run.</returns>
        public int RunUntilStable(int max)
        {
            bool done = false;
            String currentStateStr = (CurrentState.ToString());

            int cycle = 0;
            do
            {
                Run();
                cycle++;

                String lastStateStr = (CurrentState.ToString());

                if (!currentStateStr.Equals(lastStateStr))
                {
                    if (cycle > max)
                    {
                        done = true;
                    }
                }
                else
                {
                    done = true;
                }

                currentStateStr = lastStateStr;
            } while (!done);

            return cycle;
        }

        /// <summary>
        /// 
        /// </summary>
        ///
        public override void UpdateProperties()
        {
            // nothing needed here
        }
    }

    public class PersistBoltzmann : ISyntPersistor
    {
        #region SyntPersistor Members

        /// <inheritdoc/>
        public virtual int FileVersion
        {
            get { return 1; }
        }


        /// <inheritdoc/>
        public virtual String PersistClassString
        {
            get { return "BoltzmannMachine"; }
        }


        /// <inheritdoc/>
        public Object Read(Stream mask0)
        {
            var result = new BoltzmannMachine();
            var ins0 = new SyntReadHelper(mask0);
            SyntFileSection section;

            while ((section = ins0.ReadNextSection()) != null)
            {
                if (section.SectionName.Equals("BOLTZMANN")
                    && section.SubSectionName.Equals("PARAMS"))
                {
                    IDictionary<String, String> paras = section.ParseParams();
                    EngineArray.PutAll(paras, result.Properties);
                }
                if (section.SectionName.Equals("BOLTZMANN")
                    && section.SubSectionName.Equals("NETWORK"))
                {
                    IDictionary<String, String> p = section.ParseParams();
                    result.Weights = NumberList.FromList(CSVFormat.EgFormat,
                                                         (p[PersistConst.Weights]));
                    result.SetCurrentState(NumberList.FromList(CSVFormat.EgFormat,
                                                               (p[PersistConst.Output])));
                    result.NeuronCount = SyntFileSection.ParseInt(p,
                                                                   PersistConst.NeuronCount);

                    result.Threshold = NumberList.FromList(CSVFormat.EgFormat,
                                                           (p[PersistConst.Thresholds]));
                    result.AnnealCycles = SyntFileSection.ParseInt(p,
                                                                    BoltzmannMachine.ParamAnnealCycles);
                    result.RunCycles = SyntFileSection.ParseInt(p,
                                                                 BoltzmannMachine.ParamRunCycles);
                    result.Temperature = SyntFileSection.ParseDouble(p,
                                                                      PersistConst.Temperature);
                }
            }

            return result;
        }

        /// <inheritdoc/>
        public void Save(Stream os, Object obj)
        {
            var xout = new SyntWriteHelper(os);
            var boltz = (BoltzmannMachine)obj;
            xout.AddSection("BOLTZMANN");
            xout.AddSubSection("PARAMS");
            xout.AddProperties(boltz.Properties);
            xout.AddSubSection("NETWORK");
            xout.WriteProperty(PersistConst.Weights, boltz.Weights);
            xout.WriteProperty(PersistConst.Output, boltz.CurrentState.Data);
            xout.WriteProperty(PersistConst.NeuronCount, boltz.NeuronCount);

            xout.WriteProperty(PersistConst.Thresholds, boltz.Threshold);
            xout.WriteProperty(BoltzmannMachine.ParamAnnealCycles,
                               boltz.AnnealCycles);
            xout.WriteProperty(BoltzmannMachine.ParamRunCycles, boltz.RunCycles);
            xout.WriteProperty(PersistConst.Temperature, boltz.Temperature);

            xout.Flush();
        }

        /// <inheritdoc/>
        public Type NativeType
        {
            get { return typeof(BoltzmannMachine); }
        }

        #endregion
    }

    public class PersistHopfield : ISyntPersistor
    {
        #region SyntPersistor Members

        /// <summary>
        /// The file version.
        /// </summary>
        public virtual int FileVersion
        {
            get { return 1; }
        }


        /// <summary>
        /// The class string.
        /// </summary>
        ///
        public virtual String PersistClassString
        {
            get { return typeof(HopfieldNetwork).Name; }
        }


        /// <summary>
        /// Read a an object.
        /// </summary>
        public Object Read(Stream mask0)
        {
            var result = new HopfieldNetwork();
            var ins0 = new SyntReadHelper(mask0);
            SyntFileSection section;

            while ((section = ins0.ReadNextSection()) != null)
            {
                if (section.SectionName.Equals("HOPFIELD")
                    && section.SubSectionName.Equals("PARAMS"))
                {
                    IDictionary<String, String> paras = section.ParseParams();
                    EngineArray.PutAll(paras, result.Properties);
                }
                if (section.SectionName.Equals("HOPFIELD")
                    && section.SubSectionName.Equals("NETWORK"))
                {
                    IDictionary<String, String> p = section.ParseParams();
                    result.Weights = NumberList.FromList(CSVFormat.EgFormat,
                                                         (p[PersistConst.Weights]));
                    result.SetCurrentState(NumberList.FromList(CSVFormat.EgFormat,
                                                               (p[PersistConst.Output])));
                    result.NeuronCount = SyntFileSection.ParseInt(p,
                                                                   PersistConst.NeuronCount);
                }
            }

            return result;
        }

        /// <summary>
        /// 
        /// </summary>
        ///
        public void Save(Stream os, Object obj)
        {
            var xout = new SyntWriteHelper(os);
            var hopfield = (HopfieldNetwork)obj;
            xout.AddSection("HOPFIELD");
            xout.AddSubSection("PARAMS");
            xout.AddProperties(hopfield.Properties);
            xout.AddSubSection("NETWORK");
            xout.WriteProperty(PersistConst.Weights, hopfield.Weights);
            xout.WriteProperty(PersistConst.Output, hopfield.CurrentState.Data);
            xout.WriteProperty(PersistConst.NeuronCount, hopfield.NeuronCount);
            xout.Flush();
        }

        /// <inheritdoc/>
        public Type NativeType
        {
            get { return typeof(HopfieldNetwork); }
        }

        #endregion
    }

    public class NeuralNetworkError : SyntError
    {
        /// <summary>
        /// Construct a message exception.
        /// </summary>
        /// <param name="str">The message.</param>
        public NeuralNetworkError(String str)
            : base(str)
        {
        }

        /// <summary>
        /// Pass on an exception.
        /// </summary>
        /// <param name="e">The other exception.</param>
        public NeuralNetworkError(Exception e)
            : base(e)
        {
        }

        /// <summary>
        /// Pass on an exception.
        /// </summary>
        /// <param name="msg">The message.</param>
        /// <param name="e">The exception.</param>
        public NeuralNetworkError(String msg, Exception e)
            : base(msg, e)
        {
        }
    }

    public class ReadHTML : ReadTags
    {
        /// <summary>
        /// Construct a HTML reader.
        /// </summary>
        /// <param name="istream">The input stream to read from.</param>
        public ReadHTML(Stream istream) : base(istream)
        {
        }

        /// <summary>
        /// Parse the attribute name.
        /// </summary>
        /// <returns>The attribute name.</returns>
        protected String ParseAttributeName()
        {
            String result = base.ParseAttributeName();
            return result.ToLower();
        }
    }

    public class ReadTags
    {
        /// <summary>
        /// The bullet character.
        /// </summary>
        public int CharBullet = 149;

        /// <summary>
        /// The bullet character.
        /// </summary>
        public int CharTrademark = 129;

        /// <summary>
        /// Maximum length string to read.
        /// </summary>
        public int MaxLength = 10000;

        /// <summary>
        /// A mapping of certain HTML Syntesisd values to their actual
        /// character values.
        /// </summary>
        private static IDictionary<string, char> _charMap;

        /// <summary>
        /// The stream that we are parsing from.
        /// </summary>
        private readonly PeekableInputStream _source;

        /// <summary>
        /// The current HTML tag. Access this property if the read function returns
        /// 0.
        /// </summary>
        private readonly Tag _tag = new Tag();


        /// <summary>
        /// Are we locked, looking for an end tag?  Such as the end of a
        /// comment?
        /// </summary>
        private string _lockedEndTag;

        /// <summary>
        /// Does a "fake" end-tag need to be added, because of a compound
        /// tag (i.e. <br/>)?  If so, this will hold a string for that tag.
        /// </summary>
        private string _insertEndTag;

        /// <summary>
        /// The constructor should be passed an InputStream that we will parse from.
        /// </summary>
        /// <param name="istream">A stream to parse from.</param>
        public ReadTags(Stream istream)
        {
            _source = new PeekableInputStream(istream);

            if (_charMap == null)
            {
                _charMap = new Dictionary<string, char>();
                _charMap["nbsp"] = ' ';
                _charMap["lt"] = '<';
                _charMap["gt"] = '>';
                _charMap["amp"] = '&';
                _charMap["quot"] = '\"';
                _charMap["bull"] = (char)CharBullet;
                _charMap["trade"] = (char)CharTrademark;
            }
        }

        /// <summary>
        /// Remove any whitespace characters that are next in the InputStream.
        /// </summary>
        protected void EatWhitespace()
        {
            while (char.IsWhiteSpace((char)_source.Peek()))
            {
                _source.Read();
            }
        }

        /// <summary>
        /// Return the last tag found, this is normally called just after the read
        /// function returns a zero.
        /// </summary>
        public Tag LastTag
        {
            get { return _tag; }
        }

        /// <summary>
        /// Checks to see if the next tag is the tag specified.
        /// </summary>
        /// <param name="name">The name of the tag desired.</param>
        /// <param name="start">True if a starting tag is desired.</param>
        /// <returns>True if the next tag matches these criteria.</returns>
        public bool IsIt(string name, bool start)
        {
            if (!LastTag.Name.Equals(name))
            {
                return false;
            }

            if (start)
            {
                return LastTag.TagType == Tag.Type.Begin;
            }
            return LastTag.TagType == Tag.Type.End;
        }

        /// <summary>
        /// Parse an attribute name, if one is present.
        /// </summary>
        /// <returns>Return the attribute name, or null if none present.</returns>
        protected string ParseAttributeName()
        {
            EatWhitespace();

            if ("\"\'".IndexOf((char)_source.Peek()) == -1)
            {
                var buffer = new StringBuilder();
                while (!char.IsWhiteSpace((char)_source.Peek())
                       && (_source.Peek() != '=')
                       && (_source.Peek() != '>')
                       && (_source.Peek() != -1))
                {
                    int ch = ParseSpecialCharacter();
                    buffer.Append((char)ch);
                }
                return buffer.ToString();
            }
            return (ParseString());
        }

        /// <summary>
        /// Parse any special characters
        /// </summary>
        /// <returns>The character that was parsed.</returns>
        private char ParseSpecialCharacter()
        {
            var result = (char)_source.Read();
            int advanceBy = 0;

            // is there a special character?
            if (result == '&')
            {
                int ch;
                var buffer = new StringBuilder();

                // loop through and read special character
                do
                {
                    ch = _source.Peek(advanceBy++);
                    if ((ch != '&') && (ch != ';') && !char.IsWhiteSpace((char)ch))
                    {
                        buffer.Append((char)ch);
                    }
                } while ((ch != ';') && (ch != -1) && !char.IsWhiteSpace((char)ch));

                string b = buffer.ToString().Trim().ToLower();

                // did we find a special character?
                if (b.Length > 0)
                {
                    if (b[0] == '#')
                    {
                        try
                        {
                            result = (char)int.Parse(b.Substring(1));
                        }
                        catch (Exception)
                        {
                            advanceBy = 0;
                        }
                    }
                    else
                    {
                        if (_charMap.ContainsKey(b))
                        {
                            result = _charMap[b];
                        }
                        else
                        {
                            advanceBy = 0;
                        }
                    }
                }
                else
                {
                    advanceBy = 0;
                }
            }

            while (advanceBy > 0)
            {
                Read();
                advanceBy--;
            }

            return result;
        }

        /// <summary>
        /// Called to parse a double or single quote string.
        /// </summary>
        /// <returns>The string parsed.</returns>
        protected string ParseString()
        {
            var result = new StringBuilder();
            EatWhitespace();
            if ("\"\'".IndexOf((char)_source.Peek()) != -1)
            {
                int delim = _source.Read();
                while ((_source.Peek() != delim)
                       && (_source.Peek() != -1))
                {
                    if (result.Length > MaxLength)
                    {
                        break;
                    }
                    int ch = ParseSpecialCharacter();
                    if ((ch == '\r') || (ch == '\n'))
                    {
                        continue;
                    }
                    result.Append((char)ch);
                }
                if ("\"\'".IndexOf((char)_source.Peek()) != -1)
                {
                    _source.Read();
                }
            }
            else
            {
                while (!char.IsWhiteSpace((char)_source.Peek())
                       && (_source.Peek() != -1)
                       && (_source.Peek() != '>'))
                {
                    result.Append(ParseSpecialCharacter());
                }
            }

            return result.ToString();
        }

        /// <summary>
        /// Called when a tag is detected. This method will parse the tag.
        /// </summary>
        protected void ParseTag()
        {
            _tag.Clear();
            _insertEndTag = null;
            var tagName = new StringBuilder();

            _source.Read();

            // Is it a comment?
            if (_source.Peek(TagConst.CommentBegin))
            {
                _source.Skip(TagConst.CommentBegin.Length);
                while (!_source.Peek(TagConst.CommentEnd))
                {
                    int ch = _source.Read();
                    if (ch != -1)
                    {
                        tagName.Append((char)ch);
                    }
                    else
                    {
                        break;
                    }
                }
                _source.Skip(TagConst.CommentEnd.Length);
                _tag.TagType = Tag.Type.Comment;
                _tag.Name = tagName.ToString();
                return;
            }

            // Is it CDATA?
            if (_source.Peek(TagConst.CDATABegin))
            {
                _source.Skip(TagConst.CDATABegin.Length);
                while (!_source.Peek(TagConst.CDATAEnd))
                {
                    int ch = _source.Read();
                    if (ch != -1)
                    {
                        tagName.Append((char)ch);
                    }
                    else
                    {
                        break;
                    }
                }
                _source.Skip(TagConst.CDATAEnd.Length);
                _tag.TagType = Tag.Type.CDATA;
                _tag.Name = tagName.ToString();
                return;
            }

            // Find the tag name
            while (_source.Peek() != -1)
            {
                // if this is the end of the tag, then stop
                if (char.IsWhiteSpace((char)_source.Peek())
                    || (_source.Peek() == '>'))
                {
                    break;
                }

                // if this is both a begin and end tag then stop
                if ((tagName.Length > 0) && (_source.Peek() == '/'))
                {
                    break;
                }

                tagName.Append((char)_source.Read());
            }

            EatWhitespace();

            if (tagName[0] == '/')
            {
                _tag.Name = tagName.ToString().Substring(1);
                _tag.TagType = Tag.Type.End;
            }
            else
            {
                _tag.Name = tagName.ToString();
                _tag.TagType = Tag.Type.Begin;
            }
            // get the attributes

            while ((_source.Peek() != '>') && (_source.Peek() != -1))
            {
                string attributeName = ParseAttributeName();
                string attributeValue = null;

                if (attributeName.Equals("/"))
                {
                    EatWhitespace();
                    if (_source.Peek() == '>')
                    {
                        _insertEndTag = _tag.Name;
                        break;
                    }
                }

                // is there a value?
                EatWhitespace();
                if (_source.Peek() == '=')
                {
                    _source.Read();
                    attributeValue = ParseString();
                }

                _tag.SetAttribute(attributeName, attributeValue);
            }
            _source.Read();
        }

        /// <summary>
        /// Check to see if the ending tag is present.
        /// </summary>
        /// <param name="name">The type of end tag being sought.</param>
        /// <returns>True if the ending tag was found.</returns>
        private bool PeekEndTag(IEnumerable<char> name)
        {
            int i = 0;

            // pass any whitespace
            while ((_source.Peek(i) != -1)
                   && char.IsWhiteSpace((char)_source.Peek(i)))
            {
                i++;
            }

            // is a tag beginning
            if (_source.Peek(i) != '<')
            {
                return false;
            }
            i++;

            // pass any whitespace
            while ((_source.Peek(i) != -1)
                   && char.IsWhiteSpace((char)_source.Peek(i)))
            {
                i++;
            }

            // is it an end tag
            if (_source.Peek(i) != '/')
            {
                return false;
            }
            i++;

            // pass any whitespace
            while ((_source.Peek(i) != -1)
                   && char.IsWhiteSpace((char)_source.Peek(i)))
            {
                i++;
            }

            // does the name match
            foreach (char t in name)
            {
                if (char.ToLower((char)_source.Peek(i)) != char
                                                                .ToLower(t))
                {
                    return false;
                }
                i++;
            }

            return true;
        }

        /// <summary>
        /// Read a single character from the HTML source, if this function returns
        /// zero(0) then you should call getTag to see what tag was found. Otherwise
        /// the value returned is simply the next character found.
        /// </summary>
        /// <returns>The character read, or zero if there is an HTML tag. If zero is
        /// returned, then call getTag to get the next tag.</returns>
        public int Read()
        {
            // handle inserting a "virtual" end tag
            if (_insertEndTag != null)
            {
                _tag.Clear();
                _tag.Name = _insertEndTag;
                _tag.TagType = Tag.Type.End;
                _insertEndTag = null;
                return 0;
            }

            // handle locked end tag
            if (_lockedEndTag != null)
            {
                if (PeekEndTag(_lockedEndTag))
                {
                    _lockedEndTag = null;
                }
                else
                {
                    return _source.Read();
                }
            }

            // look for next tag
            if (_source.Peek() == '<')
            {
                ParseTag();

                if ((_tag.TagType == Tag.Type.Begin)
                    && ((StringUtil.EqualsIgnoreCase(_tag.Name, "script"))
                        || (StringUtil.EqualsIgnoreCase(_tag.Name, "style"))))
                {
                    _lockedEndTag = _tag.Name.ToLower();
                }
                return 0;
            }
            if (_source.Peek() == '&')
            {
                return ParseSpecialCharacter();
            }
            return (_source.Read());
        }

        /// <summary>
        /// Read until we reach the next tag.
        /// </summary>
        /// <returns>True if a tag was found, false on EOF.</returns>
        public bool ReadToTag()
        {
            int ch;
            while ((ch = Read()) != -1)
            {
                if (ch == 0)
                {
                    return true;
                }
            }
            return false;
        }

        /// <summary>
        /// Returns this object as a string.
        /// </summary>
        /// <returns>This object as a string.</returns>
        public override string ToString()
        {
            var result = new StringBuilder();
            result.Append("[ReadTags: currentTag=");
            if (_tag != null)
            {
                result.Append(_tag.ToString());
            }
            result.Append("]");
            return result.ToString();
        }
    }

    public class ReadXML : ReadTags
    {

        /// <summary>
        /// Construct an XML reader.
        /// </summary>
        /// <param name="istream">The input stream to read from.</param>
        public ReadXML(Stream istream)
            : base(istream)
        {
        }

        /// <summary>
        /// Advance until the specified tag is found.
        /// </summary>
        /// <param name="name">The name of the tag we are looking for.</param>
        /// <param name="beginTag">True if this is a begin tage, false otherwise.</param>
        /// <returns>True if the tag was found.</returns>
        public bool FindTag(String name, bool beginTag)
        {
            while (ReadToTag())
            {
                if (beginTag)
                {
                    if (LastTag.Name.Equals(name)
                        && (LastTag.TagType == Tag.Type.Begin))
                    {
                        return true;
                    }
                }
                else
                {
                    if (LastTag.Name.Equals(name)
                        && (LastTag.TagType == Tag.Type.End))
                    {
                        return true;
                    }
                }
            }

            return false;
        }

        /// <summary>
        /// Read an integer that is contained between the current position, and the
        /// next tag.
        /// </summary>
        /// <returns>The integer that was found.</returns>
        public int ReadIntToTag()
        {
            try
            {
                String str = ReadTextToTag();
                return int.Parse(str);
            }
            catch (Exception e)
            {
#if logging
                if (logger.IsErrorEnabled)
                {
                    logger.Error("Exception", e);
                }
#endif
                throw new ParseError(e);
            }
        }

        /// <summary>
        /// Read all property data until an end tag, which corrisponds to the current
        /// tag, is found. The properties found will be returned in a map.
        /// </summary>
        /// <returns>The properties found.</returns>
        public IDictionary<String, String> ReadPropertyBlock()
        {
            IDictionary<String, String> result = new Dictionary<String, String>();

            String endingBlock = LastTag.Name;

            while (ReadToTag())
            {
                if (LastTag.Name.Equals(endingBlock)
                    && (LastTag.TagType == Tag.Type.End))
                {
                    break;
                }
                String name = LastTag.Name;
                String value = ReadTextToTag().Trim();
                result[name] = value;
            }

            return result;
        }

        /// <summary>
        /// Read all text between the current position and the next tag.
        /// </summary>
        /// <returns>The string that was read.</returns>
        public String ReadTextToTag()
        {
            var result = new StringBuilder();
            bool done = false;

            while (!done)
            {
                int ch = Read();
                if ((ch == -1) || (ch == 0))
                {
                    done = true;
                }
                else
                {
                    result.Append((char)ch);
                }
            }
            return result.ToString();
        }
    }

    public class WriteTags
    {
        /// <summary>
        /// The output stream to write to.
        /// </summary>
        private readonly Stream _output;

        /// <summary>
        /// Stack to keep track of beginning and ending tags.
        /// </summary>
        private readonly Stack<String> _tagStack;

        /// <summary>
        /// The attributes for the current tag.
        /// </summary>
        private readonly IDictionary<String, String> _attributes;

        /// <summary>
        /// Used to Syntesis strings to bytes.
        /// </summary>
        private readonly StreamWriter _Syntesisr;

        /// <summary>
        /// Construct an object to write tags.
        /// </summary>
        /// <param name="output">THe output stream.</param>
        public WriteTags(Stream output)
        {
            _output = output;
            _tagStack = new Stack<String>();
            _attributes = new Dictionary<String, String>();
            _Syntesisr = new StreamWriter(output);
        }

        /// <summary>
        /// Add an attribute to be written with the next tag.
        /// </summary>
        /// <param name="name">The name of the attribute.</param>
        /// <param name="v">The value of the attribute.</param>
        public void AddAttribute(String name, String v)
        {
            _attributes.Add(name, v);
        }

        /// <summary>
        /// Add CDATA to the output stream. XML allows a large block of unformatted
        /// text to be added as a CDATA tag.
        /// </summary>
        /// <param name="text">The text to add.</param>
        public void AddCDATA(String text)
        {
            var builder = new StringBuilder();
            builder.Append('<');
            builder.Append(TagConst.CDATABegin);
            builder.Append(text);
            builder.Append(TagConst.CDATAEnd);
            builder.Append('>');
            try
            {
                _Syntesisr.Write(builder.ToString());
            }
            catch (IOException e)
            {
                throw new ParseError(e);
            }
        }

        /// <summary>
        /// Add a property as a double. A property is a value enclosed in two tags.
        /// </summary>
        /// <param name="name">The name of the enclosing tags.</param>
        /// <param name="d">The value to store.</param>
        public void AddProperty(String name, double d)
        {
            BeginTag(name);
            AddText("" + d);
            EndTag();
        }

        /// <summary>
        /// Add a property as an integer. A property is a value enclosed in two tags.
        /// </summary>
        /// <param name="name">The name of the enclosing tags.</param>
        /// <param name="i">The value to store.</param>
        public void AddProperty(String name, int i)
        {
            AddProperty(name, "" + i);
        }

        /// <summary>
        /// Add a property as a string. A property is a value enclosed in two tags.
        /// </summary>
        /// <param name="name">The name of the enclosing tags.</param>
        /// <param name="str">The value to store.</param>
        public void AddProperty(String name, String str)
        {
            BeginTag(name);
            AddText(str);
            EndTag();
        }

        /// <summary>
        /// Add text.
        /// </summary>
        /// <param name="text">The text to add.</param>
        public void AddText(String text)
        {
            try
            {
                _Syntesisr.Write(text);
            }
            catch (IOException e)
            {
                throw new ParseError(e);
            }
        }

        /// <summary>
        /// Called to begin the document.
        /// </summary>
        public void BeginDocument()
        {
        }

        /// <summary>
        /// Begin a tag with the specified name.
        /// </summary>
        /// <param name="name">The tag to begin.</param>
        public void BeginTag(String name)
        {
            var builder = new StringBuilder();
            builder.Append("<");
            builder.Append(name);
            if (_attributes.Count > 0)
            {
                foreach (String key in _attributes.Keys)
                {
                    String value = _attributes[key];
                    builder.Append(' ');
                    builder.Append(key);
                    builder.Append('=');
                    builder.Append("\"");
                    builder.Append(value);
                    builder.Append("\"");
                }
            }
            builder.Append(">");

            try
            {
                _Syntesisr.Write(builder.ToString());
            }
            catch (IOException e)
            {
                throw new ParseError(e);
            }
            _attributes.Clear();
            _tagStack.Push(name);
        }

        /// <summary>
        /// Close this object.
        /// </summary>
        public void Close()
        {
            try
            {
                _output.Close();
            }
            catch (Exception e)
            {
                throw new SyntError(e);
            }
        }

        /// <summary>
        /// End the document.
        /// </summary>
        public void EndDocument()
        {
            _Syntesisr.Flush();
        }

        /// <summary>
        /// End the current tag.
        /// </summary>
        public void EndTag()
        {
            if (_tagStack.Count < 1)
            {
                throw new ParseError(
                    "Can't create end tag, no beginning tag.");
            }
            String tag = _tagStack.Pop();

            var builder = new StringBuilder();
            builder.Append("</");
            builder.Append(tag);
            builder.Append(">");

            try
            {
                _Syntesisr.Write(builder.ToString());
            }
            catch (IOException e)
            {
                throw new ParseError(e);
            }
        }

        /// <summary>
        /// Write an array as a property.
        /// </summary>
        /// <param name="name">The name of the property.</param>
        /// <param name="array">The array to write.</param>
        /// <param name="len">The length of the array to write.</param>
        public void AddProperty(String name, double[] array, int len)
        {
            if (array != null)
            {
                var str = new StringBuilder();
                for (int i = 0; i < len; i++)
                {
                    if (i != 0)
                        str.Append(' ');
                    str.Append(array[i]);
                }
                AddProperty(name, str.ToString());
            }
        }

        /// <summary>
        /// Write an array as a property.
        /// </summary>
        /// <param name="name">The name of the property.</param>
        /// <param name="array">The array to write.</param>
        /// <param name="len">The length of the array to write.</param>
        public void AddProperty(String name, int[] array, int len)
        {
            if (array != null)
            {
                var str = new StringBuilder();
                for (int i = 0; i < len; i++)
                {
                    if (i != 0)
                        str.Append(' ');
                    str.Append(array[i]);
                }
                AddProperty(name, str.ToString());
            }
        }


        /// <summary>
        /// End a tag, require that we are ending the specified tag.
        /// </summary>
        /// <param name="name">The tag to be ending.</param>
        public void EndTag(String name)
        {
            if (!_tagStack.Peek().Equals(name))
            {
                String str = "End tag mismatch, should be ending: "
                             + _tagStack.Peek() + ", but trying to end: " + name
                             + ".";
#if logging
                if (logger.IsErrorEnabled)
                {
                    logger.Error(str);
                }
#endif

            }
            EndTag();
        }
    }

    public class WriteXML : WriteTags
    {
        /// <summary>
        /// Construct an object to write an XML file.
        /// </summary>
        /// <param name="os">The output stream.</param>
        public WriteXML(Stream os) : base(os)
        {
        }
    }

    public class Tag
    {
        /// <summary>
        /// Tag types.
        /// </summary>
        public enum Type
        {
            /// <summary>
            /// A beginning tag.
            /// </summary>
            Begin,
            /// <summary>
            /// An ending tag.
            /// </summary>
            End,
            /// <summary>
            /// A comment.
            /// </summary>
            Comment,
            /// <summary>
            /// A CDATA section.
            /// </summary>
            CDATA
        };


        /// <summary>
        /// The tag's attributes.
        /// </summary>
        private readonly IDictionary<String, String> _attributes =
            new Dictionary<String, String>();

        /// <summary>
        /// The tag name.
        /// </summary>
        private String _name = "";

        /// <summary>
        /// The tag type.
        /// </summary>
        private Type _type;

        /// <summary>
        /// Clear the name, type and attributes.
        /// </summary>
        public void Clear()
        {
            _attributes.Clear();
            _name = "";
            _type = Type.Begin;
        }

        /// <summary>
        /// Clone this object.
        /// </summary>
        /// <returns>A cloned copy of the object.</returns>
        public virtual object Clone()
        {
            var result = new Tag { Name = Name, TagType = TagType };
            foreach (String key in _attributes.Keys)
            {
                String value = _attributes[key];
                result.Attributes[key] = value;
            }
            return result;
        }

        /// <summary>
        /// Get the specified attribute as an integer.
        /// </summary>
        /// <param name="attributeId">The attribute name.</param>
        /// <returns>The attribute value.</returns>
        public int GetAttributeInt(String attributeId)
        {
            try
            {
                String str = GetAttributeValue(attributeId);
                return int.Parse(str);
            }
            catch (Exception e)
            {
#if logging
                if (logger.IsErrorEnabled)
                {
                    logger.Error("Exception", e);
                }
#endif
                throw new ParseError(e);
            }
        }


        /// <summary>
        /// The attributes for this tag as a dictionary.
        /// </summary>
        public IDictionary<String, String> Attributes
        {
            get { return _attributes; }
        }

        /// <summary>
        /// Get the value of the specified attribute.
        /// </summary>
        /// <param name="name">The name of an attribute.</param>
        /// <returns>The value of the specified attribute.</returns>
        public String GetAttributeValue(String name)
        {
            if (!_attributes.ContainsKey(name))
                return null;

            return _attributes[name];
        }


        /// <summary>
        /// The tag name.
        /// </summary>
        public String Name
        {
            get { return _name; }
            set { _name = value; }
        }

        /// <summary>
        /// The tag type.
        /// </summary>
        public Type TagType
        {
            get { return _type; }
            set { _type = value; }
        }

        /// <summary>
        /// Set a HTML attribute.
        /// </summary>
        /// <param name="name">The name of the attribute.</param>
        /// <param name="valueRen">The value of the attribute.</param>
        public void SetAttribute(String name, String valueRen)
        {
            _attributes[name] = valueRen;
        }

        /// <summary>
        /// Convert this tag back into string form, with the 
        /// beginning &lt; and ending &gt;.
        /// </summary>
        /// <returns>The Attribute object that was found.</returns>
        public override String ToString()
        {
            var buffer = new StringBuilder("<");

            if (_type == Type.End)
            {
                buffer.Append("/");
            }

            buffer.Append(_name);

            ICollection<String> set = _attributes.Keys;
            foreach (String key in set)
            {
                String value = _attributes[key];
                buffer.Append(' ');

                if (value == null)
                {
                    buffer.Append("\"");
                    buffer.Append(key);
                    buffer.Append("\"");
                }
                else
                {
                    buffer.Append(key);
                    buffer.Append("=\"");
                    buffer.Append(value);
                    buffer.Append("\"");
                }
            }

            buffer.Append(">");
            return buffer.ToString();
        }
    }

    public class TagConst
    {
        /// <summary>
        /// The beginning of a comment.
        /// </summary>
        public const String CommentBegin = "!--";

        /// <summary>
        /// The end of a comment.
        /// </summary>
        public const String CommentEnd = "-->";

        /// <summary>
        /// The beginning of a CDATA section.
        /// </summary>
        public const String CDATABegin = "![CDATA[";

        /// <summary>
        /// The end of a CDATA section.
        /// </summary>
        public const String CDATAEnd = "]]";

        /// <summary>
        /// Private constructor.
        /// </summary>
        private TagConst()
        {
        }
    }

    public class ParseError : SyntError
    {
        /// <summary>
        /// Construct a message exception.
        /// </summary>
        /// <param name="str">The message.</param>
        public ParseError(String str)
            : base(str)
        {
        }

        /// <summary>
        /// Pass on an exception.
        /// </summary>
        /// <param name="e">The other exception.</param>
        public ParseError(Exception e)
            : base(e)
        {
        }
    }

    public class PeekableInputStream : Stream
    {
        /// <summary>
        /// The underlying stream.
        /// </summary>
        private readonly Stream _stream;

        /// <summary>
        /// Bytes that have been peeked at.
        /// </summary>
        private byte[] _peekBytes;

        /// <summary>
        /// How many bytes have been peeked at.
        /// </summary>
        private int _peekLength;

        /// <summary>
        /// Construct a peekable input stream based on the specified stream.
        /// </summary>
        /// <param name="stream">The underlying stream.</param>
        public PeekableInputStream(Stream stream)
        {
            _stream = stream;
            _peekBytes = new byte[10];
            _peekLength = 0;
        }

        /// <summary>
        /// Specifies that the stream can read.
        /// </summary>
        public override bool CanRead
        {
            get { return true; }
        }

        /// <summary>
        /// Specifies that the stream cannot write.
        /// </summary>
        public override bool CanWrite
        {
            get { return false; }
        }

        /// <summary>
        /// Specifies that the stream cannot seek.
        /// </summary>
        public override bool CanSeek
        {
            get { return false; }
        }

        /// <summary>
        /// Specifies that the stream cannot determine its length.
        /// </summary>
        public override long Length
        {
            get { throw new NotSupportedException(); }
        }

        /// <summary>
        /// Specifies that the stream cannot determine its position.
        /// </summary>
        public override long Position
        {
            get { throw new NotSupportedException(); }
            set { throw new NotSupportedException(); }
        }

        /// <summary>
        /// Not supported.
        /// </summary>
        public override void Flush()
        {
            // writing is not supported, so nothing to do here
        }

        /// <summary>
        /// Not supported.
        /// </summary>
        /// <param name="v">The length.</param>
        public override void SetLength(long v)
        {
            throw new NotSupportedException();
        }

        /// <summary>
        /// Not supported.
        /// </summary>
        /// <param name="offset"></param>
        /// <param name="origin"></param>
        /// <returns></returns>
        public override long Seek(long offset, SeekOrigin origin)
        {
            throw new NotSupportedException();
        }

        /// <summary>
        /// Read bytes from the stream.
        /// </summary>
        /// <param name="buffer">The buffer to read the bytes into.</param>
        /// <param name="offset">The offset to begin storing the bytes at.</param>
        /// <param name="count">How many bytes to read.</param>
        /// <returns>The number of bytes read.</returns>
        public override int Read(byte[] buffer, int offset, int count)
        {
            if (_peekLength == 0)
            {
                return _stream.Read(buffer, offset, count);
            }

            for (int i = 0; i < count; i++)
            {
                buffer[offset + i] = Pop();
            }
            return count;
        }

        /// <summary>
        /// Not supported.
        /// </summary>
        /// <param name="buffer"></param>
        /// <param name="offset"></param>
        /// <param name="count"></param>
        public override void Write(byte[] buffer, int offset, int count)
        {
            throw new NotSupportedException();
        }

        /// <summary>
        /// Read a single byte.
        /// </summary>
        /// <returns>The byte read, or -1 for end of stream.</returns>
        public int Read()
        {
            var b = new byte[1];
            int count = Read(b, 0, 1);
            if (count < 1)
                return -1;
            return b[0];
        }

        /// <summary>
        /// Peek ahead the specified depth.
        /// </summary>
        /// <param name="depth">How far to peek ahead.</param>
        /// <returns>The byte read.</returns>
        public int Peek(int depth)
        {
            // does the size of the peek buffer need to be extended?
            if (_peekBytes.Length <= depth)
            {
                var temp = new byte[depth + 10];
                for (int i = 0; i < _peekBytes.Length; i++)
                {
                    temp[i] = _peekBytes[i];
                }
                _peekBytes = temp;
            }

            // does more data need to be read?
            if (depth >= _peekLength)
            {
                int offset = _peekLength;
                int length = (depth - _peekLength) + 1;
                int lengthRead = _stream.Read(_peekBytes, offset, length);

                if (lengthRead < 1)
                {
                    return -1;
                }

                _peekLength = depth + 1;
            }

            return _peekBytes[depth];
        }

        private byte Pop()
        {
            byte result = _peekBytes[0];
            _peekLength--;
            for (int i = 0; i < _peekLength; i++)
            {
                _peekBytes[i] = _peekBytes[i + 1];
            }

            return result;
        }

        /// <summary>
        /// Peek at the next character from the stream.
        /// </summary>
        /// <returns>The next character.</returns>
        public int Peek()
        {
            return Peek(0);
        }


        /// <summary>
        /// Peek ahead and see if the specified string is present.
        /// </summary>
        /// <param name="str">The string we are looking for.</param>
        /// <returns>True if the string was found.</returns>
        public bool Peek(String str)
        {
            return !str.Where((t, i) => Peek(i) != t).Any();
        }


        /// <summary>
        /// Skip the specified number of bytes.
        /// </summary>
        /// <param name="count">The number of bytes to skip.</param>
        /// <returns>The actual number of bytes skipped.</returns>
        public long Skip(long count)
        {
            long count2 = count;
            while (count2 > 0)
            {
                Read();
                count2--;
            }
            return count;
        }
    }

    public class SyntDirectoryPersistence
    {
        /// <summary>
        /// The directory that holds the EG files.
        /// </summary>
        ///
        private readonly FileInfo _parent;

        /// <summary>
        /// Construct the object.
        /// </summary>
        ///
        /// <param name="parent">The directory to use.</param>
        public SyntDirectoryPersistence(FileInfo parent)
        {
            _parent = parent;
        }

        /// <value>The directory.</value>
        public FileInfo Parent
        {
            get { return _parent; }
        }

        /// <summary>
        /// Load the specified object.
        /// </summary>
        ///
        /// <param name="file">The file to load.</param>
        /// <returns>The loaded object.</returns>
        public static Object LoadObject(FileInfo file)
        {
            FileStream fis = null;

            try
            {
                fis = file.OpenRead();
                Object result = LoadObject(fis);

                return result;
            }
            catch (IOException ex)
            {
                throw new PersistError(ex);
            }
            finally
            {
                if (fis != null)
                {
                    try
                    {
                        fis.Close();
                    }
                    catch (IOException e)
                    {
                        SyntLogging.Log(e);
                    }
                }
            }
        }

        /// <summary>
        /// Load an EG object as a reousrce.
        /// </summary>
        /// <param name="res">The resource to load.</param>
        /// <returns>The loaded object.</returns>
        public static Object LoadResourceObject(String res)
        {
            using (Stream s = ResourceLoader.CreateStream(res))
            {
                return LoadObject(s);
            }
        }

        /// <summary>
        /// Load an object from an input stream.
        /// </summary>
        ///
        /// <param name="mask0">The input stream to read from.</param>
        /// <returns>The loaded object.</returns>
        public static Object LoadObject(Stream mask0)
        {
            String header = ReadLine(mask0);
            String[] paras = header.Split(',');

            if (!"Synt".Equals(paras[0]))
            {
                throw new PersistError("Not a valid EG file.");
            }

            String name = paras[1];

            ISyntPersistor p = PersistorRegistry.Instance.GetPersistor(
                name);

            if (p == null)
            {

            }

            if (p.FileVersion < Int32.Parse(paras[4]))
            {

            }

            return p.Read(mask0);
        }

        /// <summary>
        /// Read a line from the input stream.
        /// </summary>
        ///
        /// <param name="mask0">The input stream.</param>
        /// <returns>The line read.</returns>
        private static String ReadLine(Stream mask0)
        {
            try
            {
                var result = new StringBuilder();

                char ch;

                do
                {
                    int b = mask0.ReadByte();
                    if (b == -1)
                    {
                        return result.ToString();
                    }

                    ch = (char)b;

                    if ((ch != 13) && (ch != 10))
                    {
                        result.Append(ch);
                    }
                } while (ch != 10);

                return result.ToString();
            }
            catch (IOException ex)
            {
                throw new PersistError(ex);
            }
        }

        /// <summary>
        /// Save the specified object.
        /// </summary>
        ///
        /// <param name="filename">The filename to save to.</param>
        /// <param name="obj">The Object to save.</param>
        public static void SaveObject(FileInfo filename, Object obj)
        {
            FileStream fos = null;

            try
            {
                filename.Delete();
                fos = filename.OpenWrite();
                SaveObject(fos, obj);
            }
            catch (IOException ex)
            {
                throw new PersistError(ex);
            }
            finally
            {
                try
                {
                    if (fos != null)
                    {
                        fos.Close();
                    }
                }
                catch (IOException e)
                {
                    SyntLogging.Log(e);
                }
            }
        }

        /// <summary>
        /// Save the specified object.
        /// </summary>
        ///
        /// <param name="os">The output stream to write to.</param>
        /// <param name="obj">The object to save.</param>
        public static void SaveObject(Stream os, Object obj)
        {
            try
            {
                ISyntPersistor p = PersistorRegistry.Instance
                    .GetPersistor(obj.GetType());

                if (p == null)
                {
                    throw new PersistError("Do not know how to persist object: "
                                           + obj.GetType().Name);
                }

                os.Flush();
                var pw = new StreamWriter(os);
                DateTime now = DateTime.Now;
                pw.WriteLine("Synt," + p.PersistClassString + ",java,"
                             + SyntFramework.Version + "," + p.FileVersion + ","
                             + (now.Ticks / 10000));
                pw.Flush();
                p.Save(os, obj);
            }
            catch (IOException ex)
            {
                throw new PersistError(ex);
            }
        }

        /// <summary>
        /// Get the type of an Synt object in an EG file, without the 
        /// need to read the entire file.
        /// </summary>
        ///
        /// <param name="name">The filename to read.</param>
        /// <returns>The type.</returns>
        public String GetSyntType(String name)
        {
            try
            {
                var path = new FileInfo(Path.Combine(_parent.FullName, name));
                TextReader br = new StreamReader(path.OpenRead());
                String header = br.ReadLine();
                String[] paras = header.Split(',');
                br.Close();
                return paras[1];
            }
            catch (IOException ex)
            {
                throw new PersistError(ex);
            }
        }


        /// <summary>
        /// Load a file from the directory that this object refers to.
        /// </summary>
        ///
        /// <param name="name">The name to load.</param>
        /// <returns>The object.</returns>
        public Object LoadFromDirectory(String name)
        {
            var path = new FileInfo(Path.Combine(_parent.FullName, name));
            return LoadObject(path);
        }

        /// <summary>
        /// Save a file to the directory that this object refers to.
        /// </summary>
        ///
        /// <param name="name">The name to load.</param>
        /// <param name="obj">The object.</param>
        public void SaveToDirectory(String name, Object obj)
        {
            var path = new FileInfo(Path.Combine(_parent.FullName, name));
            SaveObject(path, obj);
        }
    }

    public class SyntFileSection
    {
        /// <summary>
        /// Any large arrays that were read.
        /// </summary>
        private IList<double[]> _largeArrays = new List<double[]>();

        /// <summary>
        /// The lines in this section/subsection.
        /// </summary>
        ///
        private readonly IList<String> _lines;

        /// <summary>
        /// The name of this section.
        /// </summary>
        ///
        private readonly String _sectionName;

        /// <summary>
        /// The name of this subsection.
        /// </summary>
        ///
        private readonly String _subSectionName;

        /// <summary>
        /// Construct the object.
        /// </summary>
        ///
        /// <param name="theSectionName">The section name.</param>
        /// <param name="theSubSectionName">The sub section name.</param>
        public SyntFileSection(String theSectionName,
                                String theSubSectionName)
        {
            _lines = new List<String>();
            _sectionName = theSectionName;
            _subSectionName = theSubSectionName;
        }


        /// <value>The lines.</value>
        public IList<String> Lines
        {
            get { return _lines; }
        }


        /// <value>All lines separated by a delimiter.</value>
        public String LinesAsString
        {
            get
            {
                var result = new StringBuilder();

                foreach (String line in _lines)
                {
                    result.Append(line);
                    result.Append("\n");
                }
                return result.ToString();
            }
        }


        /// <value>The section name.</value>
        public String SectionName
        {
            get { return _sectionName; }
        }


        /// <value>The section name.</value>
        public String SubSectionName
        {
            get { return _subSectionName; }
        }

        /// <summary>
        /// Parse an activation function from a string.
        /// </summary>
        ///
        /// <param name="paras">The params.</param>
        /// <param name="name">The name of the param to parse.</param>
        /// <returns>The parsed activation function.</returns>
        public static IActivationFunction ParseActivationFunction(
            IDictionary<String, String> paras, String name)
        {
            String v;
            try
            {
                v = paras[name];
                if (v == null)
                {
                    throw new PersistError("Missing property: " + name);
                }

                IActivationFunction af;
                String[] cols = v.Split('|');

                String afName = ReflectionUtil.AfPath
                                + cols[0];
                try
                {
                    af = (IActivationFunction)ReflectionUtil.LoadObject(afName);
                }
                catch (Exception e)
                {
                    throw new PersistError(e);
                }

                for (int i = 0; i < af.ParamNames.Length; i++)
                {
                    af.Params[i] = CSVFormat.EgFormat.Parse(cols[i + 1]);
                }

                return af;
            }
            catch (Exception ex)
            {
                throw new PersistError(ex);
            }
        }

        /// <summary>
        /// Parse a boolean from a name-value collection of params.
        /// </summary>
        ///
        /// <param name="paras">The name-value pairs.</param>
        /// <param name="name">The name to parse.</param>
        /// <returns>The parsed boolean value.</returns>
        public static bool ParseBoolean(IDictionary<String, String> paras,
                                        String name)
        {
            String v = null;
            try
            {
                v = paras[name];
                if (v == null)
                {
                    return true;
                }

                return v.Trim().ToLower()[0] == 't';
            }
            catch (FormatException)
            {
                return false;
            }
        }

        /// <summary>
        /// Parse a double from a name-value collection of params.
        /// </summary>
        ///
        /// <param name="paras">The name-value pairs.</param>
        /// <param name="name">The name to parse.</param>
        /// <returns>The parsed double value.</returns>
        public static double ParseDouble(IDictionary<String, String> paras,
                                         String name)
        {
            String v = null;
            try
            {
                v = paras[name];
                if (v == null)
                {
                    return 0;
                }

                return CSVFormat.EgFormat.Parse(v);
            }
            catch (FormatException)
            {
                return -1;

            }
        }

        /// <summary>
        /// Parse a double array from a name-value collection of params.
        /// </summary>
        ///
        /// <param name="paras">The name-value pairs.</param>
        /// <param name="name">The name to parse.</param>
        /// <returns>The parsed double array value.</returns>
        public double[] ParseDoubleArray(IDictionary<String, String> paras,
                                                String name)
        {
            String v = null;
            try
            {

                if (!paras.ContainsKey(name))
                {
                    return null;
                }

                v = paras[name];

                if (v.StartsWith("##"))
                {
                    int i = int.Parse(v.Substring(2));
                    return _largeArrays[i];
                }
                else
                {
                    return NumberList.FromList(CSVFormat.EgFormat, v);
                }
            }
            catch (FormatException)
            {
                return null;
            }
        }

        /// <summary>
        /// Parse an int from a name-value collection of params.
        /// </summary>
        ///
        /// <param name="paras">The name-value pairs.</param>
        /// <param name="name">The name to parse.</param>
        /// <returns>The parsed int value.</returns>
        public static int ParseInt(IDictionary<string, String> paras,
                                   String name)
        {
            String v = null;
            try
            {
                v = paras[name];
                if (v == null)
                {
                    return -1;
                }

                return Int32.Parse(v);
            }
            catch (FormatException)
            {
                return -1;
            }
        }

        /// <summary>
        /// Parse an int array from a name-value collection of params.
        /// </summary>
        ///
        /// <param name="paras">The name-value pairs.</param>
        /// <param name="name">The name to parse.</param>
        /// <returns>The parsed int array value.</returns>
        public static int[] ParseIntArray(IDictionary<String, String> paras,
                                          String name)
        {
            String v = null;
            try
            {
                v = paras[name];
                if (v == null)
                {
                    return null;
                }

                return NumberList.FromListInt(CSVFormat.EgFormat, v);
            }
            catch (FormatException)
            {
                return null;
            }
        }

        /// <summary>
        /// Parse a matrix from a name-value collection of params.
        /// </summary>
        ///
        /// <param name="paras">The name-value pairs.</param>
        /// <param name="name">The name to parse.</param>
        /// <returns>The parsed matrix value.</returns>
        public static Matrix ParseMatrix(IDictionary<String, String> paras,
                                         String name)
        {
            if (!paras.ContainsKey(name))
            {
                throw new PersistError("Missing property: " + name);
            }

            String line = paras[name];

            double[] d = NumberList.FromList(CSVFormat.EgFormat, line);
            var rows = (int)d[0];
            var cols = (int)d[1];

            var result = new Matrix(rows, cols);

            int index = 2;
            for (int r = 0; r < rows; r++)
            {
                for (int c = 0; c < cols; c++)
                {
                    result[r, c] = d[index++];
                }
            }

            return result;
        }

        /// <summary>
        /// Split a delimited string into columns.
        /// </summary>
        ///
        /// <param name="line">THe string to split.</param>
        /// <returns>The string split.</returns>
        public static IList<String> SplitColumns(String line)
        {
            IList<String> result = new List<String>();
            string[] tok = line.Split(',');
            foreach (string t in tok)
            {
                String str = t.Trim();
                if ((str.Length > 0) && (str[0] == '\"'))
                {
                    str = str.Substring(1);
                    if (str.EndsWith("\""))
                    {
                        str = str.Substring(0, (str.Length - 1) - (0));
                    }
                }
                result.Add(str);
            }
            return result;
        }


        /// <returns>The params.</returns>
        public IDictionary<String, String> ParseParams()
        {
            IDictionary<String, String> result = new Dictionary<String, String>();


            foreach (String line in _lines)
            {
                String line2 = line.Trim();
                if (line2.Length > 0)
                {
                    int idx = line2.IndexOf('=');
                    if (idx == -1)
                    {
                        throw new SyntError("Invalid setup item: " + line);
                    }
                    String name = line2.Substring(0, (idx) - (0)).Trim();
                    String v = line2.Substring(idx + 1).Trim();

                    result[name] = v;
                }
            }

            return result;
        }

        /// <summary>
        /// Large arrays.
        /// </summary>
        public IList<double[]> LargeArrays
        {
            get
            {
                return _largeArrays;
            }
            set
            {
                _largeArrays = value;
            }
        }

        /// <inheritdoc/>
        public override sealed String ToString()
        {
            var result = new StringBuilder("[");
            result.Append(GetType().Name);
            result.Append(" sectionName=");
            result.Append(_sectionName);
            result.Append(", subSectionName=");
            result.Append(_subSectionName);
            result.Append("]");
            return result.ToString();
        }
    }
    [Serializable]
    public class svm_problem
    {
        public int l;
        public double[] y;
        public svm_node[][] x;
    }

    public class SyntReadHelper
    {
        /// <summary>
        /// The lines read from the file.
        /// </summary>
        ///
        private readonly IList<String> lines;

        /// <summary>
        /// The file being read.
        /// </summary>
        ///
        private readonly TextReader reader;

        /// <summary>
        /// The current section name.
        /// </summary>
        ///
        private String currentSectionName;

        /// <summary>
        /// The current subsection name.
        /// </summary>
        ///
        private String currentSubSectionName;

        /// <summary>
        /// The current section name.
        /// </summary>
        ///
        private SyntFileSection section;

        /// <summary>
        /// Construct the object.
        /// </summary>
        ///
        /// <param name="mask0">The input stream.</param>
        public SyntReadHelper(Stream mask0)
        {
            lines = new List<String>();
            currentSectionName = "";
            currentSubSectionName = "";
            reader = new StreamReader(mask0);
        }

        /// <summary>
        /// Close the file.
        /// </summary>
        ///
        public void Close()
        {
            try
            {
                reader.Close();
            }
            catch (IOException e)
            {
                throw new PersistError(e);
            }
        }

        /// <summary>
        /// Read the next section.
        /// </summary>
        ///
        /// <returns>The next section.</returns>
        public SyntFileSection ReadNextSection()
        {
            try
            {
                String line;
                var largeArrays = new List<double[]>();

                while ((line = reader.ReadLine()) != null)
                {
                    line = line.Trim();

                    // is it a comment
                    if (line.StartsWith("//"))
                    {
                        continue;
                    }

                    // is it a section or subsection
                    else if (line.StartsWith("["))
                    {
                        // handle previous section
                        section = new SyntFileSection(
                            currentSectionName, currentSubSectionName);

                        foreach (String str in lines)
                        {
                            section.Lines.Add(str);
                        }


                        // now begin the new section
                        lines.Clear();
                        String s = line.Substring(1).Trim();
                        if (!s.EndsWith("]"))
                        {

                        }
                        s = s.Substring(0, (line.Length - 2) - (0));
                        int idx = s.IndexOf(':');
                        if (idx == -1)
                        {
                            currentSectionName = s;
                            currentSubSectionName = "";
                        }
                        else
                        {
                            if (currentSectionName.Length < 1)
                            {

                            }

                            String newSection = s.Substring(0, (idx) - (0));
                            String newSubSection = s.Substring(idx + 1);

                            if (!newSection.Equals(currentSectionName))
                            {

                            }

                            currentSubSectionName = newSubSection;
                        }
                        section.LargeArrays = largeArrays;
                        return section;
                    }
                    else if (line.Length < 1)
                    {
                        continue;
                    }
                    else if (line.StartsWith("##double"))
                    {
                        double[] d = ReadLargeArray(line);
                        largeArrays.Add(d);
                    }
                    else
                    {
                        if (currentSectionName.Length < 1)
                        {

                        }

                        lines.Add(line);
                    }
                }

                if (currentSectionName.Length == 0)
                {
                    return null;
                }

                section = new SyntFileSection(currentSectionName,
                                               currentSubSectionName);

                foreach (String l in lines)
                {
                    section.Lines.Add(l);
                }

                currentSectionName = "";
                currentSubSectionName = "";
                section.LargeArrays = largeArrays;
                return section;
            }
            catch (IOException ex)
            {
                throw new PersistError(ex);
            }
        }

        /// <summary>
        /// Called internally to read a large array.
        /// </summary>
        /// <param name="line">The line containing the beginning of a large array.</param>
        /// <returns>The array read.</returns>
        private double[] ReadLargeArray(String line)
        {
            String str = line.Substring(9);
            int l = int.Parse(str);
            double[] result = new double[l];

            int index = 0;
            while ((line = this.reader.ReadLine()) != null)
            {
                line = line.Trim();

                // is it a comment
                if (line.StartsWith("//"))
                {
                    continue;
                }
                else if (line.StartsWith("##end"))
                {
                    break;
                }

                double[] t = NumberList.FromList(CSVFormat.EgFormat, line);
                EngineArray.ArrayCopy(t, 0, result, index, t.Length);
                index += t.Length;
            }

            return result;
        }
    }

    public class SyntWriteHelper
    {
        /// <summary>
        /// The current large array that we are on.
        /// </summary>
        private int _largeArrayNumber;

        /// <summary>
        /// A quote char.
        /// </summary>
        ///
        public const char QUOTE = '\"';

        /// <summary>
        /// A comma char.
        /// </summary>
        ///
        public const char COMMA = ',';

        /// <summary>
        /// The current line.
        /// </summary>
        ///
        private readonly StringBuilder line;

        /// <summary>
        /// The file to write to.
        /// </summary>
        ///
        private readonly StreamWriter xout;

        /// <summary>
        /// The current section.
        /// </summary>
        ///
        private String currentSection;

        /// <summary>
        /// Construct the object.
        /// </summary>
        ///
        /// <param name="stream">The stream to write to.</param>
        public SyntWriteHelper(Stream stream)
        {
            line = new StringBuilder();
            xout = new StreamWriter(stream);
        }

        /// <value>The current section.</value>
        public String CurrentSection
        {
            get { return currentSection; }
        }

        /// <summary>
        /// Add a boolean value as a column.  
        /// </summary>
        ///
        /// <param name="b">The boolean value.</param>
        public void AddColumn(bool b)
        {
            if (line.Length > 0)
            {
                line.Append(COMMA);
            }

            line.Append((b) ? 1 : 0);
        }

        /// <summary>
        /// Add a column as a double.
        /// </summary>
        ///
        /// <param name="d">The double to add.</param>
        public void AddColumn(double d)
        {
            if (line.Length > 0)
            {
                line.Append(COMMA);
            }

            line.Append(CSVFormat.English.Format(d, SyntFramework.DefaultPrecision));
        }

        /// <summary>
        /// Add a column as a long.
        /// </summary>
        ///
        /// <param name="v">The long to add.</param>
        public void AddColumn(long v)
        {
            if (line.Length > 0)
            {
                line.Append(COMMA);
            }

            line.Append(v);
        }

        /// <summary>
        /// Add a column as an integer.
        /// </summary>
        ///
        /// <param name="i">The integer to add.</param>
        public void AddColumn(int i)
        {
            if (line.Length > 0)
            {
                line.Append(COMMA);
            }

            line.Append(i);
        }

        /// <summary>
        /// Add a column as a string.
        /// </summary>
        ///
        /// <param name="str">The string to add.</param>
        public void AddColumn(String str)
        {
            if (line.Length > 0)
            {
                line.Append(COMMA);
            }

            line.Append(QUOTE);
            line.Append(str);
            line.Append(QUOTE);
        }

        /// <summary>
        /// Add a list of string columns.
        /// </summary>
        ///
        /// <param name="cols">The columns to add.</param>
        public void AddColumns(IList<String> cols)
        {
            foreach (String str in cols)
            {
                AddColumn(str);
            }
        }

        /// <summary>
        /// Add a line.
        /// </summary>
        ///
        /// <param name="l">The line to add.</param>
        public void AddLine(String l)
        {
            if (line.Length > 0)
            {
                WriteLine();
            }
            xout.WriteLine(l);
        }

        /// <summary>
        /// Add the specified properties.
        /// </summary>
        ///
        /// <param name="properties">The properties.</param>
        public void AddProperties(IDictionary<String, String> properties)
        {
            foreach (String key in properties.Keys)
            {
                String value_ren = properties[key];
                WriteProperty(key, value_ren);
            }
        }

        /// <summary>
        /// Add a new section.
        /// </summary>
        ///
        /// <param name="str">The section to add.</param>
        public void AddSection(String str)
        {
            currentSection = str;
            xout.WriteLine("[" + str + "]");
        }

        /// <summary>
        /// Add a new subsection.
        /// </summary>
        ///
        /// <param name="str">The subsection.</param>
        public void AddSubSection(String str)
        {
            xout.WriteLine("[" + currentSection + ":" + str + "]");
            _largeArrayNumber = 0;
        }

        /// <summary>
        /// Flush the file.
        /// </summary>
        ///
        public void Flush()
        {
            xout.Flush();
        }


        /// <summary>
        /// Write the specified string.
        /// </summary>
        ///
        /// <param name="str">The string to write.</param>
        public void Write(String str)
        {
            xout.Write(str);
        }

        /// <summary>
        /// Write the line.
        /// </summary>
        ///
        public void WriteLine()
        {
            xout.WriteLine(line.ToString());
            line.Length = 0;
        }

        /// <summary>
        /// Write a property as an activation function.
        /// </summary>
        ///
        /// <param name="name">The name of the property.</param>
        /// <param name="act">The activation function.</param>
        public void WriteProperty(String name,
                                  IActivationFunction act)
        {
            var result = new StringBuilder();
            result.Append(act.GetType().Name);

            for (int i = 0; i < act.Params.Length; i++)
            {
                result.Append('|');
                result.Append(CSVFormat.EgFormat.Format(act.Params[i],
                                                         SyntFramework.DefaultPrecision));
            }
            WriteProperty(name, result.ToString());
        }

        /// <summary>
        /// Write the property as a boolean.
        /// </summary>
        ///
        /// <param name="name">The name of the property.</param>
        /// <param name="value_ren">The boolean value.</param>
        public void WriteProperty(String name, bool value_ren)
        {
            xout.WriteLine(name + "=" + ((value_ren) ? 't' : 'f'));
        }

        /// <summary>
        /// Write a property as a CSV format.
        /// </summary>
        ///
        /// <param name="name">The name of the property.</param>
        /// <param name="csvFormat">The format.</param>
        public void WriteProperty(String name, CSVFormat csvFormat)
        {
            String fmt;
            if ((csvFormat == CSVFormat.English)
                || (csvFormat == CSVFormat.English)
                || (csvFormat == CSVFormat.DecimalPoint))
            {
                fmt = "decpnt";
            }
            else if (csvFormat == CSVFormat.DecimalComma)
            {
                fmt = "deccomma";
            }
            else
            {
                fmt = "decpnt";
            }
            xout.WriteLine(name + "=" + fmt);
        }

        /// <summary>
        /// Write the property as a double.
        /// </summary>
        ///
        /// <param name="name">The name of the property.</param>
        /// <param name="value_ren">The value.</param>
        public void WriteProperty(String name, double value_ren)
        {
            xout.WriteLine(name + "="
                           + CSVFormat.EgFormat.Format(value_ren, SyntFramework.DefaultPrecision));
        }

        /// <summary>
        /// Write the property as a long.
        /// </summary>
        ///
        /// <param name="name">The name of the property.</param>
        /// <param name="v">The value.</param>
        public void WriteProperty(String name, long v)
        {
            xout.WriteLine(name + "="
                           + v);
        }

        /// <summary>
        /// Write the property as a double array.
        /// </summary>
        ///
        /// <param name="name">The name of the property.</param>
        /// <param name="d">The double value.</param>
        public void WriteProperty(String name, double[] d)
        {
            if (d.Length < 2048)
            {
                var result = new StringBuilder();
                NumberList.ToList(CSVFormat.EgFormat, result, d);
                WriteProperty(name, result.ToString());
            }
            else
            {
                xout.Write(name);
                xout.Write("=##");
                xout.WriteLine(_largeArrayNumber++);
                xout.Write("##double#");
                xout.WriteLine(d.Length);

                int index = 0;

                while (index < d.Length)
                {
                    bool first = true;
                    for (int i = 0; (i < 2048) && (index < d.Length); i++)
                    {
                        if (!first)
                        {
                            xout.Write(",");
                        }
                        else
                        {
                            xout.Write("   ");
                        }
                        xout.Write(CSVFormat.EgFormat.Format(d[index],
                                SyntFramework.DefaultPrecision));
                        index++;
                        first = false;
                    }
                    xout.WriteLine();
                }
                xout.WriteLine("##end");
            }
        }

        /// <summary>
        /// Write a property as an int value.
        /// </summary>
        ///
        /// <param name="name">The name of the property.</param>
        /// <param name="value_ren">The int value.</param>
        public void WriteProperty(String name, int value_ren)
        {
            xout.WriteLine(name + "=" + value_ren);
        }

        /// <summary>
        /// Write a property as an int array.
        /// </summary>
        ///
        /// <param name="name">The name of the property.</param>
        /// <param name="array">The array.</param>
        public void WriteProperty(String name, int[] array)
        {
            var result = new StringBuilder();
            NumberList.ToListInt(CSVFormat.EgFormat, result, array);
            WriteProperty(name, result.ToString());
        }

        /// <summary>
        /// Write a matrix as a property.
        /// </summary>
        ///
        /// <param name="name">The property name.</param>
        /// <param name="matrix">The matrix.</param>
        public void WriteProperty(String name, Matrix matrix)
        {
            var result = new StringBuilder();
            result.Append(matrix.Rows);
            result.Append(',');
            result.Append(matrix.Cols);

            for (int row = 0; row < matrix.Rows; row++)
            {
                for (int col = 0; col < matrix.Cols; col++)
                {
                    result.Append(',');
                    result.Append(CSVFormat.EgFormat.Format(matrix[row, col],
                                                             SyntFramework.DefaultPrecision));
                }
            }

            WriteProperty(name, result.ToString());
        }

        /// <summary>
        /// Write the property a s string.
        /// </summary>
        ///
        /// <param name="name">The name of the property.</param>
        /// <param name="value_ren">The value.</param>
        public void WriteProperty(String name, String value_ren)
        {
            xout.WriteLine(name + "=" + value_ren);
        }
    }

    public static class PersistConst
    {
        /// <summary>
        /// A Hopfield neural network.
        /// </summary>
        ///
        public const String TypeHopfield = "HopfieldNetwork";

        /// <summary>
        /// A Boltzmann machine.
        /// </summary>
        ///
        public const String TypeBoltzmann = "BoltzmannMachine";

        /// <summary>
        /// An ART1 neural network.
        /// </summary>
        ///
        public const String TypeART1 = "ART1";

        /// <summary>
        /// A BAM neural network.
        /// </summary>
        ///
        public const String TypeBAM = "BAM";

        /// <summary>
        /// A SOM neural network.
        /// </summary>
        ///
        public const String TypeSOM = "SOM";

        /// <summary>
        /// A Y neural network.
        /// </summary>
        ///
        public const String TypeY = "YNetwork";

        /// <summary>
        /// A Y population.
        /// </summary>
        ///
        public const String TypeYPopulation = "YPopulation";

        /// <summary>
        /// A species.
        /// </summary>
        ///
        public const String TypeBasicSpecies = "BasicSpecies";

        /// <summary>
        /// A neuron gene.
        /// </summary>
        ///
        public const String TypeYNeuronGene = "YNeuronGene";

        /// <summary>
        /// A support vector machine.
        /// </summary>
        ///
        public const String TypeSVM = "SVM";

        /// <summary>
        /// A neural network.
        /// </summary>
        ///
        public const String TypeBasicNetwork = "BasicNetwork";

        /// <summary>
        /// A RBF network.
        /// </summary>
        ///
        public const String TypeRBFNetwork = "RBFNetwork";

        /// <summary>
        /// A name.
        /// </summary>
        ///
        public const String Name = "name";

        /// <summary>
        /// A description.
        /// </summary>
        ///
        public const String Description = "description";

        /// <summary>
        /// Neurons.
        /// </summary>
        ///
        public const String NeuronCount = "neurons";

        /// <summary>
        /// Thresholds.
        /// </summary>
        ///
        public const String Thresholds = "thresholds";

        /// <summary>
        /// Weights.
        /// </summary>
        ///
        public const String Weights = "weights";

        /// <summary>
        /// Output.
        /// </summary>
        ///
        public const String Output = "output";

        /// <summary>
        /// Native.
        /// </summary>
        ///
        public const String Native = "native";

        /// <summary>
        /// Temperature.
        /// </summary>
        ///
        public const String Temperature = "temperature";

        /// <summary>
        /// The input count.
        /// </summary>
        ///
        public const String InputCount = "inputCount";

        /// <summary>
        /// The output count.
        /// </summary>
        ///
        public const String OutputCount = "outputCount";

        /// <summary>
        /// List.
        /// </summary>
        ///
        public const String List = "list";

        /// <summary>
        /// Data.
        /// </summary>
        ///
        public const String Data = "data";

        /// <summary>
        /// matrix.
        /// </summary>
        ///
        public const String Matrix = "matrix";

        /// <summary>
        /// An activation function.
        /// </summary>
        ///
        public const String ActivationType = "af";

        /// <summary>
        /// The F1 count.
        /// </summary>
        ///
        public const String PropertyF1Count = "f1Count";

        /// <summary>
        /// The F2 count.
        /// </summary>
        ///
        public const String PropertyF2Count = "f2Count";

        /// <summary>
        /// The weights from F1 to F2.
        /// </summary>
        ///
        public const String PropertyWeightsF1F2 = "weightsF1F2";

        /// <summary>
        /// The weights from F2 to F1.
        /// </summary>
        ///
        public const String PropertyWeightsF2F1 = "weightsF2F1";

        /// <summary>
        /// Activation function.
        /// </summary>
        ///
        public const String ActivationFunction = "activationFunction";

        /// <summary>
        /// Neuron count.
        /// </summary>
        ///
        public const String Neurons = "neurons";

        /// <summary>
        /// Type.
        /// </summary>
        ///
        public const String Type = "type";

        /// <summary>
        /// Recurrent.
        /// </summary>
        ///
        public const String Recurrent = "recurrent";

        /// <summary>
        /// Weight.
        /// </summary>
        ///
        public const String Weight = "weight";

        /// <summary>
        /// Links.
        /// </summary>
        ///
        public const String Links = "links";

        /// <summary>
        /// Y innovation.
        /// </summary>
        ///
        public const String TypeYInnovation = "YInnovation";

        /// <summary>
        /// Property id.
        /// </summary>
        ///
        public const String PropertyID = "id";

        /// <summary>
        /// Y T.
        /// </summary>
        ///
        public const String TypeYT = "YT";

        /// <summary>
        /// Enabled.
        /// </summary>
        ///
        public const String Enabled = "enabled";

        /// <summary>
        /// idata.
        /// </summary>
        ///
        public const String Idata = "idata";

        /// <summary>
        /// Properties.
        /// </summary>
        ///
        public const String Properties = "properties";

        /// <summary>
        /// Version.
        /// </summary>
        ///
        public const String Version = "ver";

        /// <summary>
        /// Depth.
        /// </summary>
        ///
        public const String Depth = "depth";

        /// <summary>
        /// Snapshot.
        /// </summary>
        ///
        public const String Snapshot = "snapshot";

        /// <summary>
        /// Error.
        /// </summary>
        ///
        public const String Error = "error";

        /// <summary>
        /// Sigma.
        /// </summary>
        ///
        public const String Sigma = "sigma";

        /// <summary>
        /// Kernel.
        /// </summary>
        ///
        public const String Kernel = "kernel";

        /// <summary>
        /// Instar.
        /// </summary>
        ///
        public const String Instar = "instar";
    }

    [Serializable]
    public class PersistError : SyntError
    {
        /// <summary>
        /// Construct a message exception.
        /// </summary>
        ///
        /// <param name="msg">The exception message.</param>
        public PersistError(String msg) : base(msg)
        {
        }

        /// <summary>
        /// Construct an exception that holds another exception.
        /// </summary>
        ///
        /// <param name="msg">The message.</param>
        /// <param name="t">The other exception.</param>
        public PersistError(String msg, Exception t) : base(msg, t)
        {
        }

        /// <summary>
        /// Construct an exception that holds another exception.
        /// </summary>
        ///
        /// <param name="t">The other exception.</param>
        public PersistError(Exception t) : base(t)
        {
        }
    }

    public class PersistSVM : ISyntPersistor
    {
        /// <summary>
        /// The parameter to hold the const C.
        /// </summary>
        ///
        public const String ParamC = "C";

        /// <summary>
        /// The parameter to hold the cache size.
        /// </summary>
        ///
        public const String ParamCacheSize = "cacheSize";

        /// <summary>
        /// The parameter to hold the coef0.
        /// </summary>
        ///
        public const String ParamCoef0 = "coef0";

        /// <summary>
        /// The parameter to hold the degree.
        /// </summary>
        ///
        public const String ParamDegree = "degree";

        /// <summary>
        /// The parameter to hold the eps.
        /// </summary>
        ///
        public const String ParamEps = "eps";

        /// <summary>
        /// The parameter to hold the gamma.
        /// </summary>
        ///
        public const String ParamGamma = "gamma";

        /// <summary>
        /// The parameter to hold the kernel type.
        /// </summary>
        ///
        public const String ParamKernelType = "kernelType";

        /// <summary>
        /// The parameter to hold the number of weights.
        /// </summary>
        ///
        public const String ParamNumWeight = "nrWeight";

        /// <summary>
        /// The parameter to hold the nu.
        /// </summary>
        ///
        public const String ParamNu = "nu";

        /// <summary>
        /// The parameter to hold the p.
        /// </summary>
        ///
        public const String ParamP = "p";

        /// <summary>
        /// The parameter to hold the probability.
        /// </summary>
        ///
        public const String ParamProbability = "probability";

        /// <summary>
        /// The parameter to hold the shrinking.
        /// </summary>
        ///
        public const String ParamShrinking = "shrinking";

        /// <summary>
        /// The parameter to hold the statIterations.
        /// </summary>
        ///
        public const String ParamStartIterations = "statIterations";

        /// <summary>
        /// The parameter to hold the SVM type.
        /// </summary>
        ///
        public const String ParamSVMType = "svmType";

        /// <summary>
        /// The paramater to hold the weight.
        /// </summary>
        ///
        public const String ParamWeight = "weight";

        /// <summary>
        /// The parameter to hold the weight label.
        /// </summary>
        ///
        public const String ParamWeightLabel = "weightLabel";

        /// <inheritdoc/>
        public Type NativeType
        {
            get { return typeof(SupportVectorMachine); }
        }

        #region SyntPersistor Members

        /// <value>The file version.</value>
        public int FileVersion
        {
            get { return 1; }
        }


        /// <inheritdoc/>
        public String PersistClassString
        {

            get { return "SVM"; }
        }


        /// <inheritdoc/>
        public Object Read(Stream mask0)
        {
            var result = new SupportVectorMachine();
            var ins0 = new SyntReadHelper(mask0);
            SyntFileSection section;

            while ((section = ins0.ReadNextSection()) != null)
            {
                if (section.SectionName.Equals("SVM")
                    && section.SubSectionName.Equals("PARAMS"))
                {
                    IDictionary<String, String> paras = section.ParseParams();
                    EngineArray.PutAll(paras, result.Properties);
                }
                if (section.SectionName.Equals("SVM")
                    && section.SubSectionName.Equals("SVM-PARAM"))
                {
                    IDictionary<String, String> p = section.ParseParams();
                    result.InputCount = SyntFileSection.ParseInt(p,
                                                                  PersistConst.InputCount);
                    result.Params.C = SyntFileSection.ParseDouble(p,
                                                                   ParamC);
                    result.Params.cache_size = SyntFileSection.ParseDouble(
                        p, ParamCacheSize);
                    result.Params.coef0 = SyntFileSection.ParseDouble(p,
                                                                       ParamCoef0);
                    result.Params.degree = SyntFileSection.ParseDouble(p,
                                                                     ParamDegree);
                    result.Params.eps = SyntFileSection.ParseDouble(p,
                                                                     ParamEps);
                    result.Params.gamma = SyntFileSection.ParseDouble(p,
                                                                       ParamGamma);
                    result.Params.kernel_type = SyntFileSection.ParseInt(
                        p, ParamKernelType);
                    result.Params.nr_weight = SyntFileSection.ParseInt(
                        p, ParamNumWeight);
                    result.Params.nu = SyntFileSection.ParseDouble(p,
                                                                    ParamNu);
                    result.Params.p = SyntFileSection.ParseDouble(p,
                                                                   ParamP);
                    result.Params.probability = SyntFileSection.ParseInt(
                        p, ParamProbability);
                    result.Params.shrinking = SyntFileSection.ParseInt(
                        p, ParamShrinking);
                    /*result.Params.statIterations = Synt.Persist.SyntFileSection.ParseInt(
							params_0, PersistSVM.PARAM_START_ITERATIONS);*/
                    result.Params.svm_type = SyntFileSection.ParseInt(p,
                                                                       ParamSVMType);
                    result.Params.weight = section.ParseDoubleArray(p, ParamWeight);
                    result.Params.weight_label = SyntFileSection
                        .ParseIntArray(p, ParamWeightLabel);
                }
                else if (section.SectionName.Equals("SVM")
                         && section.SubSectionName.Equals("SVM-MODEL"))
                {
                    try
                    {
                        var rdr = new StringReader(
                            section.LinesAsString);
                        TextReader br = rdr;
                        svm_model model = svm.svm_load_model(rdr);
                        result.Model = model;
                        br.Close();
                        rdr.Close();
                    }
                    catch (IOException ex)
                    {
                        throw new PersistError(ex);
                    }
                }
            }

            return result;
        }

        /// <inheritdoc/>
        public void Save(Stream os, Object obj)
        {
            var xout = new SyntWriteHelper(os);
            var svm2 = (SupportVectorMachine)obj;
            xout.AddSection("SVM");
            xout.AddSubSection("PARAMS");
            xout.AddProperties(svm2.Properties);
            xout.AddSubSection("SVM-PARAM");
            xout.WriteProperty(PersistConst.InputCount, svm2.InputCount);
            xout.WriteProperty(ParamC, svm2.Params.C);
            xout.WriteProperty(ParamCacheSize,
                               svm2.Params.cache_size);
            xout.WriteProperty(ParamCoef0, svm2.Params.coef0);
            xout.WriteProperty(ParamDegree, svm2.Params.degree);
            xout.WriteProperty(ParamEps, svm2.Params.eps);
            xout.WriteProperty(ParamGamma, svm2.Params.gamma);
            xout.WriteProperty(ParamKernelType,
                               svm2.Params.kernel_type);
            xout.WriteProperty(ParamNumWeight,
                               svm2.Params.nr_weight);
            xout.WriteProperty(ParamNu, svm2.Params.nu);
            xout.WriteProperty(ParamP, svm2.Params.p);
            xout.WriteProperty(ParamProbability,
                               svm2.Params.probability);
            xout.WriteProperty(ParamShrinking,
                               svm2.Params.shrinking);
            /* xout.WriteProperty(PersistSVM.PARAM_START_ITERATIONS,
					svm2.Params.statIterations); */
            xout.WriteProperty(ParamSVMType, svm2.Params.svm_type);
            xout.WriteProperty(ParamWeight, svm2.Params.weight);
            xout.WriteProperty(ParamWeightLabel,
                               svm2.Params.weight_label);
            if (svm2.Model != null)
            {
                xout.AddSubSection("SVM-MODEL");
                try
                {
                    var ba = new MemoryStream();
                    var w = new StreamWriter(ba);
                    svm.svm_save_model(w, svm2.Model);
                    var enc = new ASCIIEncoding();
                    xout.Write(enc.GetString(ba.ToArray()));
                    w.Close();
                    ba.Close();
                }
                catch (IOException ex)
                {
                    throw new PersistError(ex);
                }
            }

            xout.Flush();
        }

        #endregion
    }

    public class PersistBAM : ISyntPersistor
    {
        #region SyntPersistor Members

        /// <inheritdoc/>
        public int FileVersion
        {
            get { return 1; }
        }


        /// <inheritdoc/>
        public String PersistClassString
        {
            get { return "BAM"; }
        }


        /// <inheritdoc/>
        public Object Read(Stream mask0)
        {
            var result = new BAMNetwork();
            var ins0 = new SyntReadHelper(mask0);
            SyntFileSection section;

            while ((section = ins0.ReadNextSection()) != null)
            {
                if (section.SectionName.Equals("BAM")
                    && section.SubSectionName.Equals("PARAMS"))
                {
                    IDictionary<String, String> paras = section.ParseParams();
                    EngineArray.PutAll(paras, result.Properties);
                }
                if (section.SectionName.Equals("BAM")
                    && section.SubSectionName.Equals("NETWORK"))
                {
                    IDictionary<String, String> p = section.ParseParams();

                    result.F1Count = SyntFileSection.ParseInt(p,
                                                               PersistConst.PropertyF1Count);
                    result.F2Count = SyntFileSection.ParseInt(p,
                                                               PersistConst.PropertyF2Count);
                    result.WeightsF1ToF2 = SyntFileSection.ParseMatrix(p, PersistConst.PropertyWeightsF1F2);
                    result.WeightsF2ToF1 = SyntFileSection.ParseMatrix(p, PersistConst.PropertyWeightsF2F1);
                }
            }

            return result;
        }

        /// <summary>
        /// 
        /// </summary>
        ///
        public void Save(Stream os, Object obj)
        {
            var xout = new SyntWriteHelper(os);
            var bam = (BAMNetwork)obj;
            xout.AddSection("BAM");
            xout.AddSubSection("PARAMS");
            xout.AddProperties(bam.Properties);
            xout.AddSubSection("NETWORK");

            xout.WriteProperty(PersistConst.PropertyF1Count, bam.F1Count);
            xout.WriteProperty(PersistConst.PropertyF2Count, bam.F2Count);
            xout.WriteProperty(PersistConst.PropertyWeightsF1F2,
                               bam.WeightsF1ToF2);
            xout.WriteProperty(PersistConst.PropertyWeightsF2F1,
                               bam.WeightsF2ToF1);

            xout.Flush();
        }

        /// <inheritdoc/>
        public Type NativeType
        {
            get { return typeof(BAMNetwork); }
        }

        #endregion
    }


    [Serializable]
    public class ART1 : BasicART, IMLResettable, IMLClassification
    {
        /// <summary>
        /// A parameter for F1 layer.
        /// </summary>
        ///
        private double _a1;

        /// <summary>
        /// B parameter for F1 layer.
        /// </summary>
        ///
        private double _b1;

        /// <summary>
        /// C parameter for F1 layer.
        /// </summary>
        ///
        private double _c1;

        /// <summary>
        /// D parameter for F1 layer.
        /// </summary>
        ///
        private double _d1;

        /// <summary>
        /// The F1 layer neuron count.
        /// </summary>
        ///
        private int _f1Count;

        /// <summary>
        /// The F2 layer neuron count.
        /// </summary>
        ///
        private int _f2Count;

        /// <summary>
        /// Allows members of the F2 layer to be inhibited.
        /// </summary>
        [NonSerialized]
        private bool[] _inhibitF2;

        /// <summary>
        /// L parameter for net.
        /// </summary>
        ///
        private double _l;

        /// <summary>
        /// This is the value that is returned if there is no winner.  
        /// This value is generally set to the number of classes, plus 1.
        /// </summary>
        ///
        private int _noWinner;

        /// <summary>
        /// The output from the F1 layer.
        /// </summary>
        ///
        private BiPolarMLData _outputF1;

        /// <summary>
        /// The output from the F2 layer.
        /// </summary>
        ///
        private BiPolarMLData _outputF2;

        /// <summary>
        /// The vigilance parameter.
        /// </summary>
        ///
        private double _vigilance;

        /// <summary>
        /// Weights from f1 to f2.
        /// </summary>
        ///
        private Matrix _weightsF1ToF2;

        /// <summary>
        /// Weights from f2 to f1.
        /// </summary>
        ///
        private Matrix _weightsF2ToF1;

        /// <summary>
        /// Default constructor, used mainly for persistence.
        /// </summary>
        ///
        public ART1()
        {
            _a1 = 1;
            _b1 = 1.5d;
            _c1 = 5;
            _d1 = 0.9d;
            _l = 3;
            _vigilance = 0.9d;
        }

        /// <summary>
        /// Construct the ART1 network.
        /// </summary>
        ///
        /// <param name="theF1Count">The neuron count for the f1 layer.</param>
        /// <param name="theF2Count">The neuron count for the f2 layer.</param>
        public ART1(int theF1Count, int theF2Count)
        {
            _a1 = 1;
            _b1 = 1.5d;
            _c1 = 5;
            _d1 = 0.9d;
            _l = 3;
            _vigilance = 0.9d;
            _f1Count = theF1Count;
            _f2Count = theF2Count;

            _weightsF1ToF2 = new Matrix(_f1Count, _f2Count);
            _weightsF2ToF1 = new Matrix(_f2Count, _f1Count);

            _inhibitF2 = new bool[_f2Count];

            _outputF1 = new BiPolarMLData(_f1Count);
            _outputF2 = new BiPolarMLData(_f2Count);

            _noWinner = _f2Count;
            Reset();
        }

        /// <summary>
        /// Set the A1 parameter.
        /// </summary>
        ///
        /// <value>The new value.</value>
        public double A1
        {
            get { return _a1; }
            set { _a1 = value; }
        }


        /// <summary>
        /// Set the B1 parameter.
        /// </summary>
        public double B1
        {
            get { return _b1; }
            set { _b1 = value; }
        }


        /// <summary>
        /// Set the C1 parameter.
        /// </summary>
        ///
        /// <value>The new value.</value>
        public double C1
        {
            get { return _c1; }
            set { _c1 = value; }
        }


        /// <summary>
        /// Set the D1 parameter.
        /// </summary>
        ///
        /// <value>The new value.</value>
        public double D1
        {
            get { return _d1; }
            set { _d1 = value; }
        }


        /// <summary>
        /// Set the F1 count.  The F1 layer is the input layer.
        /// </summary>
        public int F1Count
        {
            get { return _f1Count; }
            set
            {
                _f1Count = value;
                _outputF1 = new BiPolarMLData(_f1Count);
            }
        }


        /// <summary>
        /// Set the F2 count.  The F2 layer is the output layer.
        /// </summary>
        ///
        /// <value>The count.</value>
        public int F2Count
        {
            get { return _f2Count; }
            set
            {
                _f2Count = value;
                _inhibitF2 = new bool[_f2Count];
                _outputF2 = new BiPolarMLData(_f2Count);
            }
        }


        /// <summary>
        /// Set the L parameter.
        /// </summary>
        ///
        /// <value>The new value.</value>
        public double L
        {
            get { return _l; }
            set { _l = value; }
        }


        /// <summary>
        /// This is the value that is returned if there is no winner.  
        /// This value is generally set to the index of the last classes, plus 1.
        /// For example, if there were 3 classes, the network would return 0-2 to
        /// represent what class was found, in this case the no winner property
        /// would be set to 3.
        /// </summary>
        public int NoWinner
        {
            get { return _noWinner; }
            set { _noWinner = value; }
        }


        /// <summary>
        /// Set the vigilance.
        /// </summary>
        public double Vigilance
        {
            get { return _vigilance; }
            set { _vigilance = value; }
        }


        /// <summary>
        /// Set the f1 to f2 matrix.
        /// </summary>
        public Matrix WeightsF1ToF2
        {
            get { return _weightsF1ToF2; }
            set { _weightsF1ToF2 = value; }
        }


        /// <summary>
        /// Set the f2 to f1 matrix.
        /// </summary>
        public Matrix WeightsF2ToF1
        {
            get { return _weightsF2ToF1; }
            set { _weightsF2ToF1 = value; }
        }


        /// <value>The winning neuron.</value>
        public int Winner { get; private set; }


        /// <returns>Does this network have a "winner"?</returns>
        public bool HasWinner
        {
            get { return Winner != _noWinner; }
        }

        /// <summary>
        /// Set the input to the neural network.
        /// </summary>
        private BiPolarMLData Input
        {
            set
            {
                for (int i = 0; i < _f1Count; i++)
                {
                    double activation = ((value.GetBoolean(i)) ? 1 : 0)
                                        / (1 + _a1 * (((value.GetBoolean(i)) ? 1 : 0) + _b1) + _c1);
                    _outputF1.SetBoolean(i, (activation > 0));
                }
            }
        }

        #region MLClassification Members

        /// <summary>
        /// Classify the input data to a class number.
        /// </summary>
        ///
        /// <param name="input">The input data.</param>
        /// <returns>The class that the data belongs to.</returns>
        public int Classify(IMLData input)
        {
            var input2 = new BiPolarMLData(_f1Count);
            var output = new BiPolarMLData(_f2Count);

            if (input.Count != input2.Count)
            {
                throw new NeuralNetworkError("Input array size does not match.");
            }

            for (int i = 0; i < input2.Count; i++)
            {
                input2.SetBoolean(i, input[i] > 0);
            }

            Compute(input2, output);

            return HasWinner ? Winner : -1;
        }

        /// <summary>
        /// The input count.
        /// </summary>
        public int InputCount
        {
            get { return _f1Count; }
        }

        /// <value>The number of neurons in the output count, which is the f2 layer
        /// count.</value>
        public int OutputCount
        {
            get { return _f2Count; }
        }

        #endregion

        #region MLResettable Members

        /// <summary>
        /// Reset the weight matrix back to starting values.
        /// </summary>
        ///
        public void Reset()
        {
            Reset(0);
        }

        /// <summary>
        /// Reset with a specic seed.
        /// </summary>
        ///
        /// <param name="seed">The seed to reset with.</param>
        public void Reset(int seed)
        {
            for (int i = 0; i < _f1Count; i++)
            {
                for (int j = 0; j < _f2Count; j++)
                {
                    _weightsF1ToF2[i, j] = (_b1 - 1) / _d1 + 0.2d;
                    _weightsF2ToF1[j, i] = _l
                                          / (_l - 1 + _f1Count) - 0.1d;
                }
            }
        }

        #endregion

        /// <summary>
        /// Adjust the weights for the pattern just presented.
        /// </summary>
        ///
        public void AdjustWeights()
        {
            for (int i = 0; i < _f1Count; i++)
            {
                if (_outputF1.GetBoolean(i))
                {
                    double magnitudeInput = Magnitude(_outputF1);
                    _weightsF1ToF2[i, Winner] = 1;
                    _weightsF2ToF1[Winner, i] = _l
                                               / (_l - 1 + magnitudeInput);
                }
                else
                {
                    _weightsF1ToF2[i, Winner] = 0;
                    _weightsF2ToF1[Winner, i] = 0;
                }
            }
        }

        /// <summary>
        /// Compute the output from the ART1 network. This can be called directly or
        /// used by the BasicNetwork class. Both input and output should be bipolar
        /// numbers.
        /// </summary>
        ///
        /// <param name="input">The input to the network.</param>
        /// <param name="output">The output from the network.</param>
        public void Compute(BiPolarMLData input,
                            BiPolarMLData output)
        {
            int i;

            for (i = 0; i < _f2Count; i++)
            {
                _inhibitF2[i] = false;
            }
            bool resonance = false;
            bool exhausted = false;
            do
            {
                Input = input;
                ComputeF2();
                GetOutput(output);
                if (Winner != _noWinner)
                {
                    ComputeF1(input);
                    double magnitudeInput1 = Magnitude(input);
                    double magnitudeInput2 = Magnitude(_outputF1);
                    if ((magnitudeInput2 / magnitudeInput1) < _vigilance)
                    {
                        _inhibitF2[Winner] = true;
                    }
                    else
                    {
                        resonance = true;
                    }
                }
                else
                {
                    exhausted = true;
                }
            } while (!(resonance || exhausted));
            if (resonance)
            {
                AdjustWeights();
            }
        }

        /// <summary>
        /// Compute the output for the BasicNetwork class.
        /// </summary>
        ///
        /// <param name="input">The input to the network.</param>
        /// <returns>The output from the network.</returns>
        public IMLData Compute(IMLData input)
        {
            if (!(input is BiPolarMLData))
            {
                throw new NeuralNetworkError(
                    "Input to ART1 logic network must be BiPolarNeuralData.");
            }

            var output = new BiPolarMLData(_f1Count);
            Compute((BiPolarMLData)input, output);
            return output;
        }

        /// <summary>
        /// Compute the output from the F1 layer.
        /// </summary>
        ///
        /// <param name="input">The input to the F1 layer.</param>
        private void ComputeF1(BiPolarMLData input)
        {
            for (int i = 0; i < _f1Count; i++)
            {
                double sum = _weightsF1ToF2[i, Winner]
                             * ((_outputF2.GetBoolean(Winner)) ? 1 : 0);
                double activation = (((input.GetBoolean(i)) ? 1 : 0) + _d1 * sum - _b1)
                                    / (1 + _a1
                                          * (((input.GetBoolean(i)) ? 1 : 0) + _d1 * sum) + _c1);
                _outputF1.SetBoolean(i, activation > 0);
            }
        }

        /// <summary>
        /// Compute the output from the F2 layer.
        /// </summary>
        ///
        private void ComputeF2()
        {
            int i;

            double maxOut = Double.NegativeInfinity;
            Winner = _noWinner;
            for (i = 0; i < _f2Count; i++)
            {
                if (!_inhibitF2[i])
                {
                    double sum = 0;
                    int j;
                    for (j = 0; j < _f1Count; j++)
                    {
                        sum += _weightsF2ToF1[i, j]
                               * ((_outputF1.GetBoolean(j)) ? 1 : 0);
                    }
                    if (sum > maxOut)
                    {
                        maxOut = sum;
                        Winner = i;
                    }
                }
                _outputF2.SetBoolean(i, false);
            }
            if (Winner != _noWinner)
            {
                _outputF2.SetBoolean(Winner, true);
            }
        }

        /// <summary>
        /// Copy the output from the network to another object.
        /// </summary>
        ///
        /// <param name="output">The target object for the output from the network.</param>
        private void GetOutput(BiPolarMLData output)
        {
            for (int i = 0; i < _f2Count; i++)
            {
                output.SetBoolean(i, _outputF2.GetBoolean(i));
            }
        }

        /// <summary>
        /// Get the magnitude of the specified input.
        /// </summary>
        ///
        /// <param name="input">The input to calculate the magnitude for.</param>
        /// <returns>The magnitude of the specified pattern.</returns>
        public double Magnitude(BiPolarMLData input)
        {
            double result;

            result = 0;
            for (int i = 0; i < _f1Count; i++)
            {
                result += (input.GetBoolean(i)) ? 1 : 0;
            }
            return result;
        }
    }

    [Serializable]
    public class BasicART : BasicML
    {
        /// <summary>
        /// Neural network property, the A1 parameter.
        /// </summary>
        ///
        public const String PropertyA1 = "A1";

        /// <summary>
        /// Neural network property, the B1 parameter.
        /// </summary>
        ///
        public const String PropertyB1 = "B1";

        /// <summary>
        /// Neural network property, the C1 parameter.
        /// </summary>
        ///
        public const String PropertyC1 = "C1";

        /// <summary>
        /// Neural network property, the D1 parameter.
        /// </summary>
        ///
        public const String PropertyD1 = "D1";

        /// <summary>
        /// Neural network property, the L parameter.
        /// </summary>
        ///
        public const String PropertyL = "L";

        /// <summary>
        /// Neural network property, the vigilance parameter.
        /// </summary>
        ///
        public const String PropertyVigilance = "VIGILANCE";

        /// <summary>
        /// Neural network property for no winner.
        /// </summary>
        ///
        public const String PropertyNoWinner = "noWinner";

        /// <summary>
        /// 
        /// </summary>
        ///
        public override void UpdateProperties()
        {
            // unneeded
        }
    }

    public class PersistART1 : ISyntPersistor
    {
        #region SyntPersistor Members

        /// <inheritdoc/>
        public int FileVersion
        {
            get { return 1; }
        }


        /// <inheritdoc/>
        public String PersistClassString
        {
            get { return "ART1"; }
        }


        /// <inheritdoc/>
        public Object Read(Stream mask0)
        {
            var result = new ART1();
            var ins0 = new SyntReadHelper(mask0);
            SyntFileSection section;

            while ((section = ins0.ReadNextSection()) != null)
            {
                if (section.SectionName.Equals("ART1")
                    && section.SubSectionName.Equals("PARAMS"))
                {
                    IDictionary<String, String> paras = section.ParseParams();
                    EngineArray.PutAll(paras, result.Properties);
                }
                if (section.SectionName.Equals("ART1")
                    && section.SubSectionName.Equals("NETWORK"))
                {
                    IDictionary<String, String> p = section.ParseParams();

                    result.A1 = SyntFileSection.ParseDouble(p,
                                                             BasicART.PropertyA1);
                    result.B1 = SyntFileSection.ParseDouble(p,
                                                             BasicART.PropertyB1);
                    result.C1 = SyntFileSection.ParseDouble(p,
                                                             BasicART.PropertyC1);
                    result.D1 = SyntFileSection.ParseDouble(p,
                                                             BasicART.PropertyD1);
                    result.F1Count = SyntFileSection.ParseInt(p,
                                                               PersistConst.PropertyF1Count);
                    result.F2Count = SyntFileSection.ParseInt(p,
                                                               PersistConst.PropertyF2Count);
                    result.NoWinner = SyntFileSection.ParseInt(p,
                                                                BasicART.PropertyNoWinner);
                    result.L = SyntFileSection
                        .ParseDouble(p, BasicART.PropertyL);
                    result.Vigilance = SyntFileSection.ParseDouble(p,
                                                                    BasicART.PropertyVigilance);
                    result.WeightsF1ToF2 = SyntFileSection.ParseMatrix(p,
                                                                        PersistConst.PropertyWeightsF1F2);
                    result.WeightsF2ToF1 = SyntFileSection.ParseMatrix(p,
                                                                        PersistConst.PropertyWeightsF2F1);
                }
            }

            return result;
        }

        /// <inheritdoc/>
        public void Save(Stream os, Object obj)
        {
            var xout = new SyntWriteHelper(os);
            var art1 = (ART1)obj;
            xout.AddSection("ART1");
            xout.AddSubSection("PARAMS");
            xout.AddProperties(art1.Properties);
            xout.AddSubSection("NETWORK");

            xout.WriteProperty(BasicART.PropertyA1, art1.A1);
            xout.WriteProperty(BasicART.PropertyB1, art1.B1);
            xout.WriteProperty(BasicART.PropertyC1, art1.C1);
            xout.WriteProperty(BasicART.PropertyD1, art1.D1);
            xout.WriteProperty(PersistConst.PropertyF1Count, art1.F1Count);
            xout.WriteProperty(PersistConst.PropertyF2Count, art1.F2Count);
            xout.WriteProperty(BasicART.PropertyNoWinner, art1.NoWinner);
            xout.WriteProperty(BasicART.PropertyL, art1.L);
            xout.WriteProperty(BasicART.PropertyVigilance, art1.Vigilance);
            xout.WriteProperty(PersistConst.PropertyWeightsF1F2,
                               art1.WeightsF1ToF2);
            xout.WriteProperty(PersistConst.PropertyWeightsF2F1,
                               art1.WeightsF2ToF1);

            xout.Flush();
        }

        /// <inheritdoc/>
        public Type NativeType
        {
            get { return typeof(ART1); }
        }

        #endregion
    }
    [Serializable]
    public class YPopulation : BasicPopulation
    {
        /// <summary>
        /// Y activation function tag.
        /// </summary>
        public const String PropertyYActivation = "YAct";

        /// <summary>
        /// Y output activation function.
        /// </summary>
        public const String PropertyOutputActivation = "outAct";

        /// <summary>
        /// The activation function for Y to use.
        /// </summary>
        ///
        private IActivationFunction _YActivationFunction;

        /// <summary>
        /// The activation function to use on the output layer of Synt.
        /// </summary>
        ///
        private IActivationFunction _outputActivationFunction;

        /// <summary>
        /// Are we using snapshot?
        /// </summary>
        private bool _snapshot;

        /// <summary>
        /// Construct a starting Y population.
        /// </summary>
        ///
        /// <param name="inputCount">The input neuron count.</param>
        /// <param name="outputCount">The output neuron count.</param>
        /// <param name="populationSize">The population size.</param>
        public YPopulation(int inputCount, int outputCount,
                              int populationSize) : base(populationSize)
        {
            _YActivationFunction = new ActivationSigmoid();
            _outputActivationFunction = new ActivationLinear();
            InputCount = inputCount;
            OutputCount = outputCount;

            if (populationSize == 0)
            {
                throw new NeuralNetworkError(
                    "Population must have more than zero Ts.");
            }

            // create the initial population
            for (int i = 0; i < populationSize; i++)
            {
                var T = new YT(AssignTID(), inputCount,
                                            outputCount);
                Add(T);
            }

            // create initial innovations
            var T2 = (YT)Ts[0];
          //  Innovations = new YInnovationList(this, T2.Links,                                           T2.Neurons);
        }

        /// <summary>
        /// Construct the object.
        /// </summary>
        public YPopulation()
        {
            _YActivationFunction = new ActivationSigmoid();
            _outputActivationFunction = new ActivationLinear();
        }


        /// <value>the inputCount to set</value>
        public int InputCount { get; set; }


        /// <value>the outputCount to set</value>
        public int OutputCount { get; set; }


        /// <value>the YActivationFunction to set</value>
        public IActivationFunction YActivationFunction
        {
            get { return _YActivationFunction; }
            set { _YActivationFunction = value; }
        }


        /// <value>the outputActivationFunction to set</value>
        public IActivationFunction OutputActivationFunction
        {
            get { return _outputActivationFunction; }
            set { _outputActivationFunction = value; }
        }


        /// <value>the snapshot to set</value>
        public bool Snapshot
        {
            get { return _snapshot; }
            set { _snapshot = value; }
        }
    }
    [Serializable]
    public class YNeuronGene : BasicGene
    {
        /// <summary>
        /// The activation response tag.
        /// </summary>
        public const String PROPERTY_ACT_RESPONSE = "aResp";

        /// <summary>
        /// The recurrent tag.
        /// </summary>
        public const String PROPERTY_RECURRENT = "recurrent";

        /// <summary>
        /// The split-x tag.
        /// </summary>
        public const String PROPERTY_SPLIT_X = "splitX";

        /// <summary>
        /// The split-y tag.
        /// </summary>
        public const String PROPERTY_SPLIT_Y = "splitY";

        /// <summary>
        /// The activation response, the slope of the activation function.
        /// </summary>
        ///
        private double activationResponse;

        /// <summary>
        /// The neuron type.
        /// </summary>
        ///
        private YNeuronType neuronType;

        /// <summary>
        /// True if this is recurrent.
        /// </summary>
        ///
        private bool recurrent;

        /// <summary>
        /// The x-split.
        /// </summary>
        ///
        private double splitX;

        /// <summary>
        /// The y-split.
        /// </summary>
        ///
        private double splitY;

        /// <summary>
        /// The default constructor.
        /// </summary>
        ///
        public YNeuronGene()
        {
        }

        /// <summary>
        /// Construct a gene.
        /// </summary>
        ///
        /// <param name="type">The type of neuron.</param>
        /// <param name="id">The id of this gene.</param>
        /// <param name="splitY_0">The split y.</param>
        /// <param name="splitX_1">The split x.</param>
        public YNeuronGene(YNeuronType type, long id,
                              double splitY_0, double splitX_1) : this(type, id, splitY_0, splitX_1, false, 1.0d)
        {
        }

        /// <summary>
        /// Construct a neuron gene.
        /// </summary>
        ///
        /// <param name="type">The type of neuron.</param>
        /// <param name="id">The id of this gene.</param>
        /// <param name="splitY_0">The split y.</param>
        /// <param name="splitX_1">The split x.</param>
        /// <param name="recurrent_2">True if this is a recurrent link.</param>
        /// <param name="act">The activation response.</param>
        public YNeuronGene(YNeuronType type, long id,
                              double splitY_0, double splitX_1, bool recurrent_2,
                              double act)
        {
            neuronType = type;
            Id = id;
            splitX = splitX_1;
            splitY = splitY_0;
            recurrent = recurrent_2;
            activationResponse = act;
        }

        /// <summary>
        /// Set the activation response.
        /// </summary>
        public double ActivationResponse
        {
            get { return activationResponse; }
            set { activationResponse = value; }
        }


        /// <summary>
        /// Set the neuron type.
        /// </summary>
        public YNeuronType NeuronType
        {
            get { return neuronType; }
            set { neuronType = value; }
        }


        /// <summary>
        /// Set the split x.
        /// </summary>
        public double SplitX
        {
            get { return splitX; }
            set { splitX = value; }
        }


        /// <summary>
        /// Set the split y.
        /// </summary>
        public double SplitY
        {
            get { return splitY; }
            set { splitY = value; }
        }


        /// <summary>
        /// Set if this is a recurrent neuron.
        /// </summary>
        public bool Recurrent
        {
            get { return recurrent; }
            set { recurrent = value; }
        }

        /// <summary>
        /// Copy another gene to this one.
        /// </summary>
        ///
        /// <param name="gene">The other gene.</param>
        public override void Copy(IGene gene)
        {
            var other = (YNeuronGene)gene;
            activationResponse = other.activationResponse;
            Id = other.Id;
            neuronType = other.neuronType;
            recurrent = other.recurrent;
            splitX = other.splitX;
            splitY = other.splitY;
        }

        /// <inheritdoc/>
        public override String ToString()
        {
            var result = new StringBuilder();
            result.Append("[YNeuronGene: id=");
            result.Append(Id);
            result.Append(", type=");
            result.Append(NeuronType);
            result.Append("]");
            return result.ToString();
        }
    }
    [Serializable]
    public class BasicInnovationList : IInnovationList
    {
        /// <summary>
        /// The list of innovations.
        /// </summary>
        ///
        private readonly IList<IInnovation> _list;

        /// <summary>
        /// Construct the object.
        /// </summary>
        public BasicInnovationList()
        {
            _list = new List<IInnovation>();
        }

        #region IInnovationList Members

        /// <summary>
        /// Add an innovation.
        /// </summary>
        ///
        /// <param name="innovation">The innovation to add.</param>
        public void Add(IInnovation innovation)
        {
            _list.Add(innovation);
        }

        /// <summary>
        /// Get a specific innovation, by index.
        /// </summary>
        ///
        /// <param name="id">The innovation index id.</param>
        /// <returns>The innovation.</returns>
        public IInnovation Get(int id)
        {
            return _list[id];
        }


        /// <value>A list of innovations.</value>
        public IList<IInnovation> Innovations
        {
            get { return _list; }
        }

        #endregion
    }
    [Serializable]
    public class YInnovationList : BasicInnovationList
    {
        /// <summary>
        /// The next neuron id.
        /// </summary>
        ///
        private long nextNeuronID;

        /// <summary>
        /// The population.
        /// </summary>
        ///
        private IPopulation population;

        /// <summary>
        /// The default constructor, used mainly for persistance.
        /// </summary>
        ///
        public YInnovationList()
        {
            nextNeuronID = 0;
        }

        /// <summary>
        /// Construct an innovation list.
        /// </summary>
        ///
        /// <param name="population_0">The population.</param>
        /// <param name="links">The links.</param>
        /// <param name="neurons">THe neurons.</param>
        public YInnovationList(IPopulation population_0,
                                  Q links, Q neurons)
        {
            //nextNeuronID = 0;
            //population = population_0;

            //foreach (IGene gene in neurons.Genes)
            //{
            //    var neuronGene = (YNeuronGene)gene;

            //    var innovation = new YInnovation(neuronGene,
            //                                        population_0.AssignInnovationID(), AssignNeuronID());
            //    Add(innovation);
            //}


            //foreach (IGene gene_1 in links.Genes)
            //{
            //    var linkGene = (YLinkGene)gene_1;
            //    var innovation_2 = new YInnovation(
            //        linkGene.FromNeuronID, linkGene.ToNeuronID,
            //        YInnovationType.NewLink,
            //        population.AssignInnovationID());
            //    Add(innovation_2);
            //}
        }

        /// <summary>
        /// The population.
        /// </summary>
        public YPopulation Population
        {
            set { population = value; }
        }

        /// <summary>
        /// Assign a neuron ID.
        /// </summary>
        ///
        /// <returns>The neuron id.</returns>
        private long AssignNeuronID()
        {
            return nextNeuronID++;
        }

        /// <summary>
        /// Check to see if we already have an innovation.
        /// </summary>
        ///
        /// <param name="ins0">The input neuron.</param>
        /// <param name="xout">THe output neuron.</param>
        /// <param name="type">The type.</param>
        /// <returns>The innovation, either new or existing if found.</returns>
        public YInnovation CheckInnovation(long ins0, long xout,
                                              YInnovationType type)
        {
            foreach (IInnovation i in Innovations)
            {
                var innovation = (YInnovation)i;
                if ((innovation.FromNeuronID == ins0)
                    && (innovation.ToNeuronID == xout)
                    && (innovation.InnovationType == type))
                {
                    return innovation;
                }
            }

            return null;
        }

        /// <summary>
        /// Create a new neuron gene from an id.
        /// </summary>
        ///
        /// <param name="neuronID">The neuron id.</param>
        /// <returns>The neuron gene.</returns>
        public YNeuronGene CreateNeuronFromID(long neuronID)
        {
            var result = new YNeuronGene(YNeuronType.Hidden,
                                            0, 0, 0);


            foreach (IInnovation i in Innovations)
            {
                var innovation = (YInnovation)i;
                if (innovation.NeuronID == neuronID)
                {
                    result.NeuronType = innovation.NeuronType;
                    result.Id = innovation.NeuronID;
                    result.SplitY = innovation.SplitY;
                    result.SplitX = innovation.SplitX;

                    return result;
                }
            }

            throw new TrainingError("Failed to find innovation for neuron: "
                                    + neuronID);
        }

        /// <summary>
        /// Create a new innovation.
        /// </summary>
        ///
        /// <param name="ins0">The input neuron.</param>
        /// <param name="xout">The output neuron.</param>
        /// <param name="type">The type.</param>
        public void CreateNewInnovation(long ins0, long xout,
                                        YInnovationType type)
        {
            var newInnovation = new YInnovation(ins0, xout, type,
                                                   population.AssignInnovationID());

            if (type == YInnovationType.NewNeuron)
            {
                newInnovation.NeuronID = AssignNeuronID();
            }

            Add(newInnovation);
        }

        /// <summary>
        /// Create a new innovation.
        /// </summary>
        ///
        /// <param name="from">The from neuron.</param>
        /// <param name="to">The to neuron.</param>
        /// <param name="innovationType">THe innovation type.</param>
        /// <param name="neuronType">The neuron type.</param>
        /// <param name="x">The x-coordinate.</param>
        /// <param name="y">The y-coordinate.</param>
        /// <returns>The new innovation.</returns>
        public long CreateNewInnovation(long from, long to,
                                        YInnovationType innovationType,
                                        YNeuronType neuronType, double x, double y)
        {
            var newInnovation = new YInnovation(from, to,
                                                   innovationType, population.AssignInnovationID(),
                                                   neuronType, x, y);

            if (innovationType == YInnovationType.NewNeuron)
            {
                newInnovation.NeuronID = AssignNeuronID();
            }

            Add(newInnovation);

            return (nextNeuronID - 1); // ??????? should it be innov?
        }
    }

    [Serializable]
    public class BasicInnovation : IInnovation
    {
        #region IInnovation Members

        /// <summary>
        /// Set the innovation id.
        /// </summary>
        public long InnovationID
        {
            get;
            set;
        }

        #endregion
    }

    [Serializable]
    public class YT : BasicT, ICloneable
    {
        /// <summary>
        /// The neurons property.
        /// </summary>
        public const String PROPERTY_NEURONS = "neurons";

        /// <summary>
        /// The links property.
        /// </summary>
        public const String PROPERTY_LINKS = "links";

        /// <summary>
        /// The adjustment factor for disjoint genes.
        /// </summary>
        ///
        public const double TWEAK_DISJOINT = 1;

        /// <summary>
        /// The adjustment factor for excess genes.
        /// </summary>
        ///
        public const double TWEAK_EXCESS = 1;

        /// <summary>
        /// The adjustment factor for matched genes.
        /// </summary>
        ///
        public const double TWEAK_MATCHED = 0.4d;

        /// <summary>
        /// The number of inputs.
        /// </summary>
        ///
        private int inputCount;

        /// <summary>
        /// The chromsome that holds the links.
        /// </summary>
        ///
        private Q linksQ;

        /// <summary>
        /// THe network depth.
        /// </summary>
        ///
        private int networkDepth;

        /// <summary>
        /// The Q that holds the neurons.
        /// </summary>
        ///
        private Q neuronsQ;

        /// <summary>
        /// The number of outputs.
        /// </summary>
        ///
        private int outputCount;

        /// <summary>
        /// The species id.
        /// </summary>
        ///
        private long speciesID;

        /// <summary>
        /// Construct a T by copying another.
        /// </summary>
        ///
        /// <param name="other">The other T.</param>
        public YT(YT other)
        {
            neuronsQ = new Q();
            linksQ = new Q();
            GA = other.GA;

            Qs.Add(neuronsQ);
            Qs.Add(linksQ);

            TID = other.TID;
            networkDepth = other.networkDepth;
            Population = other.Population;
            Score = other.Score;
            AdjustedScore = other.AdjustedScore;
            AmountToSpawn = other.AmountToSpawn;
            inputCount = other.inputCount;
            outputCount = other.outputCount;
            speciesID = other.speciesID;


            // copy neurons
            foreach (IGene gene in other.Neurons.Genes)
            {
                var oldGene = (YNeuronGene)gene;
                var newGene = new YNeuronGene(
                    oldGene.NeuronType, oldGene.Id,
                    oldGene.SplitY, oldGene.SplitX,
                    oldGene.Recurrent, oldGene.ActivationResponse);
                Neurons.Add(newGene);
            }


            // copy links
            foreach (IGene gene_0 in other.Links.Genes)
            {
                var oldGene_1 = (YLinkGene)gene_0;
                var newGene_2 = new YLinkGene(
                    oldGene_1.FromNeuronID, oldGene_1.ToNeuronID,
                    oldGene_1.Enabled, oldGene_1.InnovationId,
                    oldGene_1.Weight, oldGene_1.Recurrent);
                Links.Add(newGene_2);
            }
        }

        /// <summary>
        /// Create a Y gnome.
        /// </summary>
        ///
        /// <param name="TID">The T id.</param>
        /// <param name="neurons">The neurons.</param>
        /// <param name="links">The links.</param>
        /// <param name="inputCount_0">The input count.</param>
        /// <param name="outputCount_1">The output count.</param>
        public YT(long TID, Q neurons,
                          Q links, int inputCount_0, int outputCount_1)
        {
            TID = TID;
            linksQ = links;
            neuronsQ = neurons;
            AmountToSpawn = 0;
            AdjustedScore = 0;
            inputCount = inputCount_0;
            outputCount = outputCount_1;

            Qs.Add(neuronsQ);
            Qs.Add(linksQ);
        }

        /// <summary>
        /// Construct a T, do not provide links and neurons.
        /// </summary>
        ///
        /// <param name="id">The T id.</param>
        /// <param name="inputCount_0">The input count.</param>
        /// <param name="outputCount_1">The output count.</param>
        public YT(long id, int inputCount_0, int outputCount_1)
        {
            TID = id;
            AdjustedScore = 0;
            inputCount = inputCount_0;
            outputCount = outputCount_1;
            AmountToSpawn = 0;
            speciesID = 0;

            double inputRowSlice = 0.8d / (inputCount_0);
            neuronsQ = new Q();
            linksQ = new Q();

            Qs.Add(neuronsQ);
            Qs.Add(linksQ);

            for (int i = 0; i < inputCount_0; i++)
            {
                neuronsQ.Add(new YNeuronGene(YNeuronType.Input,
                                                         i, 0, 0.1d + i * inputRowSlice));
            }

            neuronsQ.Add(new YNeuronGene(YNeuronType.Bias,
                                                     inputCount_0, 0, 0.9d));

            double outputRowSlice = 1 / (double)(outputCount_1 + 1);

            for (int i_2 = 0; i_2 < outputCount_1; i_2++)
            {
                neuronsQ.Add(new YNeuronGene(
                                          YNeuronType.Output, i_2 + inputCount_0 + 1, 1, (i_2 + 1)
                                                                                            * outputRowSlice));
            }

            for (int i_3 = 0; i_3 < inputCount_0 + 1; i_3++)
            {
                for (int j = 0; j < outputCount_1; j++)
                {
                    linksQ.Add(new YLinkGene(
                                            ((YNeuronGene)neuronsQ.Get(i_3)).Id,
                                            ((YNeuronGene)Neurons.Get(
                                                inputCount_0 + j + 1)).Id, true, inputCount_0
                                                                                 + outputCount_1 + 1 + NumGenes,
                                            RangeRandomizer.Randomize(-1, 1), false));
                }
            }
        }

        /// <summary>
        /// Construct the object.
        /// </summary>
        public YT()
        {
        }

        /// <value>the inputCount to set</value>
        public int InputCount
        {
            get { return inputCount; }
            set { inputCount = value; }
        }


        /// <value>THe links Q.</value>
        public Q Links
        {
            get { return linksQ; }
        }


        /// <value>the networkDepth to set</value>
        public int NetworkDepth
        {
            get { return networkDepth; }
            set { networkDepth = value; }
        }


        /// <value>The neurons Q.</value>
        public Q Neurons
        {
            get { return neuronsQ; }
        }


        /// <value>The number of genes in the links Q.</value>
        public int NumGenes
        {
            get { return linksQ.Size(); }
        }


        /// <value>the outputCount to set</value>
        public int OutputCount
        {
            get { return outputCount; }
            set { outputCount = value; }
        }


        /// <summary>
        /// Set the species id.
        /// </summary>
        ///
        /// <value>The species id.</value>
        public long SpeciesID
        {
            get { return speciesID; }
            set { speciesID = value; }
        }

        /// <value>the linksQ to set</value>
        public Q LinksQ
        {
            get { return linksQ; }
            set { linksQ = value; }
        }


        /// <value>the neuronsQ to set</value>
        public Q NeuronsQ
        {
            get { return neuronsQ; }
            set { neuronsQ = value; }
        }

        #region ICloneable Members

        /// <summary>
        /// Clone the object. Not currently supported.
        /// </summary>
        /// <returns>The cloned object.</returns>
        public object Clone()
        {
            throw new NotImplementedException();
        }

        #endregion

        /// <summary>
        /// Mutate the T by adding a link to this T.
        /// </summary>
        ///
        /// <param name="mutationRate">The mutation rate.</param>
        /// <param name="chanceOfLooped">The chance of a self-connected neuron.</param>
        /// <param name="numTrysToFindLoop">The number of tries to find a loop.</param>
        /// <param name="numTrysToAddLink">The number of tries to add a link.</param>
        internal void AddLink(double mutationRate, double chanceOfLooped,
                              int numTrysToFindLoop, int numTrysToAddLink)
        {
            // should we even add the link
            if (ThreadSafeRandom.NextDouble() > mutationRate)
            {
                return;
            }

            int countTrysToFindLoop = numTrysToFindLoop;
            int countTrysToAddLink = numTrysToFindLoop;

            // the link will be between these two neurons
            long neuron1ID = -1;
            long neuron2ID = -1;

            bool recurrent = false;

            // a self-connected loop?
            if (ThreadSafeRandom.NextDouble() < chanceOfLooped)
            {
                // try to find(randomly) a neuron to add a self-connected link to
                while ((countTrysToFindLoop--) > 0)
                {
                    YNeuronGene neuronGene = ChooseRandomNeuron(false);

                    // no self-links on input or bias neurons
                    if (!neuronGene.Recurrent
                        && (neuronGene.NeuronType != YNeuronType.Bias)
                        && (neuronGene.NeuronType != YNeuronType.Input))
                    {
                        neuron1ID = neuronGene.Id;
                        neuron2ID = neuronGene.Id;

                        neuronGene.Recurrent = true;
                        recurrent = true;

                        countTrysToFindLoop = 0;
                    }
                }
            }
            else
            {
                // try to add a regular link
                while ((countTrysToAddLink--) > 0)
                {
                    YNeuronGene neuron1 = ChooseRandomNeuron(true);
                    YNeuronGene neuron2 = ChooseRandomNeuron(false);

                    if (!IsDuplicateLink(neuron1ID, neuron2ID)
                        && (neuron1.Id != neuron2.Id)
                        && (neuron2.NeuronType != YNeuronType.Bias))
                    {
                        neuron1ID = neuron1.Id;
                        neuron2ID = neuron2.Id;
                        break;
                    }
                }
            }

            // did we fail to find a link
            if ((neuron1ID < 0) || (neuron2ID < 0))
            {
                return;
            }

            // check to see if this innovation has already been tried
            YInnovation innovation = ((YTraining)GA).Innovations.CheckInnovation(neuron1ID,
                                                                                                      neuron1ID,
                                                                                                      YInnovationType
                                                                                                          .NewLink);

            // see if this is a recurrent(backwards) link
            var neuronGene_0 = (YNeuronGene)neuronsQ
                                                    .Get(GetElementPos(neuron1ID));
            if (neuronGene_0.SplitY > neuronGene_0.SplitY)
            {
                recurrent = true;
            }

            // is this a new innovation?
            if (innovation == null)
            {
                // new innovation
                ((YTraining)GA).Innovations
                    .CreateNewInnovation(neuron1ID, neuron2ID,
                                         YInnovationType.NewLink);

                long id2 = GA.Population.AssignInnovationID();

                var linkGene = new YLinkGene(neuron1ID,
                                                neuron2ID, true, id2, RangeRandomizer.Randomize(-1, 1),
                                                recurrent);
                linksQ.Add(linkGene);
            }
            else
            {
                // existing innovation
                var linkGene_1 = new YLinkGene(neuron1ID,
                                                  neuron2ID, true, innovation.InnovationID,
                                                  RangeRandomizer.Randomize(-1, 1), recurrent);
                linksQ.Add(linkGene_1);
            }
        }

        /// <summary>
        /// Mutate the T by adding a neuron.
        /// </summary>
        ///
        /// <param name="mutationRate">The mutation rate.</param>
        /// <param name="numTrysToFindOldLink">The number of tries to find a link to split.</param>
        internal void AddNeuron(double mutationRate, int numTrysToFindOldLink)
        {
            // should we add a neuron?
            if (ThreadSafeRandom.NextDouble() > mutationRate)
            {
                return;
            }

            int countTrysToFindOldLink = numTrysToFindOldLink;

            // the link to split
            YLinkGene splitLink = null;

            int sizeBias = inputCount + outputCount + 10;

            // if there are not at least
            int upperLimit;
            if (linksQ.Size() < sizeBias)
            {
                upperLimit = NumGenes - 1 - (int)Math.Sqrt(NumGenes);
            }
            else
            {
                upperLimit = NumGenes - 1;
            }

            while ((countTrysToFindOldLink--) > 0)
            {
                // choose a link, use the square root to prefer the older links
                int i = RangeRandomizer.RandomInt(0, upperLimit);
                var link = (YLinkGene)linksQ
                                              .Get(i);

                // get the from neuron
                long fromNeuron = link.FromNeuronID;

                if ((link.Enabled)
                    && (!link.Recurrent)
                    && (((YNeuronGene)Neurons.Get(
                        GetElementPos(fromNeuron))).NeuronType != YNeuronType.Bias))
                {
                    splitLink = link;
                    break;
                }
            }

            if (splitLink == null)
            {
                return;
            }

            splitLink.Enabled = false;

            double originalWeight = splitLink.Weight;

            long from = splitLink.FromNeuronID;
            long to = splitLink.ToNeuronID;

            var fromGene = (YNeuronGene)Neurons.Get(
                GetElementPos(from));
            var toGene = (YNeuronGene)Neurons.Get(
                GetElementPos(to));

            double newDepth = (fromGene.SplitY + toGene.SplitY) / 2;
            double newWidth = (fromGene.SplitX + toGene.SplitX) / 2;

            // has this innovation already been tried?
            YInnovation innovation = ((YTraining)GA).Innovations.CheckInnovation(from, to,
                                                                                                      YInnovationType
                                                                                                          .NewNeuron);

            // prevent chaining
            if (innovation != null)
            {
                long neuronID = innovation.NeuronID;

                if (AlreadyHaveThisNeuronID(neuronID))
                {
                    innovation = null;
                }
            }

            if (innovation == null)
            {
                // this innovation has not been tried, create it
                long newNeuronID = ((YTraining)GA).Innovations.CreateNewInnovation(from, to,
                                                                                                     YInnovationType.
                                                                                                         NewNeuron,
                                                                                                     YNeuronType.
                                                                                                         Hidden,
                                                                                                     newWidth, newDepth);

                neuronsQ.Add(new YNeuronGene(
                                          YNeuronType.Hidden, newNeuronID, newDepth, newWidth));

                // add the first link
                long link1ID = (GA).Population.AssignInnovationID();

                ((YTraining)GA).Innovations
                    .CreateNewInnovation(from, newNeuronID,
                                         YInnovationType.NewLink);

                var link1 = new YLinkGene(from, newNeuronID,
                                             true, link1ID, 1.0d, false);

                linksQ.Add(link1);

                // add the second link
                long link2ID = (GA).Population.AssignInnovationID();

                ((YTraining)GA).Innovations
                    .CreateNewInnovation(newNeuronID, to,
                                         YInnovationType.NewLink);

                var link2 = new YLinkGene(newNeuronID, to, true,
                                             link2ID, originalWeight, false);

                linksQ.Add(link2);
            }

            else
            {
                // existing innovation
                long newNeuronID_0 = innovation.NeuronID;

                YInnovation innovationLink1 = ((YTraining)GA).Innovations.CheckInnovation(from,
                                                                                                               newNeuronID_0,
                                                                                                               YInnovationType
                                                                                                                   .
                                                                                                                   NewLink);
                YInnovation innovationLink2 =
                    ((YTraining)GA).Innovations.CheckInnovation(newNeuronID_0, to,
                                                                                  YInnovationType.NewLink);

                if ((innovationLink1 == null) || (innovationLink2 == null))
                {
                    throw new NeuralNetworkError("Y Error");
                }

                var link1_1 = new YLinkGene(from, newNeuronID_0,
                                               true, innovationLink1.InnovationID, 1.0d, false);
                var link2_2 = new YLinkGene(newNeuronID_0, to, true,
                                               innovationLink2.InnovationID, originalWeight, false);

                linksQ.Add(link1_1);
                linksQ.Add(link2_2);

                var newNeuron = new YNeuronGene(
                    YNeuronType.Hidden, newNeuronID_0, newDepth, newWidth);

                neuronsQ.Add(newNeuron);
            }

            return;
        }

        /// <summary>
        /// Do we already have this neuron id?
        /// </summary>
        ///
        /// <param name="id">The id to check for.</param>
        /// <returns>True if we already have this neuron id.</returns>
        public bool AlreadyHaveThisNeuronID(long id)
        {
            foreach (IGene gene in neuronsQ.Genes)
            {
                var neuronGene = (YNeuronGene)gene;

                if (neuronGene.Id == id)
                {
                    return true;
                }
            }

            return false;
        }

        /// <summary>
        /// Choose a random neuron.
        /// </summary>
        ///
        /// <param name="includeInput">Should the input neurons be included.</param>
        /// <returns>The random neuron.</returns>
        private YNeuronGene ChooseRandomNeuron(bool includeInput)
        {
            int start;

            if (includeInput)
            {
                start = 0;
            }
            else
            {
                start = inputCount + 1;
            }

            int neuronPos = RangeRandomizer.RandomInt(start, Neurons
                                                                 .Size() - 1);
            var neuronGene = (YNeuronGene)neuronsQ
                                                  .Get(neuronPos);
            return neuronGene;
        }

        /// <summary>
        /// Convert the genes to an actual network.
        /// </summary>
        ///
        public override void Decode()
        {
            var pop = (YPopulation)Population;

            IList<YNeuron> neurons = new List<YNeuron>();


            foreach (IGene gene in Neurons.Genes)
            {
                var neuronGene = (YNeuronGene)gene;
                var neuron = new YNeuron(
                    neuronGene.NeuronType, neuronGene.Id,
                    neuronGene.SplitY, neuronGene.SplitX,
                    neuronGene.ActivationResponse);

                neurons.Add(neuron);
            }


            // now to create the links.
            foreach (IGene gene_0 in Links.Genes)
            {
                var linkGene = (YLinkGene)gene_0;
                if (linkGene.Enabled)
                {
                    int element = GetElementPos(linkGene.FromNeuronID);
                    YNeuron fromNeuron = neurons[element];

                    element = GetElementPos(linkGene.ToNeuronID);
                    if (element == -1)
                    {
                        Console.Out.WriteLine("test");
                    }
                    YNeuron toNeuron = neurons[element];

                    var link = new YLink(linkGene.Weight,
                                            fromNeuron, toNeuron, linkGene.Recurrent);

                    fromNeuron.OutputboundLinks.Add(link);
                    toNeuron.InboundLinks.Add(link);
                }
            }

            var network = new YNetwork(inputCount, outputCount, neurons,
                                          pop.YActivationFunction,
                                          pop.OutputActivationFunction, 0);

            network.Snapshot = pop.Snapshot;
            Organism = network;
        }

        /// <summary>
        /// Convert the network to genes. Not currently supported.
        /// </summary>
        ///
        public override void Syntesis()
        {
        }

        /// <summary>
        /// Get the compatibility score with another T. Used to determine
        /// species.
        /// </summary>
        ///
        /// <param name="T">The other T.</param>
        /// <returns>The score.</returns>
        public double GetCompatibilityScore(YT T)
        {
            double numDisjoint = 0;
            double numExcess = 0;
            double numMatched = 0;
            double weightDifference = 0;

            int g1 = 0;
            int g2 = 0;

            while ((g1 < linksQ.Size() - 1)
                   || (g2 < linksQ.Size() - 1))
            {
                if (g1 == linksQ.Size() - 1)
                {
                    g2++;
                    numExcess++;

                    continue;
                }

                if (g2 == T.Links.Size() - 1)
                {
                    g1++;
                    numExcess++;

                    continue;
                }

                // get innovation numbers for each gene at this point
                long id1 = ((YLinkGene)linksQ.Get(g1)).InnovationId;
                long id2 = ((YLinkGene)T.Links.Get(g2)).InnovationId;

                // innovation numbers are identical so increase the matched score
                if (id1 == id2)
                {
                    g1++;
                    g2++;
                    numMatched++;

                    // get the weight difference between these two genes
                    weightDifference += Math.Abs(((YLinkGene)linksQ.Get(g1)).Weight
                                                 - ((YLinkGene)T.Links.Get(g2)).Weight);
                }

                // innovation numbers are different so increment the disjoint score
                if (id1 < id2)
                {
                    numDisjoint++;
                    g1++;
                }

                if (id1 > id2)
                {
                    ++numDisjoint;
                    ++g2;
                }
            }

            int longest = T.NumGenes;

            if (NumGenes > longest)
            {
                longest = NumGenes;
            }

            double score = (TWEAK_EXCESS * numExcess / longest)
                           + (TWEAK_DISJOINT * numDisjoint / longest)
                           + (TWEAK_MATCHED * weightDifference / numMatched);

            return score;
        }

        /// <summary>
        /// Get the specified neuron's index.
        /// </summary>
        ///
        /// <param name="neuronID">The neuron id to check for.</param>
        /// <returns>The index.</returns>
        private int GetElementPos(long neuronID)
        {
            for (int i = 0; i < Neurons.Size(); i++)
            {
                var neuronGene = (YNeuronGene)neuronsQ
                                                      .GetGene(i);
                if (neuronGene.Id == neuronID)
                {
                    return i;
                }
            }

            return -1;
        }


        /// <summary>
        /// Get the specified split y.
        /// </summary>
        ///
        /// <param name="nd">The neuron.</param>
        /// <returns>The split y.</returns>
        public double GetSplitY(int nd)
        {
            return ((YNeuronGene)neuronsQ.Get(nd)).SplitY;
        }

        /// <summary>
        /// Determine if this is a duplicate link.
        /// </summary>
        ///
        /// <param name="fromNeuronID">The from neuron id.</param>
        /// <param name="toNeuronID">The to neuron id.</param>
        /// <returns>True if this is a duplicate link.</returns>
        public bool IsDuplicateLink(long fromNeuronID,
                                    long toNeuronID)
        {
            foreach (IGene gene in Links.Genes)
            {
                var linkGene = (YLinkGene)gene;
                if ((linkGene.FromNeuronID == fromNeuronID)
                    && (linkGene.ToNeuronID == toNeuronID))
                {
                    return true;
                }
            }

            return false;
        }

        /// <summary>
        /// Mutate the activation response.
        /// </summary>
        ///
        /// <param name="mutateRate">The mutation rate.</param>
        /// <param name="maxPertubation">The maximum to perturb it by.</param>
        public void MutateActivationResponse(double mutateRate,
                                             double maxPertubation)
        {
            foreach (IGene gene in neuronsQ.Genes)
            {
                if (ThreadSafeRandom.NextDouble() < mutateRate)
                {
                    var neuronGene = (YNeuronGene)gene;
                    neuronGene.ActivationResponse = neuronGene.ActivationResponse
                                                    + RangeRandomizer.Randomize(-1, 1) * maxPertubation;
                }
            }
        }

        /// <summary>
        /// Mutate the weights.
        /// </summary>
        ///
        /// <param name="mutateRate">The mutation rate.</param>
        /// <param name="probNewMutate">The probability of a whole new weight.</param>
        /// <param name="maxPertubation">The max perturbation.</param>
        public void MutateWeights(double mutateRate,
                                  double probNewMutate, double maxPertubation)
        {
            foreach (IGene gene in linksQ.Genes)
            {
                var linkGene = (YLinkGene)gene;
                if (ThreadSafeRandom.NextDouble() < mutateRate)
                {
                    if (ThreadSafeRandom.NextDouble() < probNewMutate)
                    {
                        linkGene.Weight = RangeRandomizer.Randomize(-1, 1);
                    }
                    else
                    {
                        linkGene.Weight = linkGene.Weight
                                          + RangeRandomizer.Randomize(-1, 1) * maxPertubation;
                    }
                }
            }
        }

        /// <summary>
        /// Sort the genes.
        /// </summary>
        ///
        public void SortGenes()
        {
            linksQ.Genes.Sort();
        }
    }

    [Serializable]
    public class YInnovation : BasicInnovation
    {
        /// <summary>
        /// The from neuron id.
        /// </summary>
        ///
        private long fromNeuronID;

        /// <summary>
        /// The type of innovation.
        /// </summary>
        ///
        private YInnovationType innovationType;

        /// <summary>
        /// The neuron id.
        /// </summary>
        ///
        private long neuronID;

        /// <summary>
        /// The type of neuron, or none, if this is a link innovation.
        /// </summary>
        ///
        private YNeuronType neuronType;

        /// <summary>
        /// The split x property.
        /// </summary>
        ///
        private double splitX;

        /// <summary>
        /// The split y property.
        /// </summary>
        ///
        private double splitY;

        /// <summary>
        /// The to neuron's id.
        /// </summary>
        ///
        private long toNeuronID;

        /// <summary>
        /// Default constructor, used mainly for persistence.
        /// </summary>
        ///
        public YInnovation()
        {
        }

        /// <summary>
        /// Construct an innovation.
        /// </summary>
        ///
        /// <param name="fromNeuronID_0">The from neuron.</param>
        /// <param name="toNeuronID_1">The two neuron.</param>
        /// <param name="innovationType_2">The innovation type.</param>
        /// <param name="innovationID">The innovation id.</param>
        public YInnovation(long fromNeuronID_0, long toNeuronID_1,
                              YInnovationType innovationType_2, long innovationID)
        {
            fromNeuronID = fromNeuronID_0;
            toNeuronID = toNeuronID_1;
            innovationType = innovationType_2;
            InnovationID = innovationID;

            neuronID = -1;
            splitX = 0;
            splitY = 0;
            neuronType = YNeuronType.None;
        }

        /// <summary>
        /// Construct an innovation.
        /// </summary>
        ///
        /// <param name="fromNeuronID_0">The from neuron.</param>
        /// <param name="toNeuronID_1">The to neuron.</param>
        /// <param name="innovationType_2">The innovation type.</param>
        /// <param name="innovationID">The innovation id.</param>
        /// <param name="neuronType_3">The neuron type.</param>
        /// <param name="x">The x coordinate.</param>
        /// <param name="y">THe y coordinate.</param>
        public YInnovation(long fromNeuronID_0, long toNeuronID_1,
                              YInnovationType innovationType_2, long innovationID,
                              YNeuronType neuronType_3, double x, double y)
        {
            fromNeuronID = fromNeuronID_0;
            toNeuronID = toNeuronID_1;
            innovationType = innovationType_2;
            InnovationID = innovationID;
            neuronType = neuronType_3;
            splitX = x;
            splitY = y;

            neuronID = 0;
        }

        /// <summary>
        /// Construct an innovation.
        /// </summary>
        ///
        /// <param name="neuronGene">The neuron gene.</param>
        /// <param name="innovationID">The innovation id.</param>
        /// <param name="neuronID_0">The neuron id.</param>
        public YInnovation(YNeuronGene neuronGene,
                              long innovationID, long neuronID_0)
        {
            neuronID = neuronID_0;
            InnovationID = innovationID;
            splitX = neuronGene.SplitX;
            splitY = neuronGene.SplitY;

            neuronType = neuronGene.NeuronType;
            innovationType = YInnovationType.NewNeuron;
            fromNeuronID = -1;
            toNeuronID = -1;
        }


        /// <value>the fromNeuronID to set</value>
        public long FromNeuronID
        {
            get { return fromNeuronID; }
            set { fromNeuronID = value; }
        }

        /// <summary>
        /// The innovation type.
        /// </summary>
        public YInnovationType InnovationType
        {
            get { return innovationType; }
            set { innovationType = value; }
        }


        /// <summary>
        /// Set the neuron id.
        /// </summary>
        public long NeuronID
        {
            get { return neuronID; }
            set { neuronID = value; }
        }

        /// <summary>
        /// The neuron type.
        /// </summary>
        public YNeuronType NeuronType
        {
            get { return neuronType; }
            set { neuronType = value; }
        }

        /// <summary>
        /// The split X, useful for display, also used during training, max is 1.0.
        /// </summary>
        public double SplitX
        {
            get { return splitX; }
            set { splitX = value; }
        }

        /// <summary>
        /// The split Y, useful for display, also used during training, max is 1.0.
        /// </summary>
        public double SplitY
        {
            get { return splitY; }
            set { splitY = value; }
        }


        /// <value>the toNeuronID to set</value>
        public long ToNeuronID
        {
            get { return toNeuronID; }
            set { toNeuronID = value; }
        }


        /// <inheritdoc/>
        public override String ToString()
        {
            var result = new StringBuilder();
            result.Append("[YInnovation:type=");
            switch (innovationType)
            {
                case YInnovationType.NewLink:
                    result.Append("link");
                    break;
                case YInnovationType.NewNeuron:
                    result.Append("neuron");
                    break;
            }
            result.Append(",from=");
            result.Append(fromNeuronID);
            result.Append(",to=");
            result.Append(toNeuronID);
            result.Append(",splitX=");
            result.Append(splitX);
            result.Append(",splitY=");
            result.Append(splitY);
            result.Append("]");
            return result.ToString();
        }
    }

    [Serializable]
    public class YLinkGene : BasicGene
    {
        /// <summary>
        /// The from neuron id.
        /// </summary>
        ///
        private long fromNeuronID;

        /// <summary>
        /// Is this a recurrent connection.
        /// </summary>
        ///
        private bool recurrent;

        /// <summary>
        /// The to neuron id.
        /// </summary>
        ///
        private long toNeuronID;

        /// <summary>
        /// The weight of this link.
        /// </summary>
        ///
        private double weight;

        /// <summary>
        /// Default constructor, used mainly for persistence.
        /// </summary>
        ///
        public YLinkGene()
        {
        }

        /// <summary>
        /// Construct a Y link gene.
        /// </summary>
        ///
        /// <param name="fromNeuronID_0">The source neuron.</param>
        /// <param name="toNeuronID_1">The target neuron.</param>
        /// <param name="enabled">Is this link enabled.</param>
        /// <param name="innovationID">The innovation id.</param>
        /// <param name="weight_2">The weight.</param>
        /// <param name="recurrent_3">Is this a recurrent link?</param>
        public YLinkGene(long fromNeuronID_0, long toNeuronID_1,
                            bool enabled, long innovationID,
                            double weight_2, bool recurrent_3)
        {
            fromNeuronID = fromNeuronID_0;
            toNeuronID = toNeuronID_1;
            Enabled = enabled;
            InnovationId = innovationID;
            weight = weight_2;
            recurrent = recurrent_3;
        }

        /// <summary>
        /// Set the weight of this connection.
        /// </summary>
        public double Weight
        {
            get { return weight; }
            set { weight = value; }
        }

        /// <summary>
        /// True if this is a recurrent link.
        /// </summary>
        public bool Recurrent
        {
            get { return recurrent; }
            set { recurrent = value; }
        }

        /// <summary>
        /// The from neuron id.
        /// </summary>
        public int FromNeuronID
        {
            get { return (int)fromNeuronID; }
            set { fromNeuronID = value; }
        }

        /// <summary>
        /// The to neuron id.
        /// </summary>
        public int ToNeuronID
        {
            get { return (int)toNeuronID; }
            set { toNeuronID = value; }
        }

        /// <summary>
        /// Copy from another gene.
        /// </summary>
        /// <param name="gene">The other gene.</param>
        public override void Copy(IGene gene)
        {
            var other = (YLinkGene)gene;
            Enabled = other.Enabled;
            fromNeuronID = other.fromNeuronID;
            toNeuronID = other.toNeuronID;
            InnovationId = other.InnovationId;
            recurrent = other.recurrent;
            weight = other.weight;
        }


        /// <inheritdoc/>
        public override String ToString()
        {
            var result = new StringBuilder();
            result.Append("[YLinkGene:innov=");
            result.Append(InnovationId);
            result.Append(",enabled=");
            result.Append(Enabled);
            result.Append(",from=");
            result.Append(fromNeuronID);
            result.Append(",to=");
            result.Append(toNeuronID);
            result.Append("]");
            return result.ToString();
        }
    }

    [Serializable]
    public class YNetwork : BasicML, IMLContext, IMLRegression,
                              IMLError
    {
        /// <summary>
        /// The depth property.
        /// </summary>
        public const String PropertyNetworkDepth = "depth";

        /// <summary>
        /// The links property.
        /// </summary>
        public const String PropertyLinks = "links";

        /// <summary>
        /// The snapshot property.
        /// </summary>
        public const String PropertySnapshot = "snapshot";

        /// <summary>
        /// The neurons that make up this network.
        /// </summary>
        ///
        private readonly IList<YNeuron> _neurons;

        /// <summary>
        /// The activation function.
        /// </summary>
        ///
        private IActivationFunction _activationFunction;

        /// <summary>
        /// The input count.
        /// </summary>
        private int _inputCount;

        /// <summary>
        /// The depth of the network.
        /// </summary>
        ///
        private int _networkDepth;

        /// <summary>
        /// The output activation function.
        /// </summary>
        private IActivationFunction _outputActivationFunction;

        /// <summary>
        /// The output count.
        /// </summary>
        private int _outputCount;

        /// <summary>
        /// Should snapshot be used to calculate the output of the neural network.
        /// </summary>
        ///
        private bool _snapshot;

        /// <summary>
        /// Default constructor.
        /// </summary>
        ///
        public YNetwork()
        {
            _neurons = new List<YNeuron>();
            _snapshot = false;
        }

        /// <summary>
        /// Construct a Y synapse.
        /// </summary>
        ///
        /// <param name="inputCount">The number of input neurons.</param>
        /// <param name="outputCount">The number of output neurons.</param>
        /// <param name="neurons">The neurons in this synapse.</param>
        /// <param name="activationFunction">The activation function to use.</param>
        /// <param name="outputActivationFunction">The output activation function.</param>
        /// <param name="networkDepth">The depth of the network.</param>
        public YNetwork(int inputCount, int outputCount,
                           IEnumerable<YNeuron> neurons,
                           IActivationFunction activationFunction,
                           IActivationFunction outputActivationFunction,
                           int networkDepth)
        {
            _neurons = new List<YNeuron>();
            _snapshot = false;
            _inputCount = inputCount;
            _outputCount = outputCount;
            _outputActivationFunction = outputActivationFunction;

            foreach (YNeuron neuron in neurons)
            {
                _neurons.Add(neuron);
            }

            _networkDepth = networkDepth;
            _activationFunction = activationFunction;
        }

        /// <summary>
        /// Construct a Y network.
        /// </summary>
        ///
        /// <param name="inputCount">The input count.</param>
        /// <param name="outputCount">The output count.</param>
        public YNetwork(int inputCount, int outputCount)
        {
            _neurons = new List<YNeuron>();
            _snapshot = false;
            _inputCount = inputCount;
            _outputCount = outputCount;
            _networkDepth = 0;
            _activationFunction = new ActivationSigmoid();
        }

        /// <summary>
        /// Set the activation function.
        /// </summary>
        public IActivationFunction ActivationFunction
        {
            get { return _activationFunction; }
            set { _activationFunction = value; }
        }

        /// <summary>
        /// The network depth.
        /// </summary>
        public int NetworkDepth
        {
            get { return _networkDepth; }
            set { _networkDepth = value; }
        }


        /// <value>The Y neurons.</value>
        public IList<YNeuron> Neurons
        {
            get { return _neurons; }
        }


        /// <summary>
        /// Sets if snapshot is used.
        /// </summary>
        public bool Snapshot
        {
            get { return _snapshot; }
            set { _snapshot = value; }
        }

        /// <value>the outputActivationFunction to set</value>
        public IActivationFunction OutputActivationFunction
        {
            get { return _outputActivationFunction; }
            set { _outputActivationFunction = value; }
        }

        #region MLContext Members

        /// <summary>
        /// Clear any context from previous runs. This sets the activation of all
        /// neurons to zero.
        /// </summary>
        ///
        public virtual void ClearContext()
        {
            foreach (YNeuron neuron in _neurons)
            {
                neuron.Output = 0;
            }
        }

        #endregion

        #region MLError Members

        /// <summary>
        /// Calculate the error for this neural network. 
        /// </summary>
        ///
        /// <param name="data">The training set.</param>
        /// <returns>The error percentage.</returns>
        public virtual double CalculateError(IMLDataSet data)
        {
            return SyntUtility.CalculateRegressionError(this, data);
        }

        #endregion

        #region MLRegression Members

        /// <summary>
        /// Compute the output from this synapse.
        /// </summary>
        ///
        /// <param name="input">The input to this synapse.</param>
        /// <returns>The output from this synapse.</returns>
        public virtual IMLData Compute(IMLData input)
        {
            IMLData result = new BasicMLData(_outputCount);

            if (_neurons.Count == 0)
            {
                throw new NeuralNetworkError(
                    "This network has not been evolved yet, it has no neurons in the Y synapse.");
            }

            int flushCount = 1;

            if (_snapshot)
            {
                flushCount = _networkDepth;
            }

            // iterate through the network FlushCount times
            for (int i = 0; i < flushCount; ++i)
            {
                int outputIndex = 0;
                int index = 0;

                result.Clear();

                // populate the input neurons
                while (_neurons[index].NeuronType == YNeuronType.Input)
                {
                    _neurons[index].Output = input[index];

                    index++;
                }

                // set the bias neuron
                _neurons[index++].Output = 1;

                while (index < _neurons.Count)
                {
                    YNeuron currentNeuron = _neurons[index];

                    double sum = 0;


                    foreach (YLink link in currentNeuron.InboundLinks)
                    {
                        double weight = link.Weight;
                        double neuronOutput = link.FromNeuron.Output;
                        sum += weight * neuronOutput;
                    }

                    var d = new double[1];
                    d[0] = sum / currentNeuron.ActivationResponse;
                    _activationFunction.ActivationFunction(d, 0, d.Length);

                    _neurons[index].Output = d[0];

                    if (currentNeuron.NeuronType == YNeuronType.Output)
                    {
                        result[outputIndex++] = currentNeuron.Output;
                    }
                    index++;
                }
            }

            _outputActivationFunction.ActivationFunction(result.Data, 0,
                                                        result.Count);

            return result;
        }

        /// <summary>
        /// The input count.
        /// </summary>
        public virtual int InputCount
        {
            get { return _inputCount; }
            set { _inputCount = value; }
        }

        /// <summary>
        /// The output count.
        /// </summary>
        public virtual int OutputCount
        {
            get { return _outputCount; }
            set { _outputCount = value; }
        }

        #endregion

        /// <summary>
        /// Not needed.
        /// </summary>
        public override void UpdateProperties()
        {
        }
    }

    [Serializable]
    public class YLink
    {
        /// <summary>
        /// The source neuron.
        /// </summary>
        ///
        private readonly YNeuron _fromNeuron;

        /// <summary>
        /// Is this link recurrent.
        /// </summary>
        ///
        private readonly bool _recurrent;

        /// <summary>
        /// The target neuron.
        /// </summary>
        ///
        private readonly YNeuron _toNeuron;

        /// <summary>
        /// The weight between the two neurons.
        /// </summary>
        ///
        private readonly double _weight;

        /// <summary>
        /// Default constructor, used mainly for persistance.
        /// </summary>
        ///
        public YLink()
        {
        }

        /// <summary>
        /// Construct a Y link.
        /// </summary>
        ///
        /// <param name="weight">The weight between the two neurons.</param>
        /// <param name="fromNeuron">The source neuron.</param>
        /// <param name="toNeuron">The target neuron.</param>
        /// <param name="recurrent">Is this a recurrent link.</param>
        public YLink(double weight, YNeuron fromNeuron,
                        YNeuron toNeuron, bool recurrent)
        {
            _weight = weight;
            _fromNeuron = fromNeuron;
            _toNeuron = toNeuron;
            _recurrent = recurrent;
        }


        /// <value>The source neuron.</value>
        public YNeuron FromNeuron
        {
            get { return _fromNeuron; }
        }


        /// <value>The target neuron.</value>
        public YNeuron ToNeuron
        {
            get { return _toNeuron; }
        }


        /// <value>The weight of the link.</value>
        public double Weight
        {
            get { return _weight; }
        }


        /// <value>True if this is a recurrent link.</value>
        public bool Recurrent
        {
            get { return _recurrent; }
        }

        /// <inheritdoc/>
        public override String ToString()
        {
            var result = new StringBuilder();
            result.Append("[YLink: fromNeuron=");
            result.Append(FromNeuron.NeuronID);
            result.Append(", toNeuron=");
            result.Append(ToNeuron.NeuronID);
            result.Append("]");
            return result.ToString();
        }
    }

    [Serializable]
    public class YNeuron
    {
        /// <summary>
        /// The activation response. This is evolved to allow Y to scale the slope
        /// of the activation function.
        /// </summary>
        ///
        private readonly double _activationResponse;

        /// <summary>
        /// Inbound links to this neuron.
        /// </summary>
        ///
        private readonly IList<YLink> _inboundLinks;

        /// <summary>
        /// The neuron id.
        /// </summary>
        ///
        private readonly long _neuronID;

        /// <summary>
        /// The type of neuron this is.
        /// </summary>
        ///
        private readonly YNeuronType _neuronType;

        /// <summary>
        /// The outbound links for this neuron.
        /// </summary>
        ///
        private readonly IList<YLink> _outputboundLinks;

        /// <summary>
        /// The x-position of this neuron. Used to split links, as well as display.
        /// </summary>
        ///
        private readonly int _posX;

        /// <summary>
        /// The y-position of this neuron. Used to split links, as well as display.
        /// </summary>
        ///
        private readonly int _posY;

        /// <summary>
        /// The split value for X. Used to track splits.
        /// </summary>
        ///
        private readonly double _splitX;

        /// <summary>
        /// The split value for Y. Used to track splits.
        /// </summary>
        ///
        private readonly double _splitY;

        /// <summary>
        /// The sum activation.
        /// </summary>
        ///
        private readonly double _sumActivation;

        /// <summary>
        /// The output from the neuron.
        /// </summary>
        ///
        private double _output;

        /// <summary>
        /// Default constructor, used for persistance.
        /// </summary>
        ///
        public YNeuron()
        {
            _inboundLinks = new List<YLink>();
            _outputboundLinks = new List<YLink>();
        }

        /// <summary>
        /// Construct a Y neuron.
        /// </summary>
        ///
        /// <param name="neuronType_0">The type of neuron.</param>
        /// <param name="neuronID_1">The id of the neuron.</param>
        /// <param name="splitY_2">The split for y.</param>
        /// <param name="splitX_3">THe split for x.</param>
        /// <param name="activationResponse_4">The activation response.</param>
        public YNeuron(YNeuronType neuronType_0, long neuronID_1,
                          double splitY_2, double splitX_3,
                          double activationResponse_4)
        {
            _inboundLinks = new List<YLink>();
            _outputboundLinks = new List<YLink>();
            _neuronType = neuronType_0;
            _neuronID = neuronID_1;
            _splitY = splitY_2;
            _splitX = splitX_3;
            _activationResponse = activationResponse_4;
            _posX = 0;
            _posY = 0;
            _output = 0;
            _sumActivation = 0;
        }


        /// <value>the activation response.</value>
        public double ActivationResponse
        {
            get { return _activationResponse; }
        }


        /// <value>the inbound links.</value>
        public IList<YLink> InboundLinks
        {
            get { return _inboundLinks; }
        }


        /// <value>The neuron id.</value>
        public long NeuronID
        {
            get { return _neuronID; }
        }


        /// <value>the neuron type.</value>
        public YNeuronType NeuronType
        {
            get { return _neuronType; }
        }


        /// <value>The output of the neuron.</value>
        public double Output
        {
            get { return _output; }
            set { _output = value; }
        }


        /// <value>The outbound links.</value>
        public IList<YLink> OutputboundLinks
        {
            get { return _outputboundLinks; }
        }


        /// <value>The x position.</value>
        public int PosX
        {
            get { return _posX; }
        }


        /// <value>The y position.</value>
        public int PosY
        {
            get { return _posY; }
        }


        /// <value>The split x.</value>
        public double SplitX
        {
            get { return _splitX; }
        }


        /// <value>The split y.</value>
        public double SplitY
        {
            get { return _splitY; }
        }


        /// <value>The sum activation.</value>
        public double SumActivation
        {
            get { return _sumActivation; }
        }


        /// <inheritdoc/>
        public override String ToString()
        {
            var result = new StringBuilder();
            result.Append("[YNeuron:id=");
            result.Append(_neuronID);
            result.Append(",type=");
            switch (_neuronType)
            {
                case YNeuronType.Input:
                    result.Append("I");
                    break;
                case YNeuronType.Output:
                    result.Append("O");
                    break;
                case YNeuronType.Bias:
                    result.Append("B");
                    break;
                case YNeuronType.Hidden:
                    result.Append("H");
                    break;
                default:
                    result.Append("Unknown");
                    break;
            }
            result.Append("]");
            return result.ToString();
        }

        /// <summary>
        /// Convert a string to a Y neuron type.
        /// </summary>
        /// <param name="t">The string.</param>
        /// <returns>The Y neuron type.</returns>
        public static YNeuronType String2NeuronType(String t)
        {
            String type = t.ToLower().Trim();

            if (type.Length > 0)
            {
                switch ((int)type[0])
                {
                    case 'i':
                        return YNeuronType.Input;
                    case 'o':
                        return YNeuronType.Output;
                    case 'h':
                        return YNeuronType.Hidden;
                    case 'b':
                        return YNeuronType.Bias;
                    case 'n':
                        return YNeuronType.None;
                }
            }

            return default(YNeuronType) /* was: null */;
        }

        /// <summary>
        /// Convert Y neuron type to string.
        /// </summary>
        /// <param name="t">The neuron type.</param>
        /// <returns>The string of the specified neuron type.</returns>
        public static String NeuronType2String(YNeuronType t)
        {
            switch (t)
            {
                case YNeuronType.Input:
                    return "I";
                case YNeuronType.Bias:
                    return "B";
                case YNeuronType.Hidden:
                    return "H";
                case YNeuronType.Output:
                    return "O";
                case YNeuronType.None:
                    return "N";
                default:
                    return null;
            }
        }
    }

    public class PersistorRegistry
    {
        /// <summary>
        /// The instance.
        /// </summary>
        ///
        private static PersistorRegistry _instance;


        /// <summary>
        /// The mapping between name and persistor.
        /// </summary>
        ///
        private readonly IDictionary<String, ISyntPersistor> _map;

        /// <summary>
        /// The class map, used to lookup native classes to their persistor.
        /// </summary>
        private readonly IDictionary<Type, ISyntPersistor> _classMap;

        /// <summary>
        /// Construct the object.
        /// </summary>
        ///
        private PersistorRegistry()
        {
            _map = new Dictionary<String, ISyntPersistor>();
            _classMap = new Dictionary<Type, ISyntPersistor>();
            Add(new PersistSVM());
            Add(new PersistHopfield());
            Add(new PersistBoltzmann());
            Add(new PersistART1());
            Add(new PersistBAM());
            Add(new PersistBasicNetwork());
            Add(new PersistRBFNetwork());
            Add(new PersistSOM());
            Add(new PersistYPopulation());
            Add(new PersistYNetwork());
            Add(new PersistBasicPNN());
            Add(new PersistCPN());
            Add(new PersistTrainingContinuation());
            Add(new PersistBayes());
            
        }

        /// <value>The singleton instance.</value>
        public static PersistorRegistry Instance
        {
            get { return _instance ?? (_instance = new PersistorRegistry()); }
        }

        /// <summary>
        /// Add a persistor.
        /// </summary>
        ///
        /// <param name="persistor">The persistor to add.</param>
        public void Add(ISyntPersistor persistor)
        {
            _map[persistor.PersistClassString] = persistor;
            _classMap[persistor.NativeType] = persistor;
        }

        /// <summary>
        /// Get a persistor.
        /// </summary>
        ///
        /// <param name="clazz">The class to get the persistor for.</param>
        /// <returns>Return the persistor.</returns>
        public ISyntPersistor GetPersistor(Type clazz)
        {
            return _classMap[clazz];
        }

        /// <summary>
        /// Get the persistor by name.
        /// </summary>
        ///
        /// <param name="name">The name of the persistor.</param>
        /// <returns>The persistor.</returns>
        public ISyntPersistor GetPersistor(String name)
        {
            return _map.ContainsKey(name) ? _map[name] : null;
        }
    }

    public class SystemActivationPlugin : ISyntPluginService1
    {
        /// <inheritdoc/>
        public String PluginDescription
        {
            get
            {
                return "This plugin provides the built in machine " +
                        "learning methods for Synt.";
            }
        }

        /// <inheritdoc/>
        public String PluginName
        {
            get
            {
                return "HRI-System-Methods";
            }
        }

        /// <summary>
        /// This is a type-1 plugin.
        /// </summary>
        public int PluginType
        {
            get
            {
                return 1;
            }
        }

        /// <summary>
        /// Allocate an activation function.
        /// </summary>
        /// <param name="name">The name of the activation function.</param>
        /// <returns>The activation function.</returns>
        private IActivationFunction AllocateAF(String name)
        {
            if (String.Compare(name, MLActivationFactory.AF_BIPOLAR) == 0)
            {
                return new ActivationBiPolar();
            }

            if (String.Compare(name, MLActivationFactory.AF_COMPETITIVE) == 0)
            {
                return new ActivationCompetitive();
            }

            if (String.Compare(name, MLActivationFactory.AF_GAUSSIAN) == 0)
            {
                return new ActivationGaussian();
            }

            if (String.Compare(name, MLActivationFactory.AF_LINEAR) == 0)
            {
                return new ActivationLinear();
            }

            if (String.Compare(name, MLActivationFactory.AF_LOG) == 0)
            {
                return new ActivationLOG();
            }

            if (String.Compare(name, MLActivationFactory.AF_RAMP) == 0)
            {
                return new ActivationRamp();
            }

            if (String.Compare(name, MLActivationFactory.AF_SIGMOID) == 0)
            {
                return new ActivationSigmoid();
            }

            if (String.Compare(name, MLActivationFactory.AF_SIN) == 0)
            {
                return new ActivationSIN();
            }

            if (String.Compare(name, MLActivationFactory.AF_SOFTMAX) == 0)
            {
                return new ActivationSoftMax();
            }

            if (String.Compare(name, MLActivationFactory.AF_STEP) == 0)
            {
                return new ActivationStep();
            }

            if (String.Compare(name, MLActivationFactory.AF_TANH) == 0)
            {
                return new ActivationTANH();
            }

            return null;
        }


        /// <inheritdoc/>
        public IActivationFunction CreateActivationFunction(String fn)
        {
            String name;
            double[] p;

            int index = fn.IndexOf('[');
            if (index != -1)
            {
                name = fn.Substring(0, index).ToLower();
                int index2 = fn.IndexOf(']');
                if (index2 == -1)
                {
                    throw new SyntError(
                            "Unbounded [ while parsing activation function.");
                }
                String a = fn.Substring(index + 1, index2);
                p = NumberList.FromList(CSVFormat.EgFormat, a);

            }
            else
            {
                name = fn.ToLower();
                p = new double[0];
            }

            IActivationFunction af = AllocateAF(name);

            if (af == null)
            {
                return null;
            }

            if (af.ParamNames.Length != p.Length)
            {
                throw new SyntError(name + " expected "
                        + af.ParamNames.Length + ", but " + p.Length
                        + " were provided.");
            }

            for (int i = 0; i < af.ParamNames.Length; i++)
            {
                af.Params[i] = p[i];
            }

            return af;
        }

        /// <inheritdoc/>
        public IMLMethod CreateMethod(String methodType, String architecture,
                int input, int output)
        {
            return null;
        }

        /// <inheritdoc/>
        public IMLTrain CreateTraining(IMLMethod method, IMLDataSet training,
                String type, String args)
        {
            return null;
        }

        /// <inheritdoc/>
        public int PluginServiceType
        {
            get
            {
                return SyntPluginBaseConst.SERVICE_TYPE_GENERAL;
            }
        }
    }

    public class SystemLoggingPlugin : ISyntPluginLogging1
    {
        /// <summary>
        /// The current level.
        /// </summary>
        ///
        private int currentLevel;

        /// <summary>
        /// True if we are logging to the console.
        /// </summary>
        ///
        private bool logConsole;

        /// <summary>
        /// Construct the object.
        /// </summary>
        public SystemLoggingPlugin()
        {
            currentLevel = SyntLogging.LevelDisable;
            logConsole = false;
        }

        #region SyntPluginType1 Members

        /// <summary>
        /// Not used for this type of plugin.
        /// </summary>
        ///
        /// <param name="gradients">Not used.</param>
        /// <param name="layerOutput">Not used.</param>
        /// <param name="weights">Not used.</param>
        /// <param name="layerDelta">Not used.</param>
        /// <param name="af">Not used.</param>
        /// <param name="index">Not used.</param>
        /// <param name="fromLayerIndex">Not used.</param>
        /// <param name="fromLayerSize">Not used.</param>
        /// <param name="toLayerIndex">Not used.</param>
        /// <param name="toLayerSize">Not used.</param>
        public void CalculateGradient(double[] gradients,
                                      double[] layerOutput, double[] weights,
                                      double[] layerDelta, IActivationFunction af,
                                      int index, int fromLayerIndex, int fromLayerSize,
                                      int toLayerIndex, int toLayerSize)
        {
        }

        /// <summary>
        /// Not used for this type of plugin.
        /// </summary>
        ///
        /// <param name="weights">Not used.</param>
        /// <param name="layerOutput">Not used.</param>
        /// <param name="startIndex">Not used.</param>
        /// <param name="outputIndex">Not used.</param>
        /// <param name="outputSize">Not used.</param>
        /// <param name="inputIndex">Not used.</param>
        /// <param name="inputSize">Not used.</param>
        /// <returns>Not used.</returns>
        public int CalculateLayer(double[] weights,
                                  double[] layerOutput, int startIndex,
                                  int outputIndex, int outputSize, int inputIndex,
                                  int inputSize)
        {
            return 0;
        }

        /// <summary>
        /// Set the logging level.
        /// </summary>
        public int LogLevel
        {
            get { return currentLevel; }
            set { currentLevel = value; }
        }


        /// <inheritdoc/>
        public String PluginDescription
        {
            get
            {
                return "This is the built in logging for Synt, it logs "
                       + "to either a file or System.out";
            }
        }


        /// <inheritdoc/>
        public String PluginName
        {
            get { return "HRI-System-Logging"; }
        }


        /// <value>Returns the service type for this plugin. This plugin provides
        /// the system calculation for layers and gradients. Therefore, this
        /// plugin returns SERVICE_TYPE_CALCULATION.</value>
        public int PluginServiceType
        {
            get { return SyntPluginBaseConst.SERVICE_TYPE_LOGGING; }
        }


        /// <value>This is a type-1 plugin.</value>
        public int PluginType
        {
            get { return 1; }
        }


        /// <summary>
        /// Log the message.
        /// </summary>
        ///
        /// <param name="level">The logging level.</param>
        /// <param name="message">The logging message.</param>
        public void Log(int level, String message)
        {
            if (currentLevel <= level)
            {
                DateTime now = DateTime.Now;
                var line = new StringBuilder();
                line.Append(now.ToString());
                line.Append(" [");
                switch (level)
                {
                    case SyntLogging.LevelCritical:
                        line.Append("CRITICAL");
                        break;
                    case SyntLogging.LevelError:
                        line.Append("ERROR");
                        break;
                    case SyntLogging.LevelInfo:
                        line.Append("INFO");
                        break;
                    case SyntLogging.LevelDebug:
                        line.Append("DEBUG");
                        break;
                    default:
                        line.Append("?");
                        break;
                }
                line.Append("][");
                line.Append(Thread.CurrentThread.Name);
                line.Append("]: ");
                line.Append(message);

                if (logConsole)
                {
                    if (currentLevel > SyntLogging.LevelError)
                    {
                        Console.Error.WriteLine(line.ToString());
                    }
                    else
                    {
                        Console.Out.WriteLine(line.ToString());
                    }
                }
            }
        }

        /// <inheritdoc/>
        public void Log(int level, Exception t)
        {
            Log(level, t.ToString());
        }

        #endregion

        /// <summary>
        /// Start logging to the console.
        /// </summary>
        ///
        public void StartConsoleLogging()
        {
            StopLogging();
            logConsole = true;
            LogLevel = SyntLogging.LevelDebug;
        }

        /// <summary>
        /// Stop any console or file logging.
        /// </summary>
        ///
        public void StopLogging()
        {
            logConsole = false;
        }
    }

    public class SystemMethodsPlugin : ISyntPluginService1
    {
        /// <summary>
        /// A factory used to create Bayesian networks
        /// </summary>
        private readonly BayesianFactory _bayesianFactory = new BayesianFactory();

        /// <summary>
        /// A factory used to create feedforward neural networks.
        /// </summary>
        private readonly FeedforwardFactory _feedforwardFactory
            = new FeedforwardFactory();

        /// <summary>
        /// The factory for PNN's.
        /// </summary>
        private readonly PNNFactory _pnnFactory = new PNNFactory();

        /// <summary>
        /// A factory used to create RBF networks.
        /// </summary>
        private readonly RBFNetworkFactory _rbfFactory = new RBFNetworkFactory();

        /// <summary>
        /// A factory used to create SOM's.
        /// </summary>
        private readonly SOMFactory _somFactory = new SOMFactory();

        /// <summary>
        /// A factory used to create support vector machines.
        /// </summary>
        private readonly SVMFactory _svmFactory = new SVMFactory();

        #region ISyntPluginService1 Members

        /// <inheritdoc/>
        public String PluginDescription
        {
            get
            {
                return "This plugin provides the built in machine " +
                       "learning methods for Synt.";
            }
        }

        /// <inheritdoc/>
        public String PluginName
        {
            get { return "HRI-System-Methods"; }
        }

        /// <summary>
        /// This is a type-1 plugin.
        /// </summary>
        public int PluginType
        {
            get { return 1; }
        }


        /// <inheritdoc/>
        public IActivationFunction CreateActivationFunction(String name)
        {
            return null;
        }

        /// <inheritdoc/>
        public IMLMethod CreateMethod(String methodType, String architecture,
                                      int input, int output)
        {
            if (MLMethodFactory.TypeFeedforward.Equals(methodType))
            {
                return _feedforwardFactory.Create(architecture, input, output);
            }
            if (MLMethodFactory.TypeRbfnetwork.Equals(methodType))
            {
                return _rbfFactory.Create(architecture, input, output);
            }
            if (MLMethodFactory.TypeSVM.Equals(methodType))
            {
                return _svmFactory.Create(architecture, input, output);
            }
            if (MLMethodFactory.TypeSOM.Equals(methodType))
            {
                return _somFactory.Create(architecture, input, output);
            }
            if (MLMethodFactory.TypePNN.Equals(methodType))
            {
                return _pnnFactory.Create(architecture, input, output);
            }
            if (MLMethodFactory.TypeBayesian.Equals(methodType))
            {
                return _bayesianFactory.Create(architecture, input, output);
            }

            throw new SyntError("Unknown method type: " + methodType);
        }

        /// <inheritdoc/>
        public IMLTrain CreateTraining(IMLMethod method, IMLDataSet training,
                                       String type, String args)
        {
            return null;
        }

        /// <inheritdoc/>
        public int PluginServiceType
        {
            get { return SyntPluginBaseConst.SERVICE_TYPE_GENERAL; }
        }

        #endregion
    }

    public class SystemTrainingPlugin : ISyntPluginService1
    {
        /// <summary>
        /// The factory for simulated annealing.
        /// </summary>
        private readonly AnnealFactory annealFactory = new AnnealFactory();

        /// <summary>
        /// The factory for backprop.
        /// </summary>
        private readonly BackPropFactory backpropFactory = new BackPropFactory();

        /// <summary>
        /// The factory for K2
        /// </summary>
        private readonly TrainBayesianFactory bayesianFactory = new TrainBayesianFactory();

        /// <summary>
        /// The factory for G.
        /// </summary>
        private readonly GFactory GFactory = new GFactory();

        /// <summary>
        /// The factory for LMA.
        /// </summary>
        private readonly LMAFactory lmaFactory = new LMAFactory();

        /// <summary>
        /// The factory for Manhattan networks.
        /// </summary>
        private readonly ManhattanFactory manhattanFactory = new ManhattanFactory();

        /// <summary>
        /// The factory for neighborhood SOM.
        /// </summary>
        private readonly NeighborhoodSOMFactory neighborhoodFactory
            = new NeighborhoodSOMFactory();

        /// <summary>
        /// Nelder Mead Factory.
        /// </summary>
        private readonly NelderMeadFactory nmFactory = new NelderMeadFactory();

        /// <summary>
        /// Factory for PNN.
        /// </summary>
        private readonly PNNTrainFactory pnnFactory = new PNNTrainFactory();

        /// <summary>
        /// PSO training factory.
        /// </summary>
        private readonly PSOFactory psoFactory = new PSOFactory();

        /// <summary>
        /// Factory for quick prop.
        /// </summary>
        private readonly QuickPropFactory qpropFactory = new QuickPropFactory();

        /// <summary>
        /// The factory for RPROP.
        /// </summary>
        private readonly RPROPFactory rpropFactory = new RPROPFactory();

        /// <summary>
        /// The factory for SCG.
        /// </summary>
        private readonly SCGFactory scgFactory = new SCGFactory();

        /// <summary>
        /// The factory for SOM cluster.
        /// </summary>
        private readonly ClusterSOMFactory somClusterFactory = new ClusterSOMFactory();

        /// <summary>
        /// Factory for SVD.
        /// </summary>
        private readonly RBFSVDFactory svdFactory = new RBFSVDFactory();

        /// <summary>
        /// The factory for basic SVM.
        /// </summary>
        private readonly SVMFactory svmFactory = new SVMFactory();

        /// <summary>
        /// The factory for SVM-Search.
        /// </summary>
        private readonly SVMSearchFactory svmSearchFactory = new SVMSearchFactory();

        #region ISyntPluginService1 Members

        /// <inheritdoc/>
        public String PluginDescription
        {
            get
            {
                return "This plugin provides the built in training " +
                       "methods for Synt.";
            }
        }

        /// <inheritdoc/>
        public String PluginName
        {
            get { return "HRI-System-Training"; }
        }

        /// <summary>
        /// This is a type-1 plugin.
        /// </summary>
        public int PluginType
        {
            get { return 1; }
        }


        /// <summary>
        /// This plugin does not support activation functions, so it will 
        /// always return null. 
        /// </summary>
        /// <param name="name">Not used.</param>
        /// <returns>The activation function.</returns>
        public IActivationFunction CreateActivationFunction(String name)
        {
            return null;
        }

        public IMLMethod CreateMethod(String methodType, String architecture,
                                      int input, int output)
        {
            // TODO Auto-generated method stub
            return null;
        }

        public IMLTrain CreateTraining(IMLMethod method, IMLDataSet training,
                                       String type, String args)
        {
            String args2 = args;

            if (args2 == null)
            {
                args2 = "";
            }

            if (String.Compare(MLTrainFactory.TypeRPROP, type) == 0)
            {
                return rpropFactory.Create(method, training, args2);
            }
            else if (String.Compare(MLTrainFactory.TypeBackprop, type) == 0)
            {
                return backpropFactory.Create(method, training, args2);
            }
            else if (String.Compare(MLTrainFactory.TypeSCG, type) == 0)
            {
                return scgFactory.Create(method, training, args2);
            }
            else if (String.Compare(MLTrainFactory.TypeLma, type) == 0)
            {
                return lmaFactory.Create(method, training, args2);
            }
          
            else if (String.Compare(MLTrainFactory.TypeSVMSearch, type) == 0)
            {
                return svmSearchFactory.Create(method, training, args2);
            }
            else if (String.Compare(MLTrainFactory.TypeSOMNeighborhood, type) == 0)
            {
                return neighborhoodFactory.Create(method, training, args2);
            }
            else if (String.Compare(MLTrainFactory.TypeAnneal, type) == 0)
            {
                return annealFactory.Create(method, training, args2);
            }
            else if (String.Compare(MLTrainFactory.TypeG, type) == 0)
            {
                return GFactory.Create(method, training, args2);
            }
            else if (String.Compare(MLTrainFactory.TypeSOMCluster, type) == 0)
            {
                return somClusterFactory.Create(method, training, args2);
            }
            else if (String.Compare(MLTrainFactory.TypeManhattan, type) == 0)
            {
                return manhattanFactory.Create(method, training, args2);
            }
            else if (String.Compare(MLTrainFactory.TypeSvd, type) == 0)
            {
                return svdFactory.Create(method, training, args2);
            }
            else if (String.Compare(MLTrainFactory.TypePNN, type) == 0)
            {
                return pnnFactory.Create(method, training, args2);
            }
            else if (String.Compare(MLTrainFactory.TypeQPROP, type) == 0)
            {
                return qpropFactory.Create(method, training, args2);
            }
            else if (MLTrainFactory.TypeBayesian.Equals(type))
            {
                return bayesianFactory.Create(method, training, args2);
            }
            else if (MLTrainFactory.TypeNelderMead.Equals(type))
            {
                return nmFactory.Create(method, training, args2);
            }
            else if (MLTrainFactory.TypePSO.Equals(type))
            {
                return psoFactory.Create(method, training, args2);
            }

            else
            {
                throw new SyntError("Unknown training type: " + type);
            }
        }

        /// <inheritdoc/>
        public int PluginServiceType
        {
            get { return SyntPluginBaseConst.SERVICE_TYPE_GENERAL; }
        }

        #endregion
    }

    public class SyntPluginBaseConst
    {
        /// <summary>
        /// A general plugin, you can have multiple plugins installed that provide
        /// general services.
        /// </summary>
        ///
        public const int SERVICE_TYPE_GENERAL = 0;

        /// <summary>
        /// A special plugin that provides logging. You may only have one logging
        /// plugin installed.
        /// </summary>
        ///
        public const int SERVICE_TYPE_LOGGING = 1;
    }

    public class ClassItem
    {
        /// <summary>
        /// The index of the class.
        /// </summary>
        ///
        private int _index;

        /// <summary>
        /// The name of the class.
        /// </summary>
        ///
        private String _name;

        /// <summary>
        /// Construct the object.
        /// </summary>
        ///
        /// <param name="theName">The name of the class.</param>
        /// <param name="theIndex">The index of the class.</param>
        public ClassItem(String theName, int theIndex)
        {
            _name = theName;
            _index = theIndex;
        }

        /// <summary>
        /// Set the index of the class.
        /// </summary>
        public int Index
        {
            get { return _index; }
            set { _index = value; }
        }


        /// <summary>
        /// Set the name of the class.
        /// </summary>
        public String Name
        {
            get { return _name; }
            set { _name = value; }
        }


        /// <inheritdoc/>
        public override sealed String ToString()
        {
            var result = new StringBuilder("[");
            result.Append(GetType().Name);
            result.Append(" name=");
            result.Append(_name);
            result.Append(", index=");
            result.Append(_index);

            result.Append("]");
            return result.ToString();
        }
    }

    public class CompareArray
    {
        public static bool Compare(double[] d1, double[] d2, double p)
        {
            for (int i = 0; i < d1.Length; i++)
            {
                double diff = Math.Abs(d1[i] - d2[i]);
                if (diff > p)
                    return false;
            }
            return true;
        }
    }

    public static class NormalizationActionExtension
    {
        /// <returns>True, if this is a classify.</returns>
        public static bool IsClassify(this NormalizationAction extensionParam)
        {
            return (extensionParam == NormalizationAction.OneOf) || (extensionParam == NormalizationAction.SingleField)
                   || (extensionParam == NormalizationAction.Equilateral);
        }
    }

    public class TemporalWindowArray
    {
        /// <summary>
        /// The fields that are to be processed.
        /// </summary>
        ///
        private TemporalWindowField[] _fields;

        /// <summary>
        /// The size of the input window.
        /// </summary>
        ///
        private int _inputWindow;

        /// <summary>
        /// The size of the prediction window.
        /// </summary>
        ///
        private int _predictWindow;

        /// <summary>
        /// Construct a time-series from an array.
        /// </summary>
        ///
        /// <param name="theInputWindow">The size of the input window.</param>
        /// <param name="thePredictWindow">The size of the predict window.</param>
        public TemporalWindowArray(int theInputWindow,
                                   int thePredictWindow)
        {
            _inputWindow = theInputWindow;
            _predictWindow = thePredictWindow;
        }

        /// <value>The fields that are to be processed.</value>
        public TemporalWindowField[] Fields
        {
            get { return _fields; }
        }


        /// <value>the inputWindow to set</value>
        public int InputWindow
        {
            get { return _inputWindow; }
            set { _inputWindow = value; }
        }


        /// <value>the predictWindow to set</value>
        public int PredictWindow
        {
            get { return _predictWindow; }
            set { _predictWindow = value; }
        }

        /// <summary>
        /// Analyze the 1D array.
        /// </summary>
        ///
        /// <param name="array">The array to analyze.</param>
        public void Analyze(double[] array)
        {
            _fields = new TemporalWindowField[1];
            _fields[0] = new TemporalWindowField("0") { Action = TemporalType.InputAndPredict };
        }

        /// <summary>
        /// Analyze the 2D array.
        /// </summary>
        ///
        /// <param name="array">The 2D array to analyze.</param>
        public void Analyze(double[][] array)
        {
            int length = array[0].Length;
            _fields = new TemporalWindowField[length];
            for (int i = 0; i < length; i++)
            {
                _fields[i] = new TemporalWindowField("" + i) { Action = TemporalType.InputAndPredict };
            }
        }

        /// <summary>
        /// Count the number of input fields, or fields used to predict.
        /// </summary>
        ///
        /// <returns>The number of input fields.</returns>
        public int CountInputFields()
        {
            return _fields.Count(field => field.Input);
        }

        /// <summary>
        /// Count the number of fields that are that are in the prediction.
        /// </summary>
        ///
        /// <returns>The number of fields predicted.</returns>
        public int CountPredictFields()
        {
            return _fields.Count(field => field.Predict);
        }


        /// <summary>
        /// Process the array.
        /// </summary>
        ///
        /// <param name="data">The array to process.</param>
        /// <returns>A neural data set that contains the time-series.</returns>
        public IMLDataSet Process(double[] data)
        {
            IMLDataSet result = new BasicMLDataSet();

            int totalWindowSize = _inputWindow + _predictWindow;
            int stopPoint = data.Length - totalWindowSize;

            for (int i = 0; i < stopPoint; i++)
            {
                IMLData inputData = new BasicMLData(_inputWindow);
                IMLData idealData = new BasicMLData(_predictWindow);

                int index = i;

                // handle input window
                for (int j = 0; j < _inputWindow; j++)
                {
                    inputData[j] = data[index++];
                }

                // handle predict window
                for (int j = 0; j < _predictWindow; j++)
                {
                    idealData[j] = data[index++];
                }

                IMLDataPair pair = new BasicMLDataPair(inputData, idealData);
                result.Add(pair);
            }

            return result;
        }




        /// <summary>
        /// Processes the specified data array in an IMLDataset.
        /// You can send a [][] array directly with this method.
        /// </summary>
        /// <param name="data">The data.</param>
        /// <returns></returns>
        public IMLDataSet Process(double[][] data)
        {
            IMLDataSet result = new BasicMLDataSet();
            foreach (double[] doubles in data)
            {
                result.Add(ProcessToPair(doubles));
            }
            return result;
        }

        /// <summary>
        /// Process the data array and returns an IMLdatapair.
        /// </summary>
        ///
        /// <param name="data">The array to process.</param>
        /// <returns>An IMLDatapair containing data.</returns>
        public IMLDataPair ProcessToPair(double[] data)
        {

            IMLDataPair pair = null;
            int totalWindowSize = _inputWindow + _predictWindow;
            int stopPoint = data.Length - totalWindowSize;

            for (int i = 0; i < stopPoint; i++)
            {
                IMLData inputData = new BasicMLData(_inputWindow);
                IMLData idealData = new BasicMLData(_predictWindow);

                int index = i;

                // handle input window
                for (int j = 0; j < _inputWindow; j++)
                {
                    inputData[j] = data[index++];
                }

                // handle predict window
                for (int j = 0; j < _predictWindow; j++)
                {
                    idealData[j] = data[index++];
                }

                pair = new BasicMLDataPair(inputData, idealData);
            }
            return pair;
        }
    }

    public class TemporalWindowField
    {
        /// <summary>
        /// The action that is to be taken on this field.
        /// </summary>
        ///
        private TemporalType _action;

        /// <summary>
        /// The name of this field.
        /// </summary>
        ///
        private String _name;

        /// <summary>
        /// Construct the object.
        /// </summary>
        ///
        /// <param name="theName">The name of the field to be considered.</param>
        public TemporalWindowField(String theName)
        {
            _name = theName;
        }


        /// <value>the action to set</value>
        public TemporalType Action
        {
            get { return _action; }
            set { _action = value; }
        }


        /// <value>Returns true, if this field is to be used as part of the input
        /// for a prediction.</value>
        public bool Input
        {
            get { return ((_action == TemporalType.Input) || (_action == TemporalType.InputAndPredict)); }
        }


        /// <value>the lastValue to set</value>
        public String LastValue { get; set; }


        /// <value>the name to set</value>
        public String Name
        {
            get { return _name; }
            set { _name = value; }
        }


        /// <value>Returns true, if this field is part of what is being predicted.</value>
        public bool Predict
        {
            get { return ((_action == TemporalType.Predict) || (_action == TemporalType.InputAndPredict)); }
        }


        /// <inheritdoc/>
        public override sealed String ToString()
        {
            var result = new StringBuilder("[");
            result.Append(GetType().Name);
            result.Append(" name=");
            result.Append(_name);
            result.Append(", action=");
            result.Append(_action);

            result.Append("]");
            return result.ToString();
        }
    }

    public class SyntesisrTrainingFactory
    {
        /// <summary>
        /// Generate an Syntesisr training set over the range [0.0,1.0].  This is the range used by
        /// Fahlman.
        /// </summary>
        /// <param name="inputCount">The number of inputs and outputs.</param>
        /// <param name="compl">True if the complement mode should be use.</param>
        /// <returns>The training set.</returns>
        public static IMLDataSet generateTraining(int inputCount, bool compl)
        {
            return GenerateTraining(inputCount, compl, 0, 1.0);
        }

        /// <summary>
        /// Generate an Syntesisr over the specified range. 
        /// </summary>
        /// <param name="inputCount">The number of inputs and outputs.</param>
        /// <param name="compl">True if the complement mode should be use. </param>
        /// <param name="min">The minimum value to use(i.e. 0 or -1)</param>
        /// <param name="max">The maximum value to use(i.e. 1 or 0)</param>
        /// <returns>The training set.</returns>
        public static IMLDataSet GenerateTraining(int inputCount, bool compl, double min, double max)
        {
            return GenerateTraining(inputCount, compl, min, max, min, max);
        }


        public static IMLDataSet GenerateTraining(int inputCount, bool compl, double inputMin, double inputMax, double outputMin, double outputMax)
        {
            double[][] input = EngineArray.AllocateDouble2D(inputCount, inputCount);
            double[][] ideal = EngineArray.AllocateDouble2D(inputCount, inputCount);

            for (int i = 0; i < inputCount; i++)
            {
                for (int j = 0; j < inputCount; j++)
                {
                    if (compl)
                    {
                        input[i][j] = (j == i) ? inputMax : inputMin;
                        ideal[i][j] = (j == i) ? outputMin : outputMax;
                    }
                    else
                    {
                        input[i][j] = (j == i) ? inputMax : inputMin;
                        ideal[i][j] = (j == i) ? inputMax : inputMin;
                    }
                }
            }
            return new BasicMLDataSet(input, ideal);
        }
    }

    public class SyntBenchmark
    {
        /// <summary>
        /// Number of steps in all.
        /// </summary>
        private const int Steps = 3;

        /// <summary>
        /// The first step.
        /// </summary>
        private const int Step1 = 1;

        /// <summary>
        /// The third step.
        /// </summary>
        private const int Step2 = 2;

        /// <summary>
        /// The fourth step.
        /// </summary>
        private const int Step3 = 3;

        /// <summary>
        /// Report progress.
        /// </summary>
        private readonly IStatusReportable _report;

        /// <summary>
        /// The binary score.
        /// </summary>
        private int _binaryScore;

        /// <summary>
        /// The CPU score.
        /// </summary>
        private int _cpuScore;

        /// <summary>
        /// The memory score.
        /// </summary>
        private int _memoryScore;

        /// <summary>
        /// Construct a benchmark object.
        /// </summary>
        /// <param name="report">The object to report progress to.</param>
        public SyntBenchmark(IStatusReportable report)
        {
            _report = report;
        }

        /// <summary>
        /// The CPU score.
        /// </summary>
        public int CpuScore
        {
            get { return _cpuScore; }
        }

        /// <summary>
        /// The memory score.
        /// </summary>
        public int MemoryScore
        {
            get { return _memoryScore; }
        }

        /// <summary>
        /// The binary score.
        /// </summary>
        public int BinaryScore
        {
            get { return _binaryScore; }
        }

        /// <summary>
        /// Perform the benchmark. Returns the total amount of time for all of the
        /// benchmarks. Returns the final score. The lower the better for a score.
        /// </summary>
        /// <returns>The total time, which is the final Synt benchmark score.</returns>
        public String Process()
        {
            _report.Report(Steps, 0, "Beginning benchmark");

            EvalCpu();
            EvalMemory();
            EvalBinary();

            var result = new StringBuilder();

            result.Append("Synt Benchmark: CPU:");
            result.Append(Format.FormatInteger(_cpuScore));

            result.Append(", Memory:");
            result.Append(Format.FormatInteger(_memoryScore));
            result.Append(", Disk:");
            result.Append(Format.FormatInteger(_binaryScore));
            _report.Report(Steps, Steps, result
                                            .ToString());

            return result.ToString();
        }


        /// <summary>
        /// Evaluate the CPU.
        /// </summary>
        private void EvalCpu()
        {
            int small = Evaluate.EvaluateTrain(2, 4, 0, 1);
            _report.Report(Steps, Step1,
                          "Evaluate CPU, tiny= " + Format.FormatInteger(small / 100));

            int medium = Evaluate.EvaluateTrain(10, 20, 0, 1);
            _report.Report(Steps, Step1,
                          "Evaluate CPU, small= " + Format.FormatInteger(medium / 30));

            int large = Evaluate.EvaluateTrain(100, 200, 40, 5);
            _report.Report(Steps, Step1,
                          "Evaluate CPU, large= " + Format.FormatInteger(large));

            int huge = Evaluate.EvaluateTrain(200, 300, 200, 50);
            _report.Report(Steps, Step1,
                          "Evaluate CPU, huge= " + Format.FormatInteger(huge));

            int result = (small / 100) + (medium / 30) + large + huge;

            _report.Report(Steps, Step1,
                          "CPU result: " + result);
            _cpuScore = result;
        }


        /// <summary>
        /// Evaluate memory.
        /// </summary>
        private void EvalMemory()
        {
            BasicMLDataSet training = RandomTrainingFactory.Generate(
                1000, 10000, 10, 10, -1, 1);

            const long stop = (10 * Evaluate.Milis);
            int record = 0;

            IMLDataPair pair = BasicMLDataPair.CreatePair(10, 10);

            int iterations = 0;
            var watch = new Stopwatch();
            watch.Start();
            while (watch.ElapsedMilliseconds < stop)
            {
                iterations++;
                training.GetRecord(record++, pair);
                if (record >= training.Count)
                    record = 0;
            }

            iterations /= 100000;

            _report.Report(Steps, Step2,
                          "Memory dataset, result: " + Format.FormatInteger(iterations));

            _memoryScore = iterations;
        }

        /// <summary>
        /// Evaluate disk.
        /// </summary>
        private void EvalBinary()
        {
            FileInfo file = FileUtil.CombinePath(new FileInfo(Path.GetTempPath()), "temp.egb");

            BasicMLDataSet training = RandomTrainingFactory.Generate(
                1000, 10000, 10, 10, -1, 1);

            // create the binary file

            if (file.Exists)
            {
                file.Delete();
            }

            var training2 = new BufferedMLDataSet(file.ToString());
            training2.Load(training);

            const long stop = (10 * Evaluate.Milis);
            int record = 0;

            IMLDataPair pair = BasicMLDataPair.CreatePair(10, 10);

            var watch = new Stopwatch();
            watch.Start();

            int iterations = 0;
            while (watch.ElapsedMilliseconds < stop)
            {
                iterations++;
                training2.GetRecord(record++, pair);
                if (record >= training2.Count)
                    record = 0;
            }

            training2.Close();

            iterations /= 100000;

            _report.Report(Steps, Step3,
                          "Disk(binary) dataset, result: "
                          + Format.FormatInteger(iterations));

            if (file.Exists)
            {
                file.Delete();
            }
            _binaryScore = iterations;
        }
    }

    public class Evaluate
    {
        /// <summary>
        /// Mili-seconds in a second.
        /// </summary>
        public const int Milis = 1000;

        /// <summary>
        /// Evaluate training.
        /// </summary>
        /// <param name="input">Input neurons.</param>
        /// <param name="hidden1">Hidden 1 neurons.</param>
        /// <param name="hidden2">Hidden 2 neurons.</param>
        /// <param name="output">Output neurons.</param>
        /// <returns>The result of the evaluation.</returns>
        public static int EvaluateTrain(int input, int hidden1, int hidden2,
                                        int output)
        {
            BasicNetwork network = SyntUtility.SimpleFeedForward(input,
                                                                  hidden1, hidden2, output, true);
            IMLDataSet training = RandomTrainingFactory.Generate(1000,
                                                                10000, input, output, -1, 1);

            return EvaluateTrain(network, training);
        }


        /// <summary>
        /// Evaluate how long it takes to calculate the error for the network. This
        /// causes each of the training pairs to be run through the network. The
        /// network is evaluated 10 times and the lowest time is reported. 
        /// </summary>
        /// <param name="network">The training data to use.</param>
        /// <param name="training">The number of seconds that it took.</param>
        /// <returns></returns>
        public static int EvaluateTrain(BasicNetwork network, IMLDataSet training)
        {
            // train the neural network
            IMLTrain train = new ResilientProp(network, training);

            int iterations = 0;
            var watch = new Stopwatch();
            watch.Start();
            while (watch.ElapsedMilliseconds < (10 * Milis))
            {
                iterations++;
                train.Iteration();
            }

            return iterations;
        }
    }

    public class RandomTrainingFactory
    {
        /// <summary>
        /// Private constructor.
        /// </summary>
        private RandomTrainingFactory()
        {
        }

        /// <summary>
        /// Generate a random training set. 
        /// </summary>
        /// <param name="seed">The seed value to use, the same seed value will always produce
        /// the same results.</param>
        /// <param name="count">How many training items to generate.</param>
        /// <param name="inputCount">How many input numbers.</param>
        /// <param name="idealCount">How many ideal numbers.</param>
        /// <param name="min">The minimum random number.</param>
        /// <param name="max">The maximum random number.</param>
        /// <returns>The random training set.</returns>
        public static BasicMLDataSet Generate(long seed,
                                              int count, int inputCount,
                                              int idealCount, double min, double max)
        {
            var rand =
                new LinearCongruentialGenerator(seed);

            var result = new BasicMLDataSet();
            for (int i = 0; i < count; i++)
            {
                IMLData inputData = new BasicMLData(inputCount);

                for (int j = 0; j < inputCount; j++)
                {
                    inputData.Data[j] = rand.Range(min, max);
                }

                IMLData idealData = new BasicMLData(idealCount);

                for (int j = 0; j < idealCount; j++)
                {
                    idealData[j] = rand.Range(min, max);
                }

                var pair = new BasicMLDataPair(inputData,
                                               idealData);
                result.Add(pair);
            }
            return result;
        }

        /// <summary>
        /// Generate random training into a training set.
        /// </summary>
        /// <param name="training">The training set to generate into.</param>
        /// <param name="seed">The seed to use.</param>
        /// <param name="count">How much data to generate.</param>
        /// <param name="min">The low random value.</param>
        /// <param name="max">The high random value.</param>
        public static void Generate(IMLDataSet training,
                                    long seed,
                                    int count,
                                    double min, double max)
        {
            var rand
                = new LinearCongruentialGenerator(seed);

            int inputCount = training.InputSize;
            int idealCount = training.IdealSize;

            for (int i = 0; i < count; i++)
            {
                IMLData inputData = new BasicMLData(inputCount);

                for (int j = 0; j < inputCount; j++)
                {
                    inputData[j] = rand.Range(min, max);
                }

                IMLData idealData = new BasicMLData(idealCount);

                for (int j = 0; j < idealCount; j++)
                {
                    idealData[j] = rand.Range(min, max);
                }

                var pair = new BasicMLDataPair(inputData,
                                               idealData);
                training.Add(pair);
            }
        }
    }

    public class JobUnitContext
    {
        /// <summary>
        /// The JobUnit that this context will execute.
        /// </summary>
        public Object JobUnit { get; set; }

        /// <summary>
        /// The owner of this job.
        /// </summary>
        public ConcurrentJob Owner { get; set; }


        /// <summary>
        /// The task number.
        /// </summary>
        public int TaskNumber { get; set; }
    }

    public class JobUnitWorker : IEngineTask
    {
        /// <summary>
        /// The context for this job unit.
        /// </summary>
        private readonly JobUnitContext _context;

        /// <summary>
        /// Construct a job unit worker to execute the specified job.
        /// </summary>
        /// <param name="context">The context of the job to execute.</param>
        public JobUnitWorker(JobUnitContext context)
        {
            _context = context;
        }

        #region IEngineTask Members

        /// <summary>
        /// Run this job.
        /// </summary>
        public void Run()
        {
            _context.Owner.PerformJobUnit(_context);
        }

        #endregion
    }

    public class DetermineWorkload
    {
        /// <summary>
        /// What is the minimum number of workload entries for a thread to be
        /// worthwhile.
        /// </summary>
        ///
        public const int MinWorthwhile = 100;

        /// <summary>
        /// How many threads to use.
        /// </summary>
        ///
        private readonly int _threadCount;

        /// <summary>
        /// What is the total workload size?
        /// </summary>
        ///
        private readonly int _workloadSize;

        /// <summary>
        /// Determine the workload.
        /// </summary>
        ///
        /// <param name="threads">Threads to use, or zero to allow Synt to pick.</param>
        /// <param name="workloadSize">Total workload size.</param>
        public DetermineWorkload(int threads, int workloadSize)
        {
            _workloadSize = workloadSize;
            if (threads == 0)
            {
                var num = (int)(Math.Log(((int)Process.GetCurrentProcess().ProcessorAffinity + 1), 2));

                // if there is more than one processor, use processor count +1
                if (num != 1)
                {
                    num++;
                }
                // if there is a single processor, just use one thread

                // Now see how big the training sets are going to be.
                // We want at least 100 training elements in each.
                // This method will likely be further "tuned" in future versions.

                long recordCount = _workloadSize;
                long workPerThread = recordCount / num;

                if (workPerThread < 100)
                {
                    num = Math.Max(1, (int)(recordCount / 100));
                }

                _threadCount = num;
            }
            else
            {
                _threadCount = Math.Min(threads, workloadSize);
            }
        }


        /// <summary>
        /// The thread count.
        /// </summary>
        public int ThreadCount
        {
            get { return _threadCount; }
        }

        /// <summary>
        /// Calculate the high and low ranges for each worker.
        /// </summary>
        /// <returns>A list of IntRange objects.</returns>
        public IList<IntRange> CalculateWorkers()
        {
            IList<IntRange> result = new List<IntRange>();
            int sizePerThread = _workloadSize / _threadCount;

            // create the workers
            for (int i = 0; i < _threadCount; i++)
            {
                int low = i * sizePerThread;
                int high;

                // if this is the last record, then high to be the last item
                // in the training set.
                if (i == (_threadCount - 1))
                {
                    high = _workloadSize - 1;
                }
                else
                {
                    high = ((i + 1) * sizePerThread) - 1;
                }

                result.Add(new IntRange(high, low));
            }

            return result;
        }
    }

    public class EngineConcurrency : IMultiThreadable
    {
        /// <summary>
        /// Singleton instance.
        /// </summary>
        private static EngineConcurrency _instance = new EngineConcurrency();

        /// <summary>
        /// The number of active tasks.
        /// </summary>
        private int _activeTasks;

        private int _currentTaskGroup;

        /// <summary>
        /// The instance to the singleton.
        /// </summary>
        public static EngineConcurrency Instance
        {
            get { return _instance; }
        }

        /// <summary>
        /// Construct a concurrency object.
        /// </summary>
        public EngineConcurrency()
        {
            SetMaxThreadsToCoreCount();
            _currentTaskGroup = 0;
        }

        /// <summary>
        /// Process the specified task.  It will be processed either now,
        /// or queued to process on the thread pool.  No group is assigned.
        /// </summary>
        /// <param name="task">The task to process.</param>
        public void ProcessTask(IEngineTask task)
        {
            ProcessTask(task, null);
        }

        /// <summary>
        /// Process the specified task.  It will be processed either now,
        /// or queued to process on the thread pool.
        /// </summary>
        /// <param name="task">The task to process.</param>
        /// <param name="group">The group this task belongs to.</param>
        public void ProcessTask(IEngineTask task, TaskGroup group)
        {
            lock (this)
            {
                _activeTasks++;
            }
            if (group != null)
                group.TaskStarting();
            var item = new PoolItem(this, task, group);
            ThreadPool.QueueUserWorkItem(item.ThreadPoolCallback);
        }

        /// <summary>
        /// How many threads should be used?
        /// </summary>
        public int MaxThreads
        {
            get
            {
                int t1, t2;
                ThreadPool.GetMaxThreads(out t1, out t2);
                return t1;
            }
            set
            {
                int threads = value;

                if (threads == 0)
                {
                    threads = Environment.ProcessorCount;
                    if (threads > 1)
                        threads++;
                }

                ThreadPool.SetMaxThreads(threads, threads);
            }
        }

        /// <summary>
        /// Set the max threads to the number of processors.
        /// </summary>
        public void SetMaxThreadsToCoreCount()
        {
            MaxThreads = Environment.ProcessorCount;
        }

        /// <summary>
        /// Create a new task group.
        /// </summary>
        /// <returns>The new task group.</returns>
        public TaskGroup CreateTaskGroup()
        {
            TaskGroup result;
            lock (this)
            {
                _currentTaskGroup++;
                result = new TaskGroup(_currentTaskGroup);
            }
            return result;
        }

        internal void TaskFinished(PoolItem poolItem)
        {
            lock (this)
            {
                _activeTasks--;
            }
        }

        public int ThreadCount { get; set; }
    }

    public class PoolItem
    {
        /// <summary>
        /// The task group that this item is a part of.
        /// </summary>
        private readonly TaskGroup _group;

        /// <summary>
        /// The concurrency object that started this.
        /// </summary>
        private readonly EngineConcurrency _owner;

        /// <summary>
        /// The task that was executed.
        /// </summary>
        private readonly IEngineTask _task;

        /// <summary>
        /// Construct a pool item.
        /// </summary>
        /// <param name="owner">The owner of this task.</param>
        /// <param name="task">The task to execute.</param>
        /// <param name="group">The group that this task belongs to.</param>
        public PoolItem(EngineConcurrency owner, IEngineTask task, TaskGroup group)
        {
            _owner = owner;
            _task = task;
            _group = group;
        }

        /// <summary>
        /// The thread callback.  This actually executes the task.
        /// </summary>
        /// <param name="threadContext">The thread context, not used.</param>
        public void ThreadPoolCallback(Object threadContext)
        {
            try
            {
                _task.Run();
                _owner.TaskFinished(this);
            }
            finally
            {
                if (_group != null)
                {
                    _group.TaskStopping();
                }
            }
        }
    }

    public class TaskGroup
    {
        /// <summary>
        /// The event used to sync waiting for tasks to stop.
        /// </summary>
        private readonly ManualResetEvent _completeEvent = new ManualResetEvent(false);

        /// <summary>
        /// The ID for this task group.
        /// </summary>
        private readonly int _id;

        /// <summary>
        /// The number of tasks that have completed.
        /// </summary>
        private int _completedTasks;

        /// <summary>
        /// The total number of tasks in this group.
        /// </summary>
        private int _totalTasks;


        /// <summary>
        /// Create a task group with the specified id.
        /// </summary>
        /// <param name="id">The ID of the task group.</param>
        public TaskGroup(int id)
        {
            _id = id;
            _totalTasks = 0;
        }

        /// <summary>
        /// The ID of the task group.
        /// </summary>
        public int ID
        {
            get { return _id; }
        }

        /// <summary>
        /// Returns true if there are no more tasks.
        /// </summary>
        public bool NoTasks
        {
            get
            {
                lock (this)
                {
                    return _totalTasks == _completedTasks;
                }
            }
        }

        /// <summary>
        /// Notify that a task is starting.
        /// </summary>
        public void TaskStarting()
        {
            lock (this)
            {
                _totalTasks++;
            }
        }

        /// <summary>
        /// Notify that a task is stopping.
        /// </summary>
        public void TaskStopping()
        {
            lock (this)
            {
                _completedTasks++;
                _completeEvent.Set();
            }
        }

        /// <summary>
        /// Wait for all tasks to complete in this group.
        /// </summary>
        public void WaitForComplete()
        {
            while (!NoTasks)
            {
                _completeEvent.WaitOne();
                _completeEvent.Reset();
            }
        }
    }

    public class CSVError : SyntError
    {
        /// <summary>
        /// Construct a message exception.
        /// </summary>
        /// <param name="str">The message.</param>
        public CSVError(String str)
            : base(str)
        {
        }

        /// <summary>
        /// Pass on an exception.
        /// </summary>
        /// <param name="e">The other exception.</param>
        public CSVError(Exception e)
            : base(e)
        {
        }
    }

    [Serializable]
    public class CSVFormat
    {
        /// <summary>
        /// The maximum number of digits.
        /// </summary>
        public const int MaxFormats = 100;

        private readonly char _decimalChar;

        private readonly NumberFormatInfo _numberFormat;
        private readonly char _separatorChar;
        private readonly String[] _formats;


        /// <summary>
        /// Create a CSV format for the specified decimal char and separator char.
        /// </summary>
        /// <param name="decimalChar">The character for a decimal point or comma.</param>
        /// <param name="separatorChar">The separator char for a number list, likely comma or semicolon.</param>
        public CSVFormat(char decimalChar, char separatorChar)
        {
            _decimalChar = decimalChar;
            _separatorChar = separatorChar;

            if (decimalChar == '.')
            {
                _numberFormat = (new CultureInfo("en-us")).NumberFormat;
            }
            else if (decimalChar == ',')
            {
                _numberFormat = (new CultureInfo("de-DE")).NumberFormat;
            }
            else
            {
                _numberFormat = NumberFormatInfo.CurrentInfo;
            }

            // There might be a better way to do this, but I can't seem to find a way in
            // C# where I can specify "x" decimal places, and not end up with trailing zeros.
            _formats = new String[MaxFormats];
            for (int i = 0; i < MaxFormats; i++)
            {
                var str = new StringBuilder();
                str.Append("#0");
                if (i > 0)
                {
                    str.Append(".");
                }
                for (int j = 0; j < i; j++)
                {
                    str.Append("#");
                }
                _formats[i] = str.ToString();
            }
        }

        /// <summary>
        /// Default constructor for reflection.
        /// </summary>
        public CSVFormat()
        {
        }

        static CSVFormat()
        {
            DecimalComma = new CSVFormat(',', ';');
            DecimalPoint = new CSVFormat('.', ',');
        }

        /// <summary>
        /// A format that uses a decimal point and a comma to separate fields.
        /// </summary>
        public static CSVFormat DecimalPoint { get; private set; }

        /// <summary>
        /// A format that uses a decimal comma and a semicolon to separate fields.
        /// </summary>
        public static CSVFormat DecimalComma { get; private set; }

        /// <summary>
        /// The typical format for English speaking countries is a decimal
        /// point and a comma for field separation.  
        /// </summary>
        public static CSVFormat English
        {
            get { return DecimalPoint; }
        }

        /// <summary>
        /// It is important that an EG file produced on one system, in one region
        /// be readable by another system in a different region.  Because of this
        /// EG files internally use a decimal point and comma separator.  Of course
        /// programs should display numbers to the user using regional settings.
        /// </summary>
        public static CSVFormat EgFormat
        {
            get { return DecimalPoint; }
        }

        /// <summary>
        /// The decimal character, usually either a period or comma.
        /// </summary>
        public char DecimalChar
        {
            get { return _decimalChar; }
        }

        /// <summary>
        /// The separator character for a list of fields in CSV, usually either comma or
        /// semicolon.
        /// </summary>
        public char Separator
        {
            get { return _separatorChar; }
        }

        /// <summary>
        /// The decimal character for the current region.
        /// </summary>
        public static char DecimalCharacter
        {
            get { return NumberFormatInfo.CurrentInfo.NumberDecimalSeparator[0]; }
        }

        /// <summary>
        /// Parse the specified string into a number.
        /// </summary>
        /// <param name="str">The string to parse.</param>
        /// <returns>The number that has been parsed.</returns>
        public double Parse(String str)
        {
            if (string.Compare(str, "?", true) == 0)
            {
                return double.NaN;
            }
            if (string.Compare(str, "NaN", true) == 0)
            {
                return double.NaN;
            }
            return double.Parse(str.Trim(), _numberFormat);
        }

        /// <summary>
        /// Format the specified number into a string.
        /// </summary>
        /// <param name="d">The number to parse.</param>
        /// <param name="digits">The number of fractional digits.</param>
        /// <returns>The formatted number.</returns>
        public String Format(double d, int digits)
        {
            int digits2 = Math.Min(digits, MaxFormats);
            digits2 = Math.Max(digits2, 0);
            return d.ToString(_formats[digits2], _numberFormat);
        }

    }

    public class NumberList
    {
        private NumberList()
        {
        }

        /// <summary>
        /// Get an array of double's from a string of comma separated text.
        /// </summary>
        /// <param name="format">The way to format this list.</param>
        /// <param name="str">The string that contains a list of numbers.</param>
        /// <returns>An array of doubles parsed from the string.</returns>
        public static double[] FromList(CSVFormat format, String str)
        {
            if (str.Trim().Length == 0)
            {
                return new double[0];
            }
            // first count the numbers

            String[] tok = str.Split(format.Separator);
            int count = tok.Length;

            // now allocate an object to hold that many numbers
            var result = new double[count];

            // and finally parse the numbers
            for (int index = 0; index < tok.Length; index++)
            {
                try
                {
                    String num = tok[index];
                    double value = format.Parse(num);
                    result[index] = value;
                }
                catch (Exception e)
                {
                    throw new PersistError(e);
                }
            }

            return result;
        }

        /// <summary>
        /// Get an array of ints's from a string of comma separated text.
        /// </summary>
        /// <param name="format">The way to format this list.</param>
        /// <param name="str">The string that contains a list of numbers.</param>
        /// <returns>An array of ints parsed from the string.</returns>
        public static int[] FromListInt(CSVFormat format, String str)
        {
            if (str.Trim().Length == 0)
            {
                return new int[0];
            }
            // first count the numbers

            String[] tok = str.Split(format.Separator);
            int count = tok.Length;

            // now allocate an object to hold that many numbers
            var result = new int[count];

            // and finally parse the numbers
            for (int index = 0; index < tok.Length; index++)
            {
                try
                {
                    String num = tok[index];
                    int value = int.Parse(num);
                    result[index] = value;
                }
                catch (Exception e)
                {
                    throw new PersistError(e);
                }
            }

            return result;
        }

        /// <summary>
        /// Convert an array of doubles to a comma separated list.
        /// </summary>
        /// <param name="format">The way to format this list.</param>
        /// <param name="result">This string will have the values appended to it.</param>
        /// <param name="data">The array of doubles to use.</param>
        public static void ToList(CSVFormat format, StringBuilder result,
                                  double[] data)
        {
            ToList(format, 20, result, data);
        }

        /// <summary>
        /// Convert an array of doubles to a comma separated list.
        /// </summary>
        /// <param name="format">The way to format this list.</param>
        /// <param name="precision">The precision.</param>
        /// <param name="result">This string will have the values appended to it.</param>
        /// <param name="data">The array of doubles to use.</param>
        public static void ToList(CSVFormat format, int precision, StringBuilder result,
                                  double[] data)
        {
            result.Length = 0;
            for (int i = 0; i < data.Length; i++)
            {
                if (i != 0)
                {
                    result.Append(format.Separator);
                }
                result.Append(format.Format(data[i], precision));
            }
        }

        /// <summary>
        /// Convert an array of ints to a comma separated list.
        /// </summary>
        /// <param name="format">The way to format this list.</param>
        /// <param name="result">This string will have the values appended to it.</param>
        /// <param name="data">The array of doubles to use.</param>
        public static void ToListInt(CSVFormat format, StringBuilder result,
                                     int[] data)
        {
            result.Length = 0;
            for (int i = 0; i < data.Length; i++)
            {
                if (i != 0)
                {
                    result.Append(format.Separator);
                }
                result.Append(data[i]);
            }
        }
    }

    public class ReadCSV
    {
        /// <summary>
        /// The names of the columns.
        /// </summary>
        private readonly IList<String> _columnNames = new List<String>();

        /// <summary>
        /// The names of the columns.
        /// </summary>
        private readonly IDictionary<String, int> _columns = new Dictionary<String, int>();

        /// <summary>
        /// The file to read.
        /// </summary>
        private readonly TextReader _reader;

        /// <summary>
        /// The data.
        /// </summary>
        private String[] _data;

        /// <summary>
        /// The delimiter.
        /// </summary>
        private char _delim;

        private CSVFormat _format;

        /// <summary>
        /// Construct a CSV reader from an input stream.
        /// </summary>
        /// <param name="istream">The InputStream to read from.</param>
        /// <param name="headers">Are headers present?</param>
        /// <param name="delim">What is the delimiter.</param>
        public ReadCSV(Stream istream, bool headers,
                       char delim)
        {
            var format = new CSVFormat(CSVFormat.DecimalCharacter, delim);
            _reader = new StreamReader(istream);
            _delim = delim;
            Begin(headers, format);
        }

        /// <summary>
        /// Construct a CSV reader from a filename.
        /// </summary>
        /// <param name="filename">The filename.</param>
        /// <param name="headers">The headers.</param>
        /// <param name="delim">The delimiter.</param>
        public ReadCSV(String filename, bool headers,
                       char delim)
        {
            var format = new CSVFormat(CSVFormat.DecimalCharacter, delim);
            _reader = new StreamReader(filename);
            _delim = delim;
            Begin(headers, format);
        }

        /// <summary>
        /// Construct a CSV reader from a filename.
        /// Allows a delimiter character to be specified.
        /// Numbers will be parsed using the current
        /// locale.
        /// </summary>
        /// <param name="filename">The filename.</param>
        /// <param name="headers">The headers.</param>
        /// <param name="format">The delimiter.</param>
        public ReadCSV(String filename, bool headers,
                       CSVFormat format)
        {
            _reader = new StreamReader(filename);
            Begin(headers, format);
        }

        /// <summary>
        /// Construct a CSV reader from an input stream.
        /// The format parameter specifies the separator 
        /// character to use, as well as the number
        /// format.
        /// </summary>
        /// <param name="stream">The Stream to read from.</param>
        /// <param name="headers">Are headers present?</param>
        /// <param name="format">What is the CSV format.</param>
        public ReadCSV(Stream stream, bool headers,
                       CSVFormat format)
        {
            _reader = new StreamReader(stream);
            Begin(headers, format);
        }

        /// <summary>
        /// The format that dates are expected to be in. (i.e. "yyyy-MM-dd")
        /// </summary>
        public String DateFormat { get; set; }

        /// <summary>
        /// The format that times are expected to be in. (i.e. "hhmmss").
        /// </summary>
        public String TimeFormat { get; set; }

        /// <summary>
        /// The current format.
        /// </summary>
        public CSVFormat Format
        {
            get { return _format; }
        }

        /// <summary>
        /// The names of the columns.
        /// </summary>
        public IList<String> ColumnNames
        {
            get { return _columnNames; }
        }

        /// <summary>
        /// Return the number of columns, if known. 
        /// </summary>
        public int ColumnCount
        {
            get
            {
                if (_data == null)
                {
                    return 0;
                }
                return _data.Length;
            }
        }

        /// <summary>
        /// Parse a date using the specified format.
        /// </summary>
        /// <param name="when">A string that contains a date in the specified format.</param>
        /// <param name="dateFormat">The date format.</param>
        /// <returns>A DateTime that was parsed.</returns>
        public static DateTime ParseDate(String when, String dateFormat)
        {
            try
            {
                return DateTime.ParseExact(when, dateFormat,
                                           CultureInfo.InvariantCulture);
            }
            catch (FormatException)
            {
                return default(DateTime);
            }
        }


        /// <summary>
        /// Read the headers.
        /// </summary>
        /// <param name="format">The format of this CSV file.</param>
        /// <param name="headers">Are headers present.</param>
        private void Begin(bool headers, CSVFormat format)
        {
            try
            {
                DateFormat = "yyyy-MM-dd";
                TimeFormat = "hhmmss";
                _format = format;
                // read the column heads
                if (headers)
                {
                    String line = _reader.ReadLine();
                    IList<String> tok = Parse(line);

                    int i = 0;
                    foreach (String header in tok)
                    {
                        if (_columns.ContainsKey(header.ToLower()))
                            throw new SyntError("Two columns cannot have the same name");
                        _columns.Add(header.ToLower(), i++);
                        _columnNames.Add(header);
                    }
                }

                _data = null;
            }
            catch (IOException e)
            {
#if logging
                if (logger.IsErrorEnabled)
                {
                    logger.Error("Exception", e);
                }
#endif
                throw new SyntError(e);
            }
        }

        /// <summary>
        /// Close the file.
        /// </summary>
        public void Close()
        {
            try
            {
                _reader.Close();
            }
            catch (IOException e)
            {
#if logging
                if (logger.IsErrorEnabled)
                {
                    logger.Error("Exception", e);
                }
#endif
                throw new SyntError(e);
            }
        }

        /// <summary>
        /// Get the specified column as a string.
        /// </summary>
        /// <param name="i">The column index, starting at zero.</param>
        /// <returns>The column as a string.</returns>
        public String Get(int i)
        {
            if (i >= _data.Length)
            {
                throw new SyntError("Can't access column " + i + " in a file that has only " + _data.Length + " columns.");
            }
            return _data[i];
        }

        /// <summary>
        /// Get the column by its string name, as a string. This will only work if
        /// column headers were defined that have string names.
        /// </summary>
        /// <param name="column">The column name.</param>
        /// <returns>The column data as a string.</returns>
        public String Get(String column)
        {
            if (!_columns.ContainsKey(column.ToLower()))
                return null;
            int i = _columns[column.ToLower()];

            return _data[i];
        }

        /// <summary>
        /// Get the column count.
        /// </summary>
        /// <returns>The column count.</returns>
        public int GetCount()
        {
            if (_data == null)
            {
                return 0;
            }

            return _data.Length;
        }

        /// <summary>
        /// Read the specified column as a date.
        /// </summary>
        /// <param name="column">The specified column.</param>
        /// <returns>The specified column as a DateTime.</returns>
        public DateTime GetDate(String column)
        {
            String str = Get(column);
            return DateTime.ParseExact(str, DateFormat, CultureInfo.InvariantCulture);
        }

        /// <summary>
        /// Read the specified column as a time.
        /// </summary>
        /// <param name="column">The specified column.</param>
        /// <returns>The specified column as a DateTime.</returns>
        public DateTime GetTime(String column)
        {
            String str = Get(column);
            return DateTime.ParseExact(str, TimeFormat, CultureInfo.InvariantCulture);
        }

        /// <summary>
        /// Read the specified column as a date.
        /// </summary>
        /// <param name="column">The specified column.</param>
        /// <returns>The specified column as a DateTime.</returns>
        public DateTime GetDate(int column)
        {
            String str = Get(column);
            return DateTime.ParseExact(str, DateFormat, CultureInfo.InvariantCulture);
        }

        /// <summary>
        /// Read the specified column as a time.
        /// </summary>
        /// <param name="column">The specified column.</param>
        /// <returns>The specified column as a DateTime.</returns>
        public DateTime GetTime(int column)
        {
            String str = Get(column);
            return DateTime.ParseExact(str, TimeFormat, CultureInfo.InvariantCulture);
        }

        /// <summary>
        /// Get the specified column as a double.
        /// </summary>
        /// <param name="column">The column to read.</param>
        /// <returns>The specified column as a double.</returns>
        public double GetDouble(String column)
        {
            String str = Get(column);
            return _format.Parse(str);
        }

        /// <summary>
        /// Get the specified column as a double.
        /// </summary>
        /// <param name="column">The column to read.</param>
        /// <returns>The specified column as a double.</returns>
        public double GetDouble(int column)
        {
            String str = Get(column);
            return _format.Parse(str);
        }

        /// <summary>
        /// Get an integer that has the specified name.
        /// </summary>
        /// <param name="col">The column name to read.</param>
        /// <returns>The specified column as an int.</returns>
        public int GetInt(String col)
        {
            String str = Get(col);
            try
            {
                return int.Parse(str);
            }
            catch (FormatException)
            {
                return 0;
            }
        }

        /// <summary>
        /// Count the columns and create a an array to hold them.
        /// </summary>
        /// <param name="line">One line from the file</param>
        private void InitData(string line)
        {
            IList<String> tok = Parse(line);
            _data = new String[tok.Count];
        }


        /// <summary>
        /// Read the next line.
        /// </summary>
        /// <returns>True if there are more lines to read.</returns>
        public bool Next()
        {
            try
            {
                String line;

                do
                {
                    line = _reader.ReadLine();
                } while ((line != null) && line.Trim().Length == 0);

                if (line == null)
                {
                    return false;
                }

                if (_data == null)
                {
                    InitData(line);
                }

                IList<String> tok = Parse(line);

                int i = 0;
                foreach (String str in tok)
                {
                    if (i < _data.Length)
                    {
                        _data[i++] = str;
                    }
                }

                return true;
            }
            catch (IOException e)
            {
#if logging
                if (logger.IsErrorEnabled)
                {
                    logger.Error("Exception", e);
                }
#endif
                throw new SyntError(e);
            }
        }

        private IList<String> Parse(string line)
        {
            if (Format.Separator == ' ')
            {
                return ParseSpaceSep(line);
            }
            else
            {
                return ParseCharSep(line);
            }
        }

        /// <summary>
        /// Parse the line into a list of values.
        /// </summary>
        /// <param name="line">The line to parse.</param>
        /// <returns>The elements on this line.</returns>
        private IList<String> ParseCharSep(string line)
        {
            var item = new StringBuilder();
            var result = new List<String>();
            bool quoted = false;
            bool hadQuotes = false;

            for (int i = 0; i < line.Length; i++)
            {
                char ch = line[i];
                if ((ch == Format.Separator) && !quoted)
                {
                    String s = item.ToString();
                    if (!hadQuotes)
                    {
                        s = s.Trim();
                    }
                    result.Add(s);
                    item.Length = 0;
                    quoted = false;
                    hadQuotes = false;
                }
                else if ((ch == '\"') && quoted)
                {
                    quoted = false;
                }
                else if ((ch == '\"') && (item.Length == 0))
                {
                    hadQuotes = true;
                    quoted = true;
                }
                else
                {
                    item.Append(ch);
                }
            }

            if (item.Length > 0)
            {
                String s = item.ToString();
                if (!hadQuotes)
                {
                    s = s.Trim();
                }
                result.Add(s);
            }

            return result;
        }

        /// <summary>
        /// Parse a line with space separators.
        /// </summary>
        /// <param name="line">The line to parse.</param>
        /// <returns>The list of items from the line.</returns>
        private static List<String> ParseSpaceSep(String line)
        {
            var result = new List<String>();
            var parse = new SimpleParser(line);

            while (!parse.EOL())
            {
                result.Add(parse.Peek() == '\"' ? parse.ReadQuotedString() : parse.ReadToWhiteSpace());
                parse.EatWhiteSpace();
            }

            return result;
        }


        internal long GetLong(int col)
        {
            String str = Get(col);
            try
            {
                return long.Parse(str);
            }
            catch (FormatException)
            {
                return 0;
            }
        }

        /// <summary>
        /// Check to see if there are any missing values on the current row.
        /// </summary>
        /// <returns>True, if there are missing values.</returns>
        public bool HasMissing()
        {
            for (int i = 0; i < _data.Length; i++)
            {
                String s = _data[i].Trim();
                if (s.Length == 0 || s.Equals("?"))
                {
                    return true;
                }
            }
            return false;
        }
    }

    public class RGBDownsample : IDownSample
    {
        /// <summary>
        /// The bottom boundary of the downsample.
        /// </summary>
        private int _downSampleBottom;

        /// <summary>
        /// The left boundary of the downsample.
        /// </summary>
        private int _downSampleLeft;

        /// <summary>
        /// The right boundary of the downsample.
        /// </summary>
        private int _downSampleRight;

        /// <summary>
        /// The top boundary of the downsample.
        /// </summary>
        private int _downSampleTop;

        /// <summary>
        /// The image height.
        /// </summary>
        private int _imageHeight;

        /// <summary>
        /// The image width.
        /// </summary>
        private int _imageWidth;

        /// <summary>
        /// The downsample x-ratio.
        /// </summary>
        private double _ratioX;

        /// <summary>
        /// The downsample y-ratio.
        /// </summary>
        private double _ratioY;

        /// <summary>
        /// The current red average.
        /// </summary>
        public int CurrentRed { get; set; }

        /// <summary>
        /// The current blue average.
        /// </summary>
        public int CurrentBlue { get; set; }

        /// <summary>
        /// The current green average.
        /// </summary>
        public int CurrentGreen { get; set; }

        /// <summary>
        /// The current image being processed.
        /// </summary>
        public Bitmap Image { get; set; }

        #region IDownSample Members

        /// <summary>
        /// The pixel map from the image.
        /// </summary>
        public int[] PixelMap { get; set; }

        /// <summary>
        /// Called to downsample the image and store it in the down sample component.
        /// </summary>
        /// <param name="image">The image to downsample.</param>
        /// <param name="height">The height to downsample to.</param>
        /// <param name="width">THe width to downsample to.</param>
        /// <returns>The downsampled image.</returns>
        public virtual double[] DownSample(Bitmap image, int height,
                                           int width)
        {
            Image = image;
            ProcessImage(image);

            var result = new double[height * width * 3];

            // now downsample

            _ratioX = (_downSampleRight - _downSampleLeft)
                     / (double)width;
            _ratioY = (_downSampleBottom - _downSampleTop)
                     / (double)height;

            int index = 0;
            for (int y = 0; y < height; y++)
            {
                for (int x = 0; x < width; x++)
                {
                    DownSampleRegion(x, y);
                    result[index++] = CurrentRed;
                    result[index++] = CurrentGreen;
                    result[index++] = CurrentBlue;
                }
            }

            return result;
        }

        /// <summary>
        /// This method is called to automatically crop the image so that whitespace
        /// is removed.
        /// </summary>
        public void FindBounds()
        {
            // top line
            for (int y = 0; y < _imageHeight; y++)
            {
                if (!HLineClear(y))
                {
                    _downSampleTop = y;
                    break;
                }
            }
            // bottom line
            for (int y = _imageHeight - 1; y >= 0; y--)
            {
                if (!HLineClear(y))
                {
                    _downSampleBottom = y;
                    break;
                }
            }
            // left line
            for (int x = 0; x < _imageWidth; x++)
            {
                if (!VLineClear(x))
                {
                    _downSampleLeft = x;
                    break;
                }
            }

            // right line
            for (int x = _imageWidth - 1; x >= 0; x--)
            {
                if (!VLineClear(x))
                {
                    _downSampleRight = x;
                    break;
                }
            }
        }

        /// <summary>
        /// The bottom of the downsample.
        /// </summary>
        public int DownSampleBottom
        {
            get { return _downSampleBottom; }
        }

        /// <summary>
        /// The left of the downsample.
        /// </summary>
        public int DownSampleLeft
        {
            get { return _downSampleLeft; }
        }

        /// <summary>
        /// The right of the downsample.
        /// </summary>
        public int DownSampleRight
        {
            get { return _downSampleRight; }
        }

        /// <summary>
        /// The top of the downsample.
        /// </summary>
        public int DownSampleTop
        {
            get { return _downSampleTop; }
        }

        /// <summary>
        /// The image height.
        /// </summary>
        public int ImageHeight
        {
            get { return _imageHeight; }
        }

        /// <summary>
        /// The image width.
        /// </summary>
        public int ImageWidth
        {
            get { return _imageWidth; }
        }


        /// <summary>
        /// The x-ratio.
        /// </summary>
        public double RatioX
        {
            get { return _ratioX; }
        }

        /// <summary>
        /// The y-ratio.
        /// </summary>
        public double RatioY
        {
            get { return _ratioY; }
        }

        /// <summary>
        /// Process the image and prepare it to be downsampled.
        /// </summary>
        /// <param name="image">The image to downsample.</param>
        public void ProcessImage(Bitmap image)
        {
            Image = image;
            _imageHeight = Image.Height;
            _imageWidth = Image.Width;
            _downSampleLeft = 0;
            _downSampleTop = 0;
            _downSampleRight = _imageWidth;
            _downSampleBottom = _imageHeight;

            _ratioX = (_downSampleRight - _downSampleLeft)
                     / (double)ImageWidth;
            _ratioY = (_downSampleBottom - _downSampleTop)
                     / (double)ImageHeight;
        }

        #endregion

        /// <summary>
        /// Called to downsample a region of the image.
        /// </summary>
        /// <param name="x">The x coordinate of the resulting downsample.</param>
        /// <param name="y">The y coordinate of the resulting downsample.</param>
        public void DownSampleRegion(int x, int y)
        {
            var startX = (int)(_downSampleLeft + x * _ratioX);
            var startY = (int)(_downSampleTop + y * _ratioY);
            var endX = (int)(startX + _ratioX);
            var endY = (int)(startY + _ratioY);

            endX = Math.Min(_imageWidth, endX);
            endY = Math.Min(_imageHeight, endY);

            int redTotal = 0;
            int greenTotal = 0;
            int blueTotal = 0;

            int total = 0;

            for (int yy = startY; yy < endY; yy++)
            {
                for (int xx = startX; xx < endX; xx++)
                {
                    Color pixel = Image.GetPixel(xx, yy);
                    redTotal += pixel.R;
                    greenTotal += pixel.G;
                    blueTotal += pixel.B;
                    total++;
                }
            }

            CurrentRed = redTotal / total;
            CurrentGreen = greenTotal / total;
            CurrentBlue = blueTotal / total;
        }

        /// <summary>
        /// This method is called internally to see if there are any pixels in the
        /// given scan line. This method is used to perform autocropping.
        /// </summary>
        /// <param name="y"></param>
        /// <returns></returns>
        private bool HLineClear(int y)
        {
            for (int i = 0; i < _imageWidth; i++)
            {
                Color pixel = Image.GetPixel(i, y);
                if (pixel.R < 250 || pixel.G < 250 || pixel.B < 250)
                {
                    return false;
                }
            }
            return true;
        }

        /// <summary>
        /// This method is called internally to see if there are any pixels in the
        /// given scan line. This method is used to perform autocropping.
        /// </summary>
        /// <param name="x">The vertical line to scan.</param>
        /// <returns>True if there are any pixels in the specified vertical line.</returns>
        private bool VLineClear(int x)
        {
            for (int i = 0; i < _imageHeight; i++)
            {
                Color pixel = Image.GetPixel(x, i);
                if (pixel.R < 250 || pixel.G < 250 || pixel.B < 250)
                {
                    return false;
                }
            }
            return true;
        }
    }

    public class SimpleIntensityDownsample : RGBDownsample
    {
        /// <summary>
        /// Called to downsample the image and store it in the down sample component. 
        /// </summary>
        /// <param name="image">The image to downsample.</param>
        /// <param name="height">The height to downsample to.</param>
        /// <param name="width">THe width to downsample to.</param>
        /// <returns>The downsampled image.</returns>
        public override double[] DownSample(Bitmap image, int height,
                                            int width)
        {
            Image = image;
            ProcessImage(image);

            var result = new double[height * width * 3];

            // now downsample

            int index = 0;
            for (int y = 0; y < height; y++)
            {
                for (int x = 0; x < width; x++)
                {
                    DownSampleRegion(x, y);
                    result[index++] = (CurrentRed + CurrentBlue
                                       + CurrentGreen) / 3;
                }
            }

            return result;
        }
    }

    public class CalculateRegressionError
    {
        /// <summary>
        /// Calculate an error for a method that uses regression.
        /// </summary>
        /// <param name="method">The method to evaluate.</param>
        /// <param name="data">The training data to evaluate with.</param>
        /// <returns>The error.</returns>
        public static double CalculateError(IMLRegression method,
                                            IMLDataSet data)
        {
            var errorCalculation = new ErrorCalculation();

            // clear context
            if (method is IMLContext)
            {
                ((IMLContext)method).ClearContext();
            }


            // calculate error
            foreach (IMLDataPair pair in data)
            {
                IMLData actual = method.Compute(pair.Input);
                errorCalculation.UpdateError(actual.Data, pair.Ideal.Data, pair.Significance);
            }
            return errorCalculation.Calculate();
        }
    }

    public static class Directory
    {
        /// <summary>
        /// Default buffer size for read/write operations.
        /// </summary>
        ///
        public const int BufferSize = 1024;

        /// <summary>
        /// Copy the specified file.
        /// </summary>
        ///
        /// <param name="source">The file to copy.</param>
        /// <param name="target">The target of the copy.</param>
        public static void CopyFile(FileInfo source, FileInfo target)
        {
            try
            {
                var buffer = new byte[BufferSize];

                // open the files before the copy
                FileStream
                    ins0 = source.OpenRead();
                target.Delete();
                FileStream xout = target.OpenWrite();

                // perform the copy
                int packetSize = 0;

                while (packetSize != -1)
                {
                    packetSize = ins0.Read(buffer, 0, buffer.Length);
                    if (packetSize != -1)
                    {
                        xout.Write(buffer, 0, packetSize);
                    }
                }

                // close the files after the copy
                ins0.Close();
                xout.Close();
            }
            catch (IOException e)
            {
                throw new SyntError(e);
            }
        }

        /// <summary>
        /// Delete a directory and all children.
        /// </summary>
        ///
        /// <param name="path">The path to delete.</param>
        /// <returns>True if successful.</returns>
        public static bool DeleteDirectory(FileInfo path)
        {
            return DeleteDirectory(path);
        }

        /// <summary>
        /// Read the entire contents of a stream into a string.
        /// </summary>
        ///
        /// <param name="mask0">The input stream to read from.</param>
        /// <returns>The string that was read in.</returns>
        public static String ReadStream(Stream mask0)
        {
            try
            {
                var sb = new StringBuilder(1024);
                TextReader reader = new StreamReader(mask0);

                var chars = new char[BufferSize];
                int numRead;
                while ((numRead = reader.Read(chars, 0, chars.Length)) > -1)
                {
                    sb.Append(new String(chars, 0, numRead));
                }
                reader.Close();

                return sb.ToString();
            }
            catch (IOException e)
            {
                throw new SyntError(e);
            }
        }

        /// <summary>
        /// Read the entire contents of a stream into a string.
        /// </summary>
        ///
        /// <param name="filename">The input stream to read from.</param>
        /// <returns>The string that was read in.</returns>
        public static String ReadTextFile(String filename)
        {
            try
            {
                var result = new StringBuilder();
                using (var sr = new StreamReader(filename))
                {
                    String line;

                    while ((line = sr.ReadLine()) != null)
                    {
                        result.Append(line);
                        result.Append("\r\n");
                    }
                }
                return result.ToString();
            }
            catch (IOException e)
            {
                throw new SyntError(e);
            }
        }
    }

    public class FileUtil
    {
        /// <summary>
        /// Add, or replace a filename base.  A filename base is between an underbar
        /// and the . for the extension.  For example: "myfile_raw.csv", the base is
        /// "raw".
        /// </summary>
        /// <param name="filename"></param>
        /// <param name="bs"></param>
        /// <returns></returns>
        public static FileInfo AddFilenameBase(FileInfo filename, String bs)
        {
            String f = GetFileName(filename);
            String ext = GetFileExt(filename);

            int idx1 = f.LastIndexOf('_');
            int idx2 = f.LastIndexOf(Path.PathSeparator);

            bool remove = false;

            if (idx1 != -1)
            {
                if (idx2 == -1)
                {
                    remove = true;
                }
                else
                {
                    remove = idx1 > idx2;
                }
            }

            if (remove)
            {
                f = f.Substring(0, (idx1) - (0));
            }

            return new FileInfo(f + bs + "." + ext);
        }

        /// <summary>
        /// Get the filename, without extension.
        /// </summary>
        /// <param name="file">The file to parse.</param>
        /// <returns>The file name.</returns>
        public static String GetFileName(FileInfo file)
        {
            String fileName = file.ToString();
            int mid = fileName.LastIndexOf(".");
            if (mid == -1)
            {
                return fileName;
            }
            return fileName.Substring(0, (mid) - (0));
        }

        /// <summary>
        /// Get the file extension.
        /// </summary>
        /// <param name="file">The base file.</param>
        /// <returns>The extension.</returns>
        public static String GetFileExt(FileInfo file)
        {
            String fileName = file.ToString();
            int mid = fileName.LastIndexOf(".");
            if (mid == -1)
                return "";
            return fileName.Substring(mid + 1, (fileName.Length) - (mid + 1));
        }

        /// <summary>
        /// Read a file into a string.
        /// </summary>
        /// <param name="filePath">The file to read.</param>
        /// <returns>The contents of the file.</returns>
        public static String ReadFileAsString(FileInfo filePath)
        {
            var fileData = new StringBuilder(1000);
            TextReader reader = new StreamReader(filePath.OpenRead());
            var buf = new char[1024];
            int numRead;
            while ((numRead = reader.Read(buf, 0, buf.Length)) != -1)
            {
                var readData = new string(buf, 0, numRead);
                fileData.Append(readData);
                buf = new char[1024];
            }
            reader.Close();
            return fileData.ToString();
        }

        /// <summary>
        /// Change a file's extension.
        /// </summary>
        /// <param name="name">The filename to change.</param>
        /// <param name="ext">The new extension.</param>
        /// <returns></returns>
        public static String ForceExtension(String name, String ext)
        {
            String b = GetFileName(new FileInfo(name));
            return b + "." + ext;
        }

        /// <summary>
        /// Write a string to a file.
        /// </summary>
        /// <param name="path"></param>
        /// <param name="str"></param>
        public static void WriteFileAsString(FileInfo path, String str)
        {
            FileStream fs = path.Create();
            var writer = new StreamWriter(fs);
            writer.Write(str);
            writer.Close();
            fs.Close();
        }

        /// <summary>
        /// Copy from one file to another.
        /// </summary>
        /// <param name="source">The source file.</param>
        /// <param name="target">The target file.</param>
        public static void Copy(FileInfo source, FileInfo target)
        {
            try
            {
                target.Delete();
                FileStream fos = target.OpenWrite();
                Stream mask0 = source.OpenRead();

                Copy(mask0, fos);

                fos.Close();
                mask0.Close();
            }
            catch (IOException e)
            {
                throw new SyntError(e);
            }
        }

        /// <summary>
        /// Copy from one stream to another.
        /// </summary>
        /// <param name="mask0">The source.</param>
        /// <param name="os">The target.</param>
        public static void Copy(Stream mask0, Stream os)
        {
            try
            {
                var buffer = new byte[BotUtil.BufferSize];
                int length;
                do
                {
                    length = mask0.Read(buffer, 0, buffer.Length);

                    if (length > 0)
                    {
                        os.Write(buffer, 0, length);
                    }
                } while (length > 0);
            }
            catch (IOException ex)
            {
                throw new SyntError(ex);
            }
        }

        /// <summary>
        /// Copy a resource to the file system.
        /// </summary>
        /// <param name="resource">The resource to copy.</param>
        /// <param name="targetFile">There to copy the resource to.</param>
        public static void CopyResource(String resource, FileInfo targetFile)
        {
            try
            {
                Stream mask0 = ResourceLoader.CreateStream(resource);
                targetFile.Delete();
                Stream os = targetFile.OpenWrite();
                Copy(mask0, os);
                mask0.Close();
                os.Close();
            }
            catch (IOException ex)
            {
                throw new SyntError(ex);
            }
        }

        /// <summary>
        /// Combine a path with a filename.
        /// </summary>
        /// <param name="dir">The path to combine.</param>
        /// <param name="f">The filename to combine.</param>
        /// <returns>The resulting path.</returns>
        public static FileInfo CombinePath(FileInfo dir, string f)
        {
            string s = dir.ToString();
            return new FileInfo(Path.Combine(s, f));
        }

        /// <summary>
        /// Copy a stream from one 
        /// </summary>
        /// <param name="input"></param>
        /// <param name="output"></param>
        /// <returns></returns>
        public static int CopyStream(Stream input, Stream output)
        {
            int result = 0;

            var buffer = new byte[32768];
            while (true)
            {
                int read = input.Read(buffer, 0, buffer.Length);
                if (read <= 0)
                    return result;
                output.Write(buffer, 0, read);
                result += read;
            }
        }



        /// <summary>
        ///Move a file or directory to a destination path.
        /// </summary>
        /// <param name="fromPath">From path.</param>
        /// <param name="toPath">To path.</param>
        /// <returns>true if we were able to move the file or directory.</returns>
        public static bool MoveFileOrDirectory(string fromPath, string toPath)
        {
            if (System.IO.File.Exists(fromPath))
            {
                System.IO.File.Move(fromPath, toPath);
                return true;
            }
            if (System.IO.Directory.Exists(fromPath))
            {
                System.IO.Directory.Move(fromPath, toPath);
                return true;
            }
            return false;
        }
    }

    public sealed class ResourceLoader
    {
        /// <summary>
        /// Private constructor.
        /// </summary>
        private ResourceLoader()
        {
        }

        /// <summary>
        /// Create a stream to read the resource.
        /// </summary>
        /// <param name="resource">The resource to load.  This should be in the form Synt.Resources.classes.txt</param>
        /// <returns>A stream.</returns>
        public static Stream CreateStream(String resource)
        {
            Stream result = null;
            Assembly[] assemblies = AppDomain.CurrentDomain.GetAssemblies();

            foreach (Assembly a in assemblies)
            {
                result = a.GetManifestResourceStream(resource);
                if (result != null)
                    break;
            }

            return result;
        }

        /// <summary>
        /// Load a string.
        /// </summary>
        /// <param name="resource">The resource to load.</param>
        /// <returns>The loaded string.</returns>
        public static String LoadString(String resource)
        {
            var result = new StringBuilder();
            Stream istream = CreateStream(resource);
            var sr = new StreamReader(istream);

            String line;
            while ((line = sr.ReadLine()) != null)
            {
                result.Append(line);
                result.Append("\r\n");
            }
            sr.Close();
            istream.Close();

            return result.ToString();
        }
    }

    public class FormUtility
    {
        /// <summary>
        /// The boundary used for a multipart post. This field is
        /// null if this is not a multipart form and has a value if
        /// this is a multipart form.
        /// </summary>
        private readonly String _boundary;

        /// <summary>
        /// The stream to output the Syntesisd form to.
        /// </summary>
        private readonly Stream _os;

        /// <summary>
        /// The text writer to use.
        /// </summary>
        private readonly TextWriter _writer;

        /// <summary>
        /// Keep track of if we're on the first form element.
        /// </summary>
        private bool _first;

        /// <summary>
        /// Prepare to access either a regular, or multipart, form.
        /// </summary>
        /// <param name="os">The stream to output to.</param>
        /// <param name="boundary">The boundary to be used, or null if this is
        /// not a multipart form.</param>
        public FormUtility(Stream os, String boundary)
        {
            _os = os;
            _writer = new StreamWriter(os);
            _boundary = boundary;
            _first = true;
        }

        /// <summary>
        /// Generate a boundary for a multipart form.
        /// </summary>
        /// <returns>The boundary.</returns>
        public static String GetBoundary()
        {
            return "---------------------------" + RandomString() + RandomString()
                   + RandomString();
        }

        /// <summary>
        /// Syntesis the specified string. This Syntesiss all special
        /// characters.
        /// </summary>
        /// <param name="str">The string to Syntesis.</param>
        /// <returns>The Syntesisd string.</returns>
        public static String Syntesis(String str)
        {
            //return HttpUtility.HtmlSyntesis(str);
            return str;
        }

        /// <summary>
        /// Generate a random string, of a specified length. This
        /// is used to generate the multipart boundary.
        /// </summary>
        /// <returns>A random string.</returns>
        protected static String RandomString()
        {
            return "" + ThreadSafeRandom.NextDouble();
        }

        /// <summary>
        /// Add a file to a multipart form.  Default mime type to
        /// application/octet-stream.
        /// </summary>
        /// <param name="name">The field name.</param>
        /// <param name="file">The file to attach.</param>
        public void AddFile(String name, String file)
        {
            AddFile(name, file, "application/octet-stream");
        }

        /// <summary>
        /// Add a file to a multipart form.
        /// </summary>
        /// <param name="name">The field name.</param>
        /// <param name="file">he file to attach.</param>
        /// <param name="type">The mime type</param>
        public void AddFile(String name, String file, String type)
        {
            if (_boundary != null)
            {
                Boundary();
                WriteName(name);
                Write("; filename=\"");
                Write(file);
                Write("\"");
                Newline();
                Write("Content-Type: ");

                Writeln(type);
                Newline();

                var buf = new byte[8192];
                int nread;

                _writer.Flush();
                _os.Flush();

                Stream istream = new FileStream(file, FileMode.Open);
                while ((nread = istream.Read(buf, 0, buf.Length)) > 0)
                {
                    _os.Write(buf, 0, nread);
                }

                _os.Flush();
                Newline();
            }
        }

        /// <summary>
        /// Add a regular text field to either a regular or
        /// multipart form.
        /// </summary>
        /// <param name="name">The name of the field.</param>
        /// <param name="v">The value of the field.</param>
        public void Add(String name, String v)
        {
            if (_boundary != null)
            {
                Boundary();
                WriteName(name);
                Newline();
                Newline();
                Writeln(v);
            }
            else
            {
                if (!_first)
                {
                    Write("&");
                }
                Write(Syntesis(name));
                Write("=");
                Write(Syntesis(v));
            }
            _first = false;
        }

        /// <summary>
        /// Complete the building of the form.
        /// </summary>
        public void Complete()
        {
            if (_boundary != null)
            {
                Boundary();
                Writeln("--");
                _os.Flush();
            }
        }

        /// <summary>
        /// Generate a multipart form boundary.
        /// </summary>
        private void Boundary()
        {
            Write("--");
            Write(_boundary);
        }

        /// <summary>
        /// Create a new line by displaying a carriage return and
        /// linefeed.
        /// </summary>
        private void Newline()
        {
            Write("\r\n");
        }

        /// <summary>
        /// Write the specified string, without a carriage return
        /// and line feed.
        /// </summary>
        /// <param name="str">The string to write.</param>
        private void Write(String str)
        {
            _writer.Write(str);
            _writer.Flush();
        }

        /// <summary>
        /// Write the name element for a multipart post.
        /// </summary>
        /// <param name="name">The name of the field.</param>
        private void WriteName(String name)
        {
            Newline();
            Write("Content-Disposition: form-data; name=\"");
            Write(name);
            Write("\"");
        }

        /// <summary>
        /// Write a string, with a carriage return and linefeed.
        /// </summary>
        /// <param name="str">The string to write.</param>
        protected void Writeln(String str)
        {
            Write(str);
            Newline();
        }
    }

    public class URLUtility
    {
        /// <summary>
        /// The name of an HTML index file.
        /// </summary>
        public const String IndexFile = "index.html";

        /// <summary>
        /// Construct a URL from a string.
        /// </summary>
        /// <param name="baseURL">The page that the URL was found on.</param>
        /// <param name="url">The URL found.</param>
        /// <param name="stripFragment">Should fragments be stripped.  Fragments are the part of a URL after the # sign.  They do not specify actual pages, but rather part of a page.  As a result, they are usually not needed by a spider or bot.</param>
        /// <returns>The constructed URL.</returns>
        public static Uri ConstructURL(Uri baseURL, String url, bool stripFragment)
        {
            var result = new Uri(baseURL, url);
            String file = result.PathAndQuery;
            String protocol = result.Scheme;
            String host = result.Host;
            String fragment = result.Fragment;
            int port = result.Port;

            file = file.Replace(" ", "%20");

            var sb = new StringBuilder();
            sb.Append(protocol);
            sb.Append("://");
            sb.Append(host);
            if (port == 80 && String.Compare(protocol, "http") != 0)
            {
                sb.Append(':');
                sb.Append("80");
            }
            else if (port == 443 && String.Compare(protocol, "https") != 0)
            {
                sb.Append(':');
                sb.Append("443");
            }

            if (!file.StartsWith("/"))
                sb.Append('/');
            sb.Append(file);


            if (!stripFragment)
            {
                sb.Append('#');
                sb.Append(fragment);
            }

            return new Uri(sb.ToString());
        }

        /// <summary>
        /// Does the URL contain invalid characters?
        /// </summary>
        /// <param name="url">The URL</param>
        /// <returns>True if the URL contains invalid characters.</returns>
        public static bool ContainsInvalidURLCharacters(String url)
        {
            return url.Any(ch => ch > 255);
        }

        /// <summary>
        /// Convert a filename for local storage. Also create the
        /// directory tree.
        /// </summary>
        /// <param name="basePath">The local path that forms the base of the
        /// downloaded web tree.</param>
        /// <param name="url">The URL path.</param>
        /// <param name="mkdir">True if a directory structure should be created
        /// to support this file.  Directories will only be
        /// created, if needed.</param>
        /// <returns></returns>
        public static String ConvertFilename(String basePath, Uri url, bool mkdir)
        {
            String result = basePath;

            // append the host name
            String host = url.Host.Replace('.', '_');
            result = Path.Combine(result, host);
          //  Directory.CreateDirectory(result);

            // determine actual filename
            int lastSegment = url.Segments.Length;
            if (lastSegment > 0)
                lastSegment--;
            String filename = url.Segments[lastSegment];
            if (filename.Equals('/'))
                filename = IndexFile;

            for (int i = 0; i < lastSegment; i++)
            {
                String segment = url.Segments[i];
                if (!segment.Equals("/"))
                {
                    result = Path.Combine(result, segment);
                    if (mkdir) { };
                      //  Directory.CreateDirectory(result);
                }
            }

            // attach name
            if (filename.EndsWith("/"))
            {
                String dir = filename.Substring(0, filename.Length - 1);
                result = Path.Combine(result, dir);
                if (mkdir) { }
                   // Directory.CreateDirectory(result);
                filename = IndexFile;
            }
            else if (filename.IndexOf('.') == -1)
            {
                filename = "/" + IndexFile;
            }


            result = Path.Combine(result, filename);

            result = result.Replace('?', '_');
            return result;
        }
    }

    [Serializable]
    public class BasicGenerateID : IGenerateID
    {
        /// <summary>
        /// Construct an ID generator.
        /// </summary>
        public BasicGenerateID()
        {
            CurrentID = 1;
        }

        #region IGenerateID Members

        /// <summary>
        /// The current id to generate.  This is the next id returned.
        /// </summary>
        public long CurrentID { get; set; }

        /// <summary>
        /// Generate a unique id.
        /// </summary>
        /// <returns>The unique id.</returns>
        public long Generate()
        {
            lock (this)
            {
                return CurrentID++;
            }
        }

        #endregion
    }

    public class Cluster<T>
    {
        /// <summary>
        /// The contents of the cluster.
        /// </summary>
        private readonly IList<T> _contents = new List<T>();

        /// <summary>
        /// The centroid of this cluster.
        /// </summary>
        private ICentroid<T> _centroid;

        /// <summary>
        /// Create an empty cluster.
        /// </summary>
        public Cluster()
        {
        }

        /// <summary>
        /// Create a cluster with one initial data point. 
        /// </summary>
        /// <param name="d">The initial data point.</param>
        public Cluster(T d)
        {
            _contents.Add(d);
            _centroid = ((ICentroidFactory<T>)d).CreateCentroid();
        }

        /// <summary>
        /// The contents of this cluster.
        /// </summary>
        public IList<T> Contents
        {
            get { return _contents as List<T>; }
        }

        /// <summary>
        /// Add a element to the cluster.
        /// </summary>
        /// <param name="e">The element to add.</param>
        public void Add(T e)
        {
            if (_centroid == null)
                _centroid = ((ICentroidFactory<T>)e) as ICentroid<T>;
            else
                _centroid.Add(e);

            _contents.Add(e);
        }

        /// <summary>
        /// Remove the specified index from the cluster. 
        /// </summary>
        /// <param name="i">The index to remove.</param>
        public void Remove(int i)
        {
            _centroid.Remove(_contents[i]);
            _contents.RemoveAt(i);
        }

        /// <summary>
        /// The centroid of this cluster.
        /// </summary>
        /// <returns>The centroid.</returns>
        public ICentroid<T> Centroid()
        {
            return _centroid;
        }
    }

    public class KMeansUtil<TK> where TK : class
    {
        /// <summary>
        /// The clusters.
        /// </summary>
        private readonly IList<Cluster<TK>> _clusters;

        /// <summary>
        /// The number of clusters.
        /// </summary>
        private readonly int _k;

        /// <summary>
        /// Construct the clusters.  Call process to perform the cluster.
        /// </summary>
        /// <param name="theK">The number of clusters.</param>
        /// <param name="theElements">The elements to cluster.</param>
        public KMeansUtil(int theK, IList theElements)
        {
            _k = theK;
            _clusters = new List<Cluster<TK>>(theK);
            InitRandomClusters(theElements);
        }

        /// <summary>
        /// The number of clusters.
        /// </summary>
        public int Count
        {
            get { return _clusters.Count; }
        }

        /// <summary>
        /// Create random clusters. 
        /// </summary>
        /// <param name="elements">The elements to cluster.</param>
        private void InitRandomClusters(IList elements)
        {
            int clusterIndex = 0;
            int elementIndex = 0;

            // first simply fill out the clusters, until we run out of clusters
            while ((elementIndex < elements.Count) && (clusterIndex < _k)
                   && (elements.Count - elementIndex > _k - clusterIndex))
            {
                var element = elements[elementIndex];

                bool added = false;

                // if this element is identical to another, add it to this cluster
                for (int i = 0; i < clusterIndex; i++)
                {
                    Cluster<TK> cluster = _clusters[i];

                    if (cluster.Centroid().Distance((TK)element) == 0)
                    {
                        cluster.Add(element as TK);
                        added = true;
                        break;
                    }
                }

                if (!added)
                {
                    _clusters.Add(new Cluster<TK>(elements[elementIndex] as TK));
                    clusterIndex++;
                }
                elementIndex++;
            }

            // create
            while (clusterIndex < _k && elementIndex < elements.Count)
            {
                _clusters.Add(new Cluster<TK>(elements[elementIndex] as TK));
                elementIndex++;
                clusterIndex++;
            }

            // handle case where there were not enough clusters created, 
            // create empty ones.
            while (clusterIndex < _k)
            {
                _clusters.Add(new Cluster<TK>());
                clusterIndex++;
            }

            // otherwise, handle case where there were still unassigned elements
            // add them to the nearest clusters.
            while (elementIndex < elements.Count)
            {
                var element = elements[elementIndex];
                NearestCluster(element as TK).Add(element as TK);
                elementIndex++;
            }
        }

        /// <summary>
        /// Perform the cluster.
        /// </summary>
        public void Process()
        {
            bool done;
            do
            {
                done = true;

                for (int i = 0; i < _k; i++)
                {
                    Cluster<TK> thisCluster = _clusters[i];
                    var thisElements = thisCluster.Contents as List<TK>;

                    for (int j = 0; j < thisElements.Count; j++)
                    {
                        TK thisElement = thisElements[j];

                        // don't make a cluster empty
                        if (thisCluster.Centroid().Distance(thisElement) > 0)
                        {
                            Cluster<TK> nearestCluster = NearestCluster(thisElement);

                            // move to nearer cluster
                            if (thisCluster != nearestCluster)
                            {
                                nearestCluster.Add(thisElement);
                                thisCluster.Remove(j);
                                done = false;
                            }
                        }
                    }
                }
            } while (!done);
        }

        /// <summary>
        /// Find the nearest cluster to the element. 
        /// </summary>
        /// <param name="element">The element.</param>
        /// <returns>The nearest cluster.</returns>
        private Cluster<TK> NearestCluster(TK element)
        {
            double distance = Double.PositiveInfinity;
            Cluster<TK> result = null;

            foreach (Cluster<TK> t in _clusters)
            {
                double thisDistance = t.Centroid().Distance(element);

                if (distance > thisDistance)
                {
                    distance = thisDistance;
                    result = t;
                }
            }

            return result;
        }

        /// <summary>
        /// Get a cluster by index.
        /// </summary>
        /// <param name="index">The index to get.</param>
        /// <returns>The cluster.</returns>
        public ICollection<TK> Get(int index)
        {
            return _clusters[index].Contents;
        }

        /// <summary>
        /// Get a cluster by index.
        /// </summary>
        /// <param name="i">The index to get.</param>
        /// <returns>The cluster.</returns>
        public Cluster<TK> GetCluster(int i)
        {
            return _clusters[i];
        }
    }

    public class DumpMatrix
    {
        /// <summary>
        /// Maximum precision.
        /// </summary>
        public const int MaxPrecis = 3;

        /// <summary>
        /// Private constructor.
        /// </summary>
        private DumpMatrix()
        {
        }


        /// <summary>
        /// Dump an array of numbers to a string.
        /// </summary>
        /// <param name="d">The array to dump.</param>
        /// <returns>The array as a string.</returns>
        public static String DumpArray(double[] d)
        {
            var result = new StringBuilder();
            result.Append("[");
            for (int i = 0; i < d.Length; i++)
            {
                if (i != 0)
                {
                    result.Append(",");
                }
                result.Append(d[i]);
            }
            result.Append("]");
            return result.ToString();
        }

        /// <summary>
        /// Dump a matrix to a string.
        /// </summary>
        /// <param name="matrix">The matrix.</param>
        /// <returns>The matrix as a string.</returns>
        public static String DumpMatrixString(Matrix matrix)
        {
            var result = new StringBuilder();
            result.Append("==");
            result.Append(matrix.ToString());
            result.Append("==\n");
            for (int row = 0; row < matrix.Rows; row++)
            {
                result.Append("  [");
                for (int col = 0; col < matrix.Cols; col++)
                {
                    if (col != 0)
                    {
                        result.Append(",");
                    }
                    result.Append(matrix[row, col]);
                }
                result.Append("]\n");
            }
            return result.ToString();
        }
    }

    public class SyntLogging
    {
        /// <summary>
        /// The lowest level log type. Debug logging provides low-level Synt
        /// diagnostics that may slow performance, but allow you to peer into the
        /// inner workings.
        /// </summary>
        ///
        public const int LevelDebug = 0;

        /// <summary>
        /// Info logging tells you when major processes start and stop.
        /// </summary>
        ///
        public const int LevelInfo = 1;

        /// <summary>
        /// Error level tells you about errors, less important to critical.
        /// </summary>
        ///
        public const int LevelError = 2;

        /// <summary>
        /// Critical logging logs errors that cannot be recovered from.
        /// </summary>
        ///
        public const int LevelCritical = 3;

        /// <summary>
        /// Logging is disabled at this level.
        /// </summary>
        ///
        public const int LevelDisable = 4;

        /// <value>The current logging level.</value>
        public int CurrentLevel
        {
            get { return SyntFramework.Instance.LoggingPlugin.LogLevel; }
        }

        /// <summary>
        /// Log the message.
        /// </summary>
        ///
        /// <param name="level">The level to log at.</param>
        /// <param name="message">The message to log.</param>
        public static void Log(int level, String message)
        {
            SyntFramework.Instance.LoggingPlugin.Log(level, message);
        }

        /// <summary>
        /// Log the error.
        /// </summary>
        ///
        /// <param name="level">The level to log at.</param>
        /// <param name="t">The exception to log.</param>
        public static void Log(int level, Exception t)
        {
            SyntFramework.Instance.LoggingPlugin.Log(level, t);
        }

        /// <summary>
        /// Log the error at ERROR level.
        /// </summary>
        ///
        /// <param name="t">The exception to log.</param>
        public static void Log(Exception t)
        {
            Log(LevelError, t);
        }
    }

    public class DateNormalize
    {

        #region normalizes days and month in a date.

        public double[] NormalizeMonth(int month)
        {
            var eq = new Equilateral(12, -1, 1);
            return eq.Syntesis(month);
        }

        public int DenormalizeMonth(double[] montharry)
        {
            var eq = new Equilateral(12, -1, 1);
            return eq.Decode(montharry);
        }

        public double[] NormalizeDays(int days)
        {
            var eq = new Equilateral(31, -1, 1);
            return eq.Syntesis(days);
        }
        public int DenormalizeDays(double[] days)
        {
            var eq = new Equilateral(31, -1, 1);
            return eq.Decode(days);
        }
        public double[] NormalizeHour(int hour)
        {
            var eq = new Equilateral(24, -1, 1);
            return eq.Syntesis(hour);
        }
        public int DenormalizeHour(double[] hour)
        {
            var eq = new Equilateral(24, -1, 1);
            return eq.Decode(hour);
        }

        public double[] NormalizeSeconds(int Seconds)
        {
            var eq = new Equilateral(60, -1, 1);
            return eq.Syntesis(Seconds);
        }
        public int DenormalizeSeconds(double[] seconds)
        {
            var eq = new Equilateral(60, -1, 1);
            return eq.Decode(seconds);
        }


        public double[] NormalizeYear(int year)
        {
            var eq = new Equilateral(2011, -1, 1);
            return eq.Syntesis(year);
        }
        public static int DenormalizeYear(double[] year)
        {
            var eq = new Equilateral(2011, -1, 1);
            return eq.Decode(year);
        }
        public double[] NormalizeYear(int hour, int MaxYear)
        {
            var eq = new Equilateral(MaxYear, -1, 1);
            return eq.Syntesis(hour);
        }
        public int DenormalizeYear(double[] days, int MaxYear)
        {
            var eq = new Equilateral(MaxYear, -1, 1);
            return eq.Decode(days);
        }

        #endregion
    }

    public class QuickCSVUtils
    {

        /// <summary>
        /// parses one column of a csv and returns an array of doubles.
        /// you can only return one double array with this method.
        /// </summary>
        /// <param name="file">The file.</param>
        /// <param name="formatused">The formatused.</param>
        /// <param name="Name">The name of the column to parse..</param>
        /// <returns></returns>
        public static List<double> QuickParseCSV(string file, CSVFormat formatused, string Name)
        {
            List<double> returnedArrays = new List<double>();
            ReadCSV csv = new ReadCSV(file, true, formatused);
            while (csv.Next())
            {
                returnedArrays.Add(csv.GetDouble(Name));
            }
            return returnedArrays;
        }
        /// <summary>
        /// parses one column of a csv and returns an array of doubles.
        /// you can only return one double array with this method.
        /// We are assuming CSVFormat english in this quick parse csv method.
        /// </summary>
        /// <param name="file">The file.</param>
        /// <param name="Name">The name of the column to parse.</param>
        /// <returns></returns>
        public static List<double> QuickParseCSV(string file, string Name)
        {
            List<double> returnedArrays = new List<double>();

            ReadCSV csv = new ReadCSV(file, true, CSVFormat.English);
            while (csv.Next())
            {
                returnedArrays.Add(csv.GetDouble(Name));
            }
            return returnedArrays;
        }


        /// <summary>
        /// parses one column of a csv and returns an array of doubles.
        /// you can only return one double array with this method.
        /// We are assuming CSVFormat english in this quick parse csv method.
        /// You can input the size (number of lines) to read.
        /// </summary>
        /// <param name="file">The file.</param>
        /// <param name="Name">The name of the column to parse.</param>
        /// <param name="size">The size.</param>
        /// <returns></returns>
        public static List<double> QuickParseCSV(string file, string Name, int size)
        {
            List<double> returnedArrays = new List<double>();
            ReadCSV csv = new ReadCSV(file, true, CSVFormat.English);
            int currentRead = 0;
            while (csv.Next() && currentRead < size)
            {
                returnedArrays.Add(csv.GetDouble(Name));
                currentRead++;
            }
            return returnedArrays;
        }

        /// <summary>
        /// parses one column of a csv and returns an array of doubles.
        /// you can only return one double array with this method.
        /// We are assuming CSVFormat english in this quick parse csv method.
        /// You can input the size (number of lines) to read and the number of lines you want to skip from the start line
        /// </summary>
        /// <param name="file">The file.</param>
        /// <param name="Name">The name of the column to parse.</param>
        /// <param name="size">The size.</param>
        /// <param name="StartLine">The start line (how many lines you want to skip from the start of the file.</param>
        /// <returns></returns>
        public static List<double> QuickParseCSV(string file, string Name, int size, int StartLine)
        {
            List<double> returnedArrays = new List<double>();
            ReadCSV csv = new ReadCSV(file, true, CSVFormat.English);

            int currentRead = 0;
            int currentLine = 0;
            while (csv.Next())
            {
                if (currentRead < size && currentLine > StartLine)
                {
                    returnedArrays.Add(csv.GetDouble(Name));
                    currentRead++;
                }
                currentLine++;
            }
            return returnedArrays;
        }
        /// <summary>
        /// parses one column of a csv and returns an array of doubles.
        /// you can only return one double array with this method.
        /// We are assuming CSVFormat english in this quick parse csv method.
        /// You can input the size (number of lines) to read.
        /// </summary>
        /// <param name="file">The file.</param>
        /// <param name="columnNumber">The column number to get.</param>
        /// <param name="size">The size.</param>
        /// <returns></returns>
        public static List<double> QuickParseCSV(string file, int columnNumber, int size)
        {
            List<double> returnedArrays = new List<double>();
            ReadCSV csv = new ReadCSV(file, true, CSVFormat.English);
            int currentRead = 0;
            while (csv.Next() && currentRead < size)
            {
                returnedArrays.Add(csv.GetDouble(columnNumber));
                currentRead++;
            }
            return returnedArrays;
        }

        /// <summary>
        /// use this method to find a date in your csv , and it will return the line number..
        /// This is useful for evaluation purpose when you need to find the line number so you can check against the real price and the network output prices.
        ///You must specify the DateFormat ("yyyy-MM-dd HH:mm:ss") for example.
        /// </summary>
        /// <param name="file">The file.</param>
        /// <param name="datetoFind">The date to find.</param>
        /// <param name="DateFormat">The date format.</param>
        /// <returns></returns>
        public static int QuickParseCSVForDate(string file, DateTime datetoFind, String DateFormat)
        {

            ReadCSV csv = new ReadCSV(file, true, CSVFormat.English);
            int currentLine = 0;
            csv.DateFormat = DateFormat;
            while (csv.Next())
            {
                csv.GetDate(0);
                if (csv.GetDate(0) == datetoFind)
                {
                    return currentLine;
                }
                else
                    currentLine++;
            }
            return currentLine;
        }
        /// <summary>
        /// use this method to find a date in your csv , and it will return the line number..
        /// This is useful for evaluation purpose when you need to find the line number so you can check against the real price and the network output prices.
        /// You can specifiy which column number you date are with this method.
        /// You must specify the DateFormat ("yyyy-MM-dd HH:mm:ss") for example.
        /// </summary>
        /// <param name="file">The file.</param>
        /// <param name="datetoFind">The date to find.</param>
        /// <param name="DateFormat">The date format.</param>
        /// <param name="Columnnumber">The columnnumber.</param>
        /// <returns></returns>
        public static int QuickParseCSVForDate(string file, DateTime datetoFind, String DateFormat, int Columnnumber)
        {

            ReadCSV csv = new ReadCSV(file, true, CSVFormat.English);
            int currentLine = 0;
            csv.DateFormat = DateFormat;
            while (csv.Next())
            {
                DateTime x = csv.GetDate(Columnnumber);
                if (x == datetoFind)
                {
                    return currentLine;
                }
                else
                    currentLine++;
            }
            return currentLine;
        }
        /// <summary>
        /// parses one column of a csv and returns an array of doubles.
        /// you can only return one double array with this method.
        /// We are assuming CSVFormat english in this quick parse csv method.
        /// You can input the size (number of lines) to read , and the number of lines you want to skip start from the first line.
        /// </summary>
        /// <param name="file">The file.</param>
        /// <param name="columnNumber">The column number to get.</param>
        /// <param name="size">The size.</param>
        /// <param name="startLine">The start line (how many lines you want to skip from the first line.</param>
        /// <returns></returns>
        public static List<double> QuickParseCSV(string file, int columnNumber, int size, int startLine)
        {
            List<double> returnedArrays = new List<double>();
            ReadCSV csv = new ReadCSV(file, true, CSVFormat.English);
            int currentRead = 0;
            int currentLine = 0;
            while (csv.Next())
            {
                if (currentRead < size && currentLine > startLine)
                {
                    returnedArrays.Add(csv.GetDouble(columnNumber));
                    currentRead++;
                }
                currentLine++;
            }
            return returnedArrays;
        }
    }

    public static class TrainerHelper
    {

        /// <summary>
        /// Makes the double [][] from single array.
        /// this is a very important method used in financial markets when you have multiple inputs (Close price, 1 indicator, 1 ATR, 1 moving average for example) , and each is already formated in an array of doubles.
        /// You just provide the number of inputs (4 here) , and it will create the resulting double [][]
        /// </summary>
        /// <param name="array">The array.</param>
        /// <param name="numberofinputs">The numberofinputs.</param>
        /// <returns></returns>
        public static double[][] MakeDoubleJaggedInputFromArray(double[] array, int numberofinputs)
        {
            //we must be able to fit all our numbers in the same double array..no spill over.
            if (array.Length % numberofinputs != 0)
                return null;
            int dimension = array.Length / numberofinputs;
            int currentindex = 0;
            double[][] result = EngineArray.AllocateDouble2D(dimension, numberofinputs);

            //now we loop through the index.
            int index = 0;
            for (index = 0; index < result.Length; index++)
            {
                for (int j = 0; j < numberofinputs; j++)
                {
                    result[index][j] = array[currentindex++];
                }
            }
            return (result);
        }



        /// <summary>
        /// Doubles the List of doubles into a jagged array.
        /// This is exactly similar as the MakeDoubleJaggedInputFromArray just it takes a List of double as parameter.
        /// It quite easier to Add doubles to a list than into a double [] Array (so this method is used more).
        /// </summary>
        /// <param name="inputs">The inputs.</param>
        /// <param name="lenght">The lenght.</param>
        /// <returns></returns>
        public static double[][] DoubleInputsToArraySimple(List<double> inputs, int lenght)
        {
            //we must be able to fit all our numbers in the same double array..no spill over.
            if (inputs.Count % lenght != 0)
                return null;
            int dimension = inputs.Count / lenght;

            double[][] result = EngineArray.AllocateDouble2D(dimension, lenght);
            foreach (double doubles in inputs)
            {
                for (int index = 0; index < result.Length; index++)
                {
                    for (int j = 0; j < lenght; j++)
                    {
                        result[index][j] = doubles;
                    }
                }

            }
            return (result);
        }


        /// <summary>
        /// Processes the specified double serie into an IMLDataset.
        /// To use this method, you must provide a formated double array.
        /// The number of points in the input window makes the input array , and the predict window will create the array used in ideal.
        /// Example you have an array with 1, 2, 3 , 4 , 5.
        /// You can use this method to make an IMLDataset 4 inputs and 1 ideal (5).
        /// </summary>
        /// <param name="data">The data.</param>
        /// <param name="_inputWindow">The _input window.</param>
        /// <param name="_predictWindow">The _predict window.</param>
        /// <returns></returns>
        public static IMLDataSet ProcessDoubleSerieIntoIMLDataset(double[] data, int _inputWindow, int _predictWindow)
        {
            IMLDataSet result = new BasicMLDataSet();
            int totalWindowSize = _inputWindow + _predictWindow;
            int stopPoint = data.Length - totalWindowSize;
            for (int i = 0; i < stopPoint; i++)
            {
                IMLData inputData = new BasicMLData(_inputWindow);
                IMLData idealData = new BasicMLData(_predictWindow);
                int index = i;
                // handle input window
                for (int j = 0; j < _inputWindow; j++)
                {
                    inputData[j] = data[index++];
                }

                // handle predict window
                for (int j = 0; j < _predictWindow; j++)
                {
                    idealData[j] = data[index++];
                }
                IMLDataPair pair = new BasicMLDataPair(inputData, idealData);
                result.Add(pair);
            }

            return result;
        }



        /// <summary>
        /// Processes the specified double serie into an IMLDataset.
        /// To use this method, you must provide a formated double array with the input data and the ideal data in another double array.
        /// The number of points in the input window makes the input array , and the predict window will create the array used in ideal.
        /// This method will use ALL the data inputs and ideals you have provided.
        /// </summary>
        /// <param name="datainput">The datainput.</param>
        /// <param name="ideals">The ideals.</param>
        /// <param name="_inputWindow">The _input window.</param>
        /// <param name="_predictWindow">The _predict window.</param>
        /// <returns></returns>
        public static IMLDataSet ProcessDoubleSerieIntoIMLDataset(List<double> datainput, List<double> ideals, int _inputWindow, int _predictWindow)
        {
            IMLDataSet result = new BasicMLDataSet();
            //int count = 0;
            ////lets check if there is a modulo , if so we move forward in the List of doubles in inputs.This is just a check
            ////as the data of inputs should be able to fill without having .
            //while (datainput.Count % _inputWindow !=0)
            //{
            //    count++;
            //}
            IMLData inputData = new BasicMLData(_inputWindow);
            IMLData idealData = new BasicMLData(_predictWindow);
            foreach (double d in datainput)
            {
                // handle input window
                for (int j = 0; j < _inputWindow; j++)
                {
                    inputData[j] = d;
                }
            }
            foreach (double ideal in ideals)
            {
                // handle predict window
                for (int j = 0; j < _predictWindow; j++)
                {
                    idealData[j] = ideal;
                }
            }
            IMLDataPair pair = new BasicMLDataPair(inputData, idealData);
            result.Add(pair);
            return result;
        }



        static bool IsNoModulo(double first, int second)
        {
            return first % second == 0;
        }

        /// <summary>
        /// Grabs every Predict point in a double serie.
        /// This is useful if you have a double series and you need to grab every 5 points for examples and make an ourput serie (like in elmhan networks).
        /// E.G , 1, 2, 1, 2,5 ...and you just need the 5..
        /// </summary>
        /// <param name="inputs">The inputs.</param>
        /// <param name="PredictSize">Size of the predict.</param>
        /// <returns></returns>
        public static List<double> CreateIdealFromSerie(List<double> inputs, int PredictSize)
        {
            //we need to copy into a new list only the doubles on each point of predict..

            List<int> Indexes = new List<int>();

            for (int i = 0; i < inputs.Count; i++)
            {
                if (i % PredictSize == 0)
                    Indexes.Add(i);
            }
            List<double> Results = Indexes.Select(index => inputs[index]).ToList();
            return Results;
        }
        /// <summary>
        /// Generates the Temporal MLDataset with a given data array.
        /// You must input the "predict" size (inputs) and the windowsize (outputs).
        /// This is oftenly used with Ehlman networks.
        /// The temporal dataset will be in RAW format (no normalization used..Most of the times it means you already have normalized your inputs /ouputs.
        /// 
        /// </summary>
        /// <param name="inputserie">The inputserie.</param>
        /// <param name="windowsize">The windowsize.</param>
        /// <param name="predictsize">The predictsize.</param>
        /// <returns>A temporalMLDataset</returns>
        public static TemporalMLDataSet GenerateTrainingWithRawSerie(double[] inputserie, int windowsize, int predictsize)
        {
            TemporalMLDataSet result = new TemporalMLDataSet(windowsize, predictsize);
            TemporalDataDescription desc = new TemporalDataDescription(
                    TemporalDataDescription.Type.Raw, true, true);
            result.AddDescription(desc);
            for (int index = 0; index < inputserie.Length - 1; index++)
            {
                TemporalPoint point = new TemporalPoint(1);
                point.Sequence = index;
                point.Data[0] = inputserie[index];
                result.Points.Add(point);
            }
            result.Generate();
            return result;
        }



        /// <summary>
        /// Generates the training with delta change on serie.
        /// </summary>
        /// <param name="inputserie">The inputserie.</param>
        /// <param name="windowsize">The windowsize.</param>
        /// <param name="predictsize">The predictsize.</param>
        /// <returns></returns>
        public static TemporalMLDataSet GenerateTrainingWithDeltaChangeOnSerie(double[] inputserie, int windowsize, int predictsize)
        {
            TemporalMLDataSet result = new TemporalMLDataSet(windowsize, predictsize);
            TemporalDataDescription desc = new TemporalDataDescription(
            TemporalDataDescription.Type.DeltaChange, true, true);
            result.AddDescription(desc);

            for (int index = 0; index < inputserie.Length - 1; index++)
            {
                TemporalPoint point = new TemporalPoint(1);
                point.Sequence = index;
                point.Data[0] = inputserie[index];
                result.Points.Add(point);
            }
            result.Generate();
            return result;
        }



        /// <summary>
        /// Generates a temporal data set with a given double serie or a any number of double series , making your inputs.
        /// uses Type percent change.
        /// </summary>
        /// <param name="windowsize">The windowsize.</param>
        /// <param name="predictsize">The predictsize.</param>
        /// <param name="inputserie">The inputserie.</param>
        /// <returns></returns>
        public static TemporalMLDataSet GenerateTrainingWithPercentChangeOnSerie(int windowsize, int predictsize, params double[][] inputserie)
        {
            TemporalMLDataSet result = new TemporalMLDataSet(windowsize, predictsize);
            TemporalDataDescription desc = new TemporalDataDescription(TemporalDataDescription.Type.PercentChange, true,
                                                                       true);
            result.AddDescription(desc);
            foreach (double[] t in inputserie)
            {
                for (int j = 0; j < t.Length; j++)
                {
                    TemporalPoint point = new TemporalPoint(1);
                    point.Sequence = j;
                    point.Data[0] = t[j];
                    result.Points.Add(point);
                }
                result.Generate();
                return result;
            }
            return null;
        }




        /// <summary>
        /// This method takes ARRAYS of arrays (parametrable arrays) and places them in double [][]
        /// You can use this method if you have already formated arrays and you want to create a double [][] ready for network.
        /// Example you could use this method to input the XOR example:
        /// A[0,0]   B[0,1]  C[1, 0]  D[1,1] would format them directly in the double [][] in one method call.
        /// This could also be used in unsupersivsed learning.
        /// </summary>
        /// <param name="Inputs">The inputs.</param>
        /// <returns></returns>
        public static double[][] NetworkbuilArrayByParams(params double[][] Inputs)
        {
            double[][] Resulting = new double[Inputs.Length][];

            int i = Inputs.Length;
            foreach (double[] doubles in Resulting)
            {
                for (int k = 0; k < Inputs.Length; k++)
                    Resulting[k] = doubles;
            }
            return Resulting;
        }




        /// <summary>
        /// Prints the content of an array to the console.(Mostly used in debugging).
        /// </summary>
        /// <param name="num">The num.</param>
        public static void PrinteJaggedArray(int[][] num)
        {
            foreach (int t1 in num.SelectMany(t => t))
            {
                Console.WriteLine(@"Values : {0}", t1);//displaying values of Jagged Array
            }
        }


        /// <summary>
        /// Processes a double array of data of input and a second array of data for ideals
        /// you must input the input and output size.
        /// this typically builds a supervised IMLDatapair, which you must add to a IMLDataset. 
        /// </summary>
        /// <param name="data">The data.</param>
        /// <param name="ideal">The ideal.</param>
        /// <param name="_inputWindow">The _input window.</param>
        /// <param name="_predictWindow">The _predict window.</param>
        /// <returns></returns>
        public static IMLDataPair ProcessPairs(double[] data, double[] ideal, int _inputWindow, int _predictWindow)
        {
            IMLDataSet result = new BasicMLDataSet();
            for (int i = 0; i < data.Length; i++)
            {
                IMLData inputData = new BasicMLData(_inputWindow);
                IMLData idealData = new BasicMLData(_predictWindow);
                int index = i;
                // handle input window
                for (int j = 0; j < _inputWindow; j++)
                {
                    inputData[j] = data[index++];
                }
                index = 0;
                // handle predict window
                for (int j = 0; j < _predictWindow; j++)
                {
                    idealData[j] = ideal[index++];
                }
                IMLDataPair pair = new BasicMLDataPair(inputData, idealData);
                return pair;
            }
            return null;
        }



        /// <summary>
        /// Takes 2 inputs arrays and makes a jagged array.
        /// this just copies the second array after the first array in a double [][]
        /// </summary>
        /// <param name="firstArray">The first array.</param>
        /// <param name="SecondArray">The second array.</param>
        /// <returns></returns>
        public static double[][] FromDualToJagged(double[] firstArray, double[] SecondArray)
        {
            return new[] { firstArray, SecondArray };

        }


        ///// <summary>
        ///// Generates the Temporal Training based on an array of doubles.
        ///// You need to have 2 array of doubles [] for this method to work!
        ///// </summary>
        ///// <param name="inputsize">The inputsize.</param>
        ///// <param name="outputsize">The outputsize.</param>
        ///// <param name="Arraydouble">The arraydouble.</param>
        ///// <returns></returns>
        //public static TemporalMLDataSet GenerateTraining(int inputsize, int outputsize, params double[][] Arraydouble)
        //{
        //    if (Arraydouble.Length < 2)
        //        return null;
        //    if (Arraydouble.Length > 2)
        //        return null;
        //    TemporalMLDataSet result = new TemporalMLDataSet(inputsize, outputsize);
        //    TemporalDataDescription desc = new TemporalDataDescription(new ActivationTANH(), TemporalDataDescription.Type.PercentChange, true, true);
        //    result.AddDescription(desc);
        //    TemporalPoint point = new TemporalPoint(Arraydouble.Length);
        //    int currentindex;


        //    for (int w = 0; w < Arraydouble[0].Length; w++)
        //    {
        //        //We have filled in one dimension now lets put them in our temporal dataset.
        //        for (int year = 0; year < Arraydouble.Length - 1; year++)
        //        {
        //            //We have as many points as we passed the array of doubles.
        //            point = new TemporalPoint(Arraydouble.Length);
        //            //our first sequence (0).
        //            point.Sequence = w;
        //            //point 0 is double[0] array.
        //            point.Data[0] = Arraydouble[0][w];
        //            point.Data[1] = Arraydouble[1][w++];
        //            //we add the point..
        //        }
        //        result.Points.Add(point);
        //    }
        //    result.Generate();
        //    return result;
        //}



        /// <summary>
        /// Calculates and returns the copied array.
        /// This is used in live data , when you want have a full array of doubles but you want to cut from a starting position
        /// and return only from that point to the end.
        /// example you have 1000 doubles , but you want only the last 100.
        /// input size is the input you must set to 100.
        /// I use this method next to every day when calculating on an array of doubles which has just received a new price (A quote for example).
        /// As the array of quotes as all the quotes since a few days, i just need the last 100 for example , so this method is used when not training but using the neural network.
        /// </summary>
        /// <param name="inputted">The inputted.</param>
        /// <param name="inputsize">The input neuron size (window size).</param>
        /// <returns></returns>
        public static double[] ReturnArrayOnSize(double[] inputted, int inputsize)
        {
            //lets say we receive an array of 105 doubles ...input size is 100.(or window size)
            //we need to just copy the last 100.
            //so if inputted.Lenght > inputsize :
            // start index = inputtedLenght - inputsize.
            //if inputtedlenght is equal to input size , well our index will be 0..
            //if inputted lenght is smaller than input...We return  null.
            double[] arr = new double[inputsize];
            int howBig = 0;
            if (inputted.Length >= inputsize)
            {
                howBig = inputted.Length - inputsize;
            }
            EngineArray.ArrayCopy(inputted, howBig, arr, 0, inputsize);
            return arr;
        }


        /// <summary>
        /// Quickly an IMLDataset from a double array using the TemporalWindow array.
        /// </summary>
        /// <param name="array">The array.</param>
        /// <param name="inputsize">The inputsize.</param>
        /// <param name="outputsize">The outputsize.</param>
        /// <returns></returns>
        public static IMLDataSet QuickTrainingFromDoubleArray(double[] array, int inputsize, int outputsize)
        {
            TemporalWindowArray temp = new TemporalWindowArray(inputsize, outputsize);
            temp.Analyze(array);

            return temp.Process(array);
        }

        /// <summary>
        /// Generates an array with as many double array inputs as wanted.
        /// This is useful for neural networks when you have already formated your data arrays and need to create a double []
        /// with all the inputs following each others.
        /// </summary>
        /// <param name="inputs">The inputs.</param>
        /// <returns>
        /// the double [] array with all inputs.
        /// </returns>
        public static double[] GenerateInputz(params double[][] inputs)
        {
            ArrayList al = new ArrayList();
            foreach (double[] doublear in inputs)
            {
                al.Add((double[])doublear);
            }
            return (double[])al.ToArray(typeof(double));
        }


        /// <summary>
        /// Prepare realtime inputs, and place them in an understandable one jagged input neuron array.
        /// This method uses linq.
        /// you can use this method if you have many inputs and need to format them as inputs with a specified "window"/input size.
        /// You can add as many inputs as wanted to this input layer (parametrable inputs).
        /// </summary>
        /// <param name="inputsize">The inputsize.</param>
        /// <param name="firstinputt">The firstinputt.</param>
        /// <returns>a ready to use jagged array with all the inputs setup.</returns>
        public static double[][] AddInputsViaLinq(int inputsize, params double[][] firstinputt)
        {
            ArrayList arlist = new ArrayList(4);
            ArrayList FirstList = new ArrayList();
            List<double> listused = new List<double>();
            int lenghtofArrays = firstinputt[0].Length;
            //There must be NO modulo...or the arrays would not be divisible by this input size.
            if (lenghtofArrays % inputsize != 0)
                return null;
            //we add each input one , after the other in a list of doubles till we reach the input size
            for (int i = 0; i < lenghtofArrays; i++)
            {
                foreach (double[] t in firstinputt.Where(t => listused.Count < inputsize * firstinputt.Length))
                {
                    listused.Add(t[i]);
                    if (listused.Count != inputsize * firstinputt.Length) continue;
                    FirstList.Add(listused.ToArray());
                    listused.Clear();
                }
            }
            return (double[][])FirstList.ToArray(typeof(double[]));
        }


        /// <summary>
        /// Prepare realtime inputs, and place them in an understandable one jagged input neuron array.
        /// you can use this method if you have many inputs and need to format them as inputs with a specified "window"/input size.
        /// You can add as many inputs as wanted to this input layer (parametrable inputs).
        /// </summary>
        /// <param name="inputsize">The inputsize.</param>
        /// <param name="firstinputt">The firstinputt.</param>
        /// <returns>a ready to use jagged array with all the inputs setup.</returns>
        public static double[][] AddInputs(int inputsize, params double[][] firstinputt)
        {
            ArrayList arlist = new ArrayList(4);
            ArrayList FirstList = new ArrayList();
            List<double> listused = new List<double>();
            int lenghtofArrays = firstinputt[0].Length;
            //There must be NO modulo...or the arrays would not be divisile by this input size.
            if (lenghtofArrays % inputsize != 0)
                return null;
            //we add each input one , after the other in a list of doubles till we reach the input size
            for (int i = 0; i < lenghtofArrays; i++)
            {
                for (int k = 0; k < firstinputt.Length; k++)
                {
                    if (listused.Count < inputsize * firstinputt.Length)
                    {
                        listused.Add(firstinputt[k][i]);
                        if (listused.Count == inputsize * firstinputt.Length)
                        {
                            FirstList.Add(listused.ToArray());
                            listused.Clear();
                        }
                    }
                }
            }
            return (double[][])FirstList.ToArray(typeof(double[]));
        }

        /// <summary>
        /// Makes a data set with parametrable inputs and one output double array.
        /// you can provide as many inputs as needed and the timelapse size (input size).
        /// for more information on this method read the AddInputs Method.
        /// </summary>
        /// <param name="outputs">The outputs.</param>
        /// <param name="inputsize">The inputsize.</param>
        /// <param name="firstinputt">The firstinputt.</param>
        /// <returns></returns>
        public static IMLDataSet MakeDataSet(double[] outputs, int inputsize, params double[][] firstinputt)
        {
            IMLDataSet set = new BasicMLDataSet();
            ArrayList outputsar = new ArrayList();
            ArrayList FirstList = new ArrayList();
            List<double> listused = new List<double>();
            int lenghtofArrays = firstinputt[0].Length;

            //There must be NO modulo...or the arrays would not be divisile by this input size.
            if (lenghtofArrays % inputsize != 0)
                return null;
            //we add each input one , after the other in a list of doubles till we reach the input size
            for (int i = 0; i < lenghtofArrays; i++)
            {
                for (int k = 0; k < firstinputt.Length; k++)
                {
                    if (listused.Count < inputsize * firstinputt.Length)
                    {
                        listused.Add(firstinputt[k][i]);
                        if (listused.Count == inputsize * firstinputt.Length)
                        {
                            FirstList.Add(listused.ToArray());
                            listused.Clear();
                        }
                    }
                }
            }
            foreach (double d in outputs)
            {
                listused.Add(d);
                outputsar.Add(listused.ToArray());
                listused.Clear();
            }
            set = new BasicMLDataSet((double[][])FirstList.ToArray(typeof(double[])), (double[][])
             outputsar.ToArray(typeof(double[])));
            return set;
        }





        public static double[] MakeInputs(int number)
        {
            Random rdn = new Random();
            RangeRandomizer SyntRnd = new RangeRandomizer(-1, 1);
            double[] x = new double[number];
            for (int i = 0; i < number; i++)
            {
                x[i] = SyntRnd.Randomize((rdn.NextDouble()));

            }
            return x;
        }
        /// <summary>
        /// Makes a random dataset with the number of IMLDatapairs.
        /// Quite useful to test networks (benchmarks).
        /// </summary>
        /// <param name="inputs">The inputs.</param>
        /// <param name="predictWindow">The predict window.</param>
        /// <param name="numberofPairs">The numberof pairs.</param>
        /// <returns></returns>
        public static BasicMLDataSet MakeRandomIMLDataset(int inputs, int predictWindow, int numberofPairs)
        {
            BasicMLDataSet SuperSet = new BasicMLDataSet();
            for (int i = 0; i < numberofPairs; i++)
            {
                double[] firstinput = MakeInputs(inputs);
                double[] secondideal = MakeInputs(inputs);
                IMLDataPair pair = ProcessPairs(firstinput, secondideal, inputs, predictWindow);
                SuperSet.Add(pair);
            }
            return SuperSet;
        }


        /// <summary>
        /// This is the most used method in finance.
        /// You send directly your double arrays and get an IMLData set ready for network training.
        /// You must place your ideal data as the last double data array.
        /// IF you have 1 data of closing prices, 1 moving average, 1 data series of interest rates , and the data you want to predict 
        /// This method will look the lenght of the first Data input to calculate how many points to take from each array.
        /// this is the method you will use to make your Dataset.
        /// </summary>
        /// <param name="number">The number.</param>
        /// <param name="inputs">The inputs.</param>
        /// <returns></returns>
        public static IMLDataSet MakeSetFromInputsSources(int predwindow, params double[][] inputs)
        {
            ArrayList list = new ArrayList(inputs.Length);
            IMLDataSet set = new BasicMLDataSet();
            //we know now how many items we have in each data series (all series should be of equal lenght).
            int dimension = inputs[0].Length;
            //we will take predictwindow of each serie and make new series.
            List<double> InputList = new List<double>();
            int index = 0;
            int currentArrayObserved = 0;
            //foreach (double[] doubles in inputs)
            //{

            //    for (int k = 0; k < dimension; k++)
            //    {
            //        //We will take predict window number from each of our array and add them up.
            //        for (int i = 0; i < predwindow; i++)
            //        {
            //            InputList.Add(doubles[index]);

            //        }

            //    }
            //    index++;
            //}

            foreach (double[] doublear in inputs)
            {

                list.Add((double[])doublear);
            }


            // return (double[][])list.ToArray(typeof(double[]));

            return set;
        }
    }

    [Serializable]
    public class BasicInputField : IInputField
    {
        /// <summary>
        /// The minimum value encountered so far for this field.
        /// </summary>
        private double _max = Double.NegativeInfinity;

        /// <summary>
        /// The maximum value encountered so far for this field.
        /// </summary>
        private double _min = Double.PositiveInfinity;

        /// <summary>
        /// True if this field is used to actually generate the input for
        /// the neural network.
        /// </summary>
        private bool _usedForNetworkInput = true;

        #region IInputField Members

        /// <summary>
        /// Given the current value, apply to the min and max values.
        /// </summary>
        /// <param name="d">The current value.</param>
        public void ApplyMinMax(double d)
        {
            _min = Math.Min(_min, d);
            _max = Math.Max(_max, d);
        }


        /// <summary>
        /// The current value of the input field.  This is only valid, 
        /// while the normalization is being performed.
        /// </summary>
        public double CurrentValue { get; set; }

        /// <summary>
        /// The maximum value for all of the input data, this is calculated
        /// during the first pass of normalization.
        /// </summary>
        public double Max
        {
            get { return _max; }
            set { _max = value; }
        }

        /// <summary>
        /// The minimum value for all of the input data, this is calculated
        /// during the first pass of normalization.
        /// </summary>
        public double Min
        {
            get { return _min; }
            set { _min = value; }
        }

        /// <summary>
        /// Not supported for this sort of class, may be implemented in subclasses.
        /// Will throw an exception.
        /// </summary>
        /// <param name="i">The index.  Not used.</param>
        /// <returns>The value at the specified index.</returns>
        public virtual double GetValue(int i)
        {
            throw new NormalizationError("Can't call getValue on "
                                         + GetType().Name);
        }


        /// <summary>
        /// True, if this field is used for network input.  
        /// This is needed so that the buildForNetworkInput method of the 
        /// normalization class knows how many input fields to expect.  For instance, 
        /// fields used only to segregate data are not used for the actual network 
        /// input and may not be provided when the network is actually being queried.
        /// </summary>
        public bool UsedForNetworkInput
        {
            get { return _usedForNetworkInput; }
            set { _usedForNetworkInput = value; }
        }

        #endregion
    }

    [Serializable]
    public class InputFieldArray1D : BasicInputField, IHasFixedLength
    {
        /// <summary>
        /// A reference to the array.
        /// </summary>
        private readonly double[] _array;

        /// <summary>
        /// Construct the 1D array field.
        /// </summary>
        /// <param name="usedForNetworkInput">True if this field is used for the actual
        /// input to the neural network.  See getUsedForNetworkInput for more info.</param>
        /// <param name="array">The array to use.</param>
        public InputFieldArray1D(bool usedForNetworkInput,
                                 double[] array)
        {
            _array = array;
            UsedForNetworkInput = usedForNetworkInput;
        }

        #region IHasFixedLength Members

        /// <summary>
        /// The length of the array.
        /// </summary>
        public int Length
        {
            get { return _array.Length; }
        }

        #endregion

        /// <summary>
        /// Get the value from the specified index.
        /// </summary>
        /// <param name="i">The index to retrieve.</param>
        /// <returns>The value at the specified index.</returns>
        public override double GetValue(int i)
        {
            return _array[i];
        }
    }

    [Serializable]
    public class InputFieldArray2D : BasicInputField, IHasFixedLength
    {
        /// <summary>
        /// The 2D array to use.
        /// </summary>
        private readonly double[][] _array;

        /// <summary>
        /// The 2nd dimension index to read the field from.
        /// </summary>
        private readonly int _index2;

        /// <summary>
        /// Construct a 2D array input.
        /// </summary>
        /// <param name="usedForNetworkInput">Construct a 2D array input field.</param>
        /// <param name="array">The array to use.</param>
        /// <param name="index2">index2 The secondary index to read the field from.</param>
        public InputFieldArray2D(bool usedForNetworkInput,
                                 double[][] array, int index2)
        {
            _array = array;
            _index2 = index2;
            UsedForNetworkInput = usedForNetworkInput;
        }

        #region IHasFixedLength Members

        /// <summary>
        /// The number of rows in the array.
        /// </summary>
        public int Length
        {
            get { return _array.Length; }
        }

        #endregion

        /// <summary>
        /// Gen index.
        /// </summary>
        /// <param name="i">Read a value from the specified index.</param>
        /// <returns>The value read.</returns>
        public
            override double GetValue(int i)
        {
            return _array[i][_index2];
        }
    }

    [Serializable]
    public class InputFieldCSV : BasicInputField
    {

        /// <summary>
        /// The file to read.
        /// </summary>
        private readonly String _file;

        /// <summary>
        /// The CSV column represented by this field.
        /// </summary>
        private readonly int _offset;


        private readonly string _columnName;
        /// <summary>
        /// Construct an InputFieldCSV with the default constructor.  This is mainly
        /// used for reflection.
        /// </summary>
        public InputFieldCSV()
        {
        }




        /// <summary>
        /// Construct a input field for a CSV file.
        /// </summary>
        /// <param name="usedForNetworkInput">True if this field is used for actual 
        /// input to the neural network, as opposed to segregation only.</param>
        /// <param name="file">The tile to read.</param>
        /// <param name="offset">The CSV file column to read.</param>
        public InputFieldCSV(bool usedForNetworkInput, String file,
                             int offset)
        {
            _file = file;
            _offset = offset;
            UsedForNetworkInput = usedForNetworkInput;
        }

        /// <summary>
        /// Construct a input field for a CSV file.
        /// </summary>
        /// <param name="usedForNetworkInput">True if this field is used for actual
        /// input to the neural network, as opposed to segregation only.</param>
        /// <param name="file">The tile to read.</param>
        /// <param name="columnname">The columnname you wish to read.</param>
        public InputFieldCSV(bool usedForNetworkInput, String file,
                             string columnname)
        {
            _file = file;
            _columnName = columnname;

            UsedForNetworkInput = usedForNetworkInput;
        }
        /// <summary>
        /// The file being read.
        /// </summary>
        public String File
        {
            get { return _file; }
        }

        /// <summary>
        /// The column in this CSV file to read.
        /// </summary>
        public int Offset
        {
            get { return _offset; }
        }

        /// <summary>
        /// Gets the name of the column we want to read.
        /// </summary>
        /// <value>
        /// The name of the column we want to read.
        /// </value>
        public string ColumnName
        {
            get { return _columnName; }
        }
    }

    [Serializable]
    public class InputFieldMLDataSet : BasicInputField
    {
        /// <summary>
        /// The data set.
        /// </summary>
        private readonly IMLDataSet _data;

        /// <summary>
        /// The input or ideal index.  This treats the input and ideal as one
        /// long array, concatenated together.
        /// </summary>
        private readonly int _offset;

        /// <summary>
        /// Construct a input field based on a NeuralDataSet.
        /// </summary>
        /// <param name="usedForNetworkInput">Is this field used for neural input.</param>
        /// <param name="data">The data set to use.</param>
        /// <param name="offset">The input or ideal index to use. This treats the input 
        /// and ideal as one long array, concatenated together.</param>
        public InputFieldMLDataSet(bool usedForNetworkInput,
                                       IMLDataSet data, int offset)
        {
            _data = data;
            _offset = offset;
            UsedForNetworkInput = usedForNetworkInput;
        }

        /// <summary>
        /// The neural data set to read.
        /// </summary>
        public IMLDataSet NeuralDataSet
        {
            get { return _data; }
        }

        /// <summary>
        /// The field to be accessed. This treats the input and 
        /// ideal as one long array, concatenated together.
        /// </summary>
        public int Offset
        {
            get { return _offset; }
        }
    }

    [Serializable]
    public class MLDataFieldHolder
    {
        /// <summary>
        /// A field.
        /// </summary>
        private readonly InputFieldMLDataSet _field;

        /// <summary>
        /// An iterator.
        /// </summary>
        private readonly IEnumerator<IMLDataPair> _iterator;

        /// <summary>
        /// A neural data pair.
        /// </summary>
        private IMLDataPair _pair;

        /// <summary>
        /// Construct the class.
        /// </summary>
        /// <param name="iterator">An iterator.</param>
        /// <param name="field">A field.</param>
        public MLDataFieldHolder(IEnumerator<IMLDataPair> iterator,
                                     InputFieldMLDataSet field)
        {
            _iterator = iterator;
            _field = field;
        }

        /// <summary>
        /// The field.
        /// </summary>
        public InputFieldMLDataSet Field
        {
            get { return _field; }
        }

        /// <summary>
        /// The pair.
        /// </summary>
        public IMLDataPair Pair
        {
            get { return _pair; }
            set { _pair = value; }
        }

        /// <summary>
        /// Get the enumerator.
        /// </summary>
        /// <returns>The enumerator.</returns>
        public IEnumerator<IMLDataPair> GetEnumerator()
        {
            return _iterator;
        }

        /// <summary>
        /// Obtain the next pair.
        /// </summary>
        public void ObtainPair()
        {
            _iterator.MoveNext();
            _pair = _iterator.Current;
        }
    }

    [Serializable]
    public class MappedRange
    {
        /// <summary>
        /// The high value for the range.
        /// </summary>       
        private readonly double _high;

        /// <summary>
        /// The low value for the range.
        /// </summary>
        private readonly double _low;

        /// <summary>
        /// The value that should be returned for this range.
        /// </summary>
        private readonly double _value;

        /// <summary>
        /// Construct the range mapping.
        /// </summary>
        /// <param name="low">The low value for the range.</param>
        /// <param name="high">The high value for the range.</param>
        /// <param name="value">The value that this range represents.</param>
        public MappedRange(double low, double high, double value)
        {
            _low = low;
            _high = high;
            _value = value;
        }

        /// <summary>
        /// The high value for this range.
        /// </summary>
        public double High
        {
            get { return _high; }
        }

        /// <summary>
        /// The low value for this range.
        /// </summary>
        public double Low
        {
            get { return _low; }
        }

        /// <summary>
        /// The value that this range represents.
        /// </summary>
        public double Value
        {
            get { return _value; }
        }

        /// <summary>
        /// Determine if the specified value is in the range.
        /// </summary>
        /// <param name="d">The value to check.</param>
        /// <returns>True if this value is within the range.</returns>
        public bool InRange(double d)
        {
            if ((d >= _low) && (d <= _high))
            {
                return true;
            }
            return false;
        }
    }

    [Serializable]
    public class OutputFieldSyntesis : BasicOutputField
    {
        /// <summary>
        /// The ranges.
        /// </summary>
        private readonly IList<MappedRange> _ranges = new List<MappedRange>();

        /// <summary>
        /// The source field.
        /// </summary>
        private readonly IInputField _sourceField;

        /// <summary>
        /// The catch all value, if nothing matches, then use this value.
        /// </summary>
        private double _catchAll;


        /// <summary>
        /// Construct an Syntesisd field.
        /// </summary>
        /// <param name="sourceField">The field that this is based on.</param>
        public OutputFieldSyntesis(IInputField sourceField)
        {
            _sourceField = sourceField;
        }

        /// <summary>
        /// The source field.
        /// </summary>
        public IInputField SourceField
        {
            get { return _sourceField; }
        }

        /// <summary>
        /// Return 1, no subfield supported.
        /// </summary>
        public override int SubfieldCount
        {
            get { return 1; }
        }

        /// <summary>
        /// The catch all value that is to be returned if none
        /// of the ranges match.
        /// </summary>
        public double CatchAll
        {
            get { return _catchAll; }
            set { _catchAll = value; }
        }

        /// <summary>
        /// Add a ranged mapped to a value.
        /// </summary>
        /// <param name="low">The low value for the range.</param>
        /// <param name="high">The high value for the range.</param>
        /// <param name="value">The value that the field should produce for this range.</param>
        public void AddRange(double low, double high, double value)
        {
            var range = new MappedRange(low, high, value);
            _ranges.Add(range);
        }

        /// <summary>
        /// Calculate the value for this field.
        /// </summary>
        /// <param name="subfield">Not used.</param>
        /// <returns>Return the value for the range the input falls within, or return
        /// the catchall if nothing matches.</returns>
        public override double Calculate(int subfield)
        {
            foreach (MappedRange range in _ranges)
            {
                if (range.InRange(_sourceField.CurrentValue))
                {
                    return range.Value;
                }
            }

            return _catchAll;
        }

        /// <summary>
        /// Not needed for this sort of output field.
        /// </summary>
        public override void RowInit()
        {
        }
    }

    [Serializable]
    public class MultiplicativeGroup : BasicOutputFieldGroup
    {
        /// <summary>
        /// The "length" of this field.
        /// </summary>
        private double _length;

        /// <summary>
        /// The length of this field.  This is the sum of the squares of
        /// all of the groupped fields.  The square root of this sum is the 
        /// length. 
        /// </summary>
        public double Length
        {
            get { return _length; }
        }

        /// <summary>
        /// Called to init this group for a new field.  This recalculates the
        /// "length".
        /// </summary>
        public override void RowInit()
        {
            double value = GroupedFields.Sum(field => (field.SourceField.CurrentValue * field.SourceField.CurrentValue));
            _length = Math.Sqrt(value);
        }
    }

    [Serializable]
    public class OutputFieldMultiplicative : OutputFieldGrouped
    {
        /// <summary>
        /// The default constructor.  Used for reflection.
        /// </summary>
        public OutputFieldMultiplicative()
        {
        }

        /// <summary>
        /// Construct a multiplicative output field.
        /// </summary>
        /// <param name="group">The group this field belongs to.</param>
        /// <param name="field">The input field that this field is based on.</param>
        public OutputFieldMultiplicative(IOutputFieldGroup group,
                                         IInputField field)
            : base(group, field)
        {
            if (!(group is MultiplicativeGroup))
            {
                throw new NormalizationError(
                    "Must use MultiplicativeGroup with OutputFieldMultiplicative.");
            }
        }

        /// <summary>
        /// Always returns 1, subfields are not used for this field.
        /// </summary>
        public override int SubfieldCount
        {
            get { return 1; }
        }

        /// <summary>
        /// Calculate the value for this output field.
        /// </summary>
        /// <param name="subfield">The subfield is not used.</param>
        /// <returns>The value for this field.</returns>
        public override double Calculate(int subfield)
        {
            return SourceField.CurrentValue
                   / ((MultiplicativeGroup)Group).Length;
        }

        /// <summary>
        /// Not needed for this sort of output field.
        /// </summary>
        public override void RowInit()
        {
        }
    }

    [Serializable]
    public class NominalItem
    {
        /// <summary>
        /// The high value for the range.
        /// </summary>
        private readonly double _high;

        /// <summary>
        /// The input field used to verify against the range.
        /// </summary>
        private readonly IInputField _inputField;

        /// <summary>
        /// The low value for the range.
        /// </summary>
        private readonly double _low;

        /// <summary>
        /// Construct a empty range item.  Used mainly for reflection.
        /// </summary>
        public NominalItem()
        {
        }

        /// <summary>
        /// Create a nominal item.
        /// </summary>
        /// <param name="inputField">The field that this item is based on.</param>
        /// <param name="high">The high value.</param>
        /// <param name="low">The low value.</param>
        public NominalItem(IInputField inputField, double low,
                           double high)
        {
            _high = high;
            _low = low;
            _inputField = inputField;
        }

        /// <summary>
        /// The high value.
        /// </summary>
        public double High
        {
            get { return _high; }
        }

        /// <summary>
        /// The input field value.
        /// </summary>
        public IInputField InputField
        {
            get { return _inputField; }
        }

        /// <summary>
        /// The low value.
        /// </summary>
        public double Low
        {
            get { return _low; }
        }

        /// <summary>
        /// Begin a row.
        /// </summary>
        public void BeginRow()
        {
        }

        /// <summary>
        /// Determine if the specified value is in range.
        /// </summary>
        /// <returns>True if this item is within range.</returns>
        public bool IsInRange()
        {
            double currentValue = _inputField.CurrentValue;
            return ((currentValue >= _low) && (currentValue <= _high));
        }
    }

    [Serializable]
    public class OutputEquilateral : BasicOutputField
    {
        /// <summary>
        /// The high value to map into.
        /// </summary>
        private readonly double _high;

        /// <summary>
        /// The nominal items.
        /// </summary>
        private readonly IList<NominalItem> _items = new List<NominalItem>();

        /// <summary>
        /// The low value to map into.
        /// </summary>
        private readonly double _low;

        /// <summary>
        /// The current value, which nominal item is selected.
        /// </summary>
        private int _currentValue;

        /// <summary>
        /// The current equilateral matrix.
        /// </summary>
        private Equilateral _equilateral;

        /// <summary>
        /// Prodvide a default constructor for reflection.
        /// Use -1 for low and +1 for high.
        /// </summary>
        public OutputEquilateral()
            : this(1, -1)
        {
        }

        /// <summary>
        /// Create an equilateral output field with the specified high and low output
        /// values. These will often be 0 to 1 or -1 to 1.
        /// </summary>
        /// <param name="high">The high output value.</param>
        /// <param name="low">The low output value.</param>
        public OutputEquilateral(double low, double high)
        {
            _high = high;
            _low = low;
        }

        /// <summary>
        /// The equalateral table being used.
        /// </summary>
        public Equilateral Equilateral
        {
            get { return _equilateral; }
        }

        /// <summary>
        /// This is the total number of nominal items minus 1.
        /// </summary>
        public override int SubfieldCount
        {
            get { return _items.Count - 1; }
        }

        /// <summary>
        /// Add a nominal value based on a single value.  This creates a 0.1 range
        /// around this value.
        /// </summary>
        /// <param name="inputField">The input field this is based on.</param>
        /// <param name="value">The value.</param>
        public void AddItem(IInputField inputField, double value)
        {
            AddItem(inputField, value - 0.1, value + 0.1);
        }

        /// <summary>
        /// Add a nominal item based on a range.
        /// </summary>
        /// <param name="inputField">The input field to use.</param>
        /// <param name="low">The low value of the range.</param>
        /// <param name="high">The high value of the range.</param>
        public void AddItem(IInputField inputField, double low,
                            double high)
        {
            var item = new NominalItem(inputField, low, high);
            _items.Add(item);
        }

        /// <summary>
        /// Calculate the value for the specified subfield.
        /// </summary>
        /// <param name="subfield">The subfield to calculate for.</param>
        /// <returns>The calculated value.</returns>
        public override double Calculate(int subfield)
        {
            return _equilateral.Syntesis(_currentValue)[subfield];
        }

        /// <summary>
        /// The high value of the range.
        /// </summary>
        public double High
        {
            get { return _high; }
        }

        /// <summary>
        /// The low value of the range.
        /// </summary>
        public double Low
        {
            get { return _low; }
        }

        /// <summary>
        /// Determine which item's index is the value.
        /// </summary>
        public override void RowInit()
        {
            for (int i = 0; i < _items.Count; i++)
            {
                NominalItem item = _items[i];
                if (item.IsInRange())
                {
                    _currentValue = i;
                    break;
                }
            }

            if (_equilateral == null)
            {
                _equilateral = new Equilateral(_items.Count, _high,
                                              _low);
            }
        }
    }

    [Serializable]
    public class OutputOneOf : BasicOutputField
    {
        /// <summary>
        /// What is the true value, often just "0" or "-1".
        /// </summary>
        private readonly double _falseValue;

        /// <summary>
        /// The nominal items to represent.
        /// </summary>
        private readonly IList<NominalItem> _items = new List<NominalItem>();

        /// <summary>
        /// What is the true value, often just "1".
        /// </summary>
        private readonly double _trueValue;

        /// <summary>
        /// Default constructor for reflection.  Use 1 for true, -1 for false.
        /// </summary>
        public OutputOneOf() : this(1, -1)
        {
        }

        /// <summary>
        /// Construct a one-of field and specify the true and false value.
        /// </summary>
        /// <param name="trueValue">The true value.</param>
        /// <param name="falseValue">The false value.</param>
        public OutputOneOf(double trueValue, double falseValue)
        {
            _trueValue = trueValue;
            _falseValue = falseValue;
        }

        /// <summary>
        /// The false value.
        /// </summary>
        public double FalseValue
        {
            get { return _falseValue; }
        }

        /// <summary>
        /// The number of subfields, or nominal classes.
        /// </summary>
        /// <returns></returns>
        public override int SubfieldCount
        {
            get { return _items.Count; }
        }

        /// <summary>
        /// Add a nominal value specifying a single value, the high and low values
        /// will be 0.5 below and 0.5 above.
        /// </summary>
        /// <param name="inputField">The input field to use.</param>
        /// <param name="value">The value to calculate the high and low values off of.</param>
        public void AddItem(IInputField inputField, double value)
        {
            AddItem(inputField, value - 0.5, value + 0.5);
        }

        /// <summary>
        /// Add a nominal item, specify the low and high values.
        /// </summary>
        /// <param name="inputField">The input field to base everything from.</param>
        /// <param name="low">The high value for this nominal item.</param>
        /// <param name="high">The low value for this nominal item.</param>
        public void AddItem(IInputField inputField, double low,
                            double high)
        {
            var item = new NominalItem(inputField, low, high);
            _items.Add(item);
        }

        /// <summary>
        /// Calculate the value for the specified subfield.
        /// </summary>
        /// <param name="subfield">The subfield to calculate for.</param>
        /// <returns>The calculated value for this field.</returns>
        public override double Calculate(int subfield)
        {
            NominalItem item = _items[subfield];
            return item.IsInRange() ? _trueValue : _falseValue;
        }

        /// <summary>
        /// The true value.
        /// </summary>
        /// <returns></returns>
        public double TrueValue
        {
            get { return _trueValue; }
        }

        /// <summary>
        /// Not needed for this sort of output field.
        /// </summary>
        public override void RowInit()
        {
        }
    }

    [Serializable]
    public class OutputFieldZAxis : OutputFieldGrouped
    {
        /// <summary>
        /// Construct a ZAxis output field.
        /// </summary>
        /// <param name="group">The group this field belongs to.</param>
        /// <param name="field">The input field this is based on.</param>
        public OutputFieldZAxis(IOutputFieldGroup group,
                                IInputField field)
            : base(group, field)
        {
            if (!(group is ZAxisGroup))
            {
                throw new NormalizationError(
                    "Must use ZAxisGroup with OutputFieldZAxis.");
            }
        }

        /// <summary>
        /// The subfield count, which is one, as this field type does not
        /// have subfields.
        /// </summary>
        public override int SubfieldCount
        {
            get { return 1; }
        }

        /// <summary>
        /// Calculate the current value for this field. 
        /// </summary>
        /// <param name="subfield">Ignored, this field type does not have subfields.</param>
        /// <returns>The current value for this field.</returns>
        public override double Calculate(int subfield)
        {
            return (SourceField.CurrentValue * ((ZAxisGroup)Group)
                                                 .Multiplier);
        }

        /// <summary>
        /// Not needed for this sort of output field.
        /// </summary>
        public override void RowInit()
        {
        }
    }

    [Serializable]
    public class OutputFieldZAxisSynthetic : OutputFieldGrouped
    {
        /// <summary>
        /// Construct a synthetic output field for Z-Axis.
        /// </summary>
        /// <param name="group">The Z-Axis group that this belongs to.</param>
        public OutputFieldZAxisSynthetic(IOutputFieldGroup group)
            : base(group, null)
        {
            if (!(group is ZAxisGroup))
            {
                throw new NormalizationError(
                    "Must use ZAxisGroup with OutputFieldZAxisSynthetic.");
            }
        }

        /// <summary>
        /// The subfield count, which is one, as this field type does not
        /// have subfields.
        /// </summary>
        public override int SubfieldCount
        {
            get { return 1; }
        }

        /// <summary>
        /// Calculate the synthetic value for this Z-Axis normalization.
        /// </summary>
        /// <param name="subfield">Not used.</param>
        /// <returns>The calculated value.</returns>
        public override double Calculate(int subfield)
        {
            double l = ((ZAxisGroup)Group).Length;
            double f = ((ZAxisGroup)Group).Multiplier;
            double n = Group.GroupedFields.Count;
            double result = f * Math.Sqrt(n - (l * l));
            return double.IsInfinity(result) || double.IsNaN(result) ? 0 : result;
        }

        /// <summary>
        /// Not needed for this sort of output field.
        /// </summary>
        public override void RowInit()
        {
        }
    }

    [Serializable]
    public class ZAxisGroup : BasicOutputFieldGroup
    {
        /// <summary>
        /// The calculated length.
        /// </summary>
        private double _length;

        /// <summary>
        /// The multiplier, which is the value that all other values will be
        /// multiplied to become normalized.
        /// </summary>
        private double _multiplier;

        /// <summary>
        /// The vector length.
        /// </summary>
        public double Length
        {
            get { return _length; }
        }

        /// <summary>
        /// The value to multiply the other values by to normalize them.
        /// </summary>
        public double Multiplier
        {
            get { return _multiplier; }
        }

        /// <summary>
        /// Initialize this group for a new row.
        /// </summary>
        public override void RowInit()
        {
            double value = (from field in GroupedFields
                            where !(field is OutputFieldZAxisSynthetic)
                            where field.SourceField != null
                            select (field.SourceField.CurrentValue * field.SourceField.CurrentValue)).Sum();

            _length = Math.Sqrt(value);
            _multiplier = 1.0 / Math.Sqrt(GroupedFields.Count);
        }
    }

    [Serializable]
    public class OutputFieldDirect : BasicOutputField
    {
        /// <summary>
        /// The source field.
        /// </summary>
        private readonly IInputField _sourceField;


        /// <summary>
        /// Default constructor for reflection.
        /// </summary>
        public OutputFieldDirect()
        {
        }

        /// <summary>
        /// Construct a direct output field.
        /// </summary>
        /// <param name="sourceField">The source field to pass directly on.</param>
        public OutputFieldDirect(IInputField sourceField)
        {
            _sourceField = sourceField;
        }

        /// <summary>
        /// Always returns 1, as subfields are not used.
        /// </summary>
        public override int SubfieldCount
        {
            get { return 1; }
        }

        /// <summary>
        /// Calculate the value for this field. This will simply be the
        /// value from the input field. 
        /// </summary>
        /// <param name="subfield">Not used, as this output field type does not
        /// support subfields.</param>
        /// <returns>The calculated value.</returns>
        public override double Calculate(int subfield)
        {
            return _sourceField.CurrentValue;
        }

        /// <summary>
        /// Not needed for this sort of output field.
        /// </summary>
        public override void RowInit()
        {
        }
    }

    public class OutputFieldRangeMapped : BasicOutputField, IRequireTwoPass
    {
        /// <summary>
        /// The input field to scale.
        /// </summary>
        private readonly IInputField _field;

        /// <summary>
        /// The high value of the field.
        /// </summary>
        private readonly double _high;

        /// <summary>
        /// The low value of the field.
        /// </summary>
        private readonly double _low;

        /// <summary>
        /// Default constructor, used mainly for reflection.
        /// </summary>
        public OutputFieldRangeMapped()
        {
        }

        /// <summary>
        /// Construct a range mapped output field.
        /// </summary>
        /// <param name="field">The input field to base this on.</param>
        /// <param name="low">The low value.</param>
        /// <param name="high">The high value.</param>
        public OutputFieldRangeMapped(IInputField field, double low,
                                      double high)
        {
            _field = field;
            _low = low;
            _high = high;
        }

        /// <summary>
        /// Construct the output field with -1 for low and +1 for high.
        /// </summary>
        /// <param name="f">The input field.</param>
        public OutputFieldRangeMapped(IInputField f) : this(f, -1, 1)
        {
        }

        /// <summary>
        /// The field that this output is based on.
        /// </summary>
        public IInputField Field
        {
            get { return _field; }
        }

        /// <summary>
        /// The high value of the range to map into.
        /// </summary>
        public double High
        {
            get { return _high; }
        }

        /// <summary>
        /// The low value of the range to map into.
        /// </summary>
        public double Low
        {
            get { return _low; }
        }

        /// <summary>
        /// This field only produces one value, so this will return 1.
        /// </summary>
        public override int SubfieldCount
        {
            get { return 1; }
        }

        /// <summary>
        /// Calculate this output field.
        /// </summary>
        /// <param name="subfield">Not used.</param>
        /// <returns>The calculated value.</returns>
        public override double Calculate(int subfield)
        {
            return ((_field.CurrentValue - _field.Min) / (_field
                                                          .Max - _field.Min))
                   * (_high - _low) + _low;
        }

        /// <summary>
        /// Not needed for this sort of output field.
        /// </summary>
        public override void RowInit()
        {
        }

        /// <summary>
        /// Convert a number back after its been normalized.
        /// </summary>
        /// <param name="data">The number to convert back.</param>
        /// <returns>The result.</returns>
        public double ConvertBack(double data)
        {
            double result = ((_field.Min - _field.Max) * data - _high
                                                            * _field.Min + _field.Max * _low)
                            / (_low - _high);
            return result;
        }
    }

    [Serializable]
    public class IndexRangeSegregator : IndexSegregator
    {
        /// <summary>
        /// The ending index.
        /// </summary>        
        private readonly int _endingIndex;

        /// <summary>
        /// The starting index.
        /// </summary>
        private readonly int _startingIndex;

        /// <summary>
        /// Default constructor for reflection.
        /// </summary>
        public IndexRangeSegregator()
        {
        }

        /// <summary>
        /// Construct an index range segregator.
        /// </summary>
        /// <param name="startingIndex">The starting index to allow.</param>
        /// <param name="endingIndex">The ending index to allow.</param>
        public IndexRangeSegregator(int startingIndex, int endingIndex)
        {
            _startingIndex = startingIndex;
            _endingIndex = endingIndex;
        }

        /// <summary>
        /// The ending index.
        /// </summary>
        public int EndingIndex
        {
            get { return _endingIndex; }
        }

        /// <summary>
        /// The starting index.
        /// </summary>
        public int StartingIndex
        {
            get { return _startingIndex; }
        }

        /// <summary>
        /// Determines if the current row should be included.
        /// </summary>
        /// <returns>True if the current row should be included.</returns>
        public override bool ShouldInclude()
        {
            bool result = ((CurrentIndex >= _startingIndex) && (CurrentIndex <= _endingIndex));
            RollIndex();
            return result;
        }
    }

    [Serializable]
    public class IndexSampleSegregator : IndexSegregator
    {
        /// <summary>
        /// The ending index (within a sample).
        /// </summary>
        private readonly int _endingIndex;

        /// <summary>
        /// The sample size.
        /// </summary>
        private readonly int _sampleSize;

        /// <summary>
        /// The starting index (within a sample).
        /// </summary>
        private readonly int _startingIndex;

        /// <summary>
        /// The default constructor, for reflection.
        /// </summary>
        public IndexSampleSegregator()
        {
        }

        /// <summary>
        /// Construct an index sample segregator.
        /// </summary>
        /// <param name="startingIndex">The starting index.</param>
        /// <param name="endingIndex">The ending index.</param>
        /// <param name="sampleSize">The sample size.</param>
        public IndexSampleSegregator(int startingIndex,
                                     int endingIndex, int sampleSize)
        {
            _sampleSize = sampleSize;
            _startingIndex = startingIndex;
            _endingIndex = endingIndex;
        }

        /// <summary>
        /// The ending index.
        /// </summary>
        public int EndingIndex
        {
            get { return _endingIndex; }
        }

        /// <summary>
        /// The sample size.
        /// </summary>
        public int SampleSize
        {
            get { return _sampleSize; }
        }

        /// <summary>
        /// The starting index.
        /// </summary>
        public int StartingIndex
        {
            get { return _startingIndex; }
        }

        /// <summary>
        /// Should this row be included.
        /// </summary>
        /// <returns>True if this row should be included.</returns>
        public override bool ShouldInclude()
        {
            int sampleIndex = CurrentIndex % _sampleSize;
            RollIndex();
            return ((sampleIndex >= _startingIndex) && (sampleIndex <= _endingIndex));
        }
    }

    [Serializable]
    public class IntegerBalanceSegregator : ISegregator
    {
        /// <summary>
        /// The count per each of the int values for the input field.
        /// </summary>
        private readonly int _count;

        /// <summary>
        /// The running totals.
        /// </summary>
        private readonly IDictionary<int, int> _runningCounts = new Dictionary<int, int>();

        /// <summary>
        /// The input field.
        /// </summary>
        private readonly IInputField _target;

        /// <summary>
        /// The normalization object to use.
        /// </summary>
        private DataNormalization _normalization;

        /// <summary>
        /// Construct a balanced segregator.
        /// </summary>
        /// <param name="target">The input field to base this on, should 
        /// be an integer value.</param>
        /// <param name="count">The number of rows to accept from each 
        /// unique value for the input.</param>
        public IntegerBalanceSegregator(IInputField target, int count)
        {
            _target = target;
            _count = count;
        }

        /// <summary>
        /// Default constructor for reflection.
        /// </summary>
        public IntegerBalanceSegregator()
        {
        }

        /// <summary>
        /// The number of groups found.
        /// </summary>
        public int Count
        {
            get { return _count; }
        }

        /// <summary>
        /// A map of the running count for each group.
        /// </summary>
        public IDictionary<int, int> RunningCounts
        {
            get { return _runningCounts; }
        }

        /// <summary>
        /// The target input field.
        /// </summary>
        public IInputField Target
        {
            get { return _target; }
        }

        #region ISegregator Members

        /// <summary>
        /// The owner of this segregator.
        /// </summary>
        public DataNormalization Owner
        {
            get { return _normalization; }
        }

        /// <summary>
        /// Init the segregator with the owning normalization object.
        /// </summary>
        /// <param name="normalization">The data normalization object to use.</param>
        public void Init(DataNormalization normalization)
        {
            _normalization = normalization;
        }

        /// <summary>
        /// Init for a new pass.
        /// </summary>
        public void PassInit()
        {
            _runningCounts.Clear();
        }

        /// <summary>
        /// Determine of the current row should be included.
        /// </summary>
        /// <returns>True if the current row should be included.</returns>
        public bool ShouldInclude()
        {
            var key = (int)_target.CurrentValue;
            int value = 0;
            if (_runningCounts.ContainsKey(key))
            {
                value = _runningCounts[key];
            }

            if (value < _count)
            {
                value++;
                _runningCounts[key] = value;
                return true;
            }
            return false;
        }

        #endregion

        /// <summary>
        /// Get information on how many rows fall into each group.
        /// </summary>
        /// <returns>A string that contains the counts for each group.</returns>
        public String DumpCounts()
        {
            var result = new StringBuilder();

            foreach (int key in _runningCounts.Keys)
            {
                int value = _runningCounts[key];
                result.Append(key);
                result.Append(" -> ");
                result.Append(value);
                result.Append(" count\n");
            }

            return result.ToString();
        }
    }

    [Serializable]
    public class RangeSegregator : ISegregator
    {
        /// <summary>
        /// If none of the ranges match, should this data be included.
        /// </summary>
        private readonly bool _include;

        /// <summary>
        /// The ranges.
        /// </summary>
        private readonly ICollection<SegregationRange> _ranges = new List<SegregationRange>();

        /// <summary>
        /// The source field that this is based on.
        /// </summary>
        private readonly IInputField _sourceField;

        /// <summary>
        /// The normalization object.
        /// </summary>
        private DataNormalization _normalization;

        /// <summary>
        /// Default constructor for reflection.
        /// </summary>
        public RangeSegregator()
        {
        }

        /// <summary>
        /// Construct a range segregator.
        /// </summary>
        /// <param name="sourceField">The source field.</param>
        /// <param name="include">Default action, if the data is not in any of the ranges,
        /// should it be included.</param>
        public RangeSegregator(IInputField sourceField, bool include)
        {
            _sourceField = sourceField;
            _include = include;
        }


        /// <summary>
        /// The source field that the ranges are compared against.
        /// </summary>
        public IInputField SourceField
        {
            get { return _sourceField; }
        }

        #region ISegregator Members

        /// <summary>
        /// The normalization object used by this object.
        /// </summary>
        public DataNormalization Owner
        {
            get { return _normalization; }
        }

        /// <summary>
        /// Init the object.
        /// </summary>
        /// <param name="normalization">The normalization object that owns this range.</param>
        public void Init(DataNormalization normalization)
        {
            _normalization = normalization;
        }

        /// <summary>
        /// True if the current row should be included according to this
        /// segregator.
        /// </summary>
        /// <returns></returns>
        public bool ShouldInclude()
        {
            double value = _sourceField.CurrentValue;
            foreach (SegregationRange range in _ranges)
            {
                if (range.InRange(value))
                {
                    return range.IsIncluded;
                }
            }
            return _include;
        }

        /// <summary>
        /// Init for pass... nothing to do fo this class.
        /// </summary>
        public void PassInit()
        {
        }

        #endregion

        /// <summary>
        /// Add a range.
        /// </summary>
        /// <param name="low">The low end of the range.</param>
        /// <param name="high">The high end of the range.</param>
        /// <param name="include">Should this range be included.</param>
        public void AddRange(double low, double high,
                             bool include)
        {
            var range = new SegregationRange(low, high, include);
            AddRange(range);
        }

        /// <summary>
        /// Add a range.
        /// </summary>
        /// <param name="range">The range to add.</param>
        public void AddRange(SegregationRange range)
        {
            _ranges.Add(range);
        }
    }

    [Serializable]
    public class SegregationRange
    {
        /// <summary>
        /// The high end of this range.
        /// </summary>
        private readonly double _high;

        /// <summary>
        /// Should this range be included.
        /// </summary>
        private readonly bool _include;

        /// <summary>
        /// The low end of this range.
        /// </summary>
        private readonly double _low;

        /// <summary>
        /// Default constructor for reflection.
        /// </summary>
        public SegregationRange()
        {
        }

        /// <summary>
        /// Construct a segregation range.
        /// </summary>
        /// <param name="low">The low end of the range.</param>
        /// <param name="high">The high end of the range.</param>
        /// <param name="include">Specifies if the range should be included.</param>
        public SegregationRange(double low, double high,
                                bool include)
        {
            _low = low;
            _high = high;
            _include = include;
        }

        /// <summary>
        /// The high end of the range.
        /// </summary>
        public double High
        {
            get { return _high; }
        }

        /// <summary>
        /// The low end of the range.
        /// </summary>
        public double Low
        {
            get { return _low; }
        }

        /// <summary>
        /// True if this range should be included.
        /// </summary>
        public bool IsIncluded
        {
            get { return _include; }
        }

        /// <summary>
        /// Is this value within the range. 
        /// </summary>
        /// <param name="value">The value to check.</param>
        /// <returns>True if the value is within the range.</returns>
        public bool InRange(double value)
        {
            return ((value >= _low) && (value <= _high));
        }
    }

    [Serializable]
    public class NormalizationStorageArray1D : INormalizationStorage
    {
        /// <summary>
        /// The array to store to.
        /// </summary>
        private readonly double[] _array;

        /// <summary>
        /// The current index.
        /// </summary>
        private int _currentIndex;


        /// <summary>
        /// Construct an object to store to a 2D array.
        /// </summary>
        /// <param name="array">The array to store to.</param>
        public NormalizationStorageArray1D(double[] array)
        {
            _array = array;
            _currentIndex = 0;
        }

        #region INormalizationStorage Members

        /// <summary>
        /// Not needed for this storage type.
        /// </summary>
        public void Close()
        {
        }

        /// <summary>
        /// Not needed for this storage type.
        /// </summary>
        public void Open()
        {
        }

        /// <summary>
        /// Write an array.
        /// </summary>
        /// <param name="data">The data to write.</param>
        /// <param name="inputCount">How much of the data is input.</param>
        public void Write(double[] data, int inputCount)
        {
            _array[_currentIndex++] = data[0];
        }

        #endregion

        public double[] GetArray()
        {
            return _array;
        }
    }

    [Serializable]
    public class NormalizationStorageArray2D : INormalizationStorage
    {
        /// <summary>
        /// The array to output to.
        /// </summary>
        private readonly double[][] _array;

        /// <summary>
        /// The current data.
        /// </summary>
        private int _currentIndex;

        /// <summary>
        /// Construct an object to store to a 2D array.
        /// </summary>
        /// <param name="array">The array to store to.</param>
        public NormalizationStorageArray2D(double[][] array)
        {
            _array = array;
            _currentIndex = 0;
        }

        #region INormalizationStorage Members

        /// <summary>
        /// Not needed for this storage type.
        /// </summary>
        public void Close()
        {
        }

        /// <summary>
        /// Not needed for this storage type.
        /// </summary>
        public void Open()
        {
        }

        /// <summary>
        /// Write an array.
        /// </summary>
        /// <param name="data">The data to write.</param>
        /// <param name="inputCount">How much of the data is input.</param>
        public void Write(double[] data, int inputCount)
        {
            for (int i = 0; i < data.Length; i++)
            {
                _array[_currentIndex][i] = data[i];
            }
            _currentIndex++;
        }

        #endregion

        /// <summary>
        /// Get the underlying array.
        /// </summary>
        /// <returns>The underlying array.</returns>
        public double[][] GetArray()
        {
            return this._array;
        }
    }

    [Serializable]
    public class NormalizationStorageCSV : INormalizationStorage
    {
        /// <summary>
        /// The CSV format to use.
        /// </summary>
        private readonly CSVFormat _format;

        /// <summary>
        /// The output file.
        /// </summary> 
        private readonly String _outputFile;

        /// <summary>
        /// The output writer.
        /// </summary>
        private StreamWriter _output;

        /// <summary>
        /// Construct a CSV storage object from the specified file.
        /// </summary>
        /// <param name="format">The format to use.</param>
        /// <param name="file">The file to write the CSV to.</param>
        public NormalizationStorageCSV(CSVFormat format, String file)
        {
            _format = format;
            _outputFile = file;
        }

        /// <summary>
        /// Construct a CSV storage object from the specified file.
        /// </summary>
        /// <param name="file">The file to write the CSV to.</param>
        public NormalizationStorageCSV(String file)
        {
            _format = CSVFormat.English;
            _outputFile = file;
        }

        #region INormalizationStorage Members

        /// <summary>
        /// Close the CSV file.
        /// </summary>
        public void Close()
        {
            _output.Close();
        }

        /// <summary>
        /// Open the CSV file.
        /// </summary>
        public void Open()
        {
            _output = new StreamWriter(_outputFile);
        }

        /// <summary>
        /// Write an array.
        /// </summary>
        /// <param name="data">The data to write.</param>
        /// <param name="inputCount"> How much of the data is input.</param>
        public void Write(double[] data, int inputCount)
        {
            var result = new StringBuilder();
            NumberList.ToList(_format, result, data);
            _output.WriteLine(result.ToString());
        }

        #endregion
    }

    [Serializable]
    public class NormalizationStorageMLDataSet : INormalizationStorage
    {
        /// <summary>
        /// The data set to add to.
        /// </summary>
        [NonSerialized]
        private readonly IMLDataSet _dataset;

        /// <summary>
        /// The ideal count.
        /// </summary>
        private readonly int _idealCount;

        /// <summary>
        /// The input count.
        /// </summary>
        private readonly int _inputCount;

        /// <summary>
        /// Construct a new NeuralDataSet based on the parameters specified.
        /// </summary>
        /// <param name="inputCount">The input count.</param>
        /// <param name="idealCount">The output count.</param>
        public NormalizationStorageMLDataSet(int inputCount,
                                                 int idealCount)
        {
            _inputCount = inputCount;
            _idealCount = idealCount;
            _dataset = new BasicMLDataSet();
        }

        /// <summary>
        /// Construct a normalized neural storage class to hold data.
        /// </summary>
        /// <param name="dataset">The data set to store to. This uses an existing data set.</param>
        public NormalizationStorageMLDataSet(IMLDataSet dataset)
        {
            _dataset = dataset;
            _inputCount = _dataset.InputSize;
            _idealCount = _dataset.IdealSize;
        }

        /// <summary>
        /// The data set being used.
        /// </summary>
        public IMLDataSet DataSet
        {
            get { return _dataset; }
        }

        #region INormalizationStorage Members

        /// <summary>
        /// Not needed for this storage type.
        /// </summary>
        public void Close()
        {
        }

        /// <summary>
        /// Not needed for this storage type.
        /// </summary>
        public void Open()
        {
        }

        /// <summary>
        /// Write an array.
        /// </summary>
        /// <param name="data">The data to write.</param>
        /// <param name="inputCount">How much of the data is input.</param>
        public void Write(double[] data, int inputCount)
        {
            if (_idealCount == 0)
            {
                var inputData = new BasicMLData(data);
                _dataset.Add(inputData);
            }
            else
            {
                var inputData = new BasicMLData(
                    _inputCount);
                var idealData = new BasicMLData(
                    _idealCount);

                int index = 0;
                for (int i = 0; i < _inputCount; i++)
                {
                    inputData[i] = data[index++];
                }

                for (int i = 0; i < _idealCount; i++)
                {
                    idealData[i] = data[index++];
                }

                _dataset.Add(inputData, idealData);
            }
        }

        #endregion
    }

    [Serializable]
    public class DataNormalization
    {
        /// <summary>
        /// Hold a map between the InputFieldCSV objects and the corresponding
        /// ReadCSV object. There will likely be many fields read from a single file.
        /// This allows only one ReadCSV object to need to be created per actual CSV
        /// file.
        /// </summary>
        [NonSerialized]
        private IDictionary<IInputField, ReadCSV> _csvMap;


        /// <summary>
        /// Map each of the input fields to an internally-build NeuralDataFieldHolder object.
        /// The NeuralDataFieldHolder object holds an Iterator, InputField and last 
        /// NeuralDataPair object loaded.
        /// </summary>
        [NonSerialized]
        private IDictionary<IInputField, MLDataFieldHolder> _dataSetFieldMap;

        /// <summary>
        /// Map each of the NeuralDataSet Iterators to an internally-build NeuralDataFieldHolder 
        /// object. The NeuralDataFieldHolder object holds an Iterator, InputField and last 
        /// NeuralDataPair object loaded.
        /// </summary>
        [NonSerialized]
        private IDictionary<IEnumerator<IMLDataPair>, MLDataFieldHolder> _dataSetIteratorMap;

        /// <summary>
        /// Output fields can be grouped together, if the value of one output field might 
        /// affect all of the others.  This collection holds a list of all of the output 
        /// field groups.
        /// </summary>
        private readonly IList<IOutputFieldGroup> _groups = new List<IOutputFieldGroup>();

        /// <summary>
        /// The input fields.
        /// </summary>
        private readonly IList<IInputField> _inputFields = new List<IInputField>();

        /// <summary>
        /// The output fields.
        /// </summary>
        private readonly IList<IOutputField> _outputFields = new List<IOutputField>();

        /// <summary>
        /// Keep a collection of all of the ReadCSV classes to support all of the
        /// distinct CSV files that are to be read.
        /// </summary>
        [NonSerialized]
        private ICollection<ReadCSV> _readCSV;

        /// <summary>
        /// For each InputFieldNeuralDataSet input field an Iterator must be kept to
        /// actually access the data. Only one Iterator should be kept per data set
        /// actually used.
        /// </summary>
        [NonSerialized]
        private ICollection<IEnumerator<IMLDataPair>> _readDataSet;

        /// <summary>
        /// A list of the segregators.
        /// </summary>
        private readonly IList<ISegregator> _segregators = new List<ISegregator>();

        /// <summary>
        /// The format to use for all CSV files.
        /// </summary>
        private CSVFormat _csvFormat = CSVFormat.English;

        /// <summary>
        /// The current record's index.
        /// </summary>
        private int _currentIndex;

        /// <summary>
        /// How long has it been since the last report.  This filters so that
        /// every single record does not produce a message.
        /// </summary>
        private int _lastReport;

        /// <summary>
        /// The number of records that were found in the first pass.
        /// </summary>
        private int _recordCount;

        /// <summary>
        /// The object to report the progress of the normalization to.
        /// </summary>
        [NonSerialized]
        private IStatusReportable _report = new NullStatusReportable();

        /// <summary>
        /// Where the final output from the normalization is sent.
        /// </summary>
        private INormalizationStorage _storage;

        /// <summary>
        /// The CSV format being used.
        /// </summary>
        public CSVFormat CSVFormatUsed
        {
            get { return _csvFormat; }
            set { _csvFormat = value; }
        }


        /// <summary>
        /// The object groups.
        /// </summary>
        public IList<IOutputFieldGroup> Groups
        {
            get { return _groups; }
        }

        /// <summary>
        /// The input fields.
        /// </summary>
        public IList<IInputField> InputFields
        {
            get { return _inputFields; }
        }

        /// <summary>
        /// The output fields.
        /// </summary>
        public IList<IOutputField> OutputFields
        {
            get { return _outputFields; }
        }

        /// <summary>
        /// The record count.
        /// </summary>
        public int RecordCount
        {
            get { return _recordCount; }
        }

        /// <summary>
        /// The class that progress will be reported to.
        /// </summary>
        public IStatusReportable Report
        {
            get { return _report; }
            set { _report = value; }
        }

        /// <summary>
        /// The segregators in use.
        /// </summary>
        public IList<ISegregator> Segregators
        {
            get { return _segregators; }
        }

        /// <summary>
        /// The place that the normalization output will be stored.
        /// </summary>
        public INormalizationStorage Storage
        {
            get { return _storage; }
            set { _storage = value; }
        }

        /// <summary>
        /// Add an input field.
        /// </summary>
        /// <param name="f">The input field to add.</param>
        public void AddInputField(IInputField f)
        {
            _inputFields.Add(f);
        }

        /// <summary>
        ///  Add an output field.  This output field will be added as a 
        /// "neural network input field", not an "ideal output field".
        /// </summary>
        /// <param name="outputField">The output field to add.</param>
        public void AddOutputField(IOutputField outputField)
        {
            AddOutputField(outputField, false);
        }

        /// <summary>
        /// Add a field and allow it to be specified as an "ideal output field".
        /// An "ideal" field is the expected output that the neural network is
        /// training towards.
        /// </summary>
        /// <param name="outputField">The output field.</param>
        /// <param name="ideal">True if this is an ideal field.</param>
        public void AddOutputField(IOutputField outputField,
                                   bool ideal)
        {
            _outputFields.Add(outputField);
            outputField.Ideal = ideal;
            if (outputField is OutputFieldGrouped)
            {
                var ofg = (OutputFieldGrouped)outputField;
                _groups.Add(ofg.Group);
            }
        }

        /// <summary>
        ///  Add a segregator.
        /// </summary>
        /// <param name="segregator">The segregator to add.</param>
        public void AddSegregator(ISegregator segregator)
        {
            _segregators.Add(segregator);
            segregator.Init(this);
        }

        /// <summary>
        /// Called internally to allow each of the input fields to update their
        /// min/max values in the first pass.
        /// </summary>
        private void ApplyMinMax()
        {
            foreach (IInputField field in _inputFields)
            {
                double value = field.CurrentValue;
                field.ApplyMinMax(value);
            }
        }

        /// <summary>
        /// Build "input data for a neural network" based on the input values
        /// provided.  This allows  input for a neural network to be normalized.
        /// This is typically used when data is to be presented to a trained
        /// neural network.
        /// </summary>
        /// <param name="data">The input values to be normalized.</param>
        /// <returns>The data to be sent to the neural network.</returns>
        public IMLData BuildForNetworkInput(double[] data)
        {
            // feed the input fields
            int index = 0;
            foreach (IInputField field in _inputFields)
            {
                if (field.UsedForNetworkInput)
                {
                    if (index >= data.Length)
                    {

                    }
                    field.CurrentValue = data[index++];
                }
            }

            // count the output fields
            int outputCount = 0;
            foreach (IOutputField ofield in _outputFields)
            {
                if (!ofield.Ideal)
                {
                    for (int sub = 0; sub < ofield.SubfieldCount; sub++)
                    {
                        outputCount++;
                    }
                }
            }

            // process the output fields

            InitForOutput();

            IMLData result = new BasicNeuralData(outputCount);

            // write the value
            int outputIndex = 0;
            foreach (IOutputField ofield in _outputFields)
            {
                if (!ofield.Ideal)
                {
                    for (int sub = 0; sub < ofield.SubfieldCount; sub++)
                    {
                        result.Data[outputIndex++] = ofield.Calculate(sub);
                    }
                }
            }

            return result;
        }



        private void DetermineInputFieldValue(IInputField field, int index, bool headers)
        {
            double result;

            if (field is InputFieldCSV)
            {
                var fieldCSV = (InputFieldCSV)field;
                ReadCSV csv = _csvMap[field];
                result = csv.GetDouble(fieldCSV.ColumnName);

            }
            else if (field is InputFieldMLDataSet)
            {
                var mlField = (InputFieldMLDataSet)field;
                MLDataFieldHolder holder = _dataSetFieldMap
                    [field];
                IMLDataPair pair = holder.Pair;
                int offset = mlField.Offset;
                if (offset < pair.Input.Count)
                {
                    result = pair.Input[offset];
                }
                else
                {
                    offset -= pair.Input.Count;
                    result = pair.Ideal[offset];
                }
            }
            else
            {
                result = field.GetValue(index);
            }

            field.CurrentValue = result;
            return;
        }
        /// <summary>
        /// Called internally to obtain the current value for an input field.
        /// </summary>
        /// <param name="field">The input field to determine.</param>
        /// <param name="index">The current index.</param>
        /// <returns>The value for this input field.</returns>
        private void DetermineInputFieldValue(IInputField field, int index)
        {
            double result;

            if (field is InputFieldCSV)
            {
                var fieldCSV = (InputFieldCSV)field;
                ReadCSV csv = _csvMap[field];
                result = csv.GetDouble(fieldCSV.Offset);

            }
            else if (field is InputFieldMLDataSet)
            {
                var mlField = (InputFieldMLDataSet)field;
                MLDataFieldHolder holder = _dataSetFieldMap
                    [field];
                IMLDataPair pair = holder.Pair;
                int offset = mlField.Offset;
                if (offset < pair.Input.Count)
                {
                    result = pair.Input[offset];
                }
                else
                {
                    offset -= pair.Input.Count;
                    result = pair.Ideal[offset];
                }
            }
            else
            {
                result = field.GetValue(index);
            }

            field.CurrentValue = result;
            return;
        }

        /// <summary>
        /// Called internally to determine all of the input field values.
        /// </summary>
        /// <param name="index">The current index.</param>
        private void DetermineInputFieldValues(int index)
        {
            foreach (IInputField field in _inputFields)
            {
                DetermineInputFieldValue(field, index);
            }
        }


        /// <summary>
        /// Called internally to determine all of the input field values.
        /// </summary>
        /// <param name="index">The current index.</param>
        /// <param name="headers">if set to <c>true</c> [headers].</param>
        private void DetermineInputFieldValues(int index, bool headers)
        {
            foreach (IInputField field in _inputFields)
            {
                DetermineInputFieldValue(field, index, headers);
            }
        }


        /// <summary>
        /// Find an input field by its class.
        /// </summary>
        /// <param name="clazz">The input field class type you are looking for.</param>
        /// <param name="count">The instance of the input field needed, 0 for the first.</param>
        /// <returns>The input field if found, otherwise null.</returns>
        public IInputField FindInputField(Type clazz, int count)
        {
            int i = 0;
            foreach (IInputField field in _inputFields)
            {
                if (field.GetType().IsInstanceOfType(clazz))
                {
                    if (i == count)
                    {
                        return field;
                    }
                    i++;
                }
            }

            return null;
        }

        /// <summary>
        /// Find an output field by its class.
        /// </summary>
        /// <param name="clazz">The output field class type you are looking for.</param>
        /// <param name="count">The instance of the output field needed, 0 for the first.</param>
        /// <returns>The output field if found, otherwise null.</returns>
        public IOutputField FindOutputField(Type clazz, int count)
        {
            int i = 0;
            foreach (IOutputField field in _outputFields)
            {
                if (field.GetType().IsInstanceOfType(clazz) || field.GetType() == clazz)
                {
                    if (i == count)
                    {
                        return field;
                    }
                    i++;
                }
            }

            return null;
        }

        /// <summary>
        /// First pass, count everything, establish min/max.
        /// </summary>
        private void FirstPass(bool headers)
        {
            OpenCSV(headers);
            OpenDataSet();

            _currentIndex = -1;
            _recordCount = 0;

            if (_report != null)
            {
                _report.Report(0, 0, "Analyzing file");
            }
            _lastReport = 0;
            int index = 0;

            InitForPass();

            // loop over all of the records
            while (Next())
            {
                DetermineInputFieldValues(index, headers);

                if (ShouldInclude())
                {
                    ApplyMinMax();
                    _recordCount++;
                    ReportResult("First pass, analyzing file", 0, _recordCount);
                }
                index++;
            }
        }




        /// <summary>
        /// First pass, count everything, establish min/max.
        /// This version doesn't read column names in csvinputfields.
        /// </summary>
        private void FirstPass()
        {
            OpenCSV();
            OpenDataSet();

            _currentIndex = -1;
            _recordCount = 0;

            if (_report != null)
            {
                _report.Report(0, 0, "Analyzing file");
            }
            _lastReport = 0;
            int index = 0;

            InitForPass();

            // loop over all of the records
            while (Next())
            {
                DetermineInputFieldValues(index);

                if (ShouldInclude())
                {
                    ApplyMinMax();
                    _recordCount++;
                    ReportResult("First pass, analyzing file", 0, _recordCount);
                }
                index++;
            }
        }





        /// <summary>
        /// Calculate the number of output fields that are not used as ideal
        /// values, these will be the input to the neural network.
        /// This is the input layer size for the neural network.
        /// </summary>
        /// <returns>The input layer size.</returns>
        public int GetNetworkInputLayerSize()
        {
            return _outputFields.Where(field => !field.Ideal).Sum(field => field.SubfieldCount);
        }

        /// <summary>
        /// The number of output fields that are used as ideal
        /// values, these will be the ideal output from the neural network.
        /// This is the output layer size for the neural network.
        /// </summary>
        /// <returns>The output layer size.</returns>
        public int GetNetworkOutputLayerSize()
        {
            return _outputFields.Where(field => field.Ideal).Sum(field => field.SubfieldCount);
        }

        /// <summary>
        /// The total size of all output fields.  This takes into
        /// account output fields that generate more than one value.
        /// </summary>
        /// <returns>The output field count.</returns>
        public int GetOutputFieldCount()
        {
            return _outputFields.Sum(field => field.SubfieldCount);
        }

        /// <summary>
        /// Setup the row for output.
        /// </summary>
        public void InitForOutput()
        {
            // init groups
            foreach (IOutputFieldGroup group in _groups)
            {
                group.RowInit();
            }

            // init output fields
            foreach (IOutputField field in _outputFields)
            {
                field.RowInit();
            }
        }

        /// <summary>
        /// Called internally to advance to the next row.
        /// </summary>
        /// <returns>True if there are more rows to reed.</returns>
        private bool Next()
        {
            // see if any of the CSV readers want to stop
            if (_readCSV.Any(csv => !csv.Next()))
            {
                return false;
            }

            // see if any of the data sets want to stop
            foreach (var iterator in _readDataSet)
            {
                if (!iterator.MoveNext())
                {
                    return false;
                }
                MLDataFieldHolder holder = _dataSetIteratorMap
                    [iterator];
                IMLDataPair pair = iterator.Current;
                holder.Pair = pair;
            }

            // see if any of the arrays want to stop
            if (_inputFields.OfType<IHasFixedLength>().Any(fl => (_currentIndex + 1) >= fl.Length))
            {
                return false;
            }

            _currentIndex++;

            return true;
        }

        /// <summary>
        /// Called internally to open the CSV file.
        /// </summary>
        private void OpenCSV()
        {
            // clear out any CSV files already there
            _csvMap.Clear();
            _readCSV.Clear();

            // only add each CSV once
            IDictionary<String, ReadCSV> uniqueFiles = new Dictionary<String, ReadCSV>();

            // find the unique files
            foreach (IInputField field in _inputFields)
            {
                if (field is InputFieldCSV)
                {
                    var csvField = (InputFieldCSV)field;
                    String file = csvField.File;
                    if (!uniqueFiles.ContainsKey(file))
                    {
                        var csv = new ReadCSV(file, false,
                                              _csvFormat);
                        uniqueFiles[file] = csv;
                        _readCSV.Add(csv);
                    }
                    _csvMap[csvField] = uniqueFiles[file];
                }
            }
        }

        /// <summary>
        /// Called internally to open the CSV file with header.
        /// </summary>
        private void OpenCSV(bool headers)
        {
            // clear out any CSV files already there
            _csvMap.Clear();
            _readCSV.Clear();

            // only add each CSV once
            IDictionary<String, ReadCSV> uniqueFiles = new Dictionary<String, ReadCSV>();

            // find the unique files
            foreach (IInputField field in _inputFields)
            {
                if (field is InputFieldCSV)
                {
                    var csvField = (InputFieldCSV)field;
                    String file = csvField.File;
                    if (!uniqueFiles.ContainsKey(file))
                    {
                        var csv = new ReadCSV(file, headers,
                                              _csvFormat);
                        uniqueFiles[file] = csv;
                        _readCSV.Add(csv);
                    }
                    _csvMap[csvField] = uniqueFiles[file];
                }
            }
        }


        /// <summary>
        /// Open any datasets that were used by the input layer.
        /// </summary>
        private void OpenDataSet()
        {
            // clear out any data sets already there
            _readDataSet.Clear();
            _dataSetFieldMap.Clear();
            _dataSetIteratorMap.Clear();

            // only add each iterator once
            IDictionary<IMLDataSet, MLDataFieldHolder> uniqueSets = new Dictionary<IMLDataSet, MLDataFieldHolder>();

            // find the unique files
            foreach (IInputField field in _inputFields)
            {
                if (field is InputFieldMLDataSet)
                {
                    var dataSetField = (InputFieldMLDataSet)field;
                    IMLDataSet dataSet = dataSetField.NeuralDataSet;
                    if (!uniqueSets.ContainsKey(dataSet))
                    {
                        IEnumerator<IMLDataPair> iterator = dataSet
                            .GetEnumerator();
                        var holder = new MLDataFieldHolder(
                            iterator, dataSetField);
                        uniqueSets[dataSet] = holder;
                        _readDataSet.Add(iterator);
                    }

                    MLDataFieldHolder holder2 = uniqueSets[dataSet];

                    _dataSetFieldMap[dataSetField] = holder2;
                    _dataSetIteratorMap[holder2.GetEnumerator()] = holder2;
                }
            }
        }

        /// <summary>
        /// Call this method to begin the normalization process.  Any status 
        /// updates will be sent to the class specified in the constructor.
        /// </summary>
        public void Process()
        {
            Init();
            if (TwoPassesNeeded())
            {
                FirstPass();
            }
            SecondPass();
        }
        /// <summary>
        /// Call this method to begin the normalization process.  Any status 
        /// updates will be sent to the class specified in the constructor.
        /// this version uses headers.
        /// </summary>
        public void Process(bool headers)
        {
            Init();
            if (TwoPassesNeeded())
            {
                FirstPass(headers);
            }
            SecondPass(headers);
        }
        /// <summary>
        /// Report on the current progress.
        /// </summary>
        /// <param name="message">The message to report.</param>
        /// <param name="total">The total number of records to process, 0 for unknown.</param>
        /// <param name="current"> The current record.</param>
        private void ReportResult(String message, int total,
                                  int current)
        {
            // count the records, report status
            _lastReport++;
            if (_lastReport >= 10000)
            {
                _report.Report(total, current, message);
                _lastReport = 0;
            }
        }

        /// <summary>
        /// The second pass actually writes the data to the output files.
        /// </summary>
        private void SecondPass()
        {
            bool twopass = TwoPassesNeeded();

            // move any CSV and datasets files back to the beginning.
            OpenCSV();
            OpenDataSet();
            InitForPass();

            _currentIndex = -1;

            // process the records
            int size = GetOutputFieldCount();
            var output = new double[size];

            _storage.Open();
            _lastReport = 0;
            int index = 0;
            int current = 0;
            while (Next())
            {
                // read the value
                foreach (IInputField field in _inputFields)
                {
                    DetermineInputFieldValue(field, index);
                }

                if (ShouldInclude())
                {
                    // handle groups
                    InitForOutput();

                    // write the value
                    int outputIndex = 0;
                    foreach (IOutputField ofield in _outputFields)
                    {
                        for (int sub = 0; sub < ofield.SubfieldCount; sub++)
                        {
                            output[outputIndex++] = ofield.Calculate(sub);
                        }
                    }

                    ReportResult(twopass ? "Second pass, normalizing data" : "Processing data (single pass)",
                                 _recordCount, ++current);
                    _storage.Write(output, 0);
                }

                index++;
            }
            _storage.Close();
        }




        /// <summary>
        /// The second pass actually writes the data to the output files.
        /// </summary>
        private void SecondPass(bool headers)
        {
            bool twopass = TwoPassesNeeded();

            // move any CSV and datasets files back to the beginning.
            OpenCSV(headers);
            OpenDataSet();
            InitForPass();

            _currentIndex = -1;

            // process the records
            int size = GetOutputFieldCount();
            var output = new double[size];

            _storage.Open();
            _lastReport = 0;
            int index = 0;
            int current = 0;
            while (Next())
            {
                // read the value
                foreach (IInputField field in _inputFields)
                {
                    DetermineInputFieldValue(field, index, headers);
                }

                if (ShouldInclude())
                {
                    // handle groups
                    InitForOutput();

                    // write the value
                    int outputIndex = 0;
                    foreach (IOutputField ofield in _outputFields)
                    {
                        for (int sub = 0; sub < ofield.SubfieldCount; sub++)
                        {
                            output[outputIndex++] = ofield.Calculate(sub);
                        }
                    }

                    ReportResult(twopass ? "Second pass, normalizing data" : "Processing data (single pass)",
                                 _recordCount, ++current);
                    _storage.Write(output, 0);
                }

                index++;
            }
            _storage.Close();
        }


        /// <summary>
        /// Should this row be included? Check the segregatprs.
        /// </summary>
        /// <returns>True if the row should be included.</returns>
        private bool ShouldInclude()
        {
            return _segregators.All(segregator => segregator.ShouldInclude());
        }


        /// <summary>
        /// Setup the row for output.
        /// </summary>
        public void InitForPass()
        {
            // init segregators
            foreach (ISegregator segregator in _segregators)
            {
                segregator.PassInit();
            }
        }

        /// <summary>
        /// Determine if two passes will be needed.
        /// </summary>
        /// <returns>True if two passes will be needed.</returns>
        public bool TwoPassesNeeded()
        {
            return _outputFields.OfType<IRequireTwoPass>().Any();
        }

        private void Init()
        {
            _csvMap = new Dictionary<IInputField, ReadCSV>();
            _dataSetFieldMap = new Dictionary<IInputField, MLDataFieldHolder>();
            _dataSetIteratorMap = new Dictionary<IEnumerator<IMLDataPair>, MLDataFieldHolder>();
            _readCSV = new List<ReadCSV>();
            _readDataSet = new List<IEnumerator<IMLDataPair>>();


        }
    }

    public class NormalizationError : SyntError
    {
        /// <summary>
        /// Construct a message exception.
        /// </summary>
        /// <param name="str">The message.</param>
        public NormalizationError(String str)
            : base(str)
        {
        }

        /// <summary>
        /// Pass on an exception.
        /// </summary>
        /// <param name="e">The other exception.</param>
        public NormalizationError(Exception e)
            : base(e)
        {
        }
    }

    public class SyntUtility
    {
        /// <summary>
        /// Private constructor.
        /// </summary>
        private SyntUtility()
        {
        }

        /// <summary>
        /// Convert a CSV file to a binary training file.
        /// </summary>
        /// <param name="csvFile">The CSV file.</param>
        /// <param name="format">The format.</param>
        /// <param name="binFile">The binary file.</param>
        /// <param name="inputCount">The number of input values.</param>
        /// <param name="outputCount">The number of output values.</param>
        /// <param name="headers">True, if there are headers on the3 CSV.</param>
        /// <param name="expectSignificance">Should a significance column be expected.</param>
        public static void ConvertCSV2Binary(String csvFile, CSVFormat format,
                                             String binFile, int inputCount, int outputCount,
                                             bool headers, bool expectSignificance)
        {
            new FileInfo(binFile).Delete();

            var csv = new CSVMLDataSet(csvFile,
                                       inputCount, outputCount, false, format, expectSignificance);
            var buffer = new BufferedMLDataSet(binFile);
            buffer.BeginLoad(inputCount, outputCount);
            foreach (IMLDataPair pair in csv)
            {
                buffer.Add(pair);
            }
            buffer.EndLoad();
        }

        /// <summary>
        /// Convert a CSV file to binary.
        /// </summary>
        /// <param name="csvFile">The CSV file to convert.</param>
        /// <param name="format">The format.</param>
        /// <param name="binFile">The binary file.</param>
        /// <param name="input">The input.</param>
        /// <param name="ideal">The ideal.</param>
        /// <param name="headers">True, if headers are present.</param>
        public static void ConvertCSV2Binary(FileInfo csvFile, CSVFormat format,
                                             FileInfo binFile, int[] input, int[] ideal, bool headers)
        {
            binFile.Delete();
            var csv = new ReadCSV(csvFile.ToString(), headers, format);

            var buffer = new BufferedMLDataSet(binFile.ToString());
            buffer.BeginLoad(input.Length, ideal.Length);
            while (csv.Next())
            {
                var inputData = new BasicMLData(input.Length);
                var idealData = new BasicMLData(ideal.Length);

                // handle input data
                for (int i = 0; i < input.Length; i++)
                {
                    inputData[i] = csv.GetDouble(input[i]);
                }

                // handle input data
                for (int i = 0; i < ideal.Length; i++)
                {
                    idealData[i] = csv.GetDouble(ideal[i]);
                }

                // add to dataset

                buffer.Add(inputData, idealData);
            }
            buffer.EndLoad();
            buffer.Close();
            csv.Close();
        }

        /// <summary>
        /// Load CSV to memory.
        /// </summary>
        /// <param name="filename">The CSV file to load.</param>
        /// <param name="input">The input count.</param>
        /// <param name="ideal">The ideal count.</param>
        /// <param name="headers">True, if headers are present.</param>
        /// <param name="format">The loaded dataset.</param>
        /// <param name="expectSignificance">The loaded dataset.</param>
        /// <returns></returns>
        public static IMLDataSet LoadCSV2Memory(String filename, int input, int ideal, bool headers, CSVFormat format, bool expectSignificance)
        {
            IDataSetCODEC codec = new CSVDataCODEC(filename, format, headers, input, ideal, expectSignificance);
            var load = new MemoryDataLoader(codec);
            IMLDataSet dataset = load.External2Memory();
            return dataset;
        }

        /// <summary>
        /// Evaluate the network and display (to the console) the output for every
        /// value in the training set. Displays ideal and actual.
        /// </summary>
        /// <param name="network">The network to evaluate.</param>
        /// <param name="training">The training set to evaluate.</param>
        public static void Evaluate(IMLRegression network,
                                    IMLDataSet training)
        {
            foreach (IMLDataPair pair in training)
            {
                IMLData output = network.Compute(pair.Input);
                Console.WriteLine(@"Input="
                                  + FormatNeuralData(pair.Input)
                                  + @", Actual=" + FormatNeuralData(output)
                                  + @", Ideal="
                                  + FormatNeuralData(pair.Ideal));
            }
        }

        /// <summary>
        /// Format neural data as a list of numbers.
        /// </summary>
        /// <param name="data">The neural data to format.</param>
        /// <returns>The formatted neural data.</returns>
        public static String FormatNeuralData(IMLData data)
        {
            var result = new StringBuilder();
            for (int i = 0; i < data.Count; i++)
            {
                if (i != 0)
                {
                    result.Append(',');
                }
                result.Append(Format.FormatDouble(data[i], 4));
            }
            return result.ToString();
        }

        /// <summary>
        /// Create a simple feedforward neural network.
        /// </summary>
        /// <param name="input">The number of input neurons.</param>
        /// <param name="hidden1">The number of hidden layer 1 neurons.</param>
        /// <param name="hidden2">The number of hidden layer 2 neurons.</param>
        /// <param name="output">The number of output neurons.</param>
        /// <param name="tanh">True to use hyperbolic tangent activation function, false to
        /// use the sigmoid activation function.</param>
        /// <returns>The neural network.</returns>
        public static BasicNetwork SimpleFeedForward(int input,
                                                     int hidden1, int hidden2, int output,
                                                     bool tanh)
        {
            var pattern = new FeedForwardPattern { InputNeurons = input, OutputNeurons = output };
            if (tanh)
            {
                pattern.ActivationFunction = new ActivationTANH();
            }
            else
            {
                pattern.ActivationFunction = new ActivationSigmoid();
            }

            if (hidden1 > 0)
            {
                pattern.AddHiddenLayer(hidden1);
            }
            if (hidden2 > 0)
            {
                pattern.AddHiddenLayer(hidden2);
            }

            var network = (BasicNetwork)pattern.Generate();
            network.Reset();
            return network;
        }

        /// <summary>
        /// Train the neural network, using SCG training, and output status to the
        /// console.
        /// </summary>
        /// <param name="network">The network to train.</param>
        /// <param name="trainingSet">The training set.</param>
        /// <param name="minutes">The number of minutes to train for.</param>
        public static void TrainConsole(BasicNetwork network,
                                        IMLDataSet trainingSet, int minutes)
        {
            Prop train = new ResilientProp(network,
                                                         trainingSet)
            { ThreadCount = 0 };
            TrainConsole(train, network, trainingSet, minutes);
        }


        /// <summary>
        /// Train the neural network, using SCG training, and output status to the
        /// console.
        /// </summary>
        /// <param name="network">The network to train.</param>
        /// <param name="trainingSet">The training set.</param>
        /// <param name="seconds">The seconds.</param>
        public static void TrainConsole(BasicNetwork network,
                                        IMLDataSet trainingSet, double seconds)
        {
            Prop train = new ResilientProp(network,
                                                         trainingSet)
            { ThreadCount = 0 };
            TrainConsole(train, network, trainingSet, seconds);
        }

        /// <summary>
        /// Train the network, using the specified training Algo, and send the
        /// output to the console.
        /// </summary>
        /// <param name="train">The training method to use.</param>
        /// <param name="network">The network to train.</param>
        /// <param name="trainingSet">The training set.</param>
        /// <param name="minutes">The number of minutes to train for.</param>
        public static void TrainConsole(IMLTrain train,
                                        BasicNetwork network, IMLDataSet trainingSet,
                                        int minutes)
        {
            int epoch = 1;
            long remaining;

            Console.WriteLine(@"Beginning training...");
            long start = Environment.TickCount;
            do
            {
                train.Iteration();

                long current = Environment.TickCount;
                long elapsed = (current - start) / 1000;
                remaining = minutes - elapsed / 60;

                Console.WriteLine(@"Iteration #" + Format.FormatInteger(epoch)
                                  + @" Error:" + Format.FormatPercent(train.Error)
                                  + @" elapsed time = " + Format.FormatTimeSpan((int)elapsed)
                                  + @" time left = "
                                  + Format.FormatTimeSpan((int)remaining * 60));
                epoch++;
            } while (remaining > 0 && !train.TrainingDone);
            train.FinishTraining();
        }


        /// <summary>
        /// Train the network, using the specified training Algo, and send the
        /// output to the console.
        /// </summary>
        /// <param name="train">The training method to use.</param>
        /// <param name="network">The network to train.</param>
        /// <param name="trainingSet">The training set.</param>
        /// <param name="seconds">The second to train for.</param>
        public static void TrainConsole(IMLTrain train, BasicNetwork network, IMLDataSet trainingSet, double seconds)
        {
            int epoch = 1;
            double remaining;

            Console.WriteLine(@"Beginning training...");
            long start = Environment.TickCount;
            do
            {
                train.Iteration();

                double current = Environment.TickCount;
                double elapsed = (current - start) / 1000;
                remaining = seconds - elapsed;

                Console.WriteLine(@"Iteration #" + Format.FormatInteger(epoch)
                                  + @" Error:" + Format.FormatPercent(train.Error)
                                  + @" elapsed time = " + Format.FormatTimeSpan((int)elapsed)
                                  + @" time left = "
                                  + Format.FormatTimeSpan((int)remaining));
                epoch++;
            } while (remaining > 0 && !train.TrainingDone);
            train.FinishTraining();
        }

        /// <summary>
        /// Train using RPROP and display progress to a dialog box.
        /// </summary>
        /// <param name="network">The network to train.</param>
        /// <param name="trainingSet">The training set to use.</param>
        public static void TrainDialog(BasicNetwork network,
                                       IMLDataSet trainingSet)
        {
            Prop train = new ResilientProp(network,
                                                         trainingSet)
            { ThreadCount = 0 };
            TrainDialog(train, network, trainingSet);
        }

        /// <summary>
        /// Train, using the specified training method, display progress to a dialog
        /// box.
        /// </summary>
        /// <param name="train">The training method to use.</param>
        /// <param name="network">The network to train.</param>
        /// <param name="trainingSet">The training set to use.</param>
        public static void TrainDialog(IMLTrain train,
                                       BasicNetwork network, IMLDataSet trainingSet)
        {
         //   var dialog = new TrainingDialog { Train = train };
          //  dialog.ShowDialog();
        }

        /// <summary>
        /// Train the network, to a specific error, send the output to the console.
        /// </summary>
        /// <param name="network">The network to train.</param>
        /// <param name="trainingSet">The training set to use.</param>
        /// <param name="error">The error level to train to.</param>
        public static void TrainToError(BasicNetwork network,
                                        IMLDataSet trainingSet, double error)
        {
            Prop train = new ResilientProp(network,
                                                         trainingSet)
            { ThreadCount = 0 };
            TrainToError(train, trainingSet, error);
        }

        /// <summary>
        /// Train to a specific error, using the specified training method, send the
        /// output to the console.
        /// </summary>
        /// <param name="train">The training method.</param>
        /// <param name="trainingSet">The training set to use.</param>
        /// <param name="error">The desired error level.</param>
        public static void TrainToError(IMLTrain train,
                                        IMLDataSet trainingSet,
                                        double error)
        {
            int epoch = 1;

            Console.WriteLine(@"Beginning training...");

            do
            {
                train.Iteration();

                Console.WriteLine(@"Iteration #" + Format.FormatInteger(epoch)
                                  + @" Error:" + Format.FormatPercent(train.Error)
                                  + @" Target Error: " + Format.FormatPercent(error));
                epoch++;
            } while (train.Error > error && !train.TrainingDone);
            train.FinishTraining();
        }

        /// <summary>
        /// Calculate a regression error.
        /// </summary>
        /// <param name="method">The method to check.</param>
        /// <param name="data">The data to check.</param>
        /// <returns>The error.</returns>
        public static double CalculateRegressionError(IMLRegression method,
                                                      IMLDataSet data)
        {
            var errorCalculation = new ErrorCalculation();
            if (method is IMLContext)
                ((IMLContext)method).ClearContext();


            foreach (IMLDataPair pair in data)
            {
                IMLData actual = method.Compute(pair.Input);
                errorCalculation.UpdateError(actual.Data, pair.Ideal.Data, pair.Significance);
            }
            return errorCalculation.Calculate();
        }

        /// <summary>
        /// Save the dataset to a CSV file.
        /// </summary>
        /// <param name="targetFile">The target file.</param>
        /// <param name="format">The format to use.</param>
        /// <param name="set">The data set.</param>
        public static void SaveCSV(FileInfo targetFile, CSVFormat format, IMLDataSet set)
        {

        }

        /// <summary>
        /// Calculate an error for a method that makes use of classification.
        /// </summary>
        /// <param name="method">The method to check.</param>
        /// <param name="data">The data to check.</param>
        /// <returns>The error.</returns>
        public static double CalculateClassificationError(IMLClassification method,
                                                          IMLDataSet data)
        {
            int total = 0;
            int correct = 0;


            foreach (IMLDataPair pair in data)
            {
                var ideal = (int)pair.Ideal[0];
                int actual = method.Classify(pair.Input);
                if (actual == ideal)
                    correct++;
                total++;
            }
            return (total - correct) / (double)total;
        }

        /// <summary>
        /// Load an EGB file to memory.
        /// </summary>
        /// <param name="filename">The file to load.</param>
        /// <returns>A memory data set.</returns>
        public static IMLDataSet LoadEGB2Memory(FileInfo filename)
        {
            var buffer = new BufferedMLDataSet(filename.ToString());
            var result = buffer.LoadToMemory();
            buffer.Close();
            return result;
        }

        /// <summary>
        /// Train to a specific error, using the specified training method, send the
        /// output to the console.
        /// </summary>
        ///
        /// <param name="train">The training method.</param>
        /// <param name="error">The desired error level.</param>
        public static void TrainToError(IMLTrain train, double error)
        {

            int epoch = 1;

            Console.Out.WriteLine(@"Beginning training...");

            do
            {
                train.Iteration();

                Console.Out.WriteLine(@"Iteration #" + Format.FormatInteger(epoch)
                        + @" Error:" + Format.FormatPercent(train.Error)
                        + @" Target Error: " + Format.FormatPercent(error));
                epoch++;
            } while ((train.Error > error) && !train.TrainingDone);
            train.FinishTraining();
        }

        /// <summary>
        /// Save the training set to an EGB file.
        /// </summary>
        /// <param name="egbFile">The EGB file to save to.</param>
        /// <param name="data">The training data to save.</param>
        public static void SaveEGB(FileInfo egbFile, IMLDataSet data)
        {
            var binary = new BufferedMLDataSet(egbFile.ToString());
            binary.Load(data);
            data.Close();
        }
    }
    
    public class TrainingSetUtil
    {
        /// <summary>
        /// Load a CSV file into a memory dataset.  
        /// </summary>
        ///
        /// <param name="format">The CSV format to use.</param>
        /// <param name="filename">The filename to load.</param>
        /// <param name="headers">True if there is a header line.</param>
        /// <param name="inputSize">The input size.  Input always comes first in a file.</param>
        /// <param name="idealSize">The ideal size, 0 for unsupervised.</param>
        /// <returns>A NeuralDataSet that holds the contents of the CSV file.</returns>
        public static IMLDataSet LoadCSVTOMemory(CSVFormat format, String filename,
                                                bool headers, int inputSize, int idealSize)
        {
            IMLDataSet result = new BasicMLDataSet();
            var csv = new ReadCSV(filename, headers, format);
            while (csv.Next())
            {
                IMLData ideal = null;
                int index = 0;

                IMLData input = new BasicMLData(inputSize);
                for (int i = 0; i < inputSize; i++)
                {
                    double d = csv.GetDouble(index++);
                    input[i] = d;
                }

                if (idealSize > 0)
                {
                    ideal = new BasicMLData(idealSize);
                    for (int i = 0; i < idealSize; i++)
                    {
                        double d = csv.GetDouble(index++);
                        ideal[i] = d;
                    }
                }

                IMLDataPair pair = new BasicMLDataPair(input, ideal);
                result.Add(pair);
            }

            return result;
        }

        /// <summary>
        /// Convert a training set to an array.
        /// </summary>
        /// <param name="training"></param>
        /// <returns></returns>
        public static ObjectPair<double[][], double[][]> TrainingToArray(
            IMLDataSet training)
        {
            var length = (int)training.Count;
            double[][] a = EngineArray.AllocateDouble2D(length, training.InputSize);
            double[][] b = EngineArray.AllocateDouble2D(length, training.IdealSize);

            int index = 0;

            foreach (IMLDataPair pair in training)
            {
                EngineArray.ArrayCopy(pair.InputArray, a[index]);
                EngineArray.ArrayCopy(pair.IdealArray, b[index]);
                index++;
            }

            return new ObjectPair<double[][], double[][]>(a, b);
        }
    }

    internal class DateUtil
    {
        /// <summary>
        /// January is 1.
        /// </summary>
        /// <param name="month"></param>
        /// <param name="day"></param>
        /// <param name="year"></param>
        /// <returns></returns>
        public static DateTime CreateDate(int month, int day, int year)
        {
            var result = new DateTime(year, month, day);
            return result;
        }

        /// <summary>
        /// Truncate a date, remove the time.
        /// </summary>
        /// <param name="date">The date to truncate.</param>
        /// <returns>The date without the time.</returns>
        public static DateTime TruncateDate(DateTime date)
        {
            return new DateTime(date.Year, date.Month, date.Day);
        }
    }

    internal class EnglishTimeUnitNames : ITimeUnitNames
    {
        #region ITimeUnitNames Members

        public String Code(TimeUnit unit)
        {
            switch (unit)
            {
                case TimeUnit.Seconds:
                    return "sec";
                case TimeUnit.Minutes:
                    return "min";
                case TimeUnit.Hours:
                    return "hr";
                case TimeUnit.Days:
                    return "d";
                case TimeUnit.Weeks:
                    return "w";
                case TimeUnit.Fortnights:
                    return "fn";
                case TimeUnit.Months:
                    return "m";
                case TimeUnit.Years:
                    return "y";
                case TimeUnit.Decades:
                    return "dec";
                case TimeUnit.Scores:
                    return "sc";
                case TimeUnit.Centuries:
                    return "c";
                case TimeUnit.Millennia:
                    return "m";
                default:
                    return "unk";
            }
        }

        public String Plural(TimeUnit unit)
        {
            switch (unit)
            {
                case TimeUnit.Seconds:
                    return "seconds";
                case TimeUnit.Minutes:
                    return "minutes";
                case TimeUnit.Hours:
                    return "hours";
                case TimeUnit.Days:
                    return "days";
                case TimeUnit.Weeks:
                    return "weeks";
                case TimeUnit.Fortnights:
                    return "fortnights";
                case TimeUnit.Months:
                    return "months";
                case TimeUnit.Years:
                    return "years";
                case TimeUnit.Decades:
                    return "decades";
                case TimeUnit.Scores:
                    return "scores";
                case TimeUnit.Centuries:
                    return "centures";
                case TimeUnit.Millennia:
                    return "millennia";
                default:
                    return "unknowns";
            }
        }

        public String Singular(TimeUnit unit)
        {
            switch (unit)
            {
                case TimeUnit.Seconds:
                    return "second";
                case TimeUnit.Minutes:
                    return "minute";
                case TimeUnit.Hours:
                    return "hour";
                case TimeUnit.Days:
                    return "day";
                case TimeUnit.Weeks:
                    return "week";
                case TimeUnit.Fortnights:
                    return "fortnight";
                case TimeUnit.Months:
                    return "month";
                case TimeUnit.Years:
                    return "year";
                case TimeUnit.Decades:
                    return "decade";
                case TimeUnit.Scores:
                    return "score";
                case TimeUnit.Centuries:
                    return "century";
                case TimeUnit.Millennia:
                    return "millenium";
                default:
                    return "unknown";
            }
        }

        #endregion
    }

    public static class NumericDateUtil
    {
        /// <summary>
        /// The numeric offset for a year.
        /// </summary>
        public const uint YearOffset = 10000;

        /// <summary>
        /// The numeric offset for a month.
        /// </summary>
        public const uint MonthOffset = 100;

        /// <summary>
        /// The numeric offset for an hour.
        /// </summary>
        public const uint HourOffset = 10000;

        /// <summary>
        /// The numeric offset for a minute.
        /// </summary>
        public const uint MinuteOffset = 100;

        /// <summary>
        /// Convert a date/time to a long.
        /// </summary>
        /// <param name="time">The time to convert.</param>
        /// <returns>A numeric date.</returns>
        public static ulong DateTime2Long(DateTime time)
        {
            return (ulong)(time.Day + (time.Month * MonthOffset) + (time.Year * YearOffset));
        }

        /// <summary>
        /// Convert a numeric date time to a regular date time.
        /// </summary>
        /// <param name="l">The numeric date time.</param>
        /// <returns>The converted date/time.</returns>
        public static DateTime Long2DateTime(ulong l)
        {
            var rest = (long)l;
            var year = (int)(rest / YearOffset);
            rest -= year * YearOffset;
            var month = (int)(rest / MonthOffset);
            rest -= month * MonthOffset;
            var day = (int)rest;
            return new DateTime(year, month, day);
        }

        /// <summary>
        /// Strip the time element.
        /// </summary>
        /// <param name="dt">The time-date element to strip.</param>
        /// <returns>A new date-time with the time stripped.</returns>
        public static DateTime StripTime(DateTime dt)
        {
            return new DateTime(dt.Year, dt.Month, dt.Day);
        }

        /// <summary>
        /// Determine of two values have the same date.
        /// </summary>
        /// <param name="d1">The first date/time.</param>
        /// <param name="d2">The second date/time.</param>
        /// <returns>True, if they have the same date.</returns>
        public static bool HaveSameDate(DateTime d1, DateTime d2)
        {
            return ((d1.Day == d2.Day) && (d1.Month == d2.Month) && (d1.Year == d2.Year));
        }

        /// <summary>
        /// Convert an int to a time.
        /// </summary>
        /// <param name="date">The date-time that provides date information.</param>
        /// <param name="i">The int that holds the time.</param>
        /// <returns>The converted date/time.</returns>
        internal static DateTime Int2Time(DateTime date, uint i)
        {
            uint rest = i;
            var hour = (int)(rest / HourOffset);
            rest -= (uint)(hour * HourOffset);
            var minute = (int)(rest / MonthOffset);
            rest -= (uint)(minute * MinuteOffset);
            var second = (int)rest;
            return new DateTime(date.Year, date.Month, date.Day, hour, minute, second);
        }

        /// <summary>
        /// Convert a time to an int.
        /// </summary>
        /// <param name="time">The time to convert.</param>
        /// <returns>The time as an int.</returns>
        internal static uint Time2Int(DateTime time)
        {
            return (uint)(time.Second + (time.Minute * MinuteOffset) + (time.Hour * HourOffset));
        }

        /// <summary>
        /// Get the year part of a numeric date.
        /// </summary>
        /// <param name="date">The numeric date.</param>
        /// <returns>The year.</returns>
        public static int GetYear(ulong date)
        {
            return (int)(date / YearOffset);
        }

        /// <summary>
        /// Get the year month of a numeric date.
        /// </summary>
        /// <param name="l">The numeric date.</param>
        /// <returns>The month.</returns>
        public static int GetMonth(ulong l)
        {
            var rest = (long)l;
            var year = (int)(rest / YearOffset);
            rest -= year * YearOffset;
            return (int)(rest / MonthOffset);
        }

        /// <summary>
        /// Get the minute period.
        /// </summary>
        /// <param name="time">The time.</param>
        /// <param name="period">The period size, in minutes.</param>
        /// <returns>The number of minutes per period.</returns>
        public static int GetMinutePeriod(uint time, int period)
        {
            uint rest = time;
            var hour = (int)(rest / HourOffset);
            rest -= (uint)(hour * HourOffset);
            var minute = (int)(rest / MonthOffset);

            int minutes = minute + (hour * 60);
            return minutes / period;
        }

        /// <summary>
        /// Combine a date and a time.
        /// </summary>
        /// <param name="date">The date.</param>
        /// <param name="time">The time.</param>
        /// <returns>The combined time.</returns>
        public static ulong Combine(ulong date, uint time)
        {
            return (date * 1000000) + time;
        }

        /// <summary>
        /// Get the day of the week for the specified numeric date.
        /// </summary>
        /// <param name="p">The time to check.</param>
        /// <returns>The day of the week, 0 is a sunday.</returns>
        public static int GetDayOfWeek(ulong p)
        {
            DateTime t = Long2DateTime(p);
            switch (t.DayOfWeek)
            {
                case DayOfWeek.Sunday:
                    return 0;
                case DayOfWeek.Monday:
                    return 1;
                case DayOfWeek.Tuesday:
                    return 2;
                case DayOfWeek.Wednesday:
                    return 3;
                case DayOfWeek.Thursday:
                    return 4;
                case DayOfWeek.Friday:
                    return 5;
                case DayOfWeek.Saturday:
                    return 6;
                default:
                    // no way this should happen!
                    return -1;
            }
        }
    }

    internal class TimeSpanUtil
    {
        private DateTime _from;
        private DateTime _to;

        public TimeSpanUtil(DateTime from, DateTime to)
        {
            _from = from;
            _to = to;
        }

        public DateTime From
        {
            get { return _from; }
        }

        public DateTime To
        {
            get { return _to; }
        }


        public long GetSpan(TimeUnit unit)
        {
            switch (unit)
            {
                case TimeUnit.Ticks:
                    return GetSpanTicks();
                case TimeUnit.Seconds:
                    return GetSpanSeconds();
                case TimeUnit.Minutes:
                    return GetSpanMinutes();
                case TimeUnit.Hours:
                    return GetSpanHours();
                case TimeUnit.Days:
                    return GetSpanDays();
                case TimeUnit.Weeks:
                    return GetSpanWeeks();
                case TimeUnit.Fortnights:
                    return GetSpanFortnights();
                case TimeUnit.Months:
                    return GetSpanMonths();
                case TimeUnit.Years:
                    return GetSpanYears();
                case TimeUnit.Scores:
                    return GetSpanScores();
                case TimeUnit.Centuries:
                    return GetSpanCenturies();
                case TimeUnit.Millennia:
                    return GetSpanMillennia();
                default:
                    return 0;
            }
        }

        private long GetSpanTicks()
        {
            TimeSpan span = _to.Subtract(_from);
            return span.Ticks;
        }

        private long GetSpanSeconds()
        {
            TimeSpan span = _to.Subtract(_from);
            return span.Ticks / TimeSpan.TicksPerSecond;
        }

        private long GetSpanMinutes()
        {
            return GetSpanSeconds() / 60;
        }

        private long GetSpanHours()
        {
            return GetSpanMinutes() / 60;
        }

        private long GetSpanDays()
        {
            return GetSpanHours() / 24;
        }

        private long GetSpanWeeks()
        {
            return GetSpanDays() / 7;
        }

        private long GetSpanFortnights()
        {
            return GetSpanWeeks() / 2;
        }

        private long GetSpanMonths()
        {
            return (_to.Month - _from.Month) + (_to.Year - _from.Year) * 12;
        }

        private long GetSpanYears()
        {
            return GetSpanMonths() / 12;
        }

        private long GetSpanScores()
        {
            return GetSpanYears() / 20;
        }

        private long GetSpanCenturies()
        {
            return GetSpanYears() / 100;
        }

        private long GetSpanMillennia()
        {
            return GetSpanYears() / 1000;
        }
    }

    public class ValidateNetwork
    {
        /// <summary>
        /// Validate that the specified data can be used with the method.
        /// </summary>
        /// <param name="method">The method to validate.</param>
        /// <param name="training">The training data.</param>
        public static void ValidateMethodToData(IMLMethod method, IMLDataSet training)
        {
            if (!(method is IMLInput) || !(method is IMLOutput))
            {
                throw new SyntError(
                    "This machine learning method is not compatible with the provided data.");
            }

            int trainingInputCount = training.InputSize;
            int trainingOutputCount = training.IdealSize;
            int methodInputCount = 0;
            int methodOutputCount = 0;

            if (method is IMLInput)
            {
                methodInputCount = ((IMLInput)method).InputCount;
            }

            if (method is IMLOutput)
            {
                methodOutputCount = ((IMLOutput)method).OutputCount;
            }

            if (methodInputCount != trainingInputCount)
            {
                throw new SyntError(
                    "The machine learning method has an input length of "
                    + methodInputCount + ", but the training data has "
                    + trainingInputCount + ". They must be the same.");
            }

            if (!(method is BasicPNN))
            {
                if (trainingOutputCount > 0 && methodOutputCount != trainingOutputCount)
                {
                    throw new SyntError(
                        "The machine learning method has an output length of "
                        + methodOutputCount
                        + ", but the training data has "
                        + trainingOutputCount + ". They must be the same.");
                }
            }
        }
    }

    public static class DirectoryUtil
    {
        /// <summary>
        /// Default buffer size for read/write operations.
        /// </summary>
        public const int BufferSize = 1024;

        /// <summary>
        /// Copy the specified file.
        /// </summary>
        /// <param name="source">The file to copy.</param>
        /// <param name="target">The target of the copy.</param>
        public static void CopyFile(String source, String target)
        {
            try
            {
                var buffer = new byte[BufferSize];

                // open the files before the copy
                Stream inFile = new FileStream(source, FileMode.Open);
                Stream outFile = new FileStream(target, FileMode.OpenOrCreate);

                // perform the copy
                int packetSize = 0;

                while (packetSize != -1)
                {
                    packetSize = inFile.Read(buffer, 0, buffer.Length);
                    if (packetSize != -1)
                    {
                        outFile.Write(buffer, 0, packetSize);
                    }
                }

                // close the files after the copy
                inFile.Close();
                outFile.Close();
            }
            catch (IOException e)
            {
                throw new SyntError(e);
            }
        }


        /// <summary>
        /// Read the entire contents of a stream into a string.
        /// </summary>
        /// <param name="istream">The input stream to read from.</param>
        /// <returns>The string that was read in.</returns>
        public static String ReadStream(Stream istream)
        {
            try
            {
                var sb = new StringBuilder(1024);

                var chars = new byte[BufferSize];
                while ((istream.Read(chars, 0, chars.Length)) > -1)
                {
                    string s = Encoding.ASCII.GetString(chars);
                    sb.Append(s);
                }

                return sb.ToString();
            }
            catch (IOException e)
            {
#if logging
                LOGGER.Error("Exception", e);
#endif
                throw new SyntError(e);
            }
        }

        /// <summary>
        /// Read the entire contents of a stream into a string.
        /// </summary>
        /// <param name="filename">The input stream to read from.</param>
        /// <returns>The string that was read in.</returns>
        public static String ReadTextFile(String filename)
        {
            Stream stream = new FileStream(filename, FileMode.Open);
            String result = ReadStream(stream);
            stream.Close();
            return result;
        }
    }

    public sealed class SyntValidate
    {
        /// <summary>
        /// Private constructor.
        /// </summary>
        ///
        private SyntValidate()
        {
        }

        /// <summary>
        /// Validate a network for training.
        /// </summary>
        ///
        /// <param name="network">The network to validate.</param>
        /// <param name="training">The training set to validate.</param>
        public static void ValidateNetworkForTraining(IContainsFlat network,
                                                      IMLDataSet training)
        {
            int inputCount = network.Flat.InputCount;
            int outputCount = network.Flat.OutputCount;

            if (inputCount != training.InputSize)
            {
                throw new NeuralNetworkError("The input layer size of "
                                             + inputCount + " must match the training input size of "
                                             + training.InputSize + ".");
            }

            if ((training.IdealSize > 0)
                && (outputCount != training.IdealSize))
            {
                throw new NeuralNetworkError("The output layer size of "
                                             + outputCount + " must match the training input size of "
                                             + training.IdealSize + ".");
            }
        }
    }

    public class EngineArray
    {
        public const int DoubleSize = sizeof(double);

        /// <summary>
        /// Copy a double array.
        /// </summary>
        /// <param name="input">The array to copy.</param>
        /// <returns>The result of the copy.</returns>
        public static double[] ArrayCopy(double[] input)
        {
            var result = new double[input.Length];
            ArrayCopy(input, result);
            return result;
        }

        /// <summary>
        /// Copy an int array.
        /// </summary>
        /// <param name="input">The array to copy.</param>
        /// <returns>The result of the copy.</returns>
        public static int[] ArrayCopy(int[] input)
        {
            var result = new int[input.Length];
            ArrayCopy(input, result);
            return result;
        }


        /// <summary>
        /// Completely copy one array into another. 
        /// </summary>
        /// <param name="src">Source array.</param>
        /// <param name="dst">Destination array.</param>
        public static void ArrayCopy(double[] src, double[] dst)
        {
            Array.Copy(src, dst, src.Length);
        }

        /// <summary>
        /// Completely copy one array into another. 
        /// </summary>
        /// <param name="src">Source array.</param>
        /// <param name="dst">Destination array.</param>
        public static void ArrayCopy(int[] src, int[] dst)
        {
            Array.Copy(src, dst, src.Length);
        }

        /// <summary>
        /// Calculate the product of two vectors (a scalar value).
        /// </summary>
        /// <param name="a">First vector to multiply.</param>
        /// <param name="b">Second vector to multiply.</param>
        /// <returns>The product of the two vectors (a scalar value).</returns>
        public static double VectorProduct(double[] a, double[] b)
        {
            int length = a.Length;
            double value = 0;

            for (int i = 0; i < length; ++i)
                value += a[i] * b[i];

            return value;
        }

        /// <summary>
        /// Allocate a 2D array of doubles.
        /// </summary>
        /// <param name="rows">The number of rows.</param>
        /// <param name="cols">The number of columns.</param>
        /// <returns>The array.</returns>
        public static double[][] AllocateDouble2D(int rows, int cols)
        {
            var result = new double[rows][];
            for (int i = 0; i < rows; i++)
            {
                result[i] = new double[cols];
            }
            return result;
        }

        /// <summary>
        /// Allocate a 2D array of bools.
        /// </summary>
        /// <param name="rows">The number of rows.</param>
        /// <param name="cols">The number of columns.</param>
        /// <returns>The array.</returns>
        public static bool[][] AllocateBool2D(int rows, int cols)
        {
            var result = new bool[rows][];
            for (int i = 0; i < rows; i++)
            {
                result[i] = new bool[cols];
            }
            return result;
        }

        /// <summary>
        /// Copy an array of doubles.
        /// </summary>
        /// <param name="source">The source array.</param>
        /// <param name="sourceIndex">The source index.</param>
        /// <param name="output">The output array.</param>
        /// <param name="targetIndex">The output index.</param>
        /// <param name="size">The size to copy.</param>
        public static void ArrayCopy(double[] source, int sourceIndex, double[] output, int targetIndex, int size)
        {
            //Array.Copy(source, sourceIndex, output, targetIndex, size);
            Buffer.BlockCopy(source, sourceIndex * DoubleSize, output, targetIndex * DoubleSize, size * DoubleSize);
        }

        /// <summary>
        /// Convert the collection to an array list of doubles.
        /// </summary>
        /// <param name="list">The list to convert.</param>
        /// <returns>The array of doubles.</returns>
        public static double[] ListToDouble(IList<double> list)
        {
            var result = new double[list.Count];
            int index = 0;
            foreach (double obj in list)
            {
                result[index++] = obj;
            }

            return result;
        }

        /// <summary>
        /// Fill the specified array with the specified value.
        /// </summary>
        /// <param name="p">The array to fill.</param>
        /// <param name="v">The value to fill.</param>
        internal static void Fill(double[] p, double v)
        {
            for (int i = 0; i < p.Length; i++)
                p[i] = v;
        }

        /// <summary>
        /// Search for a string in an array. 
        /// </summary>
        /// <param name="search">Where to search.</param>
        /// <param name="searchFor">What we are looking for.</param>
        /// <returns>The index that the string occurs at.</returns>
        public static int FindStringInArray(String[] search, String searchFor)
        {
            for (int i = 0; i < search.Length; i++)
            {
                if (search[i].Equals(searchFor))
                    return i;
            }
            return -1;
        }


        /// <summary>
        /// Gets the last N closing values of a double serie;
        /// copied in a new double serie.
        /// </summary>
        /// <param name="lenth">The lenth to get.</param>
        /// <param name="closes"></param>
        /// <returns>a double serie with the last n requested values.</returns>
        public double[] TransferNvaluesOfSerie(int lenth, double[] closes)
        {
            if (closes != null)
            {
                double[] output;

                if (closes.Length > lenth)
                {
                    //we have more closing values than our length so we'll return values based on last - Length.
                    int startIndex = closes.Length - lenth;
                    output = new double[lenth];
                    EngineArray.ArrayCopy(closes, startIndex, output, 0, lenth);
                    return output;
                }
                if (closes.Length == lenth)
                {
                    //we have the same values , so we just return the full closing values.
                    int startIndex = closes.Length - lenth;
                    output = new double[lenth];
                    EngineArray.ArrayCopy(closes, startIndex, output, 0, lenth);
                    return output;
                }
            }

            //we didn't get any right values to return N lenght of the serie.
            return null;

        }

        /// <summary>
        /// Copy a 2d array.
        /// </summary>
        /// <param name="source">The source.</param>
        /// <returns>The result.</returns>
        public static double[][] ArrayCopy(double[][] source)
        {
            double[][] result = AllocateDouble2D(source.Length, source[0].Length);

            for (int row = 0; row < source.Length; row++)
            {
                for (int col = 0; col < source[0].Length; col++)
                {
                    result[row][col] = source[row][col];
                }
            }

            return result;
        }

        /// <summary>
        /// Copy a float array to a double array.
        /// </summary>
        /// <param name="source">The double array.</param>
        /// <param name="target">The float array.</param>
        public static void ArrayCopy(float[] source, double[] target)
        {
            for (int i = 0; i < source.Length; i++)
            {
                target[i] = source[i];
            }
        }

        /// <summary>
        /// Copy a double array to a float array.
        /// </summary>
        /// <param name="source">The double array.</param>
        /// <param name="target">The float array.</param>
        public static void ArrayCopy(double[] source, float[] target)
        {
            for (int i = 0; i < source.Length; i++)
            {
                target[i] = (float)source[i];
            }
        }

        /// <summary>
        /// Fill the array with the specified value.
        /// </summary>
        /// <param name="target">The array to fill.</param>
        /// <param name="v">The value to fill.</param>
        public static void Fill(double[] target, int v)
        {
            for (int i = 0; i < target.Length; i++)
                target[i] = v;
        }

        /// <summary>
        /// Fill the array with the specified value.
        /// </summary>
        /// <param name="target">The array to fill.</param>
        /// <param name="v">The value to fill.</param>
        public static void Fill(float[] target, int v)
        {
            for (int i = 0; i < target.Length; i++)
                target[i] = v;
        }

        /// <summary>
        /// Get the index of the largest value in the array.
        /// </summary>
        /// <param name="data">The array to search.</param>
        /// <returns>The index.</returns>
        public static int IndexOfLargest(double[] data)
        {
            int result = -1;

            for (int i = 0; i < data.Length; i++)
            {
                if (result == -1 || data[i] > data[result])
                    result = i;
            }

            return result;
        }
        /// <summary>
        /// Get the min value in an array.
        /// </summary>
        /// <param name="weights">The array to search.</param>
        /// <returns>The result.</returns>
        public static double Min(double[] weights)
        {
            double result = double.MaxValue;
            for (int i = 0; i < weights.Length; i++)
            {
                result = Math.Min(result, weights[i]);
            }
            return result;
        }

        /// <summary>
        /// Get the max value from an array.
        /// </summary>
        /// <param name="weights">The array to search.</param>
        /// <returns>The value.</returns>
        public static double Max(double[] weights)
        {
            double result = Double.MinValue;
            for (int i = 0; i < weights.Length; i++)
            {
                result = Math.Max(result, weights[i]);
            }
            return result;
        }

        /// <summary>
        /// Put all elements from one dictionary to another.
        /// </summary>
        /// <typeparam name="TK">The key type.</typeparam>
        /// <typeparam name="TV">The value type.</typeparam>
        /// <param name="source">The source dictionary.</param>
        /// <param name="target">The target dictionary.</param>
        public static void PutAll<TK, TV>(IDictionary<TK, TV> source, IDictionary<TK, TV> target)
        {
            foreach (var x in source)
            {
                target.Add(x);
            }
        }

        /// <summary>
        /// Determine if the array contains the specified number.
        /// </summary>
        /// <param name="array">The array to search.</param>
        /// <param name="target">The number being searched for.</param>
        /// <returns>True, if the number was found.</returns>
        public static bool Contains(int[] array, int target)
        {
            for (int i = 0; i < array.Length; i++)
            {
                if (array[i] == target)
                {
                    return true;
                }
            }

            return false;
        }

        /// <summary>
        /// Get the index of the max value in the array.
        /// </summary>
        /// <param name="data">The array to search.</param>
        /// <returns>The result</returns>
        public static int MaxIndex(double[] data)
        {
            int result = -1;
            for (int i = 0; i < data.Length; i++)
            {
                if (result == -1 || data[i] > data[result])
                {
                    result = i;
                }
            }
            return result;
        }

        /// <summary>
        /// Get the index of the max value in the array.
        /// </summary>
        /// <param name="data">The array to search.</param>
        /// <returns>The result</returns>
        public static int MaxIndex(int[] data)
        {
            int result = -1;
            for (int i = 0; i < data.Length; i++)
            {
                if (result == -1 || data[i] > data[result])
                {
                    result = i;
                }
            }
            return result;
        }


        /// <summary>
        /// Creates a jagged array and initializes it.
        /// You can virtually create any kind of jagged array up to N dimension.
        /// double[][] resultingArray = CreateArray  <double[ ]> (2, () => CreateArray<double>(100, () => 0));
        /// Create a double[2] [100] , with all values at 0..
        /// </summary>
        /// <typeparam name="T"></typeparam>
        /// <param name="cnt">The CNT.</param>
        /// <param name="itemCreator">The item creator.</param>
        /// <returns></returns>
        public static T[] CreateArray<T>(int cnt, Func<T> itemCreator)
        {
            T[] result = new T[cnt];
            for (int i = 0; i < result.Length; i++)
            {
                result[i] = itemCreator();
            }
            return result;
        }

        /// <summary>
        /// Fill the array with the specified value.
        /// </summary>
        /// <param name="array">The array.</param>
        /// <param name="v">The value.</param>
        public static void Fill(bool[] array, bool v)
        {
            for (int i = 0; i < array.Length; i++)
            {
                array[i] = v;
            }
        }

        /// <summary>
        /// Add two vectors.
        /// </summary>
        /// <param name="d">First vector.</param>
        /// <param name="m">Second vector.</param>
        /// <returns>Result vector.</returns>
        public static double[] Add(double[] d, double[] m)
        {
            double[] result = new double[d.Length];
            for (int i = 0; i < d.Length; i++)
            {
                result[i] = d[i] + m[i];
            }
            return result;
        }

        /// <summary>
        /// Subtract two vectors.
        /// </summary>
        /// <param name="a">First vector.</param>
        /// <param name="b">Second vector.</param>
        /// <returns>Result vector.</returns>
        public static double[] Subtract(double[] a, double[] b)
        {
            double[] result = new double[a.Length];
            for (int i = 0; i < a.Length; i++)
            {
                result[i] = a[i] - b[i];
            }
            return result;
        }

        internal static int[][] AllocateInt2D(int rows, int cols)
        {
            var result = new int[rows][];
            for (int i = 0; i < rows; i++)
            {
                result[i] = new int[cols];
            }
            return result;

        }

        public static double[][][] AllocDouble3D(int x, int y, int z)
        {
            var result = new double[x][][];
            for (int i = 0; i < x; i++)
            {
                result[i] = new double[y][];
                for (int j = 0; j < y; j++)
                {
                    result[i][j] = new double[z];
                }
            }
            return result;

        }

        /// <summary>
        /// Copy one double 2d array to another.
        /// </summary>
        /// <param name="source">The source array.</param>
        /// <param name="target">The target array.</param>
        public static void ArrayCopy(double[][] source, double[][] target)
        {
            for (var row = 0; row < source.Length; row++)
            {
                for (var col = 0; col < source[row].Length; col++)
                {
                    target[row][col] = source[row][col];
                }
            }
        }

        /// <summary>
        /// Calculate the Euclidean distance between two vectors.
        /// </summary>
        /// <param name="p1">The first vector.</param>
        /// <param name="p2">The second vector.</param>
        /// <returns>The distance.</returns>
        public static double EuclideanDistance(double[] p1, double[] p2)
        {
            double sum = 0;
            for (int i = 0; i < p1.Length; i++)
            {
                double d = p1[i] - p2[i];
                sum += d * d;
            }
            return Math.Sqrt(sum);
        }
    }

    public class Format
    {
        /// <summary>
        /// One hundred percent.
        /// </summary>
        public const double HundredPercent = 100.0;

        /// <summary>
        /// Bytes in a KB.
        /// </summary>
        public const long MemoryK = 1024;

        /// <summary>
        /// Bytes in a MB.
        /// </summary>
        public const long MemoryMeg = (1024 * MemoryK);

        /// <summary>
        /// Bytes in a GB.
        /// </summary>
        public const long MemoryGig = (1024 * MemoryMeg);

        /// <summary>
        /// Bytes in a TB.
        /// </summary>
        public const long MemoryTera = (1024 * MemoryGig);

        /// <summary>
        /// Seconds in a minute.
        /// </summary>
        public const int SecondsInaMinute = 60;

        /// <summary>
        /// Seconds in an hour.
        /// </summary>
        public const int SecondsInaHour = SecondsInaMinute * 60;

        /// <summary>
        /// Seconds in a day.
        /// </summary>
        public const int SecondsInaDay = SecondsInaHour * 24;

        /// <summary>
        /// Miliseconds in a day.
        /// </summary>
        public const long MiliInSec = 1000;

        /// <summary>
        /// Private constructor.
        /// </summary>
        private Format()
        {
        }

        /// <summary>
        /// Format a double.
        /// </summary>
        /// <param name="d">The double value to format.</param>
        /// <param name="i">The number of decimal places.</param>
        /// <returns>The double as a string.</returns>
        public static String FormatDouble(double d, int i)
        {
            if (Double.IsNaN(d) || Double.IsInfinity(d))
                return "NaN";
            return d.ToString("N" + i);
        }


        /// <summary>
        /// Format a memory amount, to something like 32 MB.
        /// </summary>
        /// <param name="memory">The amount of bytes.</param>
        /// <returns>The formatted memory size.</returns>
        public static String FormatMemory(long memory)
        {
            if (memory < MemoryK)
            {
                return memory + " bytes";
            }
            if (memory < MemoryMeg)
            {
                return FormatDouble((memory) / ((double)MemoryK), 2) + " KB";
            }
            if (memory < MemoryGig)
            {
                return FormatDouble((memory) / ((double)MemoryMeg), 2) + " MB";
            }
            if (memory < MemoryTera)
            {
                return FormatDouble((memory) / ((double)MemoryGig), 2) + " GB";
            }
            return FormatDouble((memory) / ((double)MemoryTera), 2) + " TB";
        }

        /// <summary>
        /// Format an integer.
        /// </summary>
        /// <param name="i">The integer.</param>
        /// <returns>The string.</returns>
        public static String FormatInteger(int i)
        {
            return String.Format("{0:n0}", i);
        }

        /// <summary>
        /// Format a percent.  Using 6 decimal places.
        /// </summary>
        /// <param name="e">The percent to format.</param>
        /// <returns>The formatted percent.</returns>
        public static String FormatPercent(double e)
        {
            if (Double.IsNaN(e) || Double.IsInfinity(e))
                return "NaN";
            return (e * 100.0).ToString("N6") + "%";
        }

        /// <summary>
        /// Format a percent with no decimal places.
        /// </summary>
        /// <param name="e">The format to percent.</param>
        /// <returns>The formatted percent.</returns>
        public static String FormatPercentWhole(double e)
        {
            if (Double.IsNaN(e) || Double.IsInfinity(e))
                return "NaN";
            return (e * 100.0).ToString("N0") + "%";
        }

        /// <summary>
        /// Format a time span as seconds, minutes, hours and days.
        /// </summary>
        /// <param name="seconds">The number of seconds in the timespan.</param>
        /// <returns>The formatted timespan.</returns>
        public static String FormatTimeSpan(int seconds)
        {
            int secondsCount = seconds;
            int days = seconds / SecondsInaDay;
            secondsCount -= days * SecondsInaDay;
            int hours = secondsCount / SecondsInaHour;
            secondsCount -= hours * SecondsInaHour;
            int minutes = secondsCount / SecondsInaMinute;
            secondsCount -= minutes * SecondsInaMinute;

            var result = new StringBuilder();

            if (days > 0)
            {
                result.Append(days);
                result.Append(days > 1 ? " days " : " day ");
            }

            result.Append(hours.ToString("00"));
            result.Append(':');
            result.Append(minutes.ToString("00"));
            result.Append(':');
            result.Append(secondsCount.ToString("00"));

            return result.ToString();
        }

        /// <summary>
        /// Format a boolean to yes/no.
        /// </summary>
        /// <param name="p">The default answer.</param>
        /// <returns>A string form of the boolean.</returns>
        public static string FormatYesNo(bool p)
        {
            return p ? "Yes" : "No";
        }
    }

    public class HTMLReport
    {
        /// <summary>
        /// Text.
        /// </summary>
        private readonly StringBuilder _text;

        /// <summary>
        /// Construct the object.
        /// </summary>
        public HTMLReport()
        {
            _text = new StringBuilder();
        }

        /// <summary>
        /// Begin an HTML tag.
        /// </summary>
        public void BeginHTML()
        {
            _text.Append("<html>");
        }

        /// <summary>
        /// End an HTML tag.
        /// </summary>
        public void EndHTML()
        {
            _text.Append("</html>");
        }

        /// <summary>
        /// Set the title.
        /// </summary>
        /// <param name="str">The title.</param>
        public void Title(String str)
        {
            _text.Append("<head><title>");
            _text.Append(str);
            _text.Append("</title></head>");
        }

        /// <summary>
        /// Begin an HTML para.
        /// </summary>
        public void BeginPara()
        {
            _text.Append("<p>");
        }

        /// <summary>
        /// End an HTML para.
        /// </summary>
        public void EndPara()
        {
            _text.Append("</p>");
        }

        /// <summary>
        /// Display in bold.
        /// </summary>
        /// <param name="str"></param>
        public void Bold(String str)
        {
            _text.Append("<b>");
            _text.Append(Syntesis(str));
            _text.Append("</b>");
        }

        /// <summary>
        /// Display a para.
        /// </summary>
        /// <param name="str">The para to display.</param>
        public void Para(String str)
        {
            _text.Append("<p>");
            _text.Append(Syntesis(str));
            _text.Append("</p>");
        }

        /// <summary>
        /// Clear the report.
        /// </summary>
        public void Clear()
        {
            _text.Length = 0;
        }

        /// <summary>
        /// Convert the report to a string.
        /// </summary>
        /// <returns>The report text.</returns>
        public override String ToString()
        {
            return _text.ToString();
        }

        /// <summary>
        /// Begin the HTML body.
        /// </summary>
        public void BeginBody()
        {
            _text.Append("<body>");
        }

        /// <summary>
        /// End the HTML body.
        /// </summary>
        public void EndBody()
        {
            _text.Append("</body>");
        }

        /// <summary>
        /// Create a H1.
        /// </summary>
        /// <param name="title"></param>
        public void H1(String title)
        {
            _text.Append("<h1>");
            _text.Append(Syntesis(title));
            _text.Append("</h1>");
        }

        /// <summary>
        /// Begin a table.
        /// </summary>
        public void BeginTable()
        {
            _text.Append("<table border=\"1\">");
        }

        /// <summary>
        /// End a table.
        /// </summary>
        public void EndTable()
        {
            _text.Append("</table>");
        }

        /// <summary>
        /// Begin a row of a table.
        /// </summary>
        public void BeginRow()
        {
            _text.Append("<tr>");
        }

        /// <summary>
        /// End a row of a table.
        /// </summary>
        public void EndRow()
        {
            _text.Append("</tr>");
        }

        /// <summary>
        /// Add a header cell.
        /// </summary>
        /// <param name="head">The text to use.</param>
        public void Header(String head)
        {
            _text.Append("<th>");
            _text.Append(Syntesis(head));
            _text.Append("</th>");
        }

        /// <summary>
        /// Add a cell, no column span.
        /// </summary>
        /// <param name="head">The head of that call.</param>
        public void Cell(String head)
        {
            Cell(head, 0);
        }

        /// <summary>
        /// Add a cell to a table.
        /// </summary>
        /// <param name="head">The text for the cell.</param>
        /// <param name="colSpan">The col span.</param>
        public void Cell(String head, int colSpan)
        {
            _text.Append("<td");
            if (colSpan > 0)
            {
                _text.Append(" colspan=\"");
                _text.Append(colSpan);
                _text.Append("\"");
            }
            _text.Append(">");
            _text.Append(Syntesis(head));
            _text.Append("</td>");
        }

        /// <summary>
        /// Add a name-value pair to a table.  This includes a row.
        /// </summary>
        /// <param name="name">The name.</param>
        /// <param name="v">The value.</param>
        public void TablePair(String name, String v)
        {
            BeginRow();
            _text.Append("<td><b>" + Syntesis(name) + "</b></td>");
            Cell(v);
            EndRow();
        }

        /// <summary>
        /// Add a H2.
        /// </summary>
        /// <param name="title">The title.</param>
        public void H2(String title)
        {
            _text.Append("<h2>");
            _text.Append(Syntesis(title));
            _text.Append("</h2>");
        }

        /// <summary>
        /// Add a H3.
        /// </summary>
        /// <param name="title">The title.</param>
        public void H3(String title)
        {
            _text.Append("<h3>");
            _text.Append(Syntesis(title));
            _text.Append("</h3>");
        }

        /// <summary>
        /// Begin a list.
        /// </summary>
        public void BeginList()
        {
            _text.Append("<ul>");
        }

        /// <summary>
        /// Add a list item.
        /// </summary>
        /// <param name="str">The item added.</param>
        public void ListItem(String str)
        {
            _text.Append("<li>");
            _text.Append(Syntesis(str));
        }

        /// <summary>
        /// End a list.
        /// </summary>
        public void EndList()
        {
            _text.Append("</ul>");
        }

        /// <summary>
        /// Begin a new table in a cell.
        /// </summary>
        /// <param name="colSpan">The column span.</param>
        public void BeginTableInCell(int colSpan)
        {
            _text.Append("<td");
            if (colSpan > 0)
            {
                _text.Append(" colspan=\"");
                _text.Append(colSpan);
                _text.Append("\"");
            }
            _text.Append(">");
            _text.Append("<table border=\"1\" width=\"100%\">");
        }

        /// <summary>
        /// End a table in a cell.
        /// </summary>
        public void EndTableInCell()
        {
            _text.Append("</table></td>");
        }

        /// <summary>
        /// Syntesis a string for HTML.
        /// </summary>
        /// <param name="str">The string to Syntesis.</param>
        /// <returns>The Syntesisd string.</returns>
        public static String Syntesis(String str)
        {
            var result = new StringBuilder();
            for (int i = 0; i < str.Length; i++)
            {
                char ch = str[i];

                if (ch == '<')
                {
                    result.Append("&lt;");
                }
                else if (ch == '>')
                {
                    result.Append("&gt;");
                }
                else if (ch == '&')
                {
                    result.Append("&amp;");
                }
                else
                {
                    result.Append(ch);
                }

            }
            return result.ToString();
        }
    }

    public class ObjectCloner
    {
        /// <summary>
        /// Private constructor.
        /// </summary>
        private ObjectCloner()
        {
        }

        /// <summary>
        /// Perform a deep copy.
        /// </summary>
        /// <param name="oldObj">The old object.</param>
        /// <returns>The new object.</returns>
        public static Object DeepCopy(Object oldObj)
        {
            var formatter = new BinaryFormatter();

            using (var memory = new MemoryStream())
            {
                try
                {
                    // serialize and pass the object
                    formatter.Serialize(memory, oldObj);
                    memory.Flush();
                    memory.Position = 0;

                    // return the new object
                    return formatter.Deserialize(memory);
                }
                catch (Exception e)
                {
                    throw new SyntError(e);
                }
            }
        }
    }

    public class ObjectPair<TA, TB>
    {
        /// <summary>
        /// The first object.
        /// </summary>
        private readonly TA _a;

        /// <summary>
        /// The second object.
        /// </summary>
        private readonly TB _b;

        /// <summary>
        /// Construct an object pair. 
        /// </summary>
        /// <param name="a">The first object.</param>
        /// <param name="b">The second object.</param>
        public ObjectPair(TA a, TB b)
        {
            _a = a;
            _b = b;
        }

        /// <summary>
        /// The first object.
        /// </summary>
        public TA A
        {
            get { return _a; }
        }

        /// <summary>
        /// The second object.
        /// </summary>
        public TB B
        {
            get { return _b; }
        }
    }

    public class ParamsHolder
    {
        /// <summary>
        /// The format that numbers will be in.
        /// </summary>
        ///
        private readonly CSVFormat _format;

        /// <summary>
        /// The params that are to be parsed.
        /// </summary>
        ///
        private readonly IDictionary<String, String> _paras;

        /// <summary>
        /// Construct the object. Allow the format to be specified.
        /// </summary>
        ///
        /// <param name="theParams">The params to be used.</param>
        /// <param name="theFormat">The format to be used.</param>
        public ParamsHolder(IDictionary<String, String> theParams, CSVFormat theFormat)
        {
            _paras = theParams;
            _format = theFormat;
        }

        /// <summary>
        /// Construct the object. Allow the format to be specified.
        /// </summary>
        ///
        /// <param name="theParams">The params to be used.</param>
        public ParamsHolder(IDictionary<String, String> theParams) : this(theParams, CSVFormat.EgFormat)
        {
        }


        /// <value>the params</value>
        public IDictionary<String, String> Params
        {
            get { return _paras; }
        }


        /// <summary>
        /// Get a param as a string.
        /// </summary>
        ///
        /// <param name="name">The name of the string.</param>
        /// <param name="required">True if this value is required.</param>
        /// <param name="defaultValue">The default value.</param>
        /// <returns>The value.</returns>
        public String GetString(String name, bool required, String defaultValue)
        {
            if (_paras.ContainsKey(name))
            {
                return _paras[name];
            }
            if (required)
            {
                throw new SyntError("Missing property: " + name);
            }
            return defaultValue;
        }

        /// <summary>
        /// Get a param as a integer.
        /// </summary>
        ///
        /// <param name="name">The name of the integer.</param>
        /// <param name="required">True if this value is required.</param>
        /// <param name="defaultValue">The default value.</param>
        /// <returns>The value.</returns>
        public int GetInt(String name, bool required, int defaultValue)
        {
            String str = GetString(name, required, null);

            if (str == null)
                return defaultValue;

            try
            {
                return Int32.Parse(str);
            }
            catch (FormatException)
            {
                throw new SyntError("Property " + name
                                     + " has an invalid value of " + str
                                     + ", should be valid integer.");
            }
        }

        /// <summary>
        /// Get a param as a double.
        /// </summary>
        ///
        /// <param name="name">The name of the double.</param>
        /// <param name="required">True if this value is required.</param>
        /// <param name="defaultValue">The default value.</param>
        /// <returns>The value.</returns>
        public double GetDouble(String name, bool required, double defaultValue)
        {
            String str = GetString(name, required, null);

            if (str == null)
                return defaultValue;

            try
            {
                return _format.Parse(str);
            }
            catch (FormatException)
            {
                throw new SyntError("Property " + name
                                     + " has an invalid value of " + str
                                     + ", should be valid floating point.");
            }
        }

        /// <summary>
        /// Get a param as a boolean.
        /// </summary>
        ///
        /// <param name="name">The name of the double.</param>
        /// <param name="required">True if this value is required.</param>
        /// <param name="defaultValue">The default value.</param>
        /// <returns>The value.</returns>
        public bool GetBoolean(String name, bool required,
                               bool defaultValue)
        {
            String str = GetString(name, required, null);

            if (str == null)
                return defaultValue;

            if (!str.Equals("true", StringComparison.InvariantCultureIgnoreCase) &&
                !str.Equals("false", StringComparison.InvariantCultureIgnoreCase))
            {
                throw new SyntError("Property " + name
                                     + " has an invalid value of " + str
                                     + ", should be true/false.");
            }

            return str.Equals("true", StringComparison.InvariantCultureIgnoreCase);
        }
    }

    public class ReflectionUtil
    {
        /// <summary>
        /// Path to the activation functions.
        /// </summary>
        public const String AfPath = "Synt.Engine.Network.Activation.";

        /// <summary>
        /// Path to RBF's.
        /// </summary>
        public const String RBFPath = "Synt.MathUtil.RBF.";

        /// <summary>
        /// A map between short class names and the full path names.
        /// </summary>
        private static readonly IDictionary<String, String> ClassMap = new Dictionary<String, String>();

        /// <summary>
        /// Private constructor.
        /// </summary>
        private ReflectionUtil()
        {
        }


        /// <summary>
        /// Find the specified field, look also in superclasses.
        /// </summary>
        /// <param name="c">The class to search.</param>
        /// <param name="name">The name of the field we are looking for.</param>
        /// <returns>The field.</returns>
        public static FieldInfo FindField(Type c, String name)
        {
            ICollection<FieldInfo> list = GetAllFields(c);
            return list.FirstOrDefault(field => field.Name.Equals(name));
        }

        /// <summary>
        /// Get all of the fields from the specified class as a collection.
        /// </summary>
        /// <param name="c">The class to access.</param>
        /// <returns>All of the fields from this class and subclasses.</returns>
        public static IList<FieldInfo> GetAllFields(Type c)
        {
            IList<FieldInfo> result = new List<FieldInfo>();
            GetAllFields(c, result);
            return result;
        }

        /// <summary>
        /// Get all of the fields for the specified class and recurse to check the base class.
        /// </summary>
        /// <param name="c">The class to scan.</param>
        /// <param name="result">A list of fields.</param>
        public static void GetAllFields(Type c, IList<FieldInfo> result)
        {
            foreach (
                FieldInfo field in c.GetFields(BindingFlags.Instance | BindingFlags.Public | BindingFlags.NonPublic))
            {
                result.Add(field);
            }

            if (c.BaseType != null)
                GetAllFields(c.BaseType, result);
        }

        /// <summary>
        /// Load the classmap file. This allows classes to be resolved using just the
        /// simple name.
        /// </summary>
        public static void LoadClassmap()
        {
            {
                Stream istream = ResourceLoader.CreateStream("Synt.Resources.classes.txt");
                var sr = new StreamReader(istream);

                String line;
                while ((line = sr.ReadLine()) != null)
                {
                    int idx = line.LastIndexOf('.');
                    if (idx != -1)
                    {
                        String simpleName = line.Substring(idx + 1);
                        ClassMap[simpleName] = line;
                    }
                }
                sr.Close();
                istream.Close();
            }
        }

        /// <summary>
        /// Resolve an Synt class using its simple name.
        /// </summary>
        /// <param name="name">The simple name of the class.</param>
        /// <returns>The class requested.</returns>
        public static String ResolveSyntClass(String name)
        {
            if (ClassMap.Count == 0)
            {
                LoadClassmap();
            }

            return !ClassMap.ContainsKey(name) ? null : ClassMap[name];
        }


        /// <summary>
        /// Determine if the specified field has the specified attribute.
        /// </summary>
        /// <param name="field">The field to check.</param>
        /// <param name="t">See if the field has this attribute.</param>
        /// <returns>True if the field has the specified attribute.</returns>
        public static bool HasAttribute(FieldInfo field, Type t)
        {
            return field.GetCustomAttributes(true).Any(obj => obj.GetType() == t);
        }


        /// <summary>
        /// Determine if the specified type contains the specified attribute.
        /// </summary>
        /// <param name="t">The type.</param>
        /// <param name="attribute">The attribute.</param>
        /// <returns>True if the type contains the attribute.</returns>
        public static bool HasAttribute(Type t, Type attribute)
        {
            return t.GetCustomAttributes(true).Any(obj => obj.GetType() == attribute);
        }

        /// <summary>
        /// Resolve an enumeration.
        /// </summary>
        /// <param name="field">The field to resolve.</param>
        /// <param name="v">The value to get the enum for.</param>
        /// <returns>The enum that was resolved.</returns>
        public static Object ResolveEnum(FieldInfo field, FieldInfo v)
        {
            Type type = field.GetType();
            Object[] objs = type.GetMembers(BindingFlags.Public | BindingFlags.Static);
            return objs.Cast<MemberInfo>().FirstOrDefault(obj => obj.Name.Equals(v));
        }

        /// <summary>
        /// Loop over all loaded assembles and try to create the class.
        /// </summary>
        /// <param name="name">The class to create.</param>
        /// <returns>The created class.</returns>
        public static Object LoadObject(String name)
        {
            Assembly[] assemblies = AppDomain.CurrentDomain.GetAssemblies();
            Object result = null;

            foreach (Assembly a in assemblies)
            {
                result = a.CreateInstance(name);
                if (result != null)
                    break;
            }

            return result;
        }
    }

    public class SerializeObject
    {
        /// <summary>
        /// Private constructor, call everything statically.
        /// </summary>
        private SerializeObject()
        {
        }

        /// <summary>
        /// Load the specified filename.
        /// </summary>
        /// <param name="filename">The filename to load from.</param>
        /// <returns>The object loaded from that file.</returns>
        public static object Load(string filename)
        {
            Stream s = new FileStream(filename, FileMode.Open, FileAccess.Read, FileShare.None);
            var b = new BinaryFormatter();
            object obj = b.Deserialize(s);
            s.Close();
            return obj;
        }

        /// <summary>
        /// Save the specified object.
        /// </summary>
        /// <param name="filename">The filename to save to.</param>
        /// <param name="obj">The object to save.</param>
        public static void Save(string filename, object obj)
        {
            Stream s = new FileStream(filename, FileMode.Create, FileAccess.Write, FileShare.None);
            var b = new BinaryFormatter();
            b.Serialize(s, obj);
            s.Close();
        }
    }

    public class SimpleParser
    {
        /// <summary>
        /// The current position.
        /// </summary>
        private int _currentPosition;

        /// <summary>
        /// The marked position.
        /// </summary>
        private int _marked;

        /// <summary>
        /// Construct the object for the specified line.
        /// </summary>
        /// <param name="line">The line to parse.</param>
        public SimpleParser(String line)
        {
            Line = line;
        }

        /// <summary>
        /// The line being parsed.
        /// </summary>
        public String Line { get; set; }

        /// <summary>
        /// The number of characters remaining.
        /// </summary>
        /// <returns>The number of characters remaining.</returns>
        public int Remaining()
        {
            return Math.Max(Line.Length - _currentPosition, 0);
        }

        /// <summary>
        /// Parse through a comma.
        /// </summary>
        /// <returns>True, if the comma was found.</returns>
        public bool ParseThroughComma()
        {
            EatWhiteSpace();
            if (!EOL())
            {
                if (Peek() == ',')
                {
                    Advance();
                    return true;
                }
            }

            return false;
        }

        /// <summary>
        /// CHeck to see if the next character is an identifier.
        /// </summary>
        /// <returns>True, if the next char is an identifier.</returns>
        public bool IsIdentifier()
        {
            if (EOL())
                return false;

            return char.IsLetterOrDigit(Peek()) || Peek() == '_';
        }

        /// <summary>
        /// Peek ahead to see the next character.  But do not advance beyond it.
        /// </summary>
        /// <returns>The next character.</returns>
        public char Peek()
        {
            if (EOL())
                return (char)0;
            if (_currentPosition >= Line.Length)
                return (char)0;
            return Line[_currentPosition];
        }

        /// <summary>
        /// Advance beyond the next character.
        /// </summary>
        public void Advance()
        {
            if (_currentPosition < Line.Length)
            {
                _currentPosition++;
            }
        }

        /// <summary>
        /// Returns true if the next character is a white space.
        /// </summary>
        /// <returns>True, if the next character is a white space.</returns>
        public bool IsWhiteSpace()
        {
            return " \t\n\r".IndexOf(Peek()) != -1;
        }

        /// <summary>
        /// Returns true of there are no more characters to read.
        /// </summary>
        /// <returns>True, if we have reached end of line.</returns>
        public bool EOL()
        {
            return (_currentPosition >= Line.Length);
        }

        /// <summary>
        /// Strip any white space from the current position.
        /// </summary>
        public void EatWhiteSpace()
        {
            while (!EOL() && IsWhiteSpace())
                Advance();
        }

        /// <summary>
        /// Read the next character.
        /// </summary>
        /// <returns>The next character.</returns>
        public char ReadChar()
        {
            if (EOL())
                return (char)0;

            char ch = Peek();
            Advance();
            return ch;
        }

        /// <summary>
        /// Read text up to the next white space.
        /// </summary>
        /// <returns>The text read up to the next white space.</returns>
        public String ReadToWhiteSpace()
        {
            var result = new StringBuilder();

            while (!IsWhiteSpace() && !EOL())
            {
                result.Append(ReadChar());
            }

            return result.ToString();
        }

        /// <summary>
        /// Look ahead to see if the specified string is present.
        /// </summary>
        /// <param name="str">The string searching for.</param>
        /// <param name="ignoreCase">True if case is to be ignored.</param>
        /// <returns>True if the string is present.</returns>
        public bool LookAhead(String str, bool ignoreCase)
        {
            if (Remaining() < str.Length)
                return false;
            for (int i = 0; i < str.Length; i++)
            {
                char c1 = str[i];
                char c2 = Line[_currentPosition + i];

                if (ignoreCase)
                {
                    c1 = char.ToLower(c1);
                    c2 = char.ToLower(c2);
                }

                if (c1 != c2)
                    return false;
            }

            return true;
        }

        /// <summary>
        /// Advance the specified number of characters.
        /// </summary>
        /// <param name="p">The number of characters to advance.</param>
        public void Advance(int p)
        {
            _currentPosition = Math.Min(Line.Length, _currentPosition + p);
        }

        /// <summary>
        /// Mark the current position.
        /// </summary>
        public void Mark()
        {
            _marked = _currentPosition;
        }

        /// <summary>
        /// Reset back to the marked position.
        /// </summary>
        public void Reset()
        {
            _currentPosition = _marked;
        }

        /// <summary>
        /// Read a quoted string.
        /// </summary>
        /// <returns>The string that was read.</returns>
        public String ReadQuotedString()
        {
            if (Peek() != '\"')
                return "";

            var result = new StringBuilder();

            Advance();
            while (Peek() != '\"' && !EOL())
            {
                result.Append(ReadChar());
            }
            Advance();

            return result.ToString();
        }

        /// <summary>
        /// Read forward to the specified characters.
        /// </summary>
        /// <param name="chs">The characters to stop at.</param>
        /// <returns>The string that was read.</returns>
        public String ReadToChars(String chs)
        {
            StringBuilder result = new StringBuilder();

            while (chs.IndexOf(this.Peek()) == -1 && !EOL())
            {
                result.Append(ReadChar());
            }

            return result.ToString();
        }

    }

    public class StringUtil
    {
        /// <summary>
        /// Compare two strings, ignore case.
        /// </summary>
        /// <param name="a">The first string.</param>
        /// <param name="b">The second string.</param>
        /// <returns></returns>
        public static Boolean EqualsIgnoreCase(String a, String b)
        {
            return a.Equals(b, StringComparison.CurrentCultureIgnoreCase);
        }

        /// <summary>
        /// Simple utility to take an array of ASCII bytes and convert to
        /// a String.  Works with Silverlight as well.
        /// </summary>
        /// <param name="b">The byte array.</param>
        /// <returns>The string created from the byte array.</returns>
        public static String FromBytes(byte[] b)
        {
            var b2 = new byte[b.Length * 2];
            for (int i = 0; i < b.Length; i++)
            {
                b2[i * 2] = b[i];
                b2[(i * 2) + 1] = 0;
            }

            return (new UnicodeEncoding()).GetString(b2, 0, b2.Length);
        }
    }

    public class YahooSearch
    {
        ///// <summary>
        ///// Perform a Yahoo search.
        ///// </summary>
        ///// <param name="url">The REST URL.</param>
        ///// <returns>The search results.</returns>
        //private ICollection<Uri> DoSearch(Uri url)
        //{
        //    ICollection<Uri> result = new List<Uri>();
        //    // submit the search
        //    //WebRequest http = WebRequest.Create(url);
        //    //var response = (HttpWebResponse)http.GetResponse();

        //    using (Stream istream = response.GetResponseStream())
        //    {
        //        var parse = new ReadHTML(istream);
        //        var buffer = new StringBuilder();
        //        bool capture = false;

        //        // parse the results
        //        int ch;
        //        while ((ch = parse.Read()) != -1)
        //        {
        //            if (ch == 0)
        //            {
        //                Tag tag = parse.LastTag;
        //                if (tag.Name.Equals("Url", StringComparison.CurrentCultureIgnoreCase))
        //                {
        //                    buffer.Length = 0;
        //                    capture = true;
        //                }
        //                else if (tag.Name.Equals("/Url", StringComparison.CurrentCultureIgnoreCase))
        //                {
        //                    result.Add(new Uri(buffer.ToString()));
        //                    buffer.Length = 0;
        //                    capture = false;
        //                }
        //            }
        //            else
        //            {
        //                if (capture)
        //                {
        //                    buffer.Append((char)ch);
        //                }
        //            }
        //        }
        //    }

        //    //response.Close();

        //    return result;
        //}

        ///// <summary>
        ///// Perform a Yahoo search.
        ///// </summary>
        ///// <param name="searchFor">What are we searching for.</param>
        ///// <returns>The URLs that contain the specified item.</returns>
        //public ICollection<Uri> Search(String searchFor)
        //{
        //    ICollection<Uri> result = null;

        //    // build the Uri
        //    var mstream = new MemoryStream();
        //    var form = new FormUtility(mstream, null);
        //    form.Add("appid", "YahooDemo");
        //    form.Add("results", "100");
        //    form.Add("query", searchFor);
        //    form.Complete();

        //    var enc = new ASCIIEncoding();

        //    String str = enc.GetString(mstream.GetBuffer());
        //    mstream.Dispose();

        //    var uri = new Uri(
        //        "http://search.yahooapis.com/WebSearchService/V1/webSearch?"
        //        + str);

        //    int tries = 0;
        //    bool done = false;
        //    while (!done)
        //    {
        //        try
        //        {
        //            result = DoSearch(uri);
        //            done = true;
        //        }
        //        catch (IOException e)
        //        {
        //            if (tries == 5)
        //            {
        //                throw;
        //            }
        //            Thread.Sleep(5000);
        //        }
        //        tries++;
        //    }

        //    return result;
        //}
    }

    public class ConsoleStatusReportable : IStatusReportable
    {
        #region IStatusReportable Members

        /// <summary>
        /// Simply display any status reports.
        /// </summary>
        /// <param name="total">Total amount.</param>
        /// <param name="current">Current item.</param>
        /// <param name="message">Current message.</param>
        public void Report(int total, int current,
                           String message)
        {
            if (total == 0)
            {
                Console.WriteLine(current + " : " + message);
            }
            else
            {
                Console.WriteLine(current + "/" + total + " : " + message);
            }
        }

        #endregion
    }

    public class SyntError : Exception
    {
        /// <summary>
        /// Construct a message exception.
        /// </summary>
        /// <param name="str">The message.</param>
        public SyntError(String str)
            : base(str)
        {
        }

        /// <summary>
        /// Pass on an exception.
        /// </summary>
        /// <param name="e">The other exception.</param>
        public SyntError(Exception e)
            : base("Nested Exception", e)
        {
        }

        /// <summary>
        /// Pass on an exception.
        /// </summary>
        /// <param name="msg">The message.</param>
        /// <param name="e">The exception.</param>
        public SyntError(String msg, Exception e)
            : base(msg, e)
        {
        }
    }

    public class SyntFramework
    {
        /// <summary>
        /// The current engog version, this should be read from the properties.
        /// </summary>
        public static string Version = "3.1.0";

        /// <summary>
        /// The platform.
        /// </summary>
        public static string PLATFORM = "DotNet";

        /// <summary>
        /// The current engog file version, this should be read from the properties.
        /// </summary>
        private const string FileVersion = "1";


        /// <summary>
        /// The default precision to use for compares.
        /// </summary>
        public const int DefaultPrecision = 10;

        /// <summary>
        /// Default point at which two doubles are equal.
        /// </summary>
        public const double DefaultDoubleEqual = 0.0000001;

        /// <summary>
        /// The version of the Synt JAR we are working with. Given in the form
        /// x.x.x.
        /// </summary>
        public const string SyntVersion = "Synt.version";

        /// <summary>
        /// The Synt file version. This determines of an Synt file can be read.
        /// This is simply an integer, that started with zero and is incramented each
        /// time the format of the Synt data file changes.
        /// </summary>
        public static string SyntFileVersion = "Synt.file.version";

        /// <summary>
        /// The instance.
        /// </summary>
        private static SyntFramework _instance = new SyntFramework();

        /// <summary>
        /// The current logging plugin.
        /// </summary>
        ///
        private ISyntPluginLogging1 _loggingPlugin;

        /// <summary>
        /// The plugins.
        /// </summary>
        ///
        private readonly IList<SyntPluginBase> _plugins;

        /// <summary>
        /// Get the instance to the singleton.
        /// </summary>
        public static SyntFramework Instance
        {
            get
            {
                return _instance;
            }
        }

        /// <summary>
        /// Get the properties as a Map.
        /// </summary>
        private readonly IDictionary<string, string> _properties =
            new Dictionary<string, string>();

        /// <summary>
        /// Private constructor.
        /// </summary>
        private SyntFramework()
        {
            _properties[SyntVersion] = Version;
            _properties[SyntFileVersion] = FileVersion;

            _plugins = new List<SyntPluginBase>();
            RegisterPlugin(new SystemLoggingPlugin());
            RegisterPlugin(new SystemMethodsPlugin());
            RegisterPlugin(new SystemTrainingPlugin());
            RegisterPlugin(new SystemActivationPlugin());
        }

        /// <summary>
        /// The Synt properties.  Contains version information.
        /// </summary>
        public IDictionary<string, string> Properties
        {
            get { return _properties; }
        }


        /// <summary>
        /// Shutdown Synt.
        /// </summary>
        public void Shutdown()
        {
        }

        /// <value>the loggingPlugin</value>
        public ISyntPluginLogging1 LoggingPlugin
        {
            get { return _loggingPlugin; }
        }

        /// <summary>
        /// Register a plugin. If this plugin provides a core service, such as
        /// calculation or logging, this will remove the old plugin.
        /// </summary>
        ///
        /// <param name="plugin">The plugin to register.</param>
        public void RegisterPlugin(SyntPluginBase plugin)
        {
            // is it not a general plugin?
            if (plugin.PluginServiceType != SyntPluginBaseConst.SERVICE_TYPE_GENERAL)
            {
                if (plugin.PluginServiceType == SyntPluginBaseConst.SERVICE_TYPE_LOGGING)
                {
                    // remove the old logging plugin
                    if (_loggingPlugin != null)
                    {
                        _plugins.Remove(_loggingPlugin);
                    }
                    _loggingPlugin = (ISyntPluginLogging1)plugin;
                }
            }
            // add to the plugins
            _plugins.Add(plugin);
        }

        /// <summary>
        /// Unregister a plugin. If you unregister the current logging or calc
        /// plugin, a new system one will be created. Synt will crash without a
        /// logging or system plugin.
        /// </summary>
        public void UnregisterPlugin(SyntPluginBase plugin)
        {
            // is it a special plugin?
            // if so, replace with the system, Synt will crash without these
            if (plugin == _loggingPlugin)
            {
                _loggingPlugin = new SystemLoggingPlugin();
            }

            // remove it
            _plugins.Remove(plugin);
        }

        /// <summary>
        /// The plugins.
        /// </summary>
        public IList<SyntPluginBase> Plugins
        {
            get { return _plugins; }
        }
    }

    public class NullStatusReportable : IStatusReportable
    {
        #region IStatusReportable Members

        /// <summary>
        /// Simply ignore any status reports.
        /// </summary>
        /// <param name="total">Not used.</param>
        /// <param name="current">Not used.</param>
        /// <param name="message">Not used.</param>
        public void Report(int total, int current,
                           String message)
        {
        }

        #endregion
    }

    public class ListExtractListener : IExtractListener
    {
        /// <summary>
        /// The list to extract into.
        /// </summary>
        private readonly IList<Object> _list = new List<Object>();

        /// <summary>
        /// The list of words extracted.
        /// </summary>
        public IList<Object> List
        {
            get { return _list; }
        }

        #region IExtractListener Members

        /// <summary>
        /// Called when a word is found, add it to the list.
        /// </summary>
        /// <param name="obj">The word found.</param>
        public void FoundData(Object obj)
        {
            _list.Add(obj);
        }

        #endregion
    }

    public class Div : DocumentRange
    {
        /// <summary>
        /// Construct a range to hold the DIV tag.
        /// </summary>
        /// <param name="source">The web page this range was found on.</param>
        public Div(WebPage source)
            : base(source)
        {
        }

        /// <summary>
        /// This object as a string.
        /// </summary>
        /// <returns>This object as a string.</returns>
        public override String ToString()
        {
            var result = new StringBuilder();
            result.Append("[Div:class=");
            result.Append(ClassAttribute);
            result.Append(",id=");
            result.Append(IdAttribute);
            result.Append(",elements=");
            result.Append(Elements.Count);
            result.Append("]");
            return result.ToString();
        }
    }

    public class DocumentRange
    {
        /// <summary>
        /// Sub elements of this range.
        /// </summary>
        private readonly IList<DocumentRange> _elements = new List<DocumentRange>();

        /// <summary>
        /// The source page for this range.
        /// </summary>
        private WebPage _source;

        /// <summary>
        /// Construct a document range from the specified WebPage.
        /// </summary>
        /// <param name="source">The web page that this range belongs to.</param>
        public DocumentRange(WebPage source)
        {
            _source = source;
        }

        /// <summary>
        /// The beginning of this attribute.
        /// </summary>
        public int Begin { get; set; }

        /// <summary>
        /// The HTML class attribiute for this element.
        /// </summary>
        public String ClassAttribute { get; set; }

        /// <summary>
        /// The elements of this document range. 
        /// </summary>
        public IList<DocumentRange> Elements
        {
            get { return _elements; }
        }

        /// <summary>
        /// The ending index.
        /// </summary>
        public int End { get; set; }

        /// <summary>
        /// The HTML id for this element.
        /// </summary>
        public String IdAttribute { get; set; }

        /// <summary>
        /// The web page that owns this class.
        /// </summary>
        public DocumentRange Parent { get; set; }

        /// <summary>
        /// The web page that this range is owned by.
        /// </summary>
        public WebPage Source
        {
            get { return _source; }
            set { _source = value; }
        }

        /// <summary>
        /// Add an element.
        /// </summary>
        /// <param name="element">The element to add.</param>
        public void AddElement(DocumentRange element)
        {
            Elements.Add(element);
            element.Parent = this;
        }

        /// <summary>
        /// Get the text from this range.
        /// </summary>
        /// <returns>The text from this range.</returns>
        public String GetTextOnly()
        {
            var result = new StringBuilder();

            for (int i = Begin; i < End; i++)
            {
                DataUnit du = _source.Data[i];
                if (du is TextDataUnit)
                {
                    result.Append(du.ToString());
                    result.Append("\n");
                }
            }

            return result.ToString();
        }


        /// <summary>
        /// This object as a string.
        /// </summary>
        /// <returns>This object as a string.</returns>
        public override String ToString()
        {
            return GetTextOnly();
        }
    }

    public class Form : DocumentRange
    {
        #region FormMethod enum

        /// <summary>
        /// The method for this form.
        /// </summary>
        public enum FormMethod
        {
            /// <summary>
            /// This form is to be POSTed.
            /// </summary>
            Post,
            /// <summary>
            /// This form is to sent using a GET.
            /// </summary>
            Get
        };

        #endregion

        /// <summary>
        /// Construct a form on the specified web page.
        /// </summary>
        /// <param name="source">The web page that contains this form.</param>
        public Form(WebPage source)
            : base(source)
        {
        }

        /// <summary>
        /// The URL to send the form to.
        /// </summary>
        public Address Action { get; set; }

        /// <summary>
        /// The method, GET or POST.
        /// </summary>
        public FormMethod Method { get; set; }

        /// <summary>
        /// Find the form input by type.
        /// </summary>
        /// <param name="type">The type of input we want.</param>
        /// <param name="index">The index to begin searching at.</param>
        /// <returns>The Input object that was found.</returns>
        public Input FindType(String type, int index)
        {
            int i = index;

            foreach (DocumentRange element in Elements)
            {
                if (element is Input)
                {
                    var input = (Input)element;
                    if (String.Compare(input.Type, type, true) == 0)
                    {
                        if (i <= 0)
                        {
                            return input;
                        }
                        i--;
                    }
                }
            }
            return null;
        }


        /// <summary>
        /// The object as a string.
        /// </summary>
        /// <returns>The object as a string.</returns>
        public override String ToString()
        {
            var builder = new StringBuilder();
            builder.Append("[Form:");
            builder.Append("method=");
            builder.Append(Method);
            builder.Append(",action=");
            builder.Append(Action);
            foreach (DocumentRange element in Elements)
            {
                builder.Append("\n\t");
                builder.Append(element.ToString());
            }
            builder.Append("]");
            return builder.ToString();
        }
    }

    public class Input : FormElement
    {
        /// <summary>
        /// The type of input element that this is.
        /// </summary>
        private String _type;

        /// <summary>
        /// Construct this Input element.
        /// </summary>
        /// <param name="source">The source for this input ent.</param>
        public Input(WebPage source)
            : base(source)
        {
        }

        /// <summary>
        /// The type of this input.
        /// </summary>
        public String Type
        {
            get { return _type; }
            set { _type = value; }
        }

        /// <summary>
        /// True if this is autosend, which means that the type is NOT
        /// submit. This prevents a form that has multiple submit buttons
        /// from sending ALL of them in a single post.
        /// </summary>
        public override bool AutoSend
        {
            get { return string.Compare(_type, "submit", true) != 0; }
        }

        /// <summary>
        /// This object as a string.
        /// </summary>
        /// <returns>This object as a string.</returns>
        public override String ToString()
        {
            var builder = new StringBuilder();
            builder.Append("[Input:");
            builder.Append("type=");
            builder.Append(Type);
            builder.Append(",name=");
            builder.Append(Name);
            builder.Append(",value=");
            builder.Append(Value);
            builder.Append("]");
            return builder.ToString();
        }
    }

    public class Link : DocumentRange
    {
        /// <summary>
        /// The target address for this link.
        /// </summary>
        private Address _target;

        /// <summary>
        /// Construct a link from the specified web page.
        /// </summary>
        /// <param name="source">The web page this link is from.</param>
        public Link(WebPage source)
            : base(source)
        {
        }

        /// <summary>
        /// The target of this link.
        /// </summary>
        public Address Target
        {
            get { return _target; }
            set { _target = value; }
        }

        /// <summary>
        /// This object as a string.
        /// </summary>
        /// <returns>This object as a string.</returns>
        public override String ToString()
        {
            var result = new StringBuilder();
            result.Append("[Link:");
            result.Append(_target);
            result.Append("|");
            result.Append(GetTextOnly());
            result.Append("]");
            return result.ToString();
        }
    }

    public class Span : DocumentRange
    {
        /// <summary>
        /// Construct a span range from the specified web page.
        /// </summary>
        /// <param name="source">The source web page.</param>
        public Span(WebPage source)
            : base(source)
        {
        }

        /// <summary>
        /// This object as a string. 
        /// </summary>
        /// <returns>This object as a string. </returns>
        public override String ToString()
        {
            var result = new StringBuilder();
            result.Append("[Span:class=");
            result.Append(ClassAttribute);
            result.Append(",id=");
            result.Append(IdAttribute);
            result.Append(",elements=");
            result.Append(Elements.Count);
            result.Append("]");
            return result.ToString();
        }
    }

    public class Address
    {
        /// <summary>
        /// The original text from the address.
        /// </summary>
        private readonly String _original;

        /// <summary>
        /// The address as a URL.
        /// </summary>
        private readonly Uri _url;

        /// <summary>
        /// Construct the address from a URL.
        /// </summary>
        /// <param name="u">The URL to use.</param>
        public Address(Uri u)
        {
            _url = u;
            _original = u.ToString();
        }

        /// <summary>
        /// Construct a URL using a perhaps relative URL and a base URL.
        /// </summary>
        /// <param name="b">The base URL.</param>
        /// <param name="original">A full URL or a URL relative to the base.</param>
        public Address(Uri b, String original)
        {
            _original = original;
            _url = b == null ? new Uri(new Uri("http://localhost/"), original) : new Uri(b, original);
        }

        /// <summary>
        /// The original text from this URL.
        /// </summary>
        public String Original
        {
            get { return _original; }
        }

        /// <summary>
        /// The URL.
        /// </summary>
        public Uri Url
        {
            get { return _url; }
        }

        /// <summary>
        /// The object as a string.
        /// </summary>
        /// <returns></returns>
        public override String ToString()
        {
            return _url != null ? _url.ToString() : _original;
        }
    }

    public class BrowseError : SyntError
    {
        /// <summary>
        /// Construct a message exception.
        /// </summary>
        /// <param name="str">The message.</param>
        public BrowseError(String str)
            : base(str)
        {
        }

        /// <summary>
        /// Pass on an exception.
        /// </summary>
        /// <param name="e">The other exception.</param>
        public BrowseError(Exception e)
            : base(e)
        {
        }
    }

    public class Browser
    {
        /// <summary>
        /// The page that is currently being browsed.
        /// </summary>
        private WebPage _currentPage;


        /// <summary>
        /// The page currently being browsed.
        /// </summary>
        public WebPage CurrentPage
        {
            get { return _currentPage; }
            set { _currentPage = value; }
        }

        /// <summary>
        /// Navigate to the specified form by performing a submit of that form.
        /// </summary>
        /// <param name="form">The form to be submitted.</param>
        public void Navigate(Form form)
        {
            Navigate(form, null);
        }

        /// <summary>
        /// Navigate based on a form. Complete and post the form.
        /// </summary>
        /// <param name="form">The form to be posted.</param>
        /// <param name="submit">The submit button on the form to simulate clicking.</param>
        public void Navigate(Form form, Input submit)
        {
//            try
//            {
//#if logging
//                if (logger.IsInfoEnabled)
//                {
//                    logger.Info("Posting a form");
//                }
//#endif
//                Stream istream;
//                Stream ostream;
//                Uri targetURL;
//                WebRequest http = null;

//                if (form.Method == Form.FormMethod.Get)
//                {
//                    ostream = new MemoryStream();
//                }
//                else
//                {
//                    http = WebRequest.Create(form.Action.Url);
//                    http.Timeout = 30000;
//                    http.ContentType = "application/x-www-form-urlSyntesisd";
//                    http.Method = "POST";
//                    ostream = http.GetRequestStream();
//                }

//                // add the parameters if present
//                var formData = new FormUtility(ostream, null);
//                foreach (DocumentRange dr in form.Elements)
//                {
//                    if (dr is FormElement)
//                    {
//                        var element = (FormElement)dr;
//                        if ((element == submit) || element.AutoSend)
//                        {
//                            String name = element.Name;
//                            String value = element.Value;
//                            if (name != null)
//                            {
//                                if (value == null)
//                                {
//                                    value = "";
//                                }
//                                formData.Add(name, value);
//                            }
//                        }
//                    }
//                }

//                // now execute the command
//                if (form.Method == Form.FormMethod.Get)
//                {
//                    String action = form.Action.Url.ToString();
//                    ostream.Close();
//                    action += "?";
//                    action += ostream.ToString();
//                    targetURL = new Uri(action);
//                    http = WebRequest.Create(targetURL);
//                    var response = (HttpWebResponse)http.GetResponse();
//                    istream = response.GetResponseStream();
//                }
//                else
//                {
//                    targetURL = form.Action.Url;
//                    ostream.Close();
//                    var response = (HttpWebResponse)http.GetResponse();
//                    istream = response.GetResponseStream();
//                }

//                Navigate(targetURL, istream);
//                istream.Close();
//            }
//            catch (IOException e)
//            {
//                throw new BrowseError(e);
//            }
        }

        /// <summary>
        /// Navigate to a new page based on a link.
        /// </summary>
        /// <param name="link">The link to navigate to.</param>
 

        /// <summary>
        /// Navigate to a page based on a URL object. This will be an HTTP GET
        /// operation.
        /// </summary>
        /// <param name="url">The URL to navigate to.</param>


        /// <summary>
        /// Navigate to a page and post the specified data.
        /// </summary>
        /// <param name="url">The URL to post the data to.</param>
        /// <param name="istream">The data to post to the page.</param>
        public void Navigate(Uri url, Stream istream)
        {
#if logging
            if (logger.IsInfoEnabled)
            {
                logger.Info("POSTing to page:" + url);
            }
#endif
            var load = new LoadWebPage(url);
            _currentPage = load.Load(istream);
        }
    }

    public class LoadWebPage
    {
        /// <summary>
        /// The loaded webpage.
        /// </summary>
        private WebPage _page;

        /// <summary>
        /// The base URL for the page being loaded.
        /// </summary>
        private readonly Uri _baseURL;

        /// <summary>
        /// The last form that was processed.
        /// </summary>
        private Form _lastForm;

        /// <summary>
        /// The last hierarchy element that was processed.
        /// </summary>
        private DocumentRange _lastHierarchyElement;

        /// <summary>
        /// Construct a web page loader with the specified base URL.
        /// </summary>
        /// <param name="baseURL">The base URL to use when loading.</param>
        public LoadWebPage(Uri baseURL)
        {
            _baseURL = baseURL;
        }

        /// <summary>
        /// Add the specified hierarchy element.
        /// </summary>
        /// <param name="element">The hierarchy element to add.</param>
        private void AddHierarchyElement(DocumentRange element)
        {
            if (_lastHierarchyElement == null)
            {
                _page.AddContent(element);
            }
            else
            {
                _lastHierarchyElement.AddElement(element);
            }
            _lastHierarchyElement = element;
        }

        /// <summary>
        /// Create a dataunit to hode the code HTML tag.
        /// </summary>
        /// <param name="str">The code to create the data unit with.</param>
        private void CreateCodeDataUnit(String str)
        {
            if (str.Trim().Length > 0)
            {
                var d = new CodeDataUnit { Code = str };
                _page.AddDataUnit(d);
            }
        }

        /// <summary>
        /// Create a tag data unit.
        /// </summary>
        /// <param name="tag">The tag name to create the data unit for.</param>
        private void CreateTagDataUnit(Tag tag)
        {
            var d = new TagDataUnit { Tag = (Tag)tag.Clone() };

            _page.AddDataUnit(d);
        }

        /// <summary>
        /// Create a text data unit.
        /// </summary>
        /// <param name="str">The text.</param>
        private void CreateTextDataUnit(String str)
        {
            if (str.Trim().Length > 0)
            {
                var d = new TextDataUnit { Text = str };
                _page.AddDataUnit(d);
            }
        }

        /// <summary>
        ///  Find the end tag that lines up to the beginning tag.
        /// </summary>
        /// <param name="index">The index to start the search on. This specifies
        /// the starting data unit.</param>
        /// <param name="tag">The beginning tag that we are seeking the end tag 
        /// for.</param>
        /// <returns>The index that the ending tag was found at. Returns -1
        /// if not found.</returns>
        protected int FindEndTag(int index, Tag tag)
        {
            int depth = 0;
            int count = index;

            while (count < _page.getDataSize())
            {
                DataUnit du = _page.GetDataUnit(count);

                if (du is TagDataUnit)
                {
                    Tag nextTag = ((TagDataUnit)du).Tag;
                    if (String.Compare(tag.Name, nextTag.Name, true) == 0)
                    {
                        if (nextTag.TagType == Tag.Type.End)
                        {
                            if (depth == 0)
                            {
                                return count;
                            }
                            depth--;
                        }
                        else if (nextTag.TagType == Tag.Type.Begin)
                        {
                            depth++;
                        }
                    }
                }
                count++;
            }
            return -1;
        }

        /// <summary>
        /// Load a web page from the specified stream.
        /// </summary>
        /// <param name="istream">The input stream to load from.</param>
        /// <returns>The loaded web page.</returns>
        public WebPage Load(Stream istream)
        {
            _page = new WebPage();

            LoadDataUnits(istream);
            LoadContents();

            return _page;
        }

        /// <summary>
        /// Load the web page from a string that contains HTML.
        /// </summary>
        /// <param name="str">A string containing HTML.</param>
        /// <returns>The loaded WebPage.</returns>
        public WebPage Load(String str)
        {
            try
            {
                byte[] array = Encoding.UTF8.GetBytes(str);
                Stream bis = new MemoryStream(array);

                WebPage result = Load(bis);
                bis.Close();
                return result;
            }
            catch (IOException e)
            {
#if logging
                if (logger.IsDebugEnabled)
                {
                    logger.Debug("Exception", e);
                }
#endif
                throw new BrowseError(e);
            }
        }

        /// <summary>
        /// Using the data units, which should have already been loaded by this 
        /// time, load the contents of the web page.  This includes the title,
        /// any links and forms.  Div tags and spans are also processed.
        /// </summary>
        protected void LoadContents()
        {
            for (int index = 0; index < _page.getDataSize(); index++)
            {
                DataUnit du = _page.GetDataUnit(index);
                if (du is TagDataUnit)
                {
                    Tag tag = ((TagDataUnit)du).Tag;

                    if (tag.TagType != Tag.Type.End)
                    {
                        if (string.Compare(tag.Name, "a", true) == 0)
                        {
                            LoadLink(index, tag);
                        }
                        else if (string.Compare(tag.Name, "title", true) == 0)
                        {
                            LoadTitle(index, tag);
                        }
                        else if (string.Compare(tag.Name, "form", true) == 0)
                        {
                            LoadForm(index, tag);
                        }
                        else if (string.Compare(tag.Name, "input", true) == 0)
                        {
                            LoadInput(index, tag);
                        }
                    }

                    if (tag.TagType == Tag.Type.Begin)
                    {
                        if (String.Compare(tag.Name, "div", true) == 0)
                        {
                            LoadDiv(index, tag);
                        }
                        else if (String.Compare(tag.Name, "span", true) == 0)
                        {
                            LoadSpan(index, tag);
                        }
                    }

                    if (tag.TagType == Tag.Type.End)
                    {
                        if (string.Compare(tag.Name, "div") == 0)
                        {
                            if (_lastHierarchyElement != null)
                            {
                                _lastHierarchyElement =
                                    _lastHierarchyElement.Parent;
                            }
                        }
                        else if (String.Compare(tag.Name, "span", true) == 0)
                        {
                            if (_lastHierarchyElement != null)
                            {
                                _lastHierarchyElement =
                                    _lastHierarchyElement.Parent;
                            }
                        }
                    }
                }
            }
        }

        /// <summary>
        /// Load the data units.  Once the lower level data units have been 
        /// loaded, the contents can be loaded.
        /// </summary>
        /// <param name="istream">The input stream that the data units are loaded from.</param>
        protected void LoadDataUnits(Stream istream)
        {
            var text = new StringBuilder();
            int ch;
            var parse = new ReadHTML(istream);
            bool style = false;
            bool script = false;

            while ((ch = parse.Read()) != -1)
            {
                if (ch == 0)
                {
                    if (style)
                    {
                        CreateCodeDataUnit(text.ToString());
                    }
                    else if (script)
                    {
                        CreateCodeDataUnit(text.ToString());
                    }
                    else
                    {
                        CreateTextDataUnit(text.ToString());
                    }
                    style = false;
                    script = false;

                    text.Length = 0;
                    CreateTagDataUnit(parse.LastTag);
                    if (String.Compare(parse.LastTag.Name, "style", true) == 0)
                    {
                        style = true;
                    }
                    else if (string.Compare(parse.LastTag.Name,
                                            "script", true) == 0)
                    {
                        script = true;
                    }
                }
                else
                {
                    text.Append((char)ch);
                }
            }

            CreateTextDataUnit(text.ToString());
        }


        /// <summary>
        /// Called by loadContents to load a div tag.
        /// </summary>
        /// <param name="index">The index to begin at.</param>
        /// <param name="tag">The beginning div tag.</param>
        private void LoadDiv(int index, Tag tag)
        {
            var div = new Div(_page);
            String classAttribute = tag.GetAttributeValue("class");
            String idAttribute = tag.GetAttributeValue("id");

            div.IdAttribute = idAttribute;
            div.ClassAttribute = (classAttribute);
            div.Begin = index;
            div.End = FindEndTag(index + 1, tag);
            AddHierarchyElement(div);
        }

        /// <summary>
        /// Called by loadContents to load a form on the page.
        /// </summary>
        /// <param name="index">The index to begin loading at.</param>
        /// <param name="tag">The beginning tag.</param>
        protected void LoadForm(int index, Tag tag)
        {
            String method = tag.GetAttributeValue("method");
            String action = tag.GetAttributeValue("action");

            var form = new Form(_page);
            form.Begin = index;
            form.End = FindEndTag(index + 1, tag);

            if ((method == null) || string.Compare(method, "GET", true) == 0)
            {
                form.Method = Form.FormMethod.Get;
            }
            else
            {
                form.Method = Form.FormMethod.Post;
            }

            if (action == null)
            {
                form.Action = new Address(_baseURL);
            }
            else
            {
                form.Action = new Address(_baseURL, action);
            }

            _page.AddContent(form);
            _lastForm = form;
        }

        /// <summary>
        /// Called by loadContents to load an input tag on the form.
        /// </summary>
        /// <param name="index">The index to begin loading at.</param>
        /// <param name="tag">The beginning tag.</param>
        protected void LoadInput(int index, Tag tag)
        {
            String type = tag.GetAttributeValue("type");
            String name = tag.GetAttributeValue("name");
            String value = tag.GetAttributeValue("value");

            var input = new Input(_page);
            input.Type = type;
            input.Name = name;
            input.Value = value;

            if (_lastForm != null)
            {
                _lastForm.AddElement(input);
            }
            else
            {
                _page.AddContent(input);
            }
        }

        /// <summary>
        /// Called by loadContents to load a link on the page.
        /// </summary>
        /// <param name="index">The index to begin loading at.</param>
        /// <param name="tag">The beginning tag.</param>
        protected void LoadLink(int index, Tag tag)
        {
            var link = new Link(_page);
            String href = tag.GetAttributeValue("href");

            if (href != null)
            {
                link.Target = new Address(_baseURL, href);
                link.Begin = index;
                link.End = FindEndTag(index + 1, tag);
                _page.AddContent(link);
            }
        }

        /// <summary>
        /// Called by loadContents to load a span.
        /// </summary>
        /// <param name="index">The index to begin loading at.</param>
        /// <param name="tag">The beginning tag.</param>
        private void LoadSpan(int index, Tag tag)
        {
            var span = new Span(_page);
            String classAttribute = tag.GetAttributeValue("class");
            String idAttribute = tag.GetAttributeValue("id");

            span.IdAttribute = idAttribute;
            span.ClassAttribute = classAttribute;
            span.Begin = index;
            span.End = FindEndTag(index + 1, tag);
            AddHierarchyElement(span);
        }

        /// <summary>
        /// Called by loadContents to load the title of the page.
        /// </summary>
        /// <param name="index">The index to begin loading at.</param>
        /// <param name="tag">The beginning tag.</param>
        protected void LoadTitle(int index, Tag tag)
        {
            var title = new DocumentRange(_page);
            title.Begin = index;
            title.End = FindEndTag(index + 1, tag);
            _page.Title = title;
        }
    }

    public class WebPage
    {
        /// <summary>
        /// The contents of this page, builds upon the list of DataUnits.
        /// </summary>
        private readonly IList<DocumentRange> _contents = new List<DocumentRange>();

        /// <summary>
        /// The data units that make up this page.
        /// </summary>
        private readonly IList<DataUnit> _data = new List<DataUnit>();

        /// <summary>
        /// The title of this HTML page.
        /// </summary>
        private DocumentRange _title;

        /// <summary>
        /// The contents in a list collection.
        /// </summary>
        public IList<DocumentRange> Contents
        {
            get { return _contents; }
        }

        /// <summary>
        /// The data units in a list collection.
        /// </summary>
        public IList<DataUnit> Data
        {
            get { return _data; }
        }

        /// <summary>
        /// The title of this document.
        /// </summary>
        public DocumentRange Title
        {
            get { return _title; }
            set
            {
                _title = value;
                _title.Source = this;
            }
        }

        /// <summary>
        /// Add to the content collection.
        /// </summary>
        /// <param name="span">The range to add to the collection.</param>
        public void AddContent(DocumentRange span)
        {
            span.Source = this;
            _contents.Add(span);
        }

        /// <summary>
        /// Add a data unit to the collection.
        /// </summary>
        /// <param name="unit">The data unit to load.</param>
        public void AddDataUnit(DataUnit unit)
        {
            _data.Add(unit);
        }

        /// <summary>
        /// Find the specified DocumentRange subclass in the contents list.
        /// </summary>
        /// <param name="c">The class type to search for.</param>
        /// <param name="index">The index to search from.</param>
        /// <returns>The document range that was found.</returns>
        public DocumentRange Find(Type c, int index)
        {
            int i = index;
            foreach (DocumentRange span in Contents)
            {
                if (span.GetType() == c)
                {
                    if (i <= 0)
                    {
                        return span;
                    }
                    i--;
                }
            }
            return null;
        }

        /// <summary>
        /// Find the link that contains the specified string.
        /// </summary>
        /// <param name="str">The string to search for.</param>
        /// <returns>The link found.</returns>
        public Link FindLink(String str)
        {
            return Contents.OfType<Link>().FirstOrDefault(link => link.GetTextOnly().Equals(str));
        }

        /// <summary>
        /// Get the number of data items in this collection.
        /// </summary>
        /// <returns>The size of the data unit.</returns>
        public int getDataSize()
        {
            return _data.Count;
        }

        /// <summary>
        /// Get the DataUnit unit at the specified index.
        /// </summary>
        /// <param name="i">The index to use.</param>
        /// <returns>The DataUnit found at the specified index.</returns>
        public DataUnit GetDataUnit(int i)
        {
            return _data[i];
        }


        /// <summary>
        /// The object as a string.
        /// </summary>
        /// <returns>The object as a string.</returns>
        public override String ToString()
        {
            var result = new StringBuilder();
            foreach (DocumentRange span in Contents)
            {
                result.Append(span.ToString());
                result.Append("\n");
            }
            return result.ToString();
        }
    }

    public class CodeDataUnit : DataUnit
    {
        /// <summary>
        /// The code for this data unit.
        /// </summary>
        private String _code;

        /// <summary>
        /// The code for this data unit.
        /// </summary>
        public String Code
        {
            get { return _code; }
            set { _code = value; }
        }

        /// <summary>
        /// This object as a string.
        /// </summary>
        /// <returns>This object as a string.</returns>
        public override String ToString()
        {
            return _code;
        }
    }

    public class DataUnit
    {
    }

    public class TagDataUnit : DataUnit
    {
        /// <summary>
        /// The tag that this data unit is based on.
        /// </summary>
        public Tag Tag { get; set; }
    }

    public class TextDataUnit : DataUnit
    {
        /// <summary>
        /// The text for this data unit.
        /// </summary>
        private String _text;

        /// <summary>
        /// The text for this data unit.
        /// </summary>
        public String Text
        {
            get { return _text; }
            set { _text = value; }
        }


        /// <summary>
        /// This object as a string.
        /// </summary>
        /// <returns>This object as a string.</returns>
        public override String ToString()
        {
            return _text;
        }
    }

    public class RSS
    {
        /// <summary>
        /// All of the attributes for this RSS document.
        /// </summary>
        private readonly Dictionary<String, String> _attributes = new Dictionary<String, String>();

        /// <summary>
        /// All RSS items, or stories, found.
        /// </summary>
        private readonly List<RSSItem> _items = new List<RSSItem>();

        /// <summary>
        /// All of the attributes for this RSS document.
        /// </summary>
        public Dictionary<String, String> Attributes
        {
            get { return _attributes; }
        }

        /// <summary>
        /// All RSS items, or stories, found.
        /// </summary>
        public List<RSSItem> Items
        {
            get { return _items; }
        }

        /// <summary>
        /// Simple utility function that converts a RSS formatted date
        /// into a C# date.
        /// </summary>
        /// <param name="datestr">A date</param>
        /// <returns>A C# DateTime object.</returns>
        public static DateTime ParseDate(String datestr)
        {
            DateTime date = DateTime.Parse(datestr);
            return date;
        }

        /// <summary>
        /// Load the specified RSS item, or story.
        /// </summary>
        /// <param name="item">A XML node that contains a RSS item.</param>
        private void LoadItem(XmlNode item)
        {
            var rssItem = new RSSItem();
            rssItem.Load(item);
            _items.Add(rssItem);
        }

        /// <summary>
        /// Load the channle node.
        /// </summary>
        /// <param name="channel">A node that contains a channel.</param>
        private void LoadChannel(XmlNode channel)
        {
            foreach (XmlNode node in channel.ChildNodes)
            {
                String nodename = node.Name;
                if (String.Compare(nodename, "item", true) == 0)
                {
                    LoadItem(node);
                }
                else
                {
                    _attributes.Remove(nodename);
                    _attributes.Add(nodename, channel.InnerText);
                }
            }
        }

        /// <summary>
        /// Load all RSS data from the specified URL.
        /// </summary>
        /// <param name="url">URL that contains XML data.</param>
        public void Load(Uri url)
        {
            //WebRequest http = WebRequest.Create(url);
            //var response = (HttpWebResponse)http.GetResponse();
            //Stream istream = response.GetResponseStream();

            //var d = new XmlDocument();
            //d.Load(istream);

            //foreach (XmlNode node in d.DocumentElement.ChildNodes)
            //{
            //    String nodename = node.Name;

            //    // RSS 2.0
            //    if (String.Compare(nodename, "channel", true) == 0)
            //    {
            //        LoadChannel(node);
            //    }
            //    // RSS 1.0
            //    else if (String.Compare(nodename, "item", true) == 0)
            //    {
            //        LoadItem(node);
            //    }
            //}
        }

        /// <summary>
        /// Convert the object to a String.
        /// </summary>
        /// <returns>The object as a String.</returns>
        public override String ToString()
        {
            var str = new StringBuilder();

            foreach (String item in _attributes.Keys)
            {
                str.Append(item);
                str.Append('=');
                str.Append(_attributes[item]);
                str.Append('\n');
            }
            str.Append("Items:\n");
            foreach (RSSItem item in _items)
            {
                str.Append(item.ToString());
                str.Append('\n');
            }
            return str.ToString();
        }
    }

    public class RSSItem
    {
        /// <summary>
        /// The date this item was published.
        /// </summary>
        private DateTime _date;

        /// <summary>
        /// The description of this item.
        /// </summary>
        private String _description;

        /// <summary>
        /// The hyperlink to this item.
        /// </summary>
        private String _link;

        /// <summary>
        /// The title of this item.
        /// </summary>
        private String _title;

        /// <summary>
        /// The title of this item.
        /// </summary>
        public String Title
        {
            get { return _title; }
            set { _title = value; }
        }

        /// <summary>
        /// The hyperlink to this item.
        /// </summary>
        public String Link
        {
            get { return _link; }
            set { _link = value; }
        }


        /// <summary>
        /// The description of this item.
        /// </summary>
        public String Description
        {
            get { return _description; }
            set { _description = value; }
        }

        /// <summary>
        /// The date this item was published.
        /// </summary>
        public DateTime Date
        {
            get { return _date; }
            set { _date = value; }
        }


        /// <summary>
        /// Load an item from the specified node.
        /// </summary>
        /// <param name="node">The Node to load the item from.</param>
        public void Load(XmlNode node)
        {
            foreach (XmlNode n in node.ChildNodes)
            {
                String name = n.Name;

                if (String.Compare(name, "title", true) == 0)
                    _title = n.InnerText;
                else if (String.Compare(name, "link", true) == 0)
                    _link = n.InnerText;
                else if (String.Compare(name, "description", true) == 0)
                    _description = n.InnerText;
                else if (String.Compare(name, "pubDate", true) == 0)
                {
                    String str = n.InnerText;
                    _date = RSS.ParseDate(str);
                }
            }
        }


        /// <summary>
        /// Convert the object to a String.
        /// </summary>
        /// <returns>The object as a String.</returns>
        public override String ToString()
        {
            var builder = new StringBuilder();
            builder.Append('[');
            builder.Append("title=\"");
            builder.Append(_title);
            builder.Append("\",link=\"");
            builder.Append(_link);
            builder.Append("\",date=\"");
            builder.Append(_date);
            builder.Append("\"]");
            return builder.ToString();
        }
    }

    public class BotError : SyntError
    {
        /// <summary>
        /// Construct a message exception.
        /// </summary>
        /// <param name="str">The message.</param>
        public BotError(String str)
            : base(str)
        {
        }

        /// <summary>
        /// Pass on an exception.
        /// </summary>
        /// <param name="e">The other exception.</param>
        public BotError(Exception e)
            : base(e)
        {
        }
    }

    public class BotUtil
    {
        /// <summary>
        /// How much data to read at once.
        /// </summary>
        public static int BufferSize = 8192;

        /// <summary>
        /// This method is very useful for grabbing information from a HTML page.
        /// </summary>
        /// <param name="str">The string to search.</param>
        /// <param name="token1">The text, or tag, that comes before the desired text</param>
        /// <param name="token2">The text, or tag, that comes after the desired text</param>
        /// <param name="index">Index in the string to start searching from.</param>
        /// <param name="occurence">What occurence.</param>
        /// <returns>The contents of the URL that was downloaded.</returns>
        public static String ExtractFromIndex(String str, String token1,
                                              String token2, int index, int occurence)
        {
            // convert everything to lower case
            String searchStr = str.ToLower();
            String token1Lower = token1.ToLower();
            String token2Lower = token2.ToLower();

            int count = occurence;

            // now search
            int location1 = index - 1;
            do
            {
                location1 = searchStr.IndexOf(token1Lower, location1 + 1);

                if (location1 == -1)
                {
                    return null;
                }

                count--;
            } while (count > 0);


            // return the result from the original string that has mixed
            // case
            int location2 = searchStr.IndexOf(token2Lower, location1 + 1);
            if (location2 == -1)
            {
                return null;
            }

            return str.Substring(location1 + token1Lower.Length, location2 - (location1 + token1.Length));
        }

        /// <summary>
        /// This method is very useful for grabbing information from a HTML page.
        /// </summary>
        /// <param name="str">The string to search.</param>
        /// <param name="token1">The text, or tag, that comes before the desired text.</param>
        /// <param name="token2">The text, or tag, that comes after the desired text.</param>
        /// <param name="index">Which occurrence of token1 to use, 1 for the first.</param>
        /// <returns>The contents of the URL that was downloaded.</returns>
        public static String Extract(String str, String token1,
                                     String token2, int index)
        {
            // convert everything to lower case
            String searchStr = str.ToLower();
            String token1Lower = token1.ToLower();
            String token2Lower = token2.ToLower();

            int count = index;

            // now search
            int location1 = -1;
            do
            {
                location1 = searchStr.IndexOf(token1Lower, location1 + 1);

                if (location1 == -1)
                {
                    return null;
                }

                count--;
            } while (count > 0);

            // return the result from the original string that has mixed
            // case
            int location2 = searchStr.IndexOf(token2Lower, location1 + 1);
            if (location2 == -1)
            {
                return null;
            }

            return str.Substring(location1 + token1Lower.Length, location2 - (location1 + token1.Length));
        }

        /// <summary>
        /// Post to a page.
        /// </summary>
        /// <param name="uri">The URI to post to.</param>
        /// <param name="param">The post params.</param>
        /// <returns>The HTTP response.</returns>
   

        /// <summary>
        /// Post bytes to a page.
        /// </summary>
        /// <param name="uri">The URI to post to.</param>
        /// <param name="bytes">The bytes to post.</param>
        /// <param name="length">The length of the posted data.</param>
        /// <returns>The HTTP response.</returns>
  

        /// <summary>
        /// Load the specified web page into a string.
        /// </summary>
        /// <param name="url">The url to load.</param>
        /// <returns>The web page as a string.</returns>
   

        /// <summary>
        /// Private constructor.
        /// </summary>
        private BotUtil()
        {
        }

        /// <summary>
        /// Post to a page.
        /// </summary>
        /// <param name="uri">The URI to post to.</param>
        /// <param name="stream">The stream.</param>
        /// <returns>The page returned.</returns>
   
    }

    [Serializable]
    public class ActivationBiPolar : IActivationFunction
    {
        /// <summary>
        /// The parameters.
        /// </summary>
        ///
        private readonly double[] _paras;

        /// <summary>
        /// Construct the bipolar activation function.
        /// </summary>
        ///
        public ActivationBiPolar()
        {
            _paras = new double[0];
        }

        /// <inheritdoc/>
        public virtual double DerivativeFunction(double b, double a)
        {
            return 1;
        }


        /// <returns>Return true, bipolar has a 1 for derivative.</returns>
        public virtual bool HasDerivative()
        {
            return true;
        }

        /// <inheritdoc />
        public virtual void ActivationFunction(double[] x, int start,
                                               int size)
        {
            for (int i = start; i < start + size; i++)
            {
                if (x[i] > 0)
                {
                    x[i] = 1;
                }
                else
                {
                    x[i] = -1;
                }
            }
        }

        /// <inheritdoc />
        public virtual String[] ParamNames
        {
            get
            {
                String[] result = { "slope" };
                return result;
            }
        }


        /// <inheritdoc />
        public virtual double[] Params
        {
            get { return _paras; }
        }

        /// <summary>
        /// Clone the object.
        /// </summary>
        /// <returns>The cloned object.</returns>
        public object Clone()
        {
            return new ActivationBiPolar();
        }
    }

    [Serializable]
    public class ActivationCompetitive : IActivationFunction
    {
        /// <summary>
        /// The offset to the parameter that holds the max winners.
        /// </summary>
        ///
        public const int ParamCompetitiveMaxWinners = 0;

        /// <summary>
        /// The parameters.
        /// </summary>
        ///
        private readonly double[] _paras;

        /// <summary>
        /// Create a competitive activation function with one winner allowed.
        /// </summary>
        ///
        public ActivationCompetitive()
            : this(1)
        {
        }

        /// <summary>
        /// Create a competitive activation function with the specified maximum
        /// number of winners.
        /// </summary>
        ///
        /// <param name="winners">The maximum number of winners that this function supports.</param>
        public ActivationCompetitive(int winners)
        {
            _paras = new double[1];
            _paras[ParamCompetitiveMaxWinners] = winners;
        }

        /// <inheritdoc />
        public virtual void ActivationFunction(double[] x, int start,
                                               int size)
        {
            var winners = new bool[x.Length];
            double sumWinners = 0;

            // find the desired number of winners
            for (int i = 0; i < _paras[0]; i++)
            {
                double maxFound = Double.NegativeInfinity;
                int winner = -1;

                // find one winner
                for (int j = start; j < start + size; j++)
                {
                    if (!winners[j] && (x[j] > maxFound))
                    {
                        winner = j;
                        maxFound = x[j];
                    }
                }
                sumWinners += maxFound;
                winners[winner] = true;
            }

            // adjust weights for winners and non-winners
            for (int i = start; i < start + size; i++)
            {
                if (winners[i])
                {
                    x[i] = x[i] / sumWinners;
                }
                else
                {
                    x[i] = 0.0d;
                }
            }
        }

        /// <summary>
        /// Clone the object.
        /// </summary>
        /// <returns>The cloned object.</returns>
        object ICloneable.Clone()
        {
            return new ActivationCompetitive(
                (int)_paras[ParamCompetitiveMaxWinners]);
        }

        /// <inheritdoc/>
        public virtual double DerivativeFunction(double b, double a)
        {
            throw new NeuralNetworkError(
                "Can't use the competitive activation function "
                + "where a derivative is required.");
        }


        /// <summary>
        /// The maximum number of winners this function supports.
        /// </summary>
        public int MaxWinners
        {
            get { return (int)_paras[ParamCompetitiveMaxWinners]; }
        }


        /// <inheritdoc />
        public virtual String[] ParamNames
        {
            get
            {
                String[] result = { "maxWinners" };
                return result;
            }
        }


        /// <inheritdoc />
        public virtual double[] Params
        {
            get { return _paras; }
        }


        /// <returns>False, indication that no derivative is available for thisfunction.</returns>
        public virtual bool HasDerivative()
        {
            return false;
        }
    }

    public class ActivationElliott : IActivationFunction
    {
        /// <summary>
        /// The params.
        /// </summary>
        private readonly double[] _p;

        /// <summary>
        /// Construct a basic Elliott activation function, with a slope of 1.
        /// </summary>
        public ActivationElliott()
        {
            _p = new double[1];
            _p[0] = 1.0;
        }

        #region IActivationFunction Members

        /// <inheritdoc />
        public void ActivationFunction(double[] x, int start,
                                       int size)
        {
            for (int i = start; i < start + size; i++)
            {
                double s = _p[0];
                x[i] = ((x[i] * s) / 2) / (1 + Math.Abs(x[i] * s)) + 0.5;
            }
        }

        /// <summary>
        /// Clone the object.
        /// </summary>
        /// <returns>The object to be cloned.</returns>
        public object Clone()
        {
            return new ActivationElliott();
        }

        /// <inheritdoc />
        public double DerivativeFunction(double b, double a)
        {
            double s = _p[0];
            return s / (2.0 * (1.0 + Math.Abs(b * s)) * (1 + Math.Abs(b * s)));
        }

        /// <inheritdoc />
        public String[] ParamNames
        {
            get
            {
                String[] result = { "Slope" };
                return result;
            }
        }

        /// <inheritdoc />
        public double[] Params
        {
            get { return _p; }
        }

        /// <summary>
        /// Return true, Elliott activation has a derivative.
        /// </summary>
        /// <returns>Return true, Elliott activation has a derivative.</returns>
        public bool HasDerivative()
        {
            return true;
        }

        #endregion

        /// <inheritdoc />
        public void SetParam(int index, double value)
        {
            _p[index] = value;
        }
    }

    public class ActivationElliottSymmetric : IActivationFunction
    {
        /// <summary>
        /// The params.
        /// </summary>
        private readonly double[] _p;

        /// <summary>
        /// Construct a basic Elliott activation function, with a slope of 1.
        /// </summary>
        public ActivationElliottSymmetric()
        {
            _p = new double[1];
            _p[0] = 1.0;
        }

        #region IActivationFunction Members

        /// <inheritdoc />
        public void ActivationFunction(double[] x, int start,
                                       int size)
        {
            for (int i = start; i < start + size; i++)
            {
                double s = _p[0];
                x[i] = (x[i] * s) / (1 + Math.Abs(x[i] * s));
            }
        }

        /// <summary>
        /// Clone the object.
        /// </summary>
        /// <returns>The object to be cloned.</returns>
        public object Clone()
        {
            return new ActivationElliottSymmetric();
        }

        /// <inheritdoc />
        public double DerivativeFunction(double b, double a)
        {
            double s = _p[0];
            double d = (1.0 + Math.Abs(b * s));
            return (s * 1.0) / (d * d);
        }

        /// <inheritdoc />
        public String[] ParamNames
        {
            get
            {
                String[] result = { "Slope" };
                return result;
            }
        }

        /// <inheritdoc />
        public double[] Params
        {
            get { return _p; }
        }

        /// <summary>
        /// Return true, Elliott activation has a derivative.
        /// </summary>
        /// <returns>Return true, Elliott activation has a derivative.</returns>
        public bool HasDerivative()
        {
            return true;
        }

        #endregion

        /// <inheritdoc />
        public void SetParam(int index, double value)
        {
            _p[index] = value;
        }
    }

    [Serializable]
    public class ActivationGaussian : IActivationFunction
    {
        /// <summary>
        /// The offset to the parameter that holds the width.
        /// </summary>
        ///
        public const int ParamGaussianCenter = 0;

        /// <summary>
        /// The offset to the parameter that holds the peak.
        /// </summary>
        ///
        public const int ParamGaussianPeak = 1;

        /// <summary>
        /// The offset to the parameter that holds the width.
        /// </summary>
        ///
        public const int ParamGaussianWidth = 2;

        /// <summary>
        /// The parameters.
        /// </summary>
        ///
        private readonly double[] _paras;

        /// <summary>
        /// Create an empty activation gaussian.
        /// </summary>
        public ActivationGaussian()
        {
        }

        /// <summary>
        /// Create a gaussian activation function.
        /// </summary>
        ///
        /// <param name="center">The center of the curve.</param>
        /// <param name="peak">The peak of the curve.</param>
        /// <param name="width">The width of the curve.</param>
        public ActivationGaussian(double center, double peak,
                                  double width)
        {
            _paras = new double[3];
            _paras[ParamGaussianCenter] = center;
            _paras[ParamGaussianPeak] = peak;
            _paras[ParamGaussianWidth] = width;
        }

        /// <summary>
        /// Clone the object.
        /// </summary>
        /// <returns>The cloned object.</returns>
        public object Clone()
        {
            return new ActivationGaussian(Center, Peak,
                                          Width);
        }


        /// <summary>
        /// The width of the function.
        /// </summary>
        private double Width
        {
            get { return Params[ParamGaussianWidth]; }
        }


        /// <summary>
        /// The center of the function.
        /// </summary>
        private double Center
        {
            get { return Params[ParamGaussianCenter]; }
        }


        /// <summary>
        /// The peak of the function.
        /// </summary>
        private double Peak
        {
            get { return Params[ParamGaussianPeak]; }
        }


        /// <summary>
        /// Return true, gaussian has a derivative.
        /// </summary>
        /// <returns>Return true, gaussian has a derivative.</returns>
        public virtual bool HasDerivative()
        {
            return true;
        }

        /// <inheritdoc />
        public virtual void ActivationFunction(double[] x, int start,
                                               int size)
        {
            for (int i = start; i < start + size; i++)
            {
                x[i] = _paras[ParamGaussianPeak]
                       * BoundMath
                            .Exp(-Math.Pow(x[i]
                                           - _paras[ParamGaussianCenter], 2)
                                 / (2.0d * _paras[ParamGaussianWidth] * _paras[ParamGaussianWidth]));
            }
        }

        /// <inheritdoc />
        public virtual double DerivativeFunction(double b, double a)
        {
            double width = _paras[ParamGaussianWidth];
            double peak = _paras[ParamGaussianPeak];
            return Math.Exp(-0.5d * width * width * b * b) * peak * width * width
                   * (width * width * b * b - 1);
        }

        /// <inheritdoc />
        public virtual String[] ParamNames
        {
            get
            {
                String[] result = { "center", "peak", "width" };
                return result;
            }
        }


        /// <summary>
        /// {@inheritDoc}
        /// </summary>
        ///
        public virtual double[] Params
        {
            get { return _paras; }
        }
    }

    [Serializable]
    public class ActivationLinear : IActivationFunction
    {
        /// <summary>
        /// The parameters.
        /// </summary>
        ///
        private readonly double[] _paras;

        /// <summary>
        /// Construct a linear activation function, with a slope of 1.
        /// </summary>
        ///
        public ActivationLinear()
        {
            _paras = new double[0];
        }


        /// <summary>
        /// Clone the object.
        /// </summary>
        /// <returns>The cloned object.</returns>
        public object Clone()
        {
            return new ActivationLinear();
        }


        /// <returns>Return true, linear has a 1 derivative.</returns>
        public virtual bool HasDerivative()
        {
            return true;
        }

        /// <inheritdoc />
        public virtual void ActivationFunction(double[] x, int start,
                                               int size)
        {
            for (int i = start; i < start + size; i++)
            {
                x[i] = x[i];
            }
        }

        /// <inheritdoc />
        public virtual double DerivativeFunction(double b, double a)
        {
            return 1;
        }

        /// <inheritdoc />
        public virtual String[] ParamNames
        {
            get
            {
                String[] result = { };
                return result;
            }
        }


        /// <inheritdoc />
        public virtual double[] Params
        {
            get { return _paras; }
        }
    }

    [Serializable]
    public class ActivationLOG : IActivationFunction
    {
        /// <summary>
        /// The parameters.
        /// </summary>
        ///
        private readonly double[] _paras;

        /// <summary>
        /// Construct the activation function.
        /// </summary>
        ///
        public ActivationLOG()
        {
            _paras = new double[0];
        }

        /// <summary>
        /// Clone the object.
        /// </summary>
        /// <returns>The cloned object.</returns>
        public object Clone()
        {
            return new ActivationLOG();
        }


        /// <returns>Return true, log has a derivative.</returns>
        public virtual bool HasDerivative()
        {
            return true;
        }

        /// <inheritdoc />
        public virtual void ActivationFunction(double[] x, int start,
                                               int size)
        {
            for (int i = start; i < start + size; i++)
            {
                if (x[i] >= 0)
                {
                    x[i] = BoundMath.Log(1 + x[i]);
                }
                else
                {
                    x[i] = -BoundMath.Log(1 - x[i]);
                }
            }
        }

        /// <inheritdoc />
        public virtual double DerivativeFunction(double b, double a)
        {
            if (b >= 0)
            {
                return 1 / (1 + b);
            }
            return 1 / (1 - b);
        }

        /// <inheritdoc />
        public virtual String[] ParamNames
        {
            get
            {
                String[] result = { };
                return result;
            }
        }


        /// <inheritdoc />
        public virtual double[] Params
        {
            get { return _paras; }
        }
    }

    [Serializable]
    public class ActivationRamp : IActivationFunction
    {
        /// <summary>
        /// The ramp high threshold parameter.
        /// </summary>
        ///
        public const int ParamRampHighThreshold = 0;

        /// <summary>
        /// The ramp low threshold parameter.
        /// </summary>
        ///
        public const int ParamRampLowThreshold = 1;

        /// <summary>
        /// The ramp high parameter.
        /// </summary>
        ///
        public const int ParamRampHigh = 2;

        /// <summary>
        /// The ramp low parameter.
        /// </summary>
        ///
        public const int ParamRampLow = 3;

        /// <summary>
        /// The parameters.
        /// </summary>
        ///
        private readonly double[] _paras;

        /// <summary>
        /// Construct a ramp activation function.
        /// </summary>
        ///
        /// <param name="thresholdHigh">The high threshold value.</param>
        /// <param name="thresholdLow">The low threshold value.</param>
        /// <param name="high">The high value, replaced if the high threshold is exceeded.</param>
        /// <param name="low">The low value, replaced if the low threshold is exceeded.</param>
        public ActivationRamp(double thresholdHigh,
                              double thresholdLow, double high, double low)
        {
            _paras = new double[4];
            _paras[ParamRampHighThreshold] = thresholdHigh;
            _paras[ParamRampLowThreshold] = thresholdLow;
            _paras[ParamRampHigh] = high;
            _paras[ParamRampLow] = low;
        }

        /// <summary>
        /// Default constructor.
        /// </summary>
        ///
        public ActivationRamp()
            : this(1, 0, 1, 0)
        {
        }


        /// <summary>
        /// Clone the object.
        /// </summary>
        /// <returns>The cloned object.</returns>
        public object Clone()
        {
            return new ActivationRamp(
                _paras[ParamRampHighThreshold],
                _paras[ParamRampLowThreshold],
                _paras[ParamRampHigh],
                _paras[ParamRampLow]);
        }


        /// <summary>
        /// The high value.
        /// </summary>
        public double High
        {
            get { return _paras[ParamRampHigh]; }
            set { _paras[ParamRampHigh] = value; }
        }


        /// <summary>
        /// The low value.
        /// </summary>
        public double Low
        {
            get { return _paras[ParamRampLow]; }
            set { _paras[ParamRampLow] = value; }
        }


        /// <summary>
        /// Set the threshold high.
        /// </summary>
        public double ThresholdHigh
        {
            get { return _paras[ParamRampHighThreshold]; }
            set { _paras[ParamRampHighThreshold] = value; }
        }


        /// <summary>
        /// The threshold low.
        /// </summary>
        public double ThresholdLow
        {
            get { return _paras[ParamRampLowThreshold]; }
            set { _paras[ParamRampLowThreshold] = value; }
        }


        /// <summary>
        /// True, as this function does have a derivative.
        /// </summary>
        /// <returns>True, as this function does have a derivative.</returns>
        public virtual bool HasDerivative()
        {
            return true;
        }

        /// <inheritdoc />
        public virtual void ActivationFunction(double[] x, int start,
                                               int size)
        {
            double slope = (_paras[ParamRampHighThreshold] - _paras[ParamRampLowThreshold])
                           / (_paras[ParamRampHigh] - _paras[ParamRampLow]);

            for (int i = start; i < start + size; i++)
            {
                if (x[i] < _paras[ParamRampLowThreshold])
                {
                    x[i] = _paras[ParamRampLow];
                }
                else if (x[i] > _paras[ParamRampHighThreshold])
                {
                    x[i] = _paras[ParamRampHigh];
                }
                else
                {
                    x[i] = (slope * x[i]);
                }
            }
        }

        /// <inheritdoc />
        public virtual double DerivativeFunction(double b, double a)
        {
            return 1.0d;
        }

        /// <inheritdoc />
        public virtual String[] ParamNames
        {
            get
            {
                String[] result = {
                                      "thresholdHigh", "thresholdLow", "high",
                                      "low"
                                  };
                return result;
            }
        }


        /// <inheritdoc />
        public virtual double[] Params
        {
            get { return _paras; }
        }
    }

    [Serializable]
    public class ActivationSigmoid : IActivationFunction
    {
        /// <summary>
        /// The parameters.
        /// </summary>
        ///
        private readonly double[] _paras;

        /// <summary>
        /// Construct a basic sigmoid function, with a slope of 1.
        /// </summary>
        ///
        public ActivationSigmoid()
        {
            _paras = new double[0];
        }

        /// <summary>
        /// Clone the object.
        /// </summary>
        /// <returns>The cloned object.</returns>
        public object Clone()
        {
            return new ActivationSigmoid();
        }

        /// <returns>True, sigmoid has a derivative.</returns>
        public virtual bool HasDerivative()
        {
            return true;
        }

        /// <inheritdoc />
        public virtual void ActivationFunction(double[] x, int start,
                                               int size)
        {
            for (int i = start; i < start + size; i++)
            {
                x[i] = 1.0d / (1.0d + BoundMath.Exp(-1 * x[i]));
            }
        }

        /// <inheritdoc />
        public virtual double DerivativeFunction(double b, double a)
        {
            return a * (1.0d - a);
        }

        /// <inheritdoc />
        public virtual String[] ParamNames
        {
            get
            {
                String[] results = { };
                return results;
            }
        }


        /// <inheritdoc />
        public virtual double[] Params
        {
            get { return _paras; }
        }


    }

    [Serializable]
    public class ActivationSIN : IActivationFunction
    {
        /// <summary>
        /// Construct the sin activation function.
        /// </summary>
        ///
        public ActivationSIN()
        {
            _paras = new double[0];
        }

        /// <summary>
        /// The parameters.
        /// </summary>
        ///
        private readonly double[] _paras;

        /// <summary>
        /// Clone the object.
        /// </summary>
        /// <returns>The cloned object.</returns>
        public object Clone()
        {
            return new ActivationSIN();
        }


        /// <returns>Return true, sin has a derivative.</returns>
        public virtual bool HasDerivative()
        {
            return true;
        }

        /// <inheritdoc />
        public virtual void ActivationFunction(double[] x, int start,
                                               int size)
        {
            for (int i = start; i < start + size; i++)
            {
                x[i] = BoundMath.Sin(x[i]);
            }
        }

        /// <inheritdoc />
        public virtual double DerivativeFunction(double b, double a)
        {
            return BoundMath.Cos(b);
        }

        /// <inheritdoc />
        public virtual String[] ParamNames
        {
            get
            {
                String[] result = { };
                return result;
            }
        }


        /// <inheritdoc />
        public virtual double[] Params
        {
            get { return _paras; }
        }
    }

    [Serializable]
    public class ActivationSoftMax : IActivationFunction
    {
        /// <summary>
        /// The parameters.
        /// </summary>
        ///
        private readonly double[] _paras;

        /// <summary>
        /// Construct the soft-max activation function.
        /// </summary>
        ///
        public ActivationSoftMax()
        {
            _paras = new double[0];
        }

        /// <summary>
        /// Clone the object.
        /// </summary>
        /// <returns>The cloned object.</returns>
        public object Clone()
        {
            return new ActivationSoftMax();
        }

        /// <returns>Return false, softmax has no derivative.</returns>
        public virtual bool HasDerivative()
        {
            return true;
        }

        /// <inheritdoc />
        public virtual void ActivationFunction(double[] x, int start,
                                               int size)
        {
            double sum = 0;
            for (int i = start; i < start + size; i++)
            {
                x[i] = BoundMath.Exp(x[i]);
                sum += x[i];
            }
            for (int i = start; i < start + size; i++)
            {
                x[i] = x[i] / sum;
            }
        }

        /// <inheritdoc />
        public virtual double DerivativeFunction(double b, double a)
        {
            return 1.0d;
        }

        /// <inheritdoc />
        public virtual String[] ParamNames
        {
            get
            {
                String[] result = { };
                return result;
            }
        }


        /// <inheritdoc />
        public virtual double[] Params
        {
            get { return _paras; }
        }
    }

    [Serializable]
    public class ActivationStep : IActivationFunction
    {
        /// <summary>
        /// The step center parameter.
        /// </summary>
        ///
        public const int ParamStepCenter = 0;

        /// <summary>
        /// The step low parameter.
        /// </summary>
        ///
        public const int ParamStepLow = 1;

        /// <summary>
        /// The step high parameter.
        /// </summary>
        ///
        public const int ParamStepHigh = 2;

        /// <summary>
        /// The parameters.
        /// </summary>
        ///
        private readonly double[] _paras;

        /// <summary>
        /// Construct a step activation function.
        /// </summary>
        ///
        /// <param name="low">The low of the function.</param>
        /// <param name="center">The center of the function.</param>
        /// <param name="high">The high of the function.</param>
        public ActivationStep(double low, double center, double high)
        {
            _paras = new double[3];
            _paras[ParamStepCenter] = center;
            _paras[ParamStepLow] = low;
            _paras[ParamStepHigh] = high;
        }

        /// <summary>
        /// Create a basic step activation with low=0, center=0, high=1.
        /// </summary>
        ///
        public ActivationStep()
            : this(0.0d, 0.0d, 1.0d)
        {
        }

        /// <summary>
        /// Set the center of this function.
        /// </summary>
        public double Center
        {
            get { return _paras[ParamStepCenter]; }
            set { _paras[ParamStepCenter] = value; }
        }


        /// <summary>
        /// Set the low of this function.
        /// </summary>
        public double Low
        {
            get { return _paras[ParamStepLow]; }
            set { _paras[ParamStepLow] = value; }
        }


        /// <summary>
        /// Set the high of this function.
        /// </summary>
        public double High
        {
            get { return _paras[ParamStepHigh]; }
            set { _paras[ParamStepHigh] = value; }
        }

        /// <summary>
        /// Clone the object.
        /// </summary>
        /// <returns>The cloned object.</returns>
        public object Clone()
        {
            var result = new ActivationStep(Low, Center,
                                            High);
            return result;
        }

        /// <returns>Returns true, this activation function has a derivative.</returns>
        public virtual bool HasDerivative()
        {
            return true;
        }

        /// <inheritdoc />
        public virtual void ActivationFunction(double[] x, int start,
                                               int size)
        {
            for (int i = start; i < start + size; i++)
            {
                if (x[i] >= _paras[ParamStepCenter])
                {
                    x[i] = _paras[ParamStepHigh];
                }
                else
                {
                    x[i] = _paras[ParamStepLow];
                }
            }
        }

        /// <inheritdoc />
        public virtual double DerivativeFunction(double b, double a)
        {
            return 1.0d;
        }

        /// <inheritdoc />
        public virtual String[] ParamNames
        {
            get
            {
                String[] result = { "center", "low", "high" };
                return result;
            }
        }


        /// <inheritdoc />
        public virtual double[] Params
        {
            get { return _paras; }
        }

    }

    [Serializable]
    public class ActivationTANH : IActivationFunction
    {
        /// <summary>
        /// The parameters.
        /// </summary>
        ///
        private readonly double[] _paras;

        /// <summary>
        /// Construct a basic HTAN activation function, with a slope of 1.
        /// </summary>
        ///
        public ActivationTANH()
        {
            _paras = new double[0];
        }

        /// <summary>
        /// Clone the object.
        /// </summary>
        /// <returns>The cloned object.</returns>
        public object Clone()
        {
            return new ActivationTANH();
        }


        /// <returns>Return true, TANH has a derivative.</returns>
        public virtual bool HasDerivative()
        {
            return true;
        }

        /// <inheritdoc />
        public virtual void ActivationFunction(double[] x, int start,
                                               int size)
        {
            for (int i = start; i < start + size; i++)
            {
                x[i] = 2.0 / (1.0 + BoundMath.Exp(-2.0 * x[i])) - 1.0; //3x faster than Math.Tanh(x[i]);
            }
        }

        /// <inheritdoc />
        public virtual double DerivativeFunction(double b, double a)
        {
            return (1.0d - a * a);
        }

        /// <inheritdoc />
        public virtual String[] ParamNames
        {
            get
            {
                String[] result = { };
                return result;
            }
        }


        /// <inheritdoc />
        public virtual double[] Params
        {
            get { return _paras; }
        }
    }

    public class BIFDefinition
    {
        /// <summary>
        /// Given definitions.
        /// </summary>
        private readonly IList<String> _givenDefinitions = new List<String>();

        /// <summary>
        /// The table of probabilities.
        /// </summary>
        private double[] _table;

        /// <summary>
        /// The "for" definition.
        /// </summary>
        public String ForDefinition { get; set; }

        /// <summary>
        /// The table of probabilities.
        /// </summary>
        public double[] Table
        {
            get { return _table; }
        }

        /// <summary>
        /// The given defintions.
        /// </summary>
        public IList<String> GivenDefinitions
        {
            get { return _givenDefinitions; }
        }

        /// <summary>
        /// Set the probabilities as a string.
        /// </summary>
        /// <param name="s">A space separated string.</param>
        public void SetTable(String s)
        {
            // parse a space separated list of numbers
            String[] tok = s.Split(' ');
            IList<Double> list = new List<Double>();
            foreach (String str in tok)
            {
                // support both radix formats
                if (str.IndexOf(",") != -1)
                {
                    list.Add(CSVFormat.DecimalComma.Parse(str));
                }
                else
                {
                    list.Add(CSVFormat.DecimalComma.Parse(str));
                }
            }

            // now copy to regular array
            _table = new double[list.Count];
            for (int i = 0; i < _table.Length; i++)
            {
                _table[i] = list[i];
            }
        }

        /// <summary>
        /// Add a given.
        /// </summary>
        /// <param name="s">The given to add.</param>
        public void AddGiven(String s)
        {
            _givenDefinitions.Add(s);
        }
    }

    public class BIFVariable
    {
        /// <summary>
        /// The name of the variable.
        /// </summary>
        public String Name { get; set; }

        /// <summary>
        /// Options for this variable.
        /// </summary>
        private IList<String> Options { get; set; }

        /// <summary>
        /// Construct the variable.
        /// </summary>
        public BIFVariable()
        {
            Options = new List<String>();
        }


        /// <summary>
        /// Add an option to the variable.
        /// </summary>
        /// <param name="s">The option to add.</param>
        public void AddOption(String s)
        {
            Options.Add(s);
        }
    }

    public class ParsedChoice
    {
        /// <summary>
        /// The label for this choice.
        /// </summary>
        private readonly String _label;

        /// <summary>
        /// The max value for this choice.
        /// </summary>
        private readonly double _max;

        /// <summary>
        /// The min value for this choice.
        /// </summary>
        private readonly double _min;

        /// <summary>
        /// Construct a continuous choice, with a min and max. 
        /// </summary>
        /// <param name="label">The label, for this chocie.</param>
        /// <param name="min">The min value, for this choice.</param>
        /// <param name="max">The max value, for this choice.</param>
        public ParsedChoice(String label, double min, double max)
        {
            _label = label;
            _min = min;
            _max = max;
        }

        /// <summary>
        /// Construct a discrete value for this choice.
        /// </summary>
        /// <param name="label">The choice label.</param>
        /// <param name="index">The index.</param>
        public ParsedChoice(String label, int index)
        {
            _label = label;
            _min = index;
            _max = index;
        }

        /// <summary>
        /// The label.
        /// </summary>
        public String Label
        {
            get { return _label; }
        }

        /// <summary>
        /// The min value.
        /// </summary>
        public double Min
        {
            get { return _min; }
        }

        /// <summary>
        /// The max value.
        /// </summary>
        public double Max
        {
            get { return _max; }
        }

        /// <summary>
        /// True, if this choice is indexed, or discrete.
        /// </summary>
        public bool IsIndex
        {
            get { return Math.Abs(_min - _max) < SyntFramework.DefaultDoubleEqual; }
        }

        /// <inheritdoc/>
        public override String ToString()
        {
            return _label;
        }
    }

    public class ParsedEvent
    {
        /// <summary>
        /// The event label.
        /// </summary>
        private readonly String label;

        /// <summary>
        /// The event value.
        /// </summary>
        public String Value { get; set; }

        /// <summary>
        /// The choices.
        /// </summary>
        private readonly IList<ParsedChoice> list = new List<ParsedChoice>();

        /// <summary>
        /// Construct a parsed even with the specified label.
        /// </summary>
        /// <param name="theLabel">The label.</param>
        public ParsedEvent(String theLabel)
        {
            this.label = theLabel;
        }

        /// <summary>
        /// The label for this event.
        /// </summary>
        public String Label
        {
            get
            {
                return label;
            }
        }

        /// <summary>
        /// Resolve the event to an actual value.
        /// </summary>
        /// <param name="actualEvent">The actual event.</param>
        /// <returns>The value.</returns>
        public int ResolveValue(BayesianEvent actualEvent)
        {
            int result = 0;

            if (this.Value == null)
            {
                throw new BayesianError("Value is undefined for " + this.label + " should express a value with +, - or =.");
            }

            foreach (BayesianChoice choice in actualEvent.Choices)
            {
                if (this.Value.Equals(choice.Label))
                {
                    return result;
                }
                result++;
            }

            // resolve true/false if not found, probably came from +/- notation
            if (String.Compare(Value, "true", true) == 0)
            {
                return 0;
            }
            else if (String.Compare(Value, "false", true) == 0)
            {
                return 1;
            }

            // try to resolve numeric index
            try
            {
                int i = int.Parse(this.Value);
                if (i < actualEvent.Choices.Count)
                {
                    return i;
                }
            }
            catch (FormatException ex)
            {
                // well, we tried
            }

            // error out if nothing found
            throw new BayesianError("Can'f find choice " + this.Value + " in the event " + this.label);
        }


        /// <summary>
        /// A list of choices.
        /// </summary>
        public IList<ParsedChoice> ChoiceList
        {
            get
            {
                return list;
            }
        }

        /// <inheritdoc/>
        public String ToString()
        {
            StringBuilder result = new StringBuilder();
            result.Append("[ParsedEvent:label=");
            result.Append(this.label);
            result.Append(",value=");
            result.Append(this.Value);
            result.Append("]");
            return result.ToString();
        }

    }

    public class ParsedProbability
    {
        /// <summary>
        /// The base events.
        /// </summary>
        private readonly IList<ParsedEvent> baseEvents = new List<ParsedEvent>();

        /// <summary>
        /// The given events.
        /// </summary>
        private readonly IList<ParsedEvent> givenEvents = new List<ParsedEvent>();

        /// <summary>
        /// Add a given event.
        /// </summary>
        /// <param name="theEvent">The event to add.</param>
        public void AddGivenEvent(ParsedEvent theEvent)
        {
            this.givenEvents.Add(theEvent);
        }


        /// <summary>
        /// Add a base event.
        /// </summary>
        /// <param name="theEvent"The base event to add.></param>
        public void AddBaseEvent(ParsedEvent theEvent)
        {
            this.baseEvents.Add(theEvent);
        }

        /// <summary>
        /// Get the arguments to this event.
        /// </summary>
        /// <param name="network">The network.</param>
        /// <returns>The arguments.</returns>
        public int[] GetArgs(BayesianNetwork network)
        {
            int[] result = new int[givenEvents.Count];

            for (int i = 0; i < givenEvents.Count; i++)
            {
                ParsedEvent givenEvent = this.givenEvents[i];
                BayesianEvent actualEvent = network.GetEvent(givenEvent.Label);
                result[i] = givenEvent.ResolveValue(actualEvent);
            }

            return result;
        }

        /// <summary>
        /// The child events.
        /// </summary>
        public ParsedEvent ChildEvent
        {
            get
            {
                if (this.baseEvents.Count > 1)
                {
                    throw new BayesianError("Only one base event may be used to define a probability, i.e. P(a), not P(a,b).");
                }

                if (this.baseEvents.Count == 0)
                {
                    throw new BayesianError("At least one event must be provided, i.e. P() or P(|a,b,c) is not allowed.");
                }

                return this.baseEvents[0];
            }
        }

        /// <summary>
        /// Define the truth table. 
        /// </summary>
        /// <param name="network">The bayesian network.</param>
        /// <param name="result">The resulting probability.</param>
        public void DefineTruthTable(BayesianNetwork network, double result)
        {

            ParsedEvent childParsed = ChildEvent;
            BayesianEvent childEvent = network.RequireEvent(childParsed.Label);

            // define truth table line
            int[] args = GetArgs(network);
            childEvent.Table.AddLine(result, childParsed.ResolveValue(childEvent), args);

        }

        /// <summary>
        /// The base events.
        /// </summary>
        public IList<ParsedEvent> BaseEvents
        {
            get
            {
                return baseEvents;
            }
        }

        /// <summary>
        /// The given events.
        /// </summary>
        public IList<ParsedEvent> GivenEvents
        {
            get
            {
                return givenEvents;
            }
        }

        /// <summary>
        /// Define the relationships.
        /// </summary>
        /// <param name="network">The network.</param>
        public void DefineRelationships(BayesianNetwork network)
        {
            // define event relations, if they are not there already
            ParsedEvent childParsed = ChildEvent;
            BayesianEvent childEvent = network.RequireEvent(childParsed.Label);
            foreach (ParsedEvent e in this.givenEvents)
            {
                BayesianEvent parentEvent = network.RequireEvent(e.Label);
                network.CreateDependency(parentEvent, childEvent);
            }

        }

        /// <inheritdoc/>
        public String ToString()
        {
            StringBuilder result = new StringBuilder();
            result.Append("[ParsedProbability:baseEvents=");
            result.Append(this.baseEvents.ToString());
            result.Append(",givenEvents=");
            result.Append(this.givenEvents.ToString());
            result.Append("]");
            return result.ToString();
        }

    }

    public class ParseProbability
    {
        /// <summary>
        /// The network used.
        /// </summary>
        private readonly BayesianNetwork network;

        /// <summary>
        /// Parse the probability for the specified network. 
        /// </summary>
        /// <param name="theNetwork">The network to parse for.</param>
        public ParseProbability(BayesianNetwork theNetwork)
        {
            this.network = theNetwork;
        }

        /// <summary>
        /// Add events, as they are pased.
        /// </summary>
        /// <param name="parser">The parser.</param>
        /// <param name="results">The events found.</param>
        /// <param name="delim">The delimiter to use.</param>
        private void AddEvents(SimpleParser parser, IList<ParsedEvent> results, String delim)
        {
            bool done = false;
            StringBuilder l = new StringBuilder();

            while (!done && !parser.EOL())
            {
                char ch = parser.Peek();
                if (delim.IndexOf(ch) != -1)
                {
                    if (ch == ')' || ch == '|')
                        done = true;

                    ParsedEvent parsedEvent;

                    // deal with a value specified by + or -
                    if (l.Length > 0 && l[0] == '+')
                    {
                        String l2 = l.ToString().Substring(1);
                        parsedEvent = new ParsedEvent(l2.Trim());
                        parsedEvent.Value = "true";
                    }
                    else if (l.Length > 0 && l[0] == '-')
                    {
                        String l2 = l.ToString().Substring(1);
                        parsedEvent = new ParsedEvent(l2.Trim());
                        parsedEvent.Value = "false";
                    }
                    else
                    {
                        String l2 = l.ToString();
                        parsedEvent = new ParsedEvent(l2.Trim());
                    }

                    // parse choices
                    if (ch == '[')
                    {
                        parser.Advance();
                        int index = 0;
                        while (ch != ']' && !parser.EOL())
                        {

                            String labelName = parser.ReadToChars(":,]");
                            if (parser.Peek() == ':')
                            {
                                parser.Advance();
                                parser.EatWhiteSpace();
                                double min = double.Parse(parser.ReadToWhiteSpace());
                                parser.EatWhiteSpace();
                                if (!parser.LookAhead("to", true))
                                {
                                    throw new BayesianError("Expected \"to\" in probability choice range.");
                                }
                                parser.Advance(2);
                                double max = CSVFormat.EgFormat.Parse(parser.ReadToChars(",]"));
                                parsedEvent.ChoiceList.Add(new ParsedChoice(labelName, min, max));

                            }
                            else
                            {
                                parsedEvent.ChoiceList.Add(new ParsedChoice(labelName, index++));
                            }
                            parser.EatWhiteSpace();
                            ch = parser.Peek();

                            if (ch == ',')
                            {
                                parser.Advance();
                            }
                        }
                    }

                    // deal with a value specified by =
                    if (parser.Peek() == '=')
                    {
                        parser.ReadChar();
                        String value = parser.ReadToChars(delim);
                        //					BayesianEvent evt = this.network.getEvent(parsedEvent.getLabel());
                        parsedEvent.Value = value;
                    }

                    if (ch == ',')
                    {
                        parser.Advance();
                    }

                    if (ch == ']')
                    {
                        parser.Advance();
                    }

                    if (parsedEvent.Label.Length > 0)
                    {
                        results.Add(parsedEvent);
                    }
                    l.Length = 0;
                }
                else
                {
                    parser.Advance();
                    l.Append(ch);
                }
            }

        }

        /// <summary>
        /// Parse the given line.
        /// </summary>
        /// <param name="line">The line to parse.</param>
        /// <returns>The parsed probability.</returns>
        public ParsedProbability Parse(String line)
        {

            ParsedProbability result = new ParsedProbability();

            SimpleParser parser = new SimpleParser(line);
            parser.EatWhiteSpace();
            if (!parser.LookAhead("P(", true))
            {
                throw new SyntError("Bayes table lines must start with P(");
            }
            parser.Advance(2);

            // handle base
            AddEvents(parser, result.BaseEvents, "|,)=[]");

            // handle conditions
            if (parser.Peek() == '|')
            {
                parser.Advance();
                AddEvents(parser, result.GivenEvents, ",)=[]");

            }

            if (parser.Peek() != ')')
            {
                throw new BayesianError("Probability not properly terminated.");
            }

            return result;

        }

        /// <summary>
        /// Parse a probability list. 
        /// </summary>
        /// <param name="network">The network to parse for.</param>
        /// <param name="line">The line to parse.</param>
        /// <returns>The parsed list.</returns>
        public static IList<ParsedProbability> ParseProbabilityList(BayesianNetwork network, String line)
        {
            IList<ParsedProbability> result = new List<ParsedProbability>();

            StringBuilder prob = new StringBuilder();
            for (int i = 0; i < line.Length; i++)
            {
                char ch = line[i];
                if (ch == ')')
                {
                    prob.Append(ch);
                    ParseProbability parse = new ParseProbability(network);
                    ParsedProbability parsedProbability = parse.Parse(prob.ToString());
                    result.Add(parsedProbability);
                    prob.Length = 0;
                }
                else
                {
                    prob.Append(ch);
                }
            }
            return result;
        }
    }

    [Serializable]
    public class EnumerationQuery : BasicQuery
    {
        /// <summary>
        /// The events that we will enumerate over.
        /// </summary>
        private readonly IList<EventState> _enumerationEvents = new List<EventState>();

        /// <summary>
        /// The calculated probability.
        /// </summary>
        private double _probability;

        /// <summary>
        /// Construct the enumeration query.
        /// </summary>
        /// <param name="theNetwork">The Bayesian network to query.</param>
        public EnumerationQuery(BayesianNetwork theNetwork)
            : base(theNetwork)
        {
        }

        /// <summary>
        /// Default constructor.
        /// </summary>
        public EnumerationQuery()
        {
        }

        /// <inheritdoc/>
        public override double Probability
        {
            get { return _probability; }
        }

        /// <summary>
        /// Reset the enumeration events. Always reset the hidden events. Optionally
        /// reset the evidence and outcome.
        /// </summary>
        /// <param name="includeEvidence">True if the evidence is to be reset.</param>
        /// <param name="includeOutcome">True if the outcome is to be reset.</param>
        public void ResetEnumeration(bool includeEvidence, bool includeOutcome)
        {
            _enumerationEvents.Clear();

            foreach (EventState state in Events.Values)
            {
                if (state.CurrentEventType == EventType.Hidden)
                {
                    _enumerationEvents.Add(state);
                    state.Value = 0;
                }
                else if (includeEvidence
                         && state.CurrentEventType == EventType.Evidence)
                {
                    _enumerationEvents.Add(state);
                    state.Value = 0;
                }
                else if (includeOutcome
                         && state.CurrentEventType == EventType.Outcome)
                {
                    _enumerationEvents.Add(state);
                    state.Value = 0;
                }
                else
                {
                    state.Value = state.CompareValue;
                }
            }
        }

        /// <summary>
        /// Roll the enumeration events forward by one.
        /// </summary>
        /// <returns>False if there are no more values to roll into, which means we're
        /// done.</returns>
        public bool Forward()
        {
            int currentIndex = 0;
            bool done = false;
            bool eof = false;

            if (_enumerationEvents.Count == 0)
            {
                done = true;
                eof = true;
            }

            while (!done)
            {
                EventState state = _enumerationEvents[currentIndex];
                int v = state.Value;
                v++;
                if (v >= state.Event.Choices.Count)
                {
                    state.Value = 0;
                }
                else
                {
                    state.Value = v;
                    break;
                }

                currentIndex++;

                if (currentIndex >= _enumerationEvents.Count)
                {
                    done = true;
                    eof = true;
                }
            }

            return !eof;
        }

        /// <summary>
        /// Obtain the arguments for an event.
        /// </summary>
        /// <param name="theEvent">The event.</param>
        /// <returns>The arguments.</returns>
        private int[] ObtainArgs(BayesianEvent theEvent)
        {
            var result = new int[theEvent.Parents.Count];

            int index = 0;
            foreach (BayesianEvent parentEvent in theEvent.Parents)
            {
                EventState state = GetEventState(parentEvent);
                result[index++] = state.Value;
            }
            return result;
        }

        /// <summary>
        /// Calculate the probability for a state.
        /// </summary>
        /// <param name="state">The state to calculate.</param>
        /// <returns>The probability.</returns>
        private double CalculateProbability(EventState state)
        {
            int[] args = ObtainArgs(state.Event);

            foreach (TableLine line in state.Event.Table.Lines)
            {
                if (line.CompareArgs(args))
                {
                    if (Math.Abs(line.Result - state.Value) < SyntFramework.DefaultDoubleEqual)
                    {
                        return line.Probability;
                    }
                }
            }

            throw new BayesianError("Could not determine the probability for "
                                    + state);
        }

        /// <summary>
        /// Perform a single enumeration. 
        /// </summary>
        /// <returns>The result.</returns>
        private double PerformEnumeration()
        {
            double result = 0;

            do
            {
                bool first = true;
                double prob = 0;
                foreach (EventState state in Events.Values)
                {
                    if (first)
                    {
                        prob = CalculateProbability(state);
                        first = false;
                    }
                    else
                    {
                        prob *= CalculateProbability(state);
                    }
                }
                result += prob;
            } while (Forward());
            return result;
        }

        /// <inheritdoc/>
        public override void Execute()
        {
            LocateEventTypes();
            ResetEnumeration(false, false);
            double numerator = PerformEnumeration();
            ResetEnumeration(false, true);
            double denominator = PerformEnumeration();
            _probability = numerator / denominator;
        }

        /// <inheritdoc/>
        public override String ToString()
        {
            var result = new StringBuilder();
            result.Append("[SamplingQuery: ");
            result.Append(Problem);
            result.Append("=");
            result.Append(Format.FormatPercent(Probability));
            result.Append("]");
            return result.ToString();
        }

        /// <summary>
        /// Roll the enumeration events forward by one.
        /// </summary>
        /// <param name="enumerationEvents">The events to roll.</param>
        /// <param name="args">The arguments to roll.</param>
        /// <returns>False if there are no more values to roll into, which means we're
        ///         done.</returns>
        public static bool Roll(IList<BayesianEvent> enumerationEvents, int[] args)
        {
            int currentIndex = 0;
            bool done = false;
            bool eof = false;

            if (enumerationEvents.Count == 0)
            {
                done = true;
                eof = true;
            }

            while (!done)
            {
                BayesianEvent e = enumerationEvents[currentIndex];
                int v = args[currentIndex];
                v++;
                if (v >= e.Choices.Count)
                {
                    args[currentIndex] = 0;
                }
                else
                {
                    args[currentIndex] = v;
                    break;
                }

                currentIndex++;

                if (currentIndex >= args.Length)
                {
                    done = true;
                    eof = true;
                }
            }

            return !eof;
        }

        /// <summary>
        /// A clone of this object.
        /// </summary>
        /// <returns>A clone of this object.</returns>
        public override IBayesianQuery Clone()
        {
            return new EnumerationQuery(Network);
        }
    }

    [Serializable]
    public class SamplingQuery : BasicQuery
    {
        /// <summary>
        /// The default sample size.
        /// </summary>
        public const int DefaultSampleSize = 100000;

        /// <summary>
        /// The number of samples that matched the result the query is looking for.
        /// </summary>
        private int _goodSamples;

        /// <summary>
        /// The total number of samples generated. This should match sampleSize at
        /// the end of a query.
        /// </summary>
        private int _totalSamples;

        /// <summary>
        /// The number of usable samples. This is the set size for the average
        /// probability.
        /// </summary>
        private int _usableSamples;

        /// <summary>
        /// Construct a sampling query. 
        /// </summary>
        /// <param name="theNetwork">The network that will be queried.</param>
        public SamplingQuery(BayesianNetwork theNetwork)
            : base(theNetwork)
        {
            SampleSize = DefaultSampleSize;
        }

        /// <summary>
        /// The sample size.
        /// </summary>
        public int SampleSize { get; set; }

        /// <inheritdoc/>
        public override double Probability
        {
            get { return _goodSamples / (double)_usableSamples; }
        }

        /// <summary>
        /// Obtain the arguments for an event. 
        /// </summary>
        /// <param name="e">The event.</param>
        /// <returns>The arguments for that event, based on the other event values.</returns>
        private int[] ObtainArgs(BayesianEvent e)
        {
            var result = new int[e.Parents.Count];

            int index = 0;
            foreach (BayesianEvent parentEvent in e.Parents)
            {
                EventState state = GetEventState(parentEvent);
                if (!state.IsCalculated)
                    return null;
                result[index++] = state.Value;
            }
            return result;
        }

        /// <summary>
        /// Set all events to random values, based on their probabilities. 
        /// </summary>
        /// <param name="eventState">The event state.</param>
        private void RandomizeEvents(EventState eventState)
        {
            // first, has this event already been randomized
            if (!eventState.IsCalculated)
            {
                // next, see if we can randomize the event passed
                int[] args = ObtainArgs(eventState.Event);
                if (args != null)
                {
                    eventState.Randomize(args);
                }
            }

            // randomize children
            foreach (BayesianEvent childEvent in eventState.Event.Children)
            {
                RandomizeEvents(GetEventState(childEvent));
            }
        }

        /// <summary>
        /// The number of events that are still uncalculated.
        /// </summary>
        /// <returns>The uncalculated count.</returns>
        private int CountUnCalculated()
        {
            return Events.Values.Count(state => !state.IsCalculated);
        }

        /// <inheritdoc/>
        public override void Execute()
        {
            LocateEventTypes();
            _usableSamples = 0;
            _goodSamples = 0;
            _totalSamples = 0;

            for (int i = 0; i < SampleSize; i++)
            {
                Reset();

                int lastUncalculated = int.MaxValue;
                int uncalculated;
                do
                {
                    foreach (EventState state in Events.Values)
                    {
                        RandomizeEvents(state);
                    }
                    uncalculated = CountUnCalculated();
                    if (uncalculated == lastUncalculated)
                    {
                        throw new BayesianError(
                            "Unable to calculate all nodes in the graph.");
                    }
                    lastUncalculated = uncalculated;
                } while (uncalculated > 0);

                // System.out.println("Sample:\n" + this.dumpCurrentState());
                _totalSamples++;
                if (IsNeededEvidence)
                {
                    _usableSamples++;
                    if (SatisfiesDesiredOutcome)
                    {
                        _goodSamples++;
                    }
                }
            }
        }

        /// <summary>
        /// The current state as a string.
        /// </summary>
        /// <returns>The state.</returns>
        public String DumpCurrentState()
        {
            var result = new StringBuilder();
            foreach (EventState state in Events.Values)
            {
                result.Append(state.ToString());
                result.Append("\n");
            }
            return result.ToString();
        }

        /// <summary>
        /// Clone the object.
        /// </summary>
        /// <returns></returns>
        public override IBayesianQuery Clone()
        {
            return new SamplingQuery(Network);
        }

        /// <inheritdoc/>
        public override String ToString()
        {
            var result = new StringBuilder();
            result.Append("[SamplingQuery: ");
            result.Append(Problem);
            result.Append("=");
            result.Append(Format.FormatPercent(Probability));
            result.Append(" ;good/usable=");
            result.Append(Format.FormatInteger(_goodSamples));
            result.Append("/");
            result.Append(Format.FormatInteger(_usableSamples));
            result.Append(";totalSamples=");
            result.Append(Format.FormatInteger(_totalSamples));
            return result.ToString();
        }
    }

    [Serializable]
    public class EventState
    {
        /// <summary>
        /// The event that this state is connected to.
        /// </summary>
        private readonly BayesianEvent _event;

        /// <summary>
        /// The current value of this event.
        /// </summary>
        private int _value;

        /// <summary>
        /// Construct an event state for the specified event. 
        /// </summary>
        /// <param name="theEvent">The event to create a state for.</param>
        public EventState(BayesianEvent theEvent)
        {
            _event = theEvent;
            CurrentEventType = EventType.Hidden;
            IsCalculated = false;
        }

        /// <summary>
        /// Has this event been calculated yet?
        /// </summary>
        public bool IsCalculated { get; set; }

        /// <summary>
        /// The type of event that this is for the query.
        /// </summary>
        public EventType CurrentEventType { get; set; }

        /// <summary>
        /// The value that we are comparing to, for probability.
        /// </summary>
        public int CompareValue { get; set; }

        /// <summary>
        /// The value.
        /// </summary>
        public int Value
        {
            get { return _value; }
            set
            {
                IsCalculated = true;
                _value = value;
            }
        }


        /// <summary>
        /// The event.
        /// </summary>
        public BayesianEvent Event
        {
            get { return _event; }
        }


        /// <summary>
        /// Is this event satisified.
        /// </summary>
        public bool IsSatisfied
        {
            get
            {
                if (CurrentEventType == EventType.Hidden)
                {
                    throw new BayesianError(
                        "Satisfy can't be called on a hidden event.");
                }
                return Math.Abs(CompareValue - _value) < SyntFramework.DefaultDoubleEqual;
            }
        }

        /// <summary>
        /// Randomize according to the arguments.
        /// </summary>
        /// <param name="args">The arguments.</param>
        public void Randomize(params int[] args)
        {
            Value = _event.Table.GenerateRandom(args);
        }

        /// <inheritdoc/>
        public override String ToString()
        {
            var result = new StringBuilder();
            result.Append("[EventState:event=");
            result.Append(_event.ToString());
            result.Append(",type=");
            result.Append(CurrentEventType.ToString());
            result.Append(",value=");
            result.Append(Format.FormatDouble(_value, 2));
            result.Append(",compare=");
            result.Append(Format.FormatDouble(CompareValue, 2));
            result.Append(",calc=");
            result.Append(IsCalculated ? "y" : "n");
            result.Append("]");
            return result.ToString();
        }

        /// <summary>
        /// Convert a state to a simple string. (probability expression) 
        /// </summary>
        /// <param name="state">The state.</param>
        /// <returns>A probability expression as a string.</returns>
        public static String ToSimpleString(EventState state)
        {
            return BayesianEvent.FormatEventName(state.Event, state.CompareValue);
        }
    }

    [Serializable]
    public class BayesianTable
    {
        /// <summary>
        /// The event that owns this truth table.
        /// </summary>
        private readonly BayesianEvent _event;

        /// <summary>
        /// The lines of the truth table.
        /// </summary>
        private readonly IList<TableLine> _lines = new List<TableLine>();

        /// <summary>
        /// Construct a Bayes truth table.
        /// </summary>
        /// <param name="theEvent">The lines of the truth table.</param>
        public BayesianTable(BayesianEvent theEvent)
        {
            _event = theEvent;
            Reset();
        }

        /// <summary>
        /// Reset the truth table to zero.
        /// </summary>
        public void Reset()
        {
            _lines.Clear();
            IList<BayesianEvent> parents = _event.Parents;
            int l = parents.Count;

            int[] args = new int[l];

            do
            {
                for (int k = 0; k < _event.Choices.Count; k++)
                {
                    AddLine(0, k, args);
                }
            } while (EnumerationQuery.Roll(parents, args));
        }

        /// <summary>
        /// Add a new line.
        /// </summary>
        /// <param name="prob">The probability.</param>
        /// <param name="result">The resulting probability.</param>
        /// <param name="args">The arguments.</param>
        public void AddLine(double prob, bool result, params bool[] args)
        {
            int[] d = new int[args.Length];
            for (int i = 0; i < args.Length; i++)
            {
                d[i] = args[i] ? 0 : 1;
            }

            AddLine(prob, result ? 0 : 1, d);
            AddLine(1.0 - prob, result ? 1 : 0, d);
        }


        /// <summary>
        /// Add a new line.
        /// </summary>
        /// <param name="prob">The probability.</param>
        /// <param name="result">The resulting probability.</param>
        /// <param name="args">The arguments.</param>
        public void AddLine(double prob, int result, params bool[] args)
        {
            int[] d = new int[args.Length];
            for (int i = 0; i < args.Length; i++)
            {
                d[i] = args[i] ? 0 : 1;
            }

            AddLine(prob, result, d);
        }


        /// <summary>
        /// Add a new line.
        /// </summary>
        /// <param name="prob">The probability.</param>
        /// <param name="result">The resulting probability.</param>
        /// <param name="args">The arguments.</param>
        public void AddLine(double prob, int result, params int[] args)
        {
            if (args.Length != _event.Parents.Count)
            {
                throw new BayesianError("Truth table line with " + args.Length
                        + ", specified for event with "
                        + _event.Parents.Count
                        + " parents.  These numbers must be the same");
            }

            TableLine line = FindLine(result, args);

            if (line == null)
            {
                if (_lines.Count == this.MaxLines)
                {
                    throw new BayesianError("This truth table is already full.");
                }

                line = new TableLine(prob, result, args);
                _lines.Add(line);
            }
            else
            {
                line.Probability = prob;
            }
        }

        /// <summary>
        /// Validate the truth table.
        /// </summary>
        public void Validate()
        {
            if (_lines.Count != this.MaxLines)
            {
                throw new BayesianError("Truth table for " + _event.ToString()
                        + " only has " + _lines.Count
                        + " line(s), should have " + this.MaxLines
                        + " line(s).");
            }

        }

        /// <summary>
        /// Generate a random sampling based on this truth table.
        /// </summary>
        /// <param name="args">The arguemtns.</param>
        /// <returns>The result.</returns>
        public int GenerateRandom(params int[] args)
        {
            double r = ThreadSafeRandom.NextDouble();
            double limit = 0;

            foreach (TableLine line in _lines)
            {
                if (line != null && line.CompareArgs(args))
                {
                    limit += line.Probability;
                    if (r < limit)
                    {
                        return line.Result;
                    }
                }
            }

            throw new BayesianError("Incomplete logic table for event: "
                    + _event.ToString());
        }

        /// <inheritdoc/>
        public String ToString()
        {
            StringBuilder result = new StringBuilder();
            foreach (TableLine line in _lines)
            {
                result.Append(line.ToString());
                result.Append("\n");
            }
            return result.ToString();
        }

        /// <summary>
        /// The lines of this truth table.
        /// </summary>
        public IList<TableLine> Lines
        {
            get
            {
                return _lines;
            }
        }

        /// <summary>
        /// Find the specified truth table line.
        /// </summary>
        /// <param name="result">The result sought.</param>
        /// <param name="args">The arguments.</param>
        /// <returns>The line that matches.</returns>
        public TableLine FindLine(int result, int[] args)
        {

            foreach (TableLine line in _lines)
            {
                if (line != null && line.CompareArgs(args))
                {
                    if (Math.Abs(line.Result - result) < SyntFramework.DefaultDoubleEqual)
                    {
                        return line;
                    }
                }
            }

            return null;
        }

        /// <summary>
        /// The maximum number of lines this truth table would have.
        /// </summary>
        public int MaxLines
        {
            get
            {
                return _event.CalculateParameterCount() * _event.Choices.Count;
            }
        }
    }

    [Serializable]
    public class TableLine
    {
        /// <summary>
        /// The arguments.
        /// </summary>
        private readonly int[] _arguments;

        /// <summary>
        /// The result.
        /// </summary>
        private readonly int _result;

        /// <summary>
        /// Construct a truth table line. 
        /// </summary>
        /// <param name="prob">The probability.</param>
        /// <param name="result">The result.</param>
        /// <param name="args">The arguments.</param>
        public TableLine(double prob, int result, int[] args)
        {
            Probability = prob;
            _result = result;
            _arguments = EngineArray.ArrayCopy(args);
        }

        /// <summary>
        /// The probability.
        /// </summary>
        public double Probability { get; set; }


        /// <summary>
        /// Arguments.
        /// </summary>
        public int[] Arguments
        {
            get { return _arguments; }
        }

        /// <summary>
        /// Result.
        /// </summary>
        public int Result
        {
            get { return _result; }
        }

        /// <inheritdoc/>
        public override String ToString()
        {
            var r = new StringBuilder();
            r.Append("result=");
            r.Append(_result);
            r.Append(",probability=");
            r.Append(Format.FormatDouble(Probability, 2));
            r.Append("|");
            foreach (int t in _arguments)
            {
                r.Append(Format.FormatDouble(t, 2));
                r.Append(" ");
            }
            return r.ToString();
        }

        /// <summary>
        /// Compare this truth line's arguments to others. 
        /// </summary>
        /// <param name="args">The other arguments to compare to.</param>
        /// <returns>True if the same.</returns>
        public bool CompareArgs(int[] args)
        {
            if (args.Length != _arguments.Length)
            {
                return false;
            }

            for (int i = 0; i < args.Length; i++)
            {
                if (Math.Abs(_arguments[i] - args[i]) > SyntFramework.DefaultDoubleEqual)
                {
                    return false;
                }
            }

            return true;
        }
    }

    public class EstimatorNone : IBayesEstimator
    {
        /// <inheritdoc/>
        public void Init(TrainBayesian theTrainer, BayesianNetwork theNetwork, IMLDataSet theData)
        {
        }

       

        /// <inheritdoc/>
        public bool Iteration()
        {
            return false;
        }
    }

    public class SimpleEstimator : IBayesEstimator
    {
        private IMLDataSet _data;
        private int _index;
        private BayesianNetwork _network;

        #region IBayesEstimator Members

        /// <inheritdoc/>
        public void Init(TrainBayesian theTrainer, BayesianNetwork theNetwork, IMLDataSet theData)
        {
            _network = theNetwork;
            _data = theData;
            _index = 0;
        }


        /// <inheritdoc/>
        public bool Iteration()
        {
            BayesianEvent e = _network.Events[_index];
            foreach (TableLine line in e.Table.Lines)
            {
                line.Probability = (CalculateProbability(e, line.Result, line.Arguments));
            }
            _index++;

            return _index < _network.Events.Count;
        }

        #endregion

        /// <summary>
        /// Calculate the probability.
        /// </summary>
        /// <param name="e">The event.</param>
        /// <param name="result">The result.</param>
        /// <param name="args">The arguments.</param>
        /// <returns>The probability.</returns>
        public double CalculateProbability(BayesianEvent e, int result, int[] args)
        {
            int eventIndex = _network.Events.IndexOf(e);
            int x = 0;
            int y = 0;

            // calculate overall probability
            foreach (IMLDataPair pair in _data)
            {
                int[] d = _network.DetermineClasses(pair.Input);

                if (args.Length == 0)
                {
                    x++;
                    if (d[eventIndex] == result)
                    {
                        y++;
                    }
                }
                else if (d[eventIndex] == result)
                {
                    x++;

                    int i = 0;
                    bool givenMatch = true;
                    foreach (BayesianEvent givenEvent in e.Parents)
                    {
                        int givenIndex = _network.GetEventIndex(givenEvent);
                        if (args[i] != d[givenIndex])
                        {
                            givenMatch = false;
                            break;
                        }
                        i++;
                    }

                    if (givenMatch)
                    {
                        y++;
                    }
                }
            }

            double num = y + 1;
            double den = x + e.Choices.Count;


            return num / den;
        }
    }

    public class SearchK2 : IBayesSearch
    {
        /// <summary>
        /// The node ordering.
        /// </summary>
        private readonly IList<BayesianEvent> _nodeOrdering = new List<BayesianEvent>();

        /// <summary>
        /// The data to use.
        /// </summary>
        private IMLDataSet _data;

        /// <summary>
        /// The current index.
        /// </summary>
        private int _index = -1;

        /// <summary>
        /// The last calculated value for p.
        /// </summary>
        private double _lastCalculatedP;

        /// <summary>
        /// The network to optimize.
        /// </summary>
        private BayesianNetwork _network;

        /// <summary>
        /// The trainer being used.
        /// </summary>
        private TrainBayesian _train;

        #region IBayesSearch Members

        /// <inheritdoc/>
        public void Init(TrainBayesian theTrainer, BayesianNetwork theNetwork, IMLDataSet theData)
        {
            _network = theNetwork;
            _data = theData;
            _train = theTrainer;
            OrderNodes();
            _index = -1;
        }

        /// <inheritdoc/>
        public bool Iteration()
        {
            if (_index == -1)
            {
                OrderNodes();
            }
            else
            {
                BayesianEvent e = _nodeOrdering[_index];
                double oldP = CalculateG(_network, e, e.Parents);

                while (e.Parents.Count < _train.MaximumParents)
                {
                    BayesianEvent z = FindZ(e, _index, oldP);
                    if (z != null)
                    {
                        _network.CreateDependency(z, e);
                        oldP = _lastCalculatedP;
                    }
                    else
                    {
                        break;
                    }
                }
            }

            _index++;
            return (_index < _data.InputSize);
        }

        #endregion

        /// <summary>
        /// Basically the goal here is to get the classification target, if it exists,
        /// to go first. This will greatly enhance K2's effectiveness.
        /// </summary>
        private void OrderNodes()
        {
            _nodeOrdering.Clear();

            // is there a classification target?
            if (_network.ClassificationTarget != -1)
            {
                _nodeOrdering.Add(_network.ClassificationTargetEvent);
            }


            // now add the others
            foreach (BayesianEvent e in _network.Events)
            {
                if (!_nodeOrdering.Contains(e))
                {
                    _nodeOrdering.Add(e);
                }
            }
        }

        /// <summary>
        /// Find the value for z.
        /// </summary>
        /// <param name="e">The event that we are clauclating for.</param>
        /// <param name="n">The value for n.</param>
        /// <param name="old">The old value.</param>
        /// <returns>The new value for z.</returns>
        private BayesianEvent FindZ(BayesianEvent e, int n, double old)
        {
            BayesianEvent result = null;
            double maxChildP = double.NegativeInfinity;
            //System.out.println("Finding parent for: " + event.toString());
            for (int i = 0; i < n; i++)
            {
                BayesianEvent trialParent = _nodeOrdering[i];
                IList<BayesianEvent> parents = new List<BayesianEvent>();
                parents.CopyTo(e.Parents.ToArray(), 0);
                parents.Add(trialParent);
                //System.out.println("Calculating adding " + trialParent.toString() + " to " + event.toString());
                _lastCalculatedP = CalculateG(_network, e, parents);
                //System.out.println("lastP:" + this.lastCalculatedP);
                //System.out.println("old:" + old);
                if (_lastCalculatedP > old && _lastCalculatedP > maxChildP)
                {
                    result = trialParent;
                    maxChildP = _lastCalculatedP;
                    //System.out.println("Current best is: " + result.toString());
                }
            }

            _lastCalculatedP = maxChildP;
            return result;
        }


        /// <summary>
        /// Calculate the value N, which is the number of cases, from the training data, where the
        /// desiredValue matches the training data.  Only cases where the parents match the specifed
        /// parent instance are considered.
        /// </summary>
        /// <param name="network">The network to calculate for.</param>
        /// <param name="e">The event we are calculating for. (variable i)</param>
        /// <param name="parents">The parents of the specified event we are considering.</param>
        /// <param name="parentInstance">The parent instance we are looking for.</param>
        /// <param name="desiredValue">The desired value.</param>
        /// <returns>The value N. </returns>
        public int CalculateN(BayesianNetwork network, BayesianEvent e,
                              IList<BayesianEvent> parents, int[] parentInstance, int desiredValue)
        {
            int result = 0;
            int eventIndex = network.GetEventIndex(e);

            foreach (IMLDataPair pair in _data)
            {
                int[] d = _network.DetermineClasses(pair.Input);

                if (d[eventIndex] == desiredValue)
                {
                    bool reject = false;

                    for (int i = 0; i < parentInstance.Length; i++)
                    {
                        BayesianEvent parentEvent = parents[i];
                        int parentIndex = network.GetEventIndex(parentEvent);
                        if (parentInstance[i] != d[parentIndex])
                        {
                            reject = true;
                            break;
                        }
                    }

                    if (!reject)
                    {
                        result++;
                    }
                }
            }
            return result;
        }


        /// <summary>
        /// Calculate the value N, which is the number of cases, from the training data, where the
        /// desiredValue matches the training data.  Only cases where the parents match the specifed
        /// parent instance are considered.
        /// </summary>
        /// <param name="network">The network to calculate for.</param>
        /// <param name="e">The event we are calculating for. (variable i)</param>
        /// <param name="parents">The parents of the specified event we are considering.</param>
        /// <param name="parentInstance">The parent instance we are looking for.</param>
        /// <returns>The value N. </returns>
        public int CalculateN(BayesianNetwork network, BayesianEvent e,
                              IList<BayesianEvent> parents, int[] parentInstance)
        {
            int result = 0;

            foreach (IMLDataPair pair in _data)
            {
                int[] d = _network.DetermineClasses(pair.Input);

                bool reject = false;

                for (int i = 0; i < parentInstance.Length; i++)
                {
                    BayesianEvent parentEvent = parents[i];
                    int parentIndex = network.GetEventIndex(parentEvent);
                    if (parentInstance[i] != (d[parentIndex]))
                    {
                        reject = true;
                        break;
                    }
                }

                if (!reject)
                {
                    result++;
                }
            }
            return result;
        }


        /// <summary>
        /// Calculate G. 
        /// </summary>
        /// <param name="network">The network to calculate for.</param>
        /// <param name="e">The event to calculate for.</param>
        /// <param name="parents">The parents.</param>
        /// <returns>The value for G.</returns>
        public double CalculateG(BayesianNetwork network,
                                 BayesianEvent e, IList<BayesianEvent> parents)
        {
            double result = 1.0;
            int r = e.Choices.Count;

            var args = new int[parents.Count];

            do
            {
                double n = SyntMath.Factorial(r - 1);
                double d = SyntMath.Factorial(CalculateN(network, e,
                                                          parents, args) + r - 1);
                double p1 = n / d;

                double p2 = 1;
                for (int k = 0; k < e.Choices.Count; k++)
                {
                    p2 *= SyntMath.Factorial(CalculateN(network, e, parents, args, k));
                }

                result *= p1 * p2;
            } while (EnumerationQuery.Roll(parents, args));

            return result;
        }
    }

    public class SearchNone : IBayesSearch
    {
        #region IBayesSearch Members

        /// <inheritdoc/>
        public void Init(TrainBayesian theTrainer, BayesianNetwork theNetwork,
                         IMLDataSet theData)
        {
        }

        /// <inheritdoc/>
        public bool Iteration()
        {
            return false;
        }

        #endregion
    }

    public sealed class TrainBayesian : BasicTraining
    {
        /// <summary>
        /// The data used for training.
        /// </summary>
        private readonly IMLDataSet _data;

        /// <summary>
        /// The method used to estimate the probabilities.
        /// </summary>
        private readonly IBayesEstimator _estimator;

        /// <summary>
        /// The maximum parents a node should have.
        /// </summary>
        private readonly int _maximumParents;

        /// <summary>
        /// The network to train.
        /// </summary>
        private readonly BayesianNetwork _network;

        /// <summary>
        /// The method used to search for the best network structure.
        /// </summary>
        private readonly IBayesSearch _search;

        /// <summary>
        /// Used to hold the query.
        /// </summary>
        private String _holdQuery;

        /// <summary>
        /// The method used to setup the initial Bayesian network.
        /// </summary>
        private BayesianInit _initNetwork = BayesianInit.InitNaiveBayes;

        /// <summary>
        /// The phase that training is currently in.
        /// </summary>
        private Phase _p = Phase.Init;

        /// <summary>
        /// Construct a Bayesian trainer. Use K2 to search, and the SimpleEstimator
        /// to estimate probability.  Init as Naive Bayes
        /// </summary>
        /// <param name="theNetwork">The network to train.</param>
        /// <param name="theData">The data to train.</param>
        /// <param name="theMaximumParents">The max number of parents.</param>
        public TrainBayesian(BayesianNetwork theNetwork, IMLDataSet theData,
                             int theMaximumParents)
            : this(theNetwork, theData, theMaximumParents,
                   BayesianInit.InitNaiveBayes, new SearchK2(),
                   new SimpleEstimator())
        {
        }

        /// <summary>
        /// Construct a Bayesian trainer. 
        /// </summary>
        /// <param name="theNetwork">The network to train.</param>
        /// <param name="theData">The data to train with.</param>
        /// <param name="theMaximumParents">The maximum number of parents.</param>
        /// <param name="theInit">How to init the new Bayes network.</param>
        /// <param name="theSearch">The search method.</param>
        /// <param name="theEstimator">The estimation mehod.</param>
        public TrainBayesian(BayesianNetwork theNetwork, IMLDataSet theData,
                             int theMaximumParents, BayesianInit theInit, IBayesSearch theSearch,
                             IBayesEstimator theEstimator)
            : base(TrainingImplementationType.Iterative)
        {
            _network = theNetwork;
            _data = theData;
            _maximumParents = theMaximumParents;

            _search = theSearch;
            _search.Init(this, theNetwork, theData);

            _estimator = theEstimator;
            _estimator.Init(this, theNetwork, theData);

            _initNetwork = theInit;
            Error = 1.0;
        }

        /// <inheritdoc/>
        public override bool TrainingDone
        {
            get { return base.TrainingDone || _p == Phase.Terminated; }
        }

        /// <inheritdoc/>
        public override bool CanContinue
        {
            get { return false; }
        }

        /// <inheritdoc/>
        public override IMLMethod Method
        {
            get { return _network; }
        }

        /// <summary>
        /// Returns the network.
        /// </summary>
        public BayesianNetwork Network
        {
            get { return _network; }
        }

        /// <summary>
        /// The maximum parents a node can have.
        /// </summary>
        public int MaximumParents
        {
            get { return _maximumParents; }
        }

        /// <summary>
        /// The search method.
        /// </summary>
        public IBayesSearch Search
        {
            get { return _search; }
        }

        /// <summary>
        /// The init method.
        /// </summary>
        public BayesianInit InitNetwork
        {
            get { return _initNetwork; }
            set { _initNetwork = value; }
        }

        /// <summary>
        /// Init to Naive Bayes.
        /// </summary>
        private void InitNaiveBayes()
        {
            // clear out anything from before
            _network.RemoveAllRelations();

            // locate the classification target event
            BayesianEvent classificationTarget = _network
                .ClassificationTargetEvent;

            // now link everything to this event
            foreach (BayesianEvent e in _network.Events)
            {
                if (e != classificationTarget)
                {
                    _network.CreateDependency(classificationTarget, e);
                }
            }

            _network.FinalizeStructure();
        }

        /// <summary>
        /// Handle iterations for the Init phase.
        /// </summary>
        private void IterationInit()
        {
            _holdQuery = _network.ClassificationStructure;

            switch (_initNetwork)
            {
                case BayesianInit.InitEmpty:
                    _network.RemoveAllRelations();
                    _network.FinalizeStructure();
                    break;
                case BayesianInit.InitNoChange:
                    break;
                case BayesianInit.InitNaiveBayes:
                    InitNaiveBayes();
                    break;
            }
            _p = Phase.Search;
        }

        /// <summary>
        /// Handle iterations for the Search phase.
        /// </summary>
        private void IterationSearch()
        {
            if (!_search.Iteration())
            {
                _p = Phase.SearchDone;
            }
        }

        /// <summary>
        /// Handle iterations for the Search Done phase.
        /// </summary>
        private void IterationSearchDone()
        {
            _network.FinalizeStructure();
            _network.Reset();
            _p = Phase.Probability;
        }

        /// <summary>
        /// Handle iterations for the Probability phase.
        /// </summary>
        private void IterationProbability()
        {
            if (!_estimator.Iteration())
            {
                _p = Phase.Finish;
            }
        }

        /// <summary>
        /// Handle iterations for the Finish phase.
        /// </summary>
        private void IterationFinish()
        {
            _network.DefineClassificationStructure(_holdQuery);
            Error = _network.CalculateError(_data);
            _p = Phase.Terminated;
        }

        /// <inheritdoc/>
        public override void Iteration()
        {
            PreIteration();

            switch (_p)
            {
                case Phase.Init:
                    IterationInit();
                    break;
                case Phase.Search:
                    IterationSearch();
                    break;
                case Phase.SearchDone:
                    IterationSearchDone();
                    break;
                case Phase.Probability:
                    IterationProbability();
                    break;
                case Phase.Finish:
                    IterationFinish();
                    break;
            }

            PostIteration();
        }

        /// <inheritdoc/>
        public override TrainingContinuation Pause()
        {
            return null;
        }

        /// <inheritdoc/>
        public override void Resume(TrainingContinuation state)
        {
        }

        #region Nested type: Phase

        /// <summary>
        /// What phase of training are we in?
        /// </summary>
        private enum Phase
        {
            /// <summary>
            /// Init phase.
            /// </summary>
            Init,
            /// <summary>
            /// Searching for a network structure.
            /// </summary>
            Search,
            /// <summary>
            /// Search complete.
            /// </summary>
            SearchDone,
            /// <summary>
            /// Finding probabilities.
            /// </summary>
            Probability,
            /// <summary>
            /// Finished training.
            /// </summary>
            Finish,
            /// <summary>
            /// Training terminated.
            /// </summary>
            Terminated
        };

        #endregion
    }

    [Serializable]
    public class BayesianChoice : IComparable<BayesianChoice>
    {
        /// <summary>
        /// The label for this choice.
        /// </summary>
        private readonly String _label;

        /// <summary>
        /// The max values, if continuous, or the index if discrete.
        /// </summary>
        private readonly double _max;

        /// <summary>
        /// The min values, if continuous, or the index if discrete.
        /// </summary>
        private readonly double _min;

        /// <summary>
        /// Construct a continuous choice that covers the specified range. 
        /// </summary>
        /// <param name="label">The label for this choice.</param>
        /// <param name="min">The minimum value for this range.</param>
        /// <param name="max">The maximum value for this range.</param>
        public BayesianChoice(String label, double min, double max)
        {
            _label = label;
            _min = min;
            _max = max;
        }

        /// <summary>
        /// Construct a discrete choice for the specified index. 
        /// </summary>
        /// <param name="label">The label for this choice.</param>
        /// <param name="index">The index for this choice.</param>
        public BayesianChoice(String label, int index)
        {
            _label = label;
            _min = index;
            _max = index;
        }

        /// <summary>
        /// Get the label.
        /// </summary>
        public String Label
        {
            get { return _label; }
        }

        /// <summary>
        /// Get the min.
        /// </summary>
        public double Min
        {
            get { return _min; }
        }

        /// <summary>
        /// Get the max.
        /// </summary>
        public double Max
        {
            get { return _max; }
        }

        /// <summary>
        /// True, if this choice has an index, as opposed to min/max. If the
        /// value has an idex, then it is discrete.
        /// </summary>
        public bool IsIndex
        {
            get { return Math.Abs(_min - _max) < SyntFramework.DefaultDoubleEqual; }
        }

        /// <inheritdoc/>
        public override String ToString()
        {
            return _label;
        }

        /// <summary>
        /// A string representation of this choice.
        /// </summary>
        /// <returns>A string representation of this choice.</returns>
        public String ToFullString()
        {
            var result = new StringBuilder();
            result.Append(Label);
            if (!IsIndex)
            {
                result.Append(":");
                result.Append(CSVFormat.EgFormat.Format(Min, 4));
                result.Append(" to ");
                result.Append(CSVFormat.EgFormat.Format(Max, 4));
            }
            return result.ToString();
        }

        /// <inheritdoc/>
        public int CompareTo(BayesianChoice other)
        {
            if (_max < other.Max)
            {
                return -1;
            }
            else
            {
                return 1;
            }
        }
    }

    public class BayesianError : SyntError
    {
        /// <summary>
        /// Construct a message exception.
        /// </summary>
        /// <param name="str">The message.</param>
        public BayesianError(String str)
            : base(str)
        {
        }

        /// <summary>
        /// Pass on an exception.
        /// </summary>
        /// <param name="e">The other exception.</param>
        public BayesianError(Exception e)
            : base(e)
        {
        }

        /// <summary>
        /// Pass on an exception.
        /// </summary>
        /// <param name="msg">The message.</param>
        /// <param name="e">The exception.</param>
        public BayesianError(String msg, Exception e)
            : base(msg, e)
        {
        }
    }

    [Serializable]
    public class BayesianEvent
    {
        /// <summary>
        /// The children, or events that use us as a given.
        /// </summary>
        private readonly IList<BayesianEvent> _children = new List<BayesianEvent>();

        /// <summary>
        /// The discrete choices that make up the state of this event.
        /// </summary>
        private readonly ICollection<BayesianChoice> _choices = new SortedSet<BayesianChoice>();

        /// <summary>
        /// The label for this event.
        /// </summary>
        private readonly String _label;

        /// <summary>
        /// The parents, or given.
        /// </summary>
        private readonly IList<BayesianEvent> _parents = new List<BayesianEvent>();

        /// <summary>
        /// The truth table for this event.
        /// </summary>
        private BayesianTable _table;

        /// <summary>
        /// The value of the maximum choice.
        /// </summary>
        private double _maximumChoice;

        /// <summary>
        /// THe value of the minimum choice.
        /// </summary>
        private double _minimumChoice;

        /// <summary>
        /// The index of the minimum choice.
        /// </summary>
        private int _minimumChoiceIndex;

        /// <summary>
        /// Construct an event with the specified label and choices.
        /// </summary>
        /// <param name="theLabel">The label.</param>
        /// <param name="theChoices">The choices, or states.</param>
        public BayesianEvent(String theLabel, IEnumerable<BayesianChoice> theChoices)
        {
            _label = theLabel;
            foreach (BayesianChoice choice in theChoices)
            {
                _choices.Add(choice);
            }
        }

        /// <summary>
        /// Construct an event with the specified label and choices. 
        /// </summary>
        /// <param name="theLabel">The label.</param>
        /// <param name="theChoices">The choices, or states.</param>
        public BayesianEvent(String theLabel, IEnumerable<string> theChoices)
        {
            _label = theLabel;

            int index = 0;
            foreach (String str in theChoices)
            {
                _choices.Add(new BayesianChoice(str, index++));
            }
        }

        /// <summary>
        /// Construct a boolean event.
        /// </summary>
        /// <param name="theLabel">The label.</param>
        public BayesianEvent(String theLabel)
            : this(theLabel, BayesianNetwork.ChoicesTrueFalse)
        {
        }

        /// <summary>
        /// the parents
        /// </summary>
        public IList<BayesianEvent> Parents
        {
            get { return _parents; }
        }

        /// <summary>
        /// the children
        /// </summary>
        public IList<BayesianEvent> Children
        {
            get { return _children; }
        }

        /// <summary>
        /// the label
        /// </summary>
        public String Label
        {
            get { return _label; }
        }

        /// <summary>
        /// True, if this event has parents.
        /// </summary>
        public bool HasParents
        {
            get { return _parents.Count > 0; }
        }

        /// <summary>
        /// True, if this event has parents.
        /// </summary>
        public bool HasChildren
        {
            get { return _parents.Count > 0; }
        }

        /// <summary>
        /// the choices
        /// </summary>
        public ICollection<BayesianChoice> Choices
        {
            get { return _choices; }
        }

        /// <summary>
        /// the table
        /// </summary>
        public BayesianTable Table
        {
            get { return _table; }
        }

        /// <summary>
        /// True, if this is a boolean event.
        /// </summary>
        public bool IsBoolean
        {
            get { return _choices.Count == 2; }
        }

        /// <summary>
        /// Add a child event.
        /// </summary>
        /// <param name="e">The child event.</param>
        public void AddChild(BayesianEvent e)
        {
            _children.Add(e);
        }

        /// <summary>
        /// Add a parent event.
        /// </summary>
        /// <param name="e">The parent event.</param>
        public void AddParent(BayesianEvent e)
        {
            _parents.Add(e);
        }

        /// <summary>
        /// A full string that contains all info for this event.
        /// </summary>
        /// <returns>A full string that contains all info for this event.</returns>
        public String ToFullString()
        {
            var result = new StringBuilder();

            result.Append("P(");
            result.Append(Label);

            result.Append("[");
            bool first = true;
            foreach (BayesianChoice choice in _choices)
            {
                if (!first)
                {
                    result.Append(",");
                }
                result.Append(choice.ToFullString());
                first = false;
            }
            result.Append("]");

            if (HasParents)
            {
                result.Append("|");
            }

            first = true;
            foreach (BayesianEvent e in _parents)
            {
                if (!first)
                    result.Append(",");
                first = false;
                result.Append(e.Label);
            }

            result.Append(")");
            return result.ToString();
        }

        /// <inheritdoc/>
        public override String ToString()
        {
            var result = new StringBuilder();

            result.Append("P(");
            result.Append(Label);

            if (HasParents)
            {
                result.Append("|");
            }

            bool first = true;
            foreach (BayesianEvent e in _parents)
            {
                if (!first)
                    result.Append(",");
                first = false;
                result.Append(e.Label);
            }

            result.Append(")");
            return result.ToString();
        }

        /// <summary>
        /// The parameter count.
        /// </summary>
        /// <returns>The parameter count.</returns>
        public int CalculateParameterCount()
        {
            int result = _choices.Count - 1;

            return _parents.Aggregate(result, (current, parent) => current * _choices.Count);
        }

        /// <summary>
        /// Finalize the structure.
        /// </summary>
        public void FinalizeStructure()
        {
            // find min/max choice
            _minimumChoiceIndex = -1;
            _minimumChoice = Double.PositiveInfinity;
            _maximumChoice = Double.NegativeInfinity;

            int index = 0;
            foreach (BayesianChoice choice in _choices)
            {
                if (choice.Min < _minimumChoice)
                {
                    _minimumChoice = choice.Min;
                    _minimumChoiceIndex = index;
                }
                if (choice.Max > _maximumChoice)
                {
                    _maximumChoice = choice.Max;
                }
                index++;
            }

            // build truth table
            if (_table == null)
            {
                _table = new BayesianTable(this);
                _table.Reset();
            }
            else
            {
                _table.Reset();
            }
        }

        /// <summary>
        /// Validate the event.
        /// </summary>
        public void Validate()
        {
            _table.Validate();
        }

        /// <summary>
        /// Roll the specified arguments through all of the possible values, return
        /// false if we are at the final iteration. This is used to enumerate through
        /// all of the possible argument values of this event.
        /// </summary>
        /// <param name="args">The arguments to enumerate.</param>
        /// <returns>True if there are more iterations.</returns>
        public bool RollArgs(double[] args)
        {
            int currentIndex = 0;
            bool done = false;
            bool eof = false;

            if (_parents.Count == 0)
            {
                done = true;
                eof = true;
            }

            while (!done)
            {
                // EventState state = this.parents.get(currentIndex);
                var v = (int)args[currentIndex];
                v++;
                if (v >= _parents[currentIndex].Choices.Count)
                {
                    args[currentIndex] = 0;
                }
                else
                {
                    args[currentIndex] = v;
                    break;
                }

                currentIndex++;

                if (currentIndex >= _parents.Count)
                {
                    done = true;
                    eof = true;
                }
            }

            return !eof;
        }

        /// <summary>
        /// Remove all relations.
        /// </summary>
        public void RemoveAllRelations()
        {
            _children.Clear();
            _parents.Clear();
        }

        /// <summary>
        /// Format the event name with +, - and =.  For example +a or -1, or a=red.
        /// </summary>
        /// <param name="theEvent">The event to format.</param>
        /// <param name="value">The value to format for.</param>
        /// <returns>The formatted name.</returns>
        public static String FormatEventName(BayesianEvent theEvent, int value)
        {
            var str = new StringBuilder();

            if (theEvent.IsBoolean)
            {
                str.Append(value == 0 ? "+" : "-");
            }
            str.Append(theEvent.Label);
            if (!theEvent.IsBoolean)
            {
                str.Append("=");
                str.Append(value);
            }

            return str.ToString();
        }

        /// <summary>
        /// Return true if the event has the specified given event.
        /// </summary>
        /// <param name="l">The event to check for.</param>
        /// <returns>True if the event has the specified given.</returns>
        public bool HasGiven(String l)
        {
            return _parents.Any(e => e.Label.Equals(l));
        }

        /// <summary>
        /// Reset the logic table.
        /// </summary>
        public void Reset()
        {
            if (_table == null)
            {
                _table = new BayesianTable(this);
            }
            _table.Reset();
        }


        /// <summary>
        /// Match a continuous value to a discrete range. This is how floating point
        /// numbers can be used as input to a Bayesian network.
        /// </summary>
        /// <param name="d">The continuous value.</param>
        /// <returns>The range that the value was mapped into.</returns>
        public int MatchChoiceToRange(double d)
        {
            if (Choices.Count > 0 && Choices.First().IsIndex)
            {
                var result = (int)d;
                if (result > Choices.Count)
                {
                    throw new BayesianError("The item id " + result + " is not valid for event " + this.ToString());
                }
                return result;
            }

            var index = 0;
            foreach (var choice in Choices)
            {
                if (d < choice.Max)
                {
                    return index;
                }

                index++;
            }

            return Math.Min(index, Choices.Count - 1);
        }

        /// <summary>
        /// Return the choice specified by the index.  This requires searching
        /// through a list.  Do not call in performance critical areas.
        /// </summary>
        /// <param name="arg">The argument number.</param>
        /// <returns>The bayesian choice found.</returns>
        public BayesianChoice GetChoice(int arg)
        {
            int a = arg;

            foreach (BayesianChoice choice in _choices)
            {
                if (a == 0)
                {
                    return choice;
                }
                a--;
            }
            return null;
        }
    }

    [Serializable]
    public class BayesianNetwork : BasicML, IMLClassification, IMLResettable, IMLError
    {
        /// <summary>
        /// Default choices for a boolean event.
        /// </summary>
        public static readonly String[] ChoicesTrueFalse = { "true", "false" };

        /// <summary>
        /// Mapping between the event string names, and the actual events.
        /// </summary>
        private readonly IDictionary<String, BayesianEvent> _eventMap = new Dictionary<String, BayesianEvent>();

        /// <summary>
        /// A listing of all of the events.
        /// </summary>
        private readonly IList<BayesianEvent> _events = new List<BayesianEvent>();

        /// <summary>
        /// The probabilities of each classification.
        /// </summary>
        private double[] _classificationProbabilities;

        /// <summary>
        /// Specifies the classification target.
        /// </summary>
        private int _classificationTarget;

        /// <summary>
        /// Specifies if each input is present.
        /// </summary>
        private bool[] _inputPresent;

        /// <summary>
        /// Construct a Bayesian network.
        /// </summary>
        public BayesianNetwork()
        {
            Query = new EnumerationQuery(this);
        }

        /// <summary>
        /// The current Bayesian query.
        /// </summary>
        public IBayesianQuery Query { get; set; }

        /// <summary>
        /// The mapping from string names to events.
        /// </summary>
        public IDictionary<String, BayesianEvent> EventMap
        {
            get { return _eventMap; }
        }

        /// <summary>
        /// The events.
        /// </summary>
        public IList<BayesianEvent> Events
        {
            get { return _events; }
        }

        /// <summary>
        /// The contents as a string. Shows both events and dependences.
        /// </summary>
        public String Contents
        {
            get
            {
                var result = new StringBuilder();
                bool first = true;

                foreach (BayesianEvent e in _events)
                {
                    if (!first)
                        result.Append(" ");
                    first = false;
                    result.Append(e.ToFullString());
                }

                return result.ToString();
            }
            set
            {
                IList<ParsedProbability> list = ParseProbability.ParseProbabilityList(this, value);
                IList<String> labelList = new List<String>();

                // ensure that all events are there
                foreach (ParsedProbability prob in list)
                {
                    ParsedEvent parsedEvent = prob.ChildEvent;
                    String eventLabel = parsedEvent.Label;
                    labelList.Add(eventLabel);

                    // create event, if not already here
                    BayesianEvent e = GetEvent(eventLabel);
                    if (e == null)
                    {
                        IList<BayesianChoice> cl = parsedEvent.ChoiceList.Select(c => new BayesianChoice(c.Label, c.Min, c.Max)).ToList();

                        CreateEvent(eventLabel, cl);
                    }
                }


                // now remove all events that were not covered
                foreach (BayesianEvent e in _events)
                {
                    if (!labelList.Contains(e.Label))
                    {
                        RemoveEvent(e);
                    }
                }

                // handle dependencies
                foreach (ParsedProbability prob in list)
                {
                    ParsedEvent parsedEvent = prob.ChildEvent;
                    String eventLabel = parsedEvent.Label;

                    BayesianEvent e = RequireEvent(eventLabel);

                    // ensure that all "givens" are present
                    IList<String> givenList = new List<String>();
                    foreach (ParsedEvent given in prob.GivenEvents)
                    {
                        if (!e.HasGiven(given.Label))
                        {
                            BayesianEvent givenEvent = RequireEvent(given.Label);
                            CreateDependency(givenEvent, e);
                        }
                        givenList.Add(given.Label);
                    }

                    // now remove givens that were not covered
                    foreach (BayesianEvent event2 in e.Parents)
                    {
                        if (!givenList.Contains(event2.Label))
                        {
                            RemoveDependency(event2, e);
                        }
                    }
                }

                // finalize the structure
                FinalizeStructure();
                if (Query != null)
                {
                    Query.FinalizeStructure();
                }
            }
        }

        /// <summary>
        /// Get the classification target. 
        /// </summary>
        public int ClassificationTarget
        {
            get { return _classificationTarget; }
        }

        /// <summary>
        /// The classification target.
        /// </summary>
        public BayesianEvent ClassificationTargetEvent
        {
            get
            {
                if (_classificationTarget == -1)
                {
                    throw new BayesianError("No classification target defined.");
                }

                return _events[_classificationTarget];
            }
        }

        /// <summary>
        /// Returns a string representation of the classification structure.
        ///         Of the form P(a|b,c,d)
        /// </summary>
        public String ClassificationStructure
        {
            get
            {
                var result = new StringBuilder();

                result.Append("P(");
                bool first = true;

                for (int i = 0; i < Events.Count; i++)
                {
                    BayesianEvent e = _events[i];
                    EventState state = Query.GetEventState(e);
                    if (state.CurrentEventType == EventType.Outcome)
                    {
                        if (!first)
                        {
                            result.Append(",");
                        }
                        result.Append(e.Label);
                        first = false;
                    }
                }

                result.Append("|");

                first = true;
                for (int i = 0; i < Events.Count; i++)
                {
                    BayesianEvent e = _events[i];
                    if (Query.GetEventState(e).CurrentEventType == EventType.Evidence)
                    {
                        if (!first)
                        {
                            result.Append(",");
                        }
                        result.Append(e.Label);
                        first = false;
                    }
                }

                result.Append(")");
                return result.ToString();
            }
        }

        /// <summary>
        /// True if this network has a valid classification target.
        /// </summary>
        public bool HasValidClassificationTarget
        {
            get
            {
                if (_classificationTarget < 0
                    || _classificationTarget >= _events.Count)
                {
                    return false;
                }
                return true;
            }
        }

        #region IMLClassification Members

        /// <inheritdoc/>
        public int InputCount
        {
            get { return _events.Count; }
        }

        /// <inheritdoc/>
        public int OutputCount
        {
            get { return 1; }
        }

        /// <summary>
        /// Classify the input. 
        /// </summary>
        /// <param name="input">The input to classify.</param>
        /// <returns>The classification.</returns>
        public int Classify(IMLData input)
        {
            if (_classificationTarget < 0 || _classificationTarget >= _events.Count)
            {
                throw new BayesianError("Must specify classification target by calling setClassificationTarget.");
            }

            int[] d = DetermineClasses(input);

            // properly tag all of the events
            for (int i = 0; i < _events.Count; i++)
            {
                BayesianEvent e = _events[i];
                if (i == _classificationTarget)
                {
                    Query.DefineEventType(e, EventType.Outcome);
                }
                else if (_inputPresent[i])
                {
                    Query.DefineEventType(e, EventType.Evidence);
                    Query.SetEventValue(e, d[i]);
                }
                else
                {
                    Query.DefineEventType(e, EventType.Hidden);
                    Query.SetEventValue(e, d[i]);
                }
            }


            // loop over and try each outcome choice
            BayesianEvent outcomeEvent = _events[_classificationTarget];
            _classificationProbabilities = new double[outcomeEvent.Choices.Count];
            for (int i = 0; i < outcomeEvent.Choices.Count; i++)
            {
                Query.SetEventValue(outcomeEvent, i);
                Query.Execute();
                _classificationProbabilities[i] = Query.Probability;
            }


            return EngineArray.MaxIndex(_classificationProbabilities);
        }

        #endregion

        #region IMLError Members

        /// <inheritdoc/>
        public double CalculateError(IMLDataSet data)
        {
            if (!HasValidClassificationTarget)
                return 1.0;

            // Call the following just to thrown an error if there is no classification target
            ClassificationTarget.ToString();

            int badCount = 0;
            int totalCount = 0;

            foreach (IMLDataPair pair in data)
            {
                int c = Classify(pair.Input);
                totalCount++;
                if (c != pair.Input[_classificationTarget])
                {
                    badCount++;
                }
            }

            return badCount / (double)totalCount;
        }

        #endregion

        #region IMLResettable Members

        /// <inheritdoc/>
        public void Reset()
        {
            Reset(0);
        }

        /// <inheritdoc/>
        public void Reset(int seed)
        {
            foreach (BayesianEvent e in _events)
            {
                e.Reset();
            }
        }

        #endregion

        /// <summary>
        /// Get an event based on the string label. 
        /// </summary>
        /// <param name="label">The label to locate.</param>
        /// <returns>The event found.</returns>
        public BayesianEvent GetEvent(String label)
        {
            if (!_eventMap.ContainsKey(label))
                return null;
            return _eventMap[label];
        }

        /// <summary>
        /// Get an event based on label, throw an error if not found.
        /// </summary>
        /// <param name="label">THe event label to find.</param>
        /// <returns>The event.</returns>
        public BayesianEvent GetEventError(String label)
        {
            if (!EventExists(label))
                throw (new BayesianError("Undefined label: " + label));
            return _eventMap[label];
        }


        /// <summary>
        /// Return true if the specified event exists. 
        /// </summary>
        /// <param name="label">The label we are searching for.</param>
        /// <returns>True, if the event exists by label.</returns>
        public bool EventExists(String label)
        {
            return _eventMap.ContainsKey(label);
        }

        /// <summary>
        /// Create, or register, the specified event with this bayesian network. 
        /// </summary>
        /// <param name="theEvent">The event to add.</param>
        public void CreateEvent(BayesianEvent theEvent)
        {
            if (EventExists(theEvent.Label))
            {
                throw new BayesianError("The label \"" + theEvent.Label
                                        + "\" has already been defined.");
            }

            _eventMap[theEvent.Label] = theEvent;
            _events.Add(theEvent);
        }


        /// <summary>
        /// Create an event specified on the label and options provided. 
        /// </summary>
        /// <param name="label">The label to create this event as.</param>
        /// <param name="options">The options, or states, that this event can have.</param>
        /// <returns>The newly created event.</returns>
        public BayesianEvent CreateEvent(String label, IList<BayesianChoice> options)
        {
            if (label == null)
            {
                throw new BayesianError("Can't create event with null label name");
            }

            if (EventExists(label))
            {
                throw new BayesianError("The label \"" + label
                                        + "\" has already been defined.");
            }

            BayesianEvent e = options.Count == 0 ? new BayesianEvent(label) : new BayesianEvent(label, options);
            CreateEvent(e);
            return e;
        }

        /// <summary>
        /// Create the specified events based on a variable number of options, or choices. 
        /// </summary>
        /// <param name="label">The label of the event to create.</param>
        /// <param name="options">The states that the event can have.</param>
        /// <returns>The newly created event.</returns>
        public BayesianEvent CreateEvent(String label, params String[] options)
        {
            if (label == null)
            {
                throw new BayesianError("Can't create event with null label name");
            }

            if (EventExists(label))
            {
                throw new BayesianError("The label \"" + label
                                        + "\" has already been defined.");
            }

            BayesianEvent e = options.Length == 0 ? new BayesianEvent(label) : new BayesianEvent(label, options);
            CreateEvent(e);
            return e;
        }

        /// <summary>
        /// Create a dependency between two events. 
        /// </summary>
        /// <param name="parentEvent">The parent event.</param>
        /// <param name="childEvent">The child event.</param>
        public void CreateDependency(BayesianEvent parentEvent,
                                     BayesianEvent childEvent)
        {
            // does the dependency exist?
            if (!HasDependency(parentEvent, childEvent))
            {
                // create the dependency
                parentEvent.AddChild(childEvent);
                childEvent.AddParent(parentEvent);
            }
        }

        /// <summary>
        /// Determine if the two events have a dependency. 
        /// </summary>
        /// <param name="parentEvent">The parent event.</param>
        /// <param name="childEvent">The child event.</param>
        /// <returns>True if a dependency exists.</returns>
        private static bool HasDependency(BayesianEvent parentEvent,
                                   BayesianEvent childEvent)
        {
            return (parentEvent.Children.Contains(childEvent));
        }

        /// <summary>
        /// Create a dependency between a parent and multiple children. 
        /// </summary>
        /// <param name="parentEvent">The parent event.</param>
        /// <param name="children">The child events.</param>
        public void CreateDependency(BayesianEvent parentEvent,
                                     params BayesianEvent[] children)
        {
            foreach (BayesianEvent childEvent in children)
            {
                parentEvent.AddChild(childEvent);
                childEvent.AddParent(parentEvent);
            }
        }

        /// <summary>
        /// Create a dependency between two labels.
        /// </summary>
        /// <param name="parentEventLabel">The parent event.</param>
        /// <param name="childEventLabel">The child event.</param>
        public void CreateDependency(String parentEventLabel, String childEventLabel)
        {
            BayesianEvent parentEvent = GetEventError(parentEventLabel);
            BayesianEvent childEvent = GetEventError(childEventLabel);
            CreateDependency(parentEvent, childEvent);
        }

        /// <summary>
        /// Remove a dependency, if it it exists.
        /// </summary>
        /// <param name="parent">The parent event.</param>
        /// <param name="child">The child event.</param>
        private static void RemoveDependency(BayesianEvent parent, BayesianEvent child)
        {
            parent.Children.Remove(child);
            child.Parents.Remove(parent);
        }

        /// <summary>
        /// Remove the specified event.
        /// </summary>
        /// <param name="theEvent">The event to remove.</param>
        private void RemoveEvent(BayesianEvent theEvent)
        {
            foreach (BayesianEvent e in theEvent.Parents)
            {
                e.Children.Remove(theEvent);
            }
            _eventMap.Remove(theEvent.Label);
            _events.Remove(theEvent);
        }

        /// <inheritdoc/>
        public override String ToString()
        {
            var result = new StringBuilder();
            bool first = true;

            foreach (BayesianEvent e in _events)
            {
                if (!first)
                    result.Append(" ");
                first = false;
                result.Append(e.ToString());
            }

            return result.ToString();
        }

        ///<summary>
        /// Calculate the parameter count.
        ///</summary>
        ///<returns>The number of parameters in this Bayesian network.</returns>
        public int CalculateParameterCount()
        {
            return _eventMap.Values.Sum(e => e.CalculateParameterCount());
        }

        /// <summary>
        /// Finalize the structure of this Bayesian network.
        /// </summary>
        public void FinalizeStructure()
        {
            foreach (BayesianEvent e in _eventMap.Values)
            {
                e.FinalizeStructure();
            }

            if (Query != null)
            {
                Query.FinalizeStructure();
            }

            _inputPresent = new bool[_events.Count];
            EngineArray.Fill(_inputPresent, true);
            _classificationTarget = -1;
        }

        /// <summary>
        /// Validate the structure of this Bayesian network.
        /// </summary>
        public void Validate()
        {
            foreach (BayesianEvent e in _eventMap.Values)
            {
                e.Validate();
            }
        }

        /// <summary>
        /// Determine if one Bayesian event is in an array of others. 
        /// </summary>
        /// <param name="given">The events to check.</param>
        /// <param name="e">See if e is amoung given.</param>
        /// <returns>True if e is amoung given.</returns>
        private static bool IsGiven(IEnumerable<BayesianEvent> given, BayesianEvent e)
        {
            return given.Any(e2 => e == e2);
        }


        /// <summary>
        /// Determine if one event is a descendant of another.
        /// </summary>
        /// <param name="a">The event to check.</param>
        /// <param name="b">The event that has children.</param>
        /// <returns>True if a is amoung b's children.</returns>
        public bool IsDescendant(BayesianEvent a, BayesianEvent b)
        {
            if (a == b)
                return true;

            return b.Children.Any(e => IsDescendant(a, e));
        }


        /// <summary>
        /// True if this event is given or conditionally dependant on the others. 
        /// </summary>
        /// <param name="given">The others to check.</param>
        /// <param name="e">The event to check.</param>
        /// <returns>True, if is given or descendant.</returns>
        private bool IsGivenOrDescendant(IEnumerable<BayesianEvent> given, BayesianEvent e)
        {
            return given.Any(e2 => IsDescendant(e2, e));
        }


        /// <summary>
        /// Help determine if one event is conditionally independent of another.
        /// </summary>
        /// <param name="previousHead">The previous head, as we traverse the list.</param>
        /// <param name="a">The event to check.</param>
        /// <param name="goal">List of events searched.</param>
        /// <param name="searched"></param>
        /// <param name="given">Given events.</param>
        /// <returns>True if conditionally independent.</returns>
        private bool IsCondIndependent(bool previousHead, BayesianEvent a,
                                       BayesianEvent goal, IDictionary<BayesianEvent, Object> searched,
                                       params BayesianEvent[] given)
        {
            // did we find it?
            if (a == goal)
            {
                return false;
            }

            // search children
            foreach (BayesianEvent e in a.Children)
            {
                if (!searched.ContainsKey(e) || !IsGiven(given, a))
                {
                    searched[e] = null;
                    if (!IsCondIndependent(true, e, goal, searched, given))
                        return false;
                }
            }

            // search parents
            foreach (BayesianEvent e in a.Parents)
            {
                if (!searched.ContainsKey(e))
                {
                    searched[e] = null;
                    if (!previousHead || IsGivenOrDescendant(given, a))
                        if (!IsCondIndependent(false, e, goal, searched, given))
                            return false;
                }
            }

            return true;
        }

        /// <summary>
        /// Determine if two events are conditionally independent.
        /// </summary>
        /// <param name="a">The first event.</param>
        /// <param name="b">The second event.</param>
        /// <param name="given">What is "given".</param>
        /// <returns>True of they are cond. independent.</returns>
        public bool IsCondIndependent(BayesianEvent a, BayesianEvent b,
                                      params BayesianEvent[] given)
        {
            IDictionary<BayesianEvent, Object> searched = new Dictionary<BayesianEvent, Object>();
            return IsCondIndependent(false, a, b, searched, given);
        }

        /// <inheritdoc/>
        public double ComputeProbability(IMLData input)
        {
            // copy the input to evidence
            int inputIndex = 0;
            foreach (BayesianEvent e in _events)
            {
                EventState state = Query.GetEventState(e);
                if (state.CurrentEventType == EventType.Evidence)
                {
                    state.Value = ((int)input[inputIndex++]);
                }
            }

            // execute the query
            Query.Execute();

            return Query.Probability;
        }


        /// <summary>
        /// Define the probability for an event.
        /// </summary>
        /// <param name="line">The event.</param>
        /// <param name="probability">The probability.</param>
        public void DefineProbability(String line, double probability)
        {
            var parse = new ParseProbability(this);
            ParsedProbability parsedProbability = parse.Parse(line);
            parsedProbability.DefineTruthTable(this, probability);
        }

        /// <summary>
        /// Define a probability.
        /// </summary>
        /// <param name="line">The line to define the probability.</param>
        public void DefineProbability(String line)
        {
            int index = line.LastIndexOf('=');
            bool error = false;
            double prob = 0.0;
            String left = "";

            if (index != -1)
            {
                left = line.Substring(0, index);
                String right = line.Substring(index + 1);

                try
                {
                    prob = CSVFormat.EgFormat.Parse(right);
                }
                catch (FormatException)
                {
                    error = true;
                }
            }

            if (error || index == -1)
            {
                throw new BayesianError(
                    "Probability must be of the form \"P(event|condition1,condition2,etc.)=0.5\".  Conditions are optional.");
            }
            DefineProbability(left, prob);
        }

        /// <summary>
        /// Require the specified event, thrown an error if it does not exist.
        /// </summary>
        /// <param name="label">The label.</param>
        /// <returns>The event.</returns>
        public BayesianEvent RequireEvent(String label)
        {
            BayesianEvent result = GetEvent(label);
            if (result == null)
            {
                throw new BayesianError("The event " + label + " is not defined.");
            }
            return result;
        }

        /// <summary>
        /// Define a relationship.
        /// </summary>
        /// <param name="line">The relationship to define.</param>
        public void DefineRelationship(String line)
        {
            var parse = new ParseProbability(this);
            ParsedProbability parsedProbability = parse.Parse(line);
            parsedProbability.DefineRelationships(this);
        }

        /// <summary>
        /// Perform a query.
        /// </summary>
        /// <param name="line">The query.</param>
        /// <returns>The probability.</returns>
        public double PerformQuery(String line)
        {
            if (Query == null)
            {
                throw new BayesianError("This Bayesian network does not have a query to define.");
            }

            var parse = new ParseProbability(this);
            ParsedProbability parsedProbability = parse.Parse(line);

            // create a temp query
            IBayesianQuery q = Query.Clone();

            // first, mark all events as hidden
            q.Reset();

            // deal with evidence (input)
            foreach (ParsedEvent parsedEvent in parsedProbability.GivenEvents)
            {
                BayesianEvent e = RequireEvent(parsedEvent.Label);
                q.DefineEventType(e, EventType.Evidence);
                q.SetEventValue(e, parsedEvent.ResolveValue(e));
            }

            // deal with outcome (output)
            foreach (ParsedEvent parsedEvent in parsedProbability.BaseEvents)
            {
                BayesianEvent e = RequireEvent(parsedEvent.Label);
                q.DefineEventType(e, EventType.Outcome);
                q.SetEventValue(e, parsedEvent.ResolveValue(e));
            }

            q.LocateEventTypes();

            q.Execute();
            return q.Probability;
        }

        /// <inheritdoc/>
        public override void UpdateProperties()
        {
            // Not needed		
        }

        ///<summary>
        /// Get the index of the given event.
        ///</summary>
        ///<param name="theEvent">The event to get the index of.</param>
        ///<returns>The index of the event.</returns>
        public int GetEventIndex(BayesianEvent theEvent)
        {
            for (int i = 0; i < _events.Count; i++)
            {
                if (theEvent == _events[i])
                    return i;
            }

            return -1;
        }

        /// <summary>
        /// Remove all relations between nodes.
        /// </summary>
        public void RemoveAllRelations()
        {
            foreach (BayesianEvent e in _events)
            {
                e.RemoveAllRelations();
            }
        }


        /// <summary>
        /// Determine the classes for the specified input. 
        /// </summary>
        /// <param name="input">The input.</param>
        /// <returns>An array of class indexes.</returns>
        public int[] DetermineClasses(IMLData input)
        {
            var result = new int[input.Count];

            for (int i = 0; i < input.Count; i++)
            {
                BayesianEvent e = _events[i];
                int classIndex = e.MatchChoiceToRange(input[i]);
                result[i] = classIndex;
            }

            return result;
        }

        /// <summary>
        /// Determine if the specified input is present. 
        /// </summary>
        /// <param name="idx">The index of the input.</param>
        /// <returns>True, if the input is present.</returns>
        public bool IsInputPresent(int idx)
        {
            return _inputPresent[idx];
        }

        /// <summary>
        /// Define a classification structure of the form P(A|B) = P(C)
        /// </summary>
        /// <param name="line">The structure.</param>
        public void DefineClassificationStructure(String line)
        {
            IList<ParsedProbability> list = ParseProbability.ParseProbabilityList(this, line);

            if (list.Count > 1)
            {
                throw new BayesianError("Must only define a single probability, not a chain.");
            }

            if (list.Count == 0)
            {
                throw new BayesianError("Must define at least one probability.");
            }

            // first define everything to be hidden
            foreach (BayesianEvent e in _events)
            {
                Query.DefineEventType(e, EventType.Hidden);
            }

            // define the base event
            ParsedProbability prob = list[0];

            if (prob.BaseEvents.Count == 0)
            {
                return;
            }

            BayesianEvent be = GetEvent(prob.ChildEvent.Label);
            _classificationTarget = _events.IndexOf(be);
            Query.DefineEventType(be, EventType.Outcome);

            // define the given events
            foreach (ParsedEvent parsedGiven in prob.GivenEvents)
            {
                BayesianEvent given = GetEvent(parsedGiven.Label);
                Query.DefineEventType(given, EventType.Evidence);

            }

            Query.LocateEventTypes();

            // set the values
            foreach (ParsedEvent parsedGiven in prob.GivenEvents)
            {
                BayesianEvent e = GetEvent(parsedGiven.Label);
                Query.SetEventValue(e, ParseInt(parsedGiven.Value));
            }

            Query.SetEventValue(be, ParseInt(prob.BaseEvents[0].Value));
        }

        private int ParseInt(String str)
        {
            if (str == null)
            {
                return 0;
            }

            try
            {
                return int.Parse(str);
            }
            catch (FormatException ex)
            {
                return 0;
            }
        }

    }

    public class PersistBayes : ISyntPersistor
    {
        /// <summary>
        /// The file version.
        /// </summary>
        public int FileVersion
        {
            get
            {
                return 1;
            }
        }

        /// <inheritdoc/>
        public Object Read(Stream istream)
        {
            BayesianNetwork result = new BayesianNetwork();
            SyntReadHelper input = new SyntReadHelper(istream);
            SyntFileSection section;
            String queryType = "";
            String queryStr = "";
            String contentsStr = "";

            while ((section = input.ReadNextSection()) != null)
            {
                if (section.SectionName.Equals("BAYES-NETWORK")
                        && section.SubSectionName.Equals("BAYES-PARAM"))
                {
                    IDictionary<String, String> p = section.ParseParams();
                    queryType = p["queryType"];
                    queryStr = p["query"];
                    contentsStr = p["contents"];
                }
                if (section.SectionName.Equals("BAYES-NETWORK")
                        && section.SubSectionName.Equals("BAYES-TABLE"))
                {

                    result.Contents = contentsStr;

                    // first, define relationships (1st pass)
                    foreach (String line in section.Lines)
                    {
                        result.DefineRelationship(line);
                    }

                    result.FinalizeStructure();

                    // now define the probabilities (2nd pass)
                    foreach (String line in section.Lines)
                    {
                        result.DefineProbability(line);
                    }
                }
                if (section.SectionName.Equals("BAYES-NETWORK")
                        && section.SubSectionName.Equals("BAYES-PROPERTIES"))
                {
                    IDictionary<String, String> paras = section.ParseParams();
                    EngineArray.PutAll(paras, result.Properties);
                }
            }

            // define query, if it exists
            if (queryType.Length > 0)
            {
                IBayesianQuery query = null;
                if (queryType.Equals("EnumerationQuery"))
                {
                    query = new EnumerationQuery(result);
                }
                else
                {
                    query = new SamplingQuery(result);
                }

                if (query != null && queryStr.Length > 0)
                {
                    result.Query = query;
                    result.DefineClassificationStructure(queryStr);
                }
            }

            return result;
        }

        /// <inheritdoc/>
        public void Save(Stream os, Object obj)
        {
            SyntWriteHelper o = new SyntWriteHelper(os);
            BayesianNetwork b = (BayesianNetwork)obj;
            o.AddSection("BAYES-NETWORK");
            o.AddSubSection("BAYES-PARAM");
            String queryType = "";
            String queryStr = b.ClassificationStructure;

            if (b.Query != null)
            {
                queryType = b.Query.GetType().Name;
            }

            o.WriteProperty("queryType", queryType);
            o.WriteProperty("query", queryStr);
            o.WriteProperty("contents", b.Contents);
            o.AddSubSection("BAYES-PROPERTIES");
            o.AddProperties(b.Properties);

            o.AddSubSection("BAYES-TABLE");
            foreach (BayesianEvent e in b.Events)
            {
                foreach (TableLine line in e.Table.Lines)
                {
                    if (line == null)
                        continue;
                    StringBuilder str = new StringBuilder();
                    str.Append("P(");

                    str.Append(BayesianEvent.FormatEventName(e, line.Result));

                    if (e.Parents.Count > 0)
                    {
                        str.Append("|");
                    }

                    int index = 0;
                    bool first = true;
                    foreach (BayesianEvent parentEvent in e.Parents)
                    {
                        if (!first)
                        {
                            str.Append(",");
                        }
                        first = false;
                        int arg = line.Arguments[index++];
                        if (parentEvent.IsBoolean)
                        {
                            if (arg == 0)
                            {
                                str.Append("+");
                            }
                            else
                            {
                                str.Append("-");
                            }
                        }
                        str.Append(parentEvent.Label);
                        if (!parentEvent.IsBoolean)
                        {
                            str.Append("=");
                            if (arg >= parentEvent.Choices.Count)
                            {
                                throw new BayesianError("Argument value " + arg + " is out of range for event " + parentEvent.ToString());
                            }
                            str.Append(parentEvent.GetChoice(arg));
                        }
                    }
                    str.Append(")=");
                    str.Append(line.Probability);
                    str.Append("\n");
                    o.Write(str.ToString());
                }
            }

            o.Flush();
        }

        /// <inheritdoc/>
        public String PersistClassString
        {
            get
            {
                return "BayesianNetwork";
            }
        }

        /// <inheritdoc/>
        public Type NativeType
        {
            get { return typeof(BayesianNetwork); }
        }

    }

    [Serializable]
    public class BasicMLComplexData : IMLComplexData
    {
        /// <summary>
        /// The data held by this object.
        /// </summary>
        private ComplexNumber[] _data;

        /// <summary>
        /// Construct this object with the specified data.  Use only real numbers. 
        /// </summary>
        /// <param name="d">The data to construct this object with.</param>
        public BasicMLComplexData(double[] d)
            : this(d.Length)
        {
        }

        /// <summary>
        /// Construct this object with the specified data. Use complex numbers. 
        /// </summary>
        /// <param name="d">The data to construct this object with.</param>
        public BasicMLComplexData(ComplexNumber[] d)
        {
            _data = d;
        }

        /// <summary>
        /// Construct this object with blank data and a specified size. 
        /// </summary>
        /// <param name="size">The amount of data to store.</param>
        public BasicMLComplexData(int size)
        {
            _data = new ComplexNumber[size];
        }

        /// <summary>
        /// Construct a new BasicMLData object from an existing one. This makes a
        /// copy of an array. If MLData is not complex, then only reals will be 
        /// created. 
        /// </summary>
        /// <param name="d">The object to be copied.</param>
        public BasicMLComplexData(IMLData d)
        {
            if (d is IMLComplexData)
            {
                var c = (IMLComplexData)d;
                for (int i = 0; i < d.Count; i++)
                {
                    _data[i] = new ComplexNumber(c.GetComplexData(i));
                }
            }
            else
            {
                for (int i = 0; i < d.Count; i++)
                {
                    _data[i] = new ComplexNumber(d[i], 0);
                }
            }
        }

        #region IMLComplexData Members

        /// <summary>
        /// Clear all values to zero.
        /// </summary>
        public void Clear()
        {
            for (int i = 0; i < _data.Length; i++)
            {
                _data[i] = new ComplexNumber(0, 0);
            }
        }

        /// <inheritdoc/>
        public Object Clone()
        {
            return new BasicMLComplexData(this);
        }


        /// <summary>
        /// The complex numbers.
        /// </summary>
        public ComplexNumber[] ComplexData
        {
            get { return _data; }
            set { _data = value; }
        }


        /// <inheritdoc/>
        public ComplexNumber GetComplexData(int index)
        {
            return _data[index];
        }

        /// <summary>
        /// Set a data element to a complex number. 
        /// </summary>
        /// <param name="index">The index to set.</param>
        /// <param name="d">The complex number.</param>
        public void SetComplexData(int index, ComplexNumber d)
        {
            _data[index] = d;
        }

        /// <summary>
        /// Set the complex data array.
        /// </summary>
        /// <param name="d">A new complex data array.</param>
        public void SetComplexData(ComplexNumber[] d)
        {
            _data = d;
        }

        /// <summary>
        /// Access the data by index.
        /// </summary>
        /// <param name="x">The index to access.</param>
        /// <returns></returns>
        public virtual double this[int x]
        {
            get { return _data[x].Real; }
            set { _data[x] = new ComplexNumber(value, 0); }
        }

        /// <summary>
        /// Get the data as an array.
        /// </summary>
        public virtual double[] Data
        {
            get
            {
                var d = new double[_data.Length];
                for (int i = 0; i < d.Length; i++)
                {
                    d[i] = _data[i].Real;
                }
                return d;
            }
            set
            {
                for (int i = 0; i < value.Length; i++)
                {
                    _data[i] = new ComplexNumber(value[i], 0);
                }
            }
        }

        /// <inheritdoc/>
        public int Count
        {
            get { return _data.Count(); }
        }

        #endregion

        /// <inheritdoc/>
        public String ToString()
        {
            var builder = new StringBuilder("[");
            builder.Append(GetType().Name);
            builder.Append(":");
            for (int i = 0; i < _data.Length; i++)
            {
                if (i != 0)
                {
                    builder.Append(',');
                }
                builder.Append(_data[i].ToString());
            }
            builder.Append("]");
            return builder.ToString();
        }

        /// <summary>
        /// Not supported.
        /// </summary>
        /// <returns>Nothing.</returns>
        public ICentroid<IMLData> CreateCentroid()
        {
            return null;
        }
    }

    [Serializable]
    public class BasicMLData : IMLData
    {
        private double[] _data;

        /// <summary>
        /// Construct this object with the specified data. 
        /// </summary>
        /// <param name="d">The data to construct this object with.</param>
        public BasicMLData(double[] d)
            : this(d.Length)
        {
            for (int i = 0; i < d.Length; i++)
            {
                _data[i] = d[i];
            }
        }


        /// <summary>
        /// Construct this object with blank data and a specified size.
        /// </summary>
        /// <param name="size">The amount of data to store.</param>
        public BasicMLData(int size)
        {
            _data = new double[size];
        }

        /// <summary>
        /// Access the data by index.
        /// </summary>
        /// <param name="x">The index to access.</param>
        /// <returns></returns>
        public virtual double this[int x]
        {
            get { return _data[x]; }
            set { _data[x] = value; }
        }

        /// <summary>
        /// Get the data as an array.
        /// </summary>
        public virtual double[] Data
        {
            get { return _data; }
            set { _data = value; }
        }

        /// <summary>
        /// Get the count of data items.
        /// </summary>
        public virtual int Count
        {
            get { return _data.Length; }
        }

        /// <summary>
        /// Convert the object to a string.
        /// </summary>
        /// <returns>The object as a string.</returns>
        public override string ToString()
        {
            var result = new StringBuilder();
            result.Append('[');
            for (int i = 0; i < Count; i++)
            {
                if (i > 0)
                    result.Append(',');
                result.Append(Data[i]);
            }
            result.Append(']');
            return result.ToString();
        }

        /// <summary>
        /// Clone this object.
        /// </summary>
        /// <returns>A clone of this object.</returns>
        public object Clone()
        {
            var result = new BasicMLData(_data);
            return result;
        }

        /// <summary>
        /// Clear to zero.
        /// </summary>
        public void Clear()
        {
            EngineArray.Fill(_data, 0);
        }

        /// <inheritdoc/>
        public ICentroid<IMLData> CreateCentroid()
        {
            return new BasicMLDataCentroid(this);
        }

        /// <summary>
        /// Add one data element to another.  This does not modify the object.
        /// </summary>
        /// <param name="o">The other data element</param>
        /// <returns>The result.</returns>
        public IMLData Plus(IMLData o)
        {
            if (Count != o.Count)
                throw new SyntError("Lengths must match.");

            var result = new BasicMLData(Count);
            for (int i = 0; i < Count; i++)
                result[i] = this[i] + o[i];

            return result;
        }

        /// <summary>
        /// Multiply one data element with another.  This does not modify the object.
        /// </summary>
        /// <param name="d">The other data element</param>
        /// <returns>The result.</returns>
        public IMLData Times(double d)
        {
            IMLData result = new BasicMLData(Count);

            for (int i = 0; i < Count; i++)
                result[i] = this[i] * d;

            return result;
        }

        /// <summary>
        /// Subtract one data element from another.  This does not modify the object.
        /// </summary>
        /// <param name="o">The other data element</param>
        /// <returns>The result.</returns>
        public IMLData Minus(IMLData o)
        {
            if (Count != o.Count)
                throw new SyntError("Counts must match.");

            IMLData result = new BasicMLData(Count);
            for (int i = 0; i < Count; i++)
                result[i] = this[i] - o[i];

            return result;
        }

    }

    public class BasicMLDataCentroid : ICentroid<IMLData>
    {
        /// <summary>
        /// The value this centroid is based on.
        /// </summary>
        private BasicMLData value;

        /// <summary>
        /// Construct the centroid. 
        /// </summary>
        /// <param name="o">The object to base the centroid on.</param>
        public BasicMLDataCentroid(IMLData o)
        {
            this.value = (BasicMLData)o.Clone();
        }

        /// <inheritdoc/>
        public void Add(IMLData d)
        {
            double[] a = d.Data;

            for (int i = 0; i < value.Count; i++)
                value.Data[i] =
                    ((value.Data[i] * value.Count + a[i]) / (value.Count + 1));
        }

        /// <inheritdoc/>
        public void Remove(IMLData d)
        {
            double[] a = d.Data;

            for (int i = 0; i < value.Count; i++)
                value[i] =
                    ((value[i] * value.Count - a[i]) / (value.Count - 1));
        }

        /// <inheritdoc/>
        public double Distance(IMLData d)
        {
            IMLData diff = value.Minus(d);
            double sum = 0.0;

            for (int i = 0; i < diff.Count; i++)
                sum += diff[i] * diff[i];

            return Math.Sqrt(sum);
        }
    }

    [Serializable]
    public class BasicMLDataPair : IMLDataPair
    {
        /// <summary>
        /// The the expected output from the neural network, or null
        /// for unsupervised training.
        /// </summary>
        private readonly IMLData _ideal;

        /// <summary>
        /// The training input to the neural network.
        /// </summary>
        private readonly IMLData _input;

        /// <summary>
        /// The significance.
        /// </summary>
        private double _significance = 1.0;

        /// <summary>
        /// Construct a BasicMLDataPair class with the specified input
        /// and ideal values.
        /// </summary>
        /// <param name="input">The input to the neural network.</param>
        /// <param name="ideal">The expected results from the neural network.</param>
        public BasicMLDataPair(IMLData input, IMLData ideal)
        {
            _input = input;
            _ideal = ideal;
        }

        /// <summary>
        /// Construct a data pair that only includes input. (unsupervised)
        /// </summary>
        /// <param name="input">The input data.</param>
        public BasicMLDataPair(IMLData input)
        {
            _input = input;
            _ideal = null;
        }

        /// <summary>
        /// The input data.
        /// </summary>
        public virtual IMLData Input
        {
            get { return _input; }
        }

        /// <summary>
        /// The ideal data.
        /// </summary>
        public virtual IMLData Ideal
        {
            get { return _ideal; }
        }

        /// <summary>
        /// Convert object to a string.
        /// </summary>
        /// <returns>The object as a string.</returns>
        public override string ToString()
        {
            var result = new StringBuilder();
            result.Append('[');
            result.Append("Input:");
            result.Append(Input);
            result.Append(",Ideal:");
            result.Append(Ideal);
            result.Append(']');
            return result.ToString();
        }

        /// <summary>
        /// Deterimine if this pair is supervised or unsupervised.
        /// </summary>
        /// <returns>True if this is a supervised pair.</returns>
        public bool IsSupervised
        {
            get { return _ideal != null; }
        }

        /// <summary>
        /// Clone this object.
        /// </summary>
        /// <returns>A clone of this object.</returns>
        public object Clone()
        {
            Object result;

            if (Ideal == null)
                result = new BasicMLDataPair((IMLData)_input.Clone());
            else
                result = new BasicMLDataPair((IMLData)_input.Clone(),
                                             (IMLData)_ideal.Clone());

            return result;
        }

        /// <summary>
        /// Create a new neural data pair object of the correct size for the neural
        /// network that is being trained. This object will be passed to the getPair
        /// method to allow the neural data pair objects to be copied to it.
        /// </summary>
        /// <param name="inputSize">The size of the input data.</param>
        /// <param name="idealSize">The size of the ideal data.</param>
        /// <returns>A new neural data pair object.</returns>
        public static IMLDataPair CreatePair(int inputSize, int idealSize)
        {
            IMLDataPair result;

            if (idealSize > 0)
            {
                result = new BasicMLDataPair(new BasicMLData(inputSize),
                                             new BasicMLData(idealSize));
            }
            else
            {
                result = new BasicMLDataPair(new BasicMLData(inputSize));
            }

            return result;
        }

        /// <summary>
        /// The supervised ideal data.
        /// </summary>
        public double[] IdealArray
        {
            get
            {
                return _ideal == null ? null : _ideal.Data;
            }
            set { _ideal.Data = value; }
        }

        /// <summary>
        /// The input array.
        /// </summary>
        public double[] InputArray
        {
            get { return _input.Data; }
            set { _input.Data = value; }
        }

        /// <summary>
        /// Returns true, if supervised.
        /// </summary>
        public bool Supervised
        {
            get { return _ideal != null; }
        }

        /// <summary>
        /// The significance of this training element.
        /// </summary>
        public double Significance
        {
            get { return _significance; }
            set { _significance = value; }
        }

        /// <inheritdoc/>
        public ICentroid<IMLDataPair> CreateCentroid()
        {
            if (!(Input is BasicMLData))
            {
                throw new SyntError("The input data type of " + Input.GetType().Name + " must be BasicMLData.");
            }
            return new BasicMLDataPairCentroid(this);
        }
    }

    public class BasicMLDataPairCentroid : ICentroid<IMLDataPair>
    {
        /// <summary>
        /// The value the centroid is based on.
        /// </summary>
        private readonly BasicMLData _value;

        /// <summary>
        /// Construct the centroid. 
        /// </summary>
        /// <param name="o"> The pair to base the centroid on.</param>
        public BasicMLDataPairCentroid(BasicMLDataPair o)
        {
            _value = (BasicMLData)o.Input.Clone();
        }

        /// <inheritdoc/>
        public void Remove(IMLDataPair d)
        {
            double[] a = d.InputArray;

            for (int i = 0; i < _value.Count; i++)
                _value[i] =
                    ((_value[i] * _value.Count - a[i]) / (_value.Count - 1));
        }

        /// <inheritdoc/>
        public double Distance(IMLDataPair d)
        {
            IMLData diff = _value.Minus(d.Input);
            double sum = 0.0;

            for (int i = 0; i < diff.Count; i++)
                sum += diff[i] * diff[i];

            return Math.Sqrt(sum);
        }

        /// <inheritdoc/>
        public void Add(IMLDataPair d)
        {
            double[] a = d.InputArray;

            for (int i = 0; i < _value.Count; i++)
                _value[i] =
                    ((_value[i] * _value.Count) + a[i]) / (_value.Count + 1);
        }

    }

    [Serializable]
    public class BasicMLDataSet : IMLDataSet, IEnumerable<IMLDataPair>
    {
        /// <summary>
        /// The enumerator for the basic neural data set.
        /// </summary>
        [Serializable]
        public class BasicNeuralEnumerator : IEnumerator<IMLDataPair>
        {
            /// <summary>
            /// The current index.
            /// </summary>
            private int _current;

            /// <summary>
            /// The owner.
            /// </summary>
            private readonly BasicMLDataSet _owner;

            /// <summary>
            /// Construct an enumerator.
            /// </summary>
            /// <param name="owner">The owner of the enumerator.</param>
            public BasicNeuralEnumerator(BasicMLDataSet owner)
            {
                _current = -1;
                _owner = owner;
            }

            /// <summary>
            /// The current data item.
            /// </summary>
            public IMLDataPair Current
            {
                get { return _owner._data[_current]; }
            }

            /// <summary>
            /// Dispose of this object.
            /// </summary>
            public void Dispose()
            {
                // nothing needed
            }

            /// <summary>
            /// The current item.
            /// </summary>
            object IEnumerator.Current
            {
                get
                {
                    if (_current < 0)
                    {
                        throw new InvalidOperationException("Must call MoveNext before reading Current.");
                    }
                    return _owner._data[_current];
                }
            }

            /// <summary>
            /// Move to the next item.
            /// </summary>
            /// <returns>True if there is a next item.</returns>
            public bool MoveNext()
            {
                _current++;
                if (_current >= _owner._data.Count)
                    return false;
                return true;
            }

            /// <summary>
            /// Reset to the beginning.
            /// </summary>
            public void Reset()
            {
                _current = -1;
            }
        }

        /// <summary>
        /// Access to the list of data items.
        /// </summary>
        public IList<IMLDataPair> Data
        {
            get { return _data; }
            set { _data = value; }
        }


        /// <summary>
        /// The data held by this object.
        /// </summary>
        private IList<IMLDataPair> _data = new List<IMLDataPair>();

        /// <summary>
        /// Construct a data set from an already created list. Mostly used to
        /// duplicate this class.
        /// </summary>
        /// <param name="data">The data to use.</param>
        public BasicMLDataSet(IList<IMLDataPair> data)
        {
            _data = data;
        }

        /// <summary>
        /// Copy whatever dataset type is specified into a memory dataset.
        /// </summary>
        ///
        /// <param name="set">The dataset to copy.</param>
        public BasicMLDataSet(IMLDataSet set)
        {
            _data = new List<IMLDataPair>();
            int inputCount = set.InputSize;
            int idealCount = set.IdealSize;


            foreach (IMLDataPair pair in set)
            {
                BasicMLData input = null;
                BasicMLData ideal = null;

                if (inputCount > 0)
                {
                    input = new BasicMLData(inputCount);
                    EngineArray.ArrayCopy(pair.InputArray, input.Data);
                }

                if (idealCount > 0)
                {
                    ideal = new BasicMLData(idealCount);
                    EngineArray.ArrayCopy(pair.IdealArray, ideal.Data);
                }

                Add(new BasicMLDataPair(input, ideal));
            }
        }


        /// <summary>
        /// Construct a data set from an input and idea array.
        /// </summary>
        /// <param name="input">The input into the neural network for training.</param>
        /// <param name="ideal">The idea into the neural network for training.</param>
        public BasicMLDataSet(double[][] input, double[][] ideal)
        {
            for (int i = 0; i < input.Length; i++)
            {
                var tempInput = new double[input[0].Length];
                double[] tempIdeal;

                for (int j = 0; j < tempInput.Length; j++)
                {
                    tempInput[j] = input[i][j];
                }

                BasicMLData idealData = null;

                if (ideal != null)
                {
                    tempIdeal = new double[ideal[0].Length];
                    for (int j = 0; j < tempIdeal.Length; j++)
                    {
                        tempIdeal[j] = ideal[i][j];
                    }
                    idealData = new BasicMLData(tempIdeal);
                }

                var inputData = new BasicMLData(tempInput);

                Add(inputData, idealData);
            }
        }

        /// <summary>
        /// Construct a basic neural data set.
        /// </summary>
        public BasicMLDataSet()
        {
        }

        /// <summary>
        /// Get the ideal size, or zero for unsupervised.
        /// </summary>
        public virtual int IdealSize
        {
            get
            {
                if (_data == null || _data.Count == 0)
                {
                    return 0;
                }

                IMLDataPair pair = _data[0];

                if (pair.IdealArray == null)
                {
                    return 0;
                }

                return pair.Ideal.Count;
            }
        }

        /// <summary>
        /// Get the input size.
        /// </summary>
        public virtual int InputSize
        {
            get
            {
                if (_data == null || _data.Count == 0)
                    return 0;
                IMLDataPair pair = _data[0];
                return pair.Input.Count;
            }
        }

        /// <summary>
        /// Add the specified data to the set.  Add unsupervised data.
        /// </summary>
        /// <param name="data1">The data to add to the set.</param>
        public virtual void Add(IMLData data1)
        {
            IMLDataPair pair = new BasicMLDataPair(data1, null);
            _data.Add(pair);
        }

        /// <summary>
        /// Add supervised data to the set.
        /// </summary>
        /// <param name="inputData">The input data.</param>
        /// <param name="idealData">The ideal data.</param>
        public virtual void Add(IMLData inputData, IMLData idealData)
        {
            IMLDataPair pair = new BasicMLDataPair(inputData, idealData);
            _data.Add(pair);
        }

        /// <summary>
        /// Add a pair to the set.
        /// </summary>
        /// <param name="inputData">The pair to add to the set.</param>
        public virtual void Add(IMLDataPair inputData)
        {
            _data.Add(inputData);
        }

        /// <summary>
        /// Close the neural data set.
        /// </summary>
        public void Close()
        {
            // not needed
        }

        /// <summary>
        /// Get an enumerator to access the data with.
        /// </summary>
        /// <returns>An enumerator.</returns>
        public IEnumerator<IMLDataPair> GetEnumerator()
        {
            return new BasicNeuralEnumerator(this);
        }

        /// <summary>
        /// Get an enumerator to access the data with.
        /// </summary>
        /// <returns>An enumerator.</returns>
        IEnumerator IEnumerable.GetEnumerator()
        {
            return new BasicNeuralEnumerator(this);
        }

        /// <summary>
        /// Determine if the dataset is supervised.  It is assumed that all pairs
        /// are either supervised or not.  So we can determine the entire set by
        /// looking at the first item.  If the set is empty then return false, or
        /// unsupervised.
        /// </summary>
        public bool IsSupervised
        {
            get
            {
                if (_data.Count == 0)
                    return false;
                return (_data[0].Supervised);
            }
        }

        /// <summary>
        /// Clone this object.
        /// </summary>
        /// <returns>A clone of this object.</returns>
        public object Clone()
        {
            var result = new BasicMLDataSet();
            foreach (IMLDataPair pair in Data)
            {
                result.Add((IMLDataPair)pair.Clone());
            }
            return result;
        }

        /// <summary>
        /// The number of records in this data set.
        /// </summary>
        public int Count
        {
            get { return _data.Count; }
        }

        /// <summary>
        /// Get one record from the data set.
        /// </summary>
        /// <param name="index">The index to read.</param>
        /// <param name="pair">The pair to read into.</param>
        public void GetRecord(int index, IMLDataPair pair)
        {
            IMLDataPair source = _data[index];
            pair.InputArray = source.Input.Data;
            if (pair.IdealArray != null)
            {
                pair.IdealArray = source.Ideal.Data;
            }
        }

        /// <summary>
        /// Open an additional instance of this dataset.
        /// </summary>
        /// <returns>The new instance of this dataset.</returns>
        public IMLDataSet OpenAdditional()
        {
            return new BasicMLDataSet(Data);
        }


        /// <summary>
        /// Return true if supervised.
        /// </summary>
        public bool Supervised
        {
            get
            {
                if (_data.Count == 0)
                {
                    return false;
                }
                return _data[0].Supervised;
            }
        }

        public IMLDataPair this[int x]
        {
            get { return _data[x]; }
        }
    }
    //__________________
    [Serializable]
    public class BasicMLSequenceSet : IMLSequenceSet
    {
        /// <summary>
        /// The data held by this object.
        /// </summary>
        private readonly IList<IMLDataSet> _sequences = new List<IMLDataSet>();

        private IMLDataSet _currentSequence;

        /// <summary>
        /// Default constructor.
        /// </summary>
        public BasicMLSequenceSet()
        {
            _currentSequence = new BasicMLDataSet();
            _sequences.Add(_currentSequence);
        }

        public BasicMLSequenceSet(BasicMLSequenceSet other)
        {
            _sequences = other._sequences;
            _currentSequence = other._currentSequence;
        }

        /// <summary>
        /// Construct a data set from an input and ideal array.
        /// </summary>
        /// <param name="input">The input into the machine learning method for training.</param>
        /// <param name="ideal">The ideal output for training.</param>
        public BasicMLSequenceSet(double[][] input, double[][] ideal)
        {
            _currentSequence = new BasicMLDataSet(input, ideal);
            _sequences.Add(_currentSequence);
        }

        /// <summary>
        /// Construct a data set from an already created list. Mostly used to
        /// duplicate this class.
        /// </summary>
        /// <param name="theData">The data to use.</param>
        public BasicMLSequenceSet(IList<IMLDataPair> theData)
        {
            _currentSequence = new BasicMLDataSet(theData);
            _sequences.Add(_currentSequence);
        }

        /// <summary>
        /// Copy whatever dataset type is specified into a memory dataset. 
        /// </summary>
        /// <param name="set">The dataset to copy.</param>
        public BasicMLSequenceSet(IMLDataSet set)
        {
            _currentSequence = new BasicMLDataSet();
            _sequences.Add(_currentSequence);

            int inputCount = set.InputSize;
            int idealCount = set.IdealSize;

            foreach (IMLDataPair pair in set)
            {
                BasicMLData input = null;
                BasicMLData ideal = null;

                if (inputCount > 0)
                {
                    input = new BasicMLData(inputCount);
                    EngineArray.ArrayCopy(pair.InputArray, input.Data);
                }

                if (idealCount > 0)
                {
                    ideal = new BasicMLData(idealCount);
                    EngineArray.ArrayCopy(pair.IdealArray, ideal.Data);
                }

                _currentSequence.Add(new BasicMLDataPair(input, ideal));
            }
        }

        #region IMLSequenceSet Members

        /// <inheritdoc/>
        public void Add(IMLData theData)
        {
            _currentSequence.Add(theData);
        }

        /// <inheritdoc/>
        public void Add(IMLData inputData, IMLData idealData)
        {
            IMLDataPair pair = new BasicMLDataPair(inputData, idealData);
            _currentSequence.Add(pair);
        }

        /// <inheritdoc/>
        public void Add(IMLDataPair inputData)
        {
            _currentSequence.Add(inputData);
        }

        /// <inheritdoc/>
        public void Close()
        {
            // nothing to close
        }


        /// <inheritdoc/>
        public int IdealSize
        {
            get
            {
                if (_sequences[0].Count == 0)
                {
                    return 0;
                }
                return _sequences[0].IdealSize;
            }
        }

        /// <inheritdoc/>
        public int InputSize
        {
            get
            {
                if (_sequences[0].Count == 0)
                {
                    return 0;
                }
                return _sequences[0].IdealSize;
            }
        }

        /// <inheritdoc/>
        public void GetRecord(int index, IMLDataPair pair)
        {
            int recordIndex = index;
            int sequenceIndex = 0;

            while (_sequences[sequenceIndex].Count < recordIndex)
            {
                recordIndex -= _sequences[sequenceIndex].Count;
                sequenceIndex++;
                if (sequenceIndex > _sequences.Count)
                {
                    throw new MLDataError("Record out of range: " + index);
                }
            }

            _sequences[sequenceIndex].GetRecord(recordIndex, pair);
        }

        /// <inheritdoc/>
        public int Count
        {
            get
            {
                return _sequences.Sum(ds => ds.Count);
            }
        }

        /// <inheritdoc/>
        public bool Supervised
        {
            get
            {
                if (_sequences[0].Count == 0)
                {
                    return false;
                }
                return _sequences[0].Supervised;
            }
        }

        /// <inheritdoc/>
        public IMLDataSet OpenAdditional()
        {
            return new BasicMLSequenceSet(this);
        }

        public void StartNewSequence()
        {
            if (_currentSequence.Count > 0)
            {
                _currentSequence = new BasicMLDataSet();
                _sequences.Add(_currentSequence);
            }
        }

        /// <inheritdoc/>
        public int SequenceCount
        {
            get { return _sequences.Count; }
        }

        /// <inheritdoc/>
        public IMLDataSet GetSequence(int i)
        {
            return _sequences[i];
        }

        /// <inheritdoc/>
        public ICollection<IMLDataSet> Sequences
        {
            get { return _sequences; }
        }

        /// <inheritdoc/>
        public void Add(IMLDataSet sequence)
        {
            foreach (IMLDataPair pair in sequence)
            {
                Add(pair);
            }
        }

        /// <summary>
        /// Get an enumerator to access the data with.
        /// </summary>
        /// <returns>An enumerator.</returns>
        public IEnumerator<IMLDataPair> GetEnumerator()
        {
            return new BasicMLSequenceSetEnumerator(this);
        }

        /// <inheritdoc/>
        public IMLDataPair this[int x]
        {
            get
            {
                IMLDataPair result = BasicMLDataPair.CreatePair(InputSize, IdealSize);
                GetRecord(x, result);
                return result;
            }
        }

        #endregion

        /// <inheritdoc/>
        public Object Clone()
        {
            return ObjectCloner.DeepCopy(this);
        }

        #region Nested type: BasicMLSequenceSetEnumerator

        /// <summary>
        /// Enumerate.
        /// </summary>
        public class BasicMLSequenceSetEnumerator : IEnumerator<IMLDataPair>
        {
            /// <summary>
            /// The owner.
            /// </summary>
            private readonly BasicMLSequenceSet _owner;

            /// <summary>
            /// The index that the iterator is currently at.
            /// </summary>
            private int _currentIndex;

            /// <summary>
            /// The sequence index.
            /// </summary>
            private int _currentSequenceIndex;

            /// <summary>
            /// Construct an enumerator.
            /// </summary>
            /// <param name="owner">The owner of the enumerator.</param>
            public BasicMLSequenceSetEnumerator(BasicMLSequenceSet owner)
            {
                Reset();
                _owner = owner;
            }

            #region IEnumerator<IMLDataPair> Members

            /// <summary>
            /// The current data item.
            /// </summary>
            public IMLDataPair Current
            {
                get
                {
                    if (_currentSequenceIndex >= _owner.SequenceCount)
                    {
                        throw new InvalidOperationException("Trying to read past the end of the dataset.");
                    }

                    if (_currentIndex < 0)
                    {
                        throw new InvalidOperationException("Must call MoveNext before reading Current.");
                    }
                    return _owner.GetSequence(_currentSequenceIndex)[_currentIndex];
                }
            }

            /// <summary>
            /// Dispose of this object.
            /// </summary>
            public void Dispose()
            {
                // nothing needed
            }

            /// <summary>
            /// The current item.
            /// </summary>
            object IEnumerator.Current
            {
                get
                {
                    if (_currentSequenceIndex >= _owner.SequenceCount)
                    {
                        throw new InvalidOperationException("Trying to read past the end of the dataset.");
                    }

                    if (_currentIndex < 0)
                    {
                        throw new InvalidOperationException("Must call MoveNext before reading Current.");
                    }
                    return _owner.GetSequence(_currentSequenceIndex)[_currentIndex];
                }
            }

            /// <summary>
            /// Move to the next item.
            /// </summary>
            /// <returns>True if there is a next item.</returns>
            public bool MoveNext()
            {
                if (_currentSequenceIndex >= _owner.SequenceCount)
                {
                    return false;
                }

                IMLDataSet current = _owner.GetSequence(_currentSequenceIndex);
                _currentIndex++;

                if (_currentIndex >= current.Count)
                {
                    _currentIndex = 0;
                    _currentSequenceIndex++;
                }

                if (_currentSequenceIndex >= _owner.SequenceCount)
                {
                    return false;
                }

                return true;
            }

            /// <summary>
            /// Reset to the beginning.
            /// </summary>
            public void Reset()
            {
                _currentIndex = -1;
                _currentSequenceIndex = 0;
            }

            #endregion
        }

        #endregion
    }

    public class ArrayDataCODEC : IDataSetCODEC
    {
        /// <summary>
        /// The ideal array.
        /// </summary>
        private double[][] _ideal;

        /// <summary>
        /// The number of ideal elements.
        /// </summary>
        private int _idealSize;

        /// <summary>
        /// The current index.
        /// </summary>
        private int _index;

        /// <summary>
        /// The input array.
        /// </summary>
        private double[][] _input;

        /// <summary>
        /// The number of input elements.
        /// </summary>
        private int _inputSize;

        /// <summary>
        /// Construct an array CODEC. 
        /// </summary>
        /// <param name="input">The input array.</param>
        /// <param name="ideal">The ideal array.</param>
        public ArrayDataCODEC(double[][] input, double[][] ideal)
        {
            _input = input;
            _ideal = ideal;
            _inputSize = input[0].Length;
            _idealSize = ideal[0].Length;
            _index = 0;
        }

        /// <summary>
        /// Default constructor.
        /// </summary>
        public ArrayDataCODEC()
        {
        }

        /// <inheritdoc/>
        public double[][] Input
        {
            get { return _input; }
        }

        /// <inheritdoc/>
        public double[][] Ideal
        {
            get { return _ideal; }
        }

        #region IDataSetCODEC Members

        /// <inheritdoc/>
        public int InputSize
        {
            get { return _inputSize; }
        }

        /// <inheritdoc/>
        public int IdealSize
        {
            get { return _idealSize; }
        }

        /// <inheritdoc/>
        public bool Read(double[] input, double[] ideal, ref double significance)
        {
            if (_index >= _input.Length)
            {
                return false;
            }
            EngineArray.ArrayCopy(_input[_index], input);
            EngineArray.ArrayCopy(_ideal[_index], ideal);
            _index++;
            significance = 1.0;
            return true;
        }

        /// <inheritdoc/>
        public void Write(double[] input, double[] ideal, double significance)
        {
            EngineArray.ArrayCopy(input, _input[_index]);
            EngineArray.ArrayCopy(ideal, _ideal[_index]);
            _index++;
        }

        /// <inheritdoc/>
        public void PrepareWrite(int recordCount,
                                 int inputSize, int idealSize)
        {
            _input = EngineArray.AllocateDouble2D(recordCount, inputSize);
            _ideal = EngineArray.AllocateDouble2D(recordCount, idealSize);
            _inputSize = inputSize;
            _idealSize = idealSize;
            _index = 0;
        }

        /// <inheritdoc/>
        public void PrepareRead()
        {
        }

        /// <inheritdoc/>
        public void Close()
        {
        }

        #endregion
    }

    public class CSVDataCODEC : IDataSetCODEC
    {
        /// <summary>
        /// The external CSV file.
        /// </summary>
        private readonly String _file;

        /// <summary>
        /// The CSV format to use.
        /// </summary>
        private readonly CSVFormat _format;

        /// <summary>
        /// True, if headers are present in the CSV file.
        /// </summary>
        private readonly bool _headers;

        /// <summary>
        /// The size of the ideal data.
        /// </summary>
        private int _idealCount;

        /// <summary>
        /// The size of the input data.
        /// </summary>
        private int _inputCount;

        /// <summary>
        /// A file used to output the CSV file.
        /// </summary>
        private TextWriter _output;

        /// <summary>
        /// The utility to assist in reading the CSV file.
        /// </summary>
        private ReadCSV _readCSV;

        /// <summary>
        /// Should a significance column be expected.
        /// </summary>
        private bool _significance;

        /// <summary>
        /// Create a CODEC to load data from CSV to binary. 
        /// </summary>
        /// <param name="file">The CSV file to load.</param>
        /// <param name="format">The format that the CSV file is in.</param>
        /// <param name="headers">True, if there are headers.</param>
        /// <param name="inputCount">The number of input columns.</param>
        /// <param name="idealCount">The number of ideal columns.</param>
        /// <param name="significance">Is there a signficance column.</param>
        public CSVDataCODEC(
            String file,
            CSVFormat format,
            bool headers,
            int inputCount, int idealCount, bool significance)
        {
            if (_inputCount != 0)
            {
                throw new BufferedDataError(
                    "To export CSV, you must use the CSVDataCODEC constructor that does not specify input or ideal sizes.");
            }
            _file = file;
            _format = format;
            _inputCount = inputCount;
            _idealCount = idealCount;
            _headers = headers;
            _significance = significance;
        }

        /// <summary>
        /// Constructor to create CSV from binary.
        /// </summary>
        /// <param name="file">The CSV file to create.</param>
        /// <param name="format">The format for that CSV file.</param>
        public CSVDataCODEC(String file, CSVFormat format, bool significance)
        {
            _file = file;
            _format = format;
            _significance = significance;
        }

        #region IDataSetCODEC Members

        /// <inheritdoc/>
        public bool Read(double[] input, double[] ideal, ref double significance)
        {
            if (_readCSV.Next())
            {
                int index = 0;
                for (int i = 0; i < input.Length; i++)
                {
                    input[i] = _readCSV.GetDouble(index++);
                }

                for (int i = 0; i < ideal.Length; i++)
                {
                    ideal[i] = _readCSV.GetDouble(index++);
                }

                if (_significance)
                {
                    significance = _readCSV.GetDouble(index++);
                }
                else
                {
                    significance = 1;
                }
                return true;
            }
            return false;
        }


        /// <inheritdoc/>
        public void Write(double[] input, double[] ideal, double significance)
        {
            if (_significance)
            {
                var record = new double[input.Length + ideal.Length + 1];
                EngineArray.ArrayCopy(input, record);
                EngineArray.ArrayCopy(ideal, 0, record, input.Length, ideal.Length);
                record[record.Length - 1] = significance;
                var result = new StringBuilder();
                NumberList.ToList(_format, result, record);
                _output.WriteLine(result.ToString());
            }
            else
            {
                var record = new double[input.Length + ideal.Length];
                EngineArray.ArrayCopy(input, record);
                EngineArray.ArrayCopy(ideal, 0, record, input.Length, ideal.Length);
                var result = new StringBuilder();
                NumberList.ToList(_format, result, record);
                _output.WriteLine(result.ToString());
            }
        }

        /// <summary>
        /// Prepare to write to a CSV file. 
        /// </summary>
        /// <param name="recordCount">The total record count, that will be written.</param>
        /// <param name="inputSize">The input size.</param>
        /// <param name="idealSize">The ideal size.</param>
        public void PrepareWrite(
            int recordCount,
            int inputSize,
            int idealSize)
        {
            try
            {
                _inputCount = inputSize;
                _idealCount = idealSize;
                _output = new StreamWriter(new FileStream(_file, FileMode.Create));
            }
            catch (IOException ex)
            {
                throw new BufferedDataError(ex);
            }
        }

        /// <summary>
        /// Prepare to read from the CSV file.
        /// </summary>
        public void PrepareRead()
        {
            if (_inputCount == 0)
            {
                throw new BufferedDataError(
                    "To import CSV, you must use the CSVDataCODEC constructor that specifies input and ideal sizes.");
            }
            _readCSV = new ReadCSV(_file, _headers,
                                  _format);
        }

        /// <inheritDoc/>
        public int InputSize
        {
            get { return _inputCount; }
        }

        /// <inheritDoc/>
        public int IdealSize
        {
            get { return _idealCount; }
        }

        /// <inheritDoc/>
        public void Close()
        {
            if (_readCSV != null)
            {
                _readCSV.Close();
                _readCSV = null;
            }

            if (_output != null)
            {
                _output.Close();
                _output = null;
            }
        }

        #endregion
    }

    public class NeuralDataSetCODEC : IDataSetCODEC
    {
        /// <summary>
        /// The dataset.
        /// </summary>
        private readonly IMLDataSet _dataset;

        /// <summary>
        /// The iterator used to read through the dataset.
        /// </summary>
        private IEnumerator<IMLDataPair> _enumerator;

        /// <summary>
        /// The number of ideal elements.
        /// </summary>
        private int _idealSize;

        /// <summary>
        /// The number of input elements.
        /// </summary>
        private int _inputSize;

        /// <summary>
        /// Construct a CODEC. 
        /// </summary>
        /// <param name="dataset">The dataset to use.</param>
        public NeuralDataSetCODEC(IMLDataSet dataset)
        {
            _dataset = dataset;
            _inputSize = dataset.InputSize;
            _idealSize = dataset.IdealSize;
        }

        #region IDataSetCODEC Members

        /// <inheritdoc/>
        public int InputSize
        {
            get { return _inputSize; }
        }

        /// <inheritdoc/>
        public int IdealSize
        {
            get { return _idealSize; }
        }

        /// <inheritdoc/>
        public bool Read(double[] input, double[] ideal, ref double significance)
        {
            if (!_enumerator.MoveNext())
            {
                return false;
            }
            else
            {
                IMLDataPair pair = _enumerator.Current;
                EngineArray.ArrayCopy(pair.Input.Data, input);
                EngineArray.ArrayCopy(pair.Ideal.Data, ideal);
                significance = pair.Significance;
                return true;
            }
        }

        /// <inheritdoc/>
        public void Write(double[] input, double[] ideal, double significance)
        {
            IMLDataPair pair = BasicMLDataPair.CreatePair(_inputSize,
                                                         _idealSize);
            EngineArray.ArrayCopy(input, pair.Input.Data);
            EngineArray.ArrayCopy(ideal, pair.Ideal.Data);
            pair.Significance = significance;
        }

        /// <inheritdoc/>
        public void PrepareWrite(int recordCount,
                                 int inputSize, int idealSize)
        {
            _inputSize = inputSize;
            _idealSize = idealSize;
        }

        /// <inheritdoc/>
        public void PrepareRead()
        {
            _enumerator = _dataset.GetEnumerator();
        }

        /// <inheritdoc/>
        public void Close()
        {
        }

        #endregion
    }

    public class SQLCODEC : IDataSetCODEC
    {
        /// <summary>
        /// The database connection.
        /// </summary>
        private readonly DbConnection _connection;

        /// <summary>
        /// What is the size of the ideal data?
        /// </summary>
        private readonly int _idealSize;

        /// <summary>
        /// What is the size of the input data?
        /// </summary>
        private readonly int _inputSize;

        /// <summary>
        /// The SQL statement being used.
        /// </summary>
        private readonly DbCommand _statement;

        /// <summary>
        /// Holds results from the SQL query.
        /// </summary>
        private DbDataReader _results;

        /// <summary>
        /// Create a SQL neural data set.
        /// </summary>
        /// <param name="sql">The SQL to execute.</param>
        /// <param name="inputSize">The size of the input data being read.</param>
        /// <param name="idealSize">The size of the ideal output data being read.</param>
        /// <param name="connectString">The connection string.</param>
        public SQLCODEC(String sql, int inputSize,
                        int idealSize, String connectString)
        {
            _inputSize = inputSize;
            _idealSize = idealSize;
            _connection = new OleDbConnection(connectString);
            _connection.Open();
            _statement = _connection.CreateCommand();
            _statement.CommandText = sql;
            _statement.Prepare();
            _statement.Connection = _connection;
        }

        #region IDataSetCODEC Members

        /// <summary>
        /// Read a record.
        /// </summary>
        /// <param name="input">The input data.</param>
        /// <param name="ideal">The ideal data.</param>
        /// <returns></returns>
        public bool Read(double[] input, double[] ideal, ref double significance)
        {
            if (!_results.NextResult())
                return false;

            for (int i = 1; i <= _inputSize; i++)
            {
                input[i - 1] = _results.GetDouble(i);
            }

            if (_idealSize > 0)
            {
                for (int i = 1; i <= _idealSize; i++)
                {
                    ideal[i - 1] =
                        _results.GetDouble(i + _inputSize);
                }
            }

            return true;
        }

        /// <inheritdoc/>
        public void Write(double[] input, double[] ideal, double significance)
        {
            throw new NotImplementedException();
        }

        /// <summary>
        /// Prepare to write.
        /// </summary>
        /// <param name="recordCount">The record count.</param>
        /// <param name="inputSize">The input size.</param>
        /// <param name="idealSize">The ideal size.</param>
        public void PrepareWrite(int recordCount, int inputSize, int idealSize)
        {
            throw new NotImplementedException();
        }

        /// <summary>
        /// Prepare to read.
        /// </summary>
        public void PrepareRead()
        {
            _results = _statement.ExecuteReader();
        }

        /// <summary>
        /// The input size.
        /// </summary>
        public int InputSize
        {
            get { return _inputSize; }
        }

        /// <summary>
        /// The ideal size.
        /// </summary>
        public int IdealSize
        {
            get { return _idealSize; }
        }

        /// <summary>
        /// Close the codec.
        /// </summary>
        public void Close()
        {
            if (_connection != null)
            {
                _connection.Close();
            }
            if (_results != null)
            {
                _results.Close();
            }
        }

        #endregion
    }

    public class BinaryDataLoader
    {
        /// <summary>
        /// The CODEC to use.
        /// </summary>
        private readonly IDataSetCODEC _codec;

        /// <summary>
        /// Construct a loader with the specified CODEC. 
        /// </summary>
        /// <param name="codec">The codec to use.</param>
        public BinaryDataLoader(IDataSetCODEC codec)
        {
            _codec = codec;
            Status = new NullStatusReportable();
        }

        /// <summary>
        /// Used to report the status.
        /// </summary>
        public IStatusReportable Status { get; set; }

        /// <summary>
        /// The CODEC that is being used.
        /// </summary>
        public IDataSetCODEC CODEC
        {
            get { return _codec; }
        }

        /// <summary>
        /// Convert an external file format, such as CSV, to the Synt binary
        /// training format. 
        /// </summary>
        /// <param name="binaryFile">The binary file to create.</param>
        public void External2Binary(String binaryFile)
        {
            Status.Report(0, 0, "Importing to binary file: "
                                + binaryFile);

            var egb = new SyntEGBFile(binaryFile);

            egb.Create(_codec.InputSize, _codec.IdealSize);

            var input = new double[_codec.InputSize];
            var ideal = new double[_codec.IdealSize];

            _codec.PrepareRead();

            int currentRecord = 0;
            int lastUpdate = 0;
            double significance = 0;

            while (_codec.Read(input, ideal, ref significance))
            {
                egb.Write(input);
                egb.Write(ideal);

                currentRecord++;
                lastUpdate++;
                if (lastUpdate >= 10000)
                {
                    lastUpdate = 0;
                    Status.Report(0, currentRecord, "Importing...");
                }
                egb.Write(significance);
            }

            egb.Close();
            _codec.Close();
            Status.Report(0, 0, "Done importing to binary file: "
                                + binaryFile);
        }

        /// <summary>
        /// Convert an Synt binary file to an external form, such as CSV. 
        /// </summary>
        /// <param name="binaryFile">THe binary file to use.</param>
        public void Binary2External(String binaryFile)
        {
            Status.Report(0, 0, "Exporting binary file: " + binaryFile);

            var egb = new SyntEGBFile(binaryFile);
            egb.Open();

            _codec.PrepareWrite(egb.NumberOfRecords, egb.InputCount,
                               egb.IdealCount);

            int inputCount = egb.InputCount;
            int idealCount = egb.IdealCount;

            var input = new double[inputCount];
            var ideal = new double[idealCount];

            int currentRecord = 0;
            int lastUpdate = 0;

            // now load the data
            for (int i = 0; i < egb.NumberOfRecords; i++)
            {
                for (int j = 0; j < inputCount; j++)
                {
                    input[j] = egb.Read();
                }

                for (int j = 0; j < idealCount; j++)
                {
                    ideal[j] = egb.Read();
                }

                double significance = egb.Read();

                _codec.Write(input, ideal, significance);

                currentRecord++;
                lastUpdate++;
                if (lastUpdate >= 10000)
                {
                    lastUpdate = 0;
                    Status.Report(egb.NumberOfRecords, currentRecord,
                                  "Exporting...");
                }
            }

            egb.Close();
            _codec.Close();
            Status.Report(0, 0, "Done exporting binary file: "
                                + binaryFile);
        }
    }

    public class BufferedDataError : SyntError
    {
        /// <summary>
        /// Construct a message exception.
        /// </summary>
        /// <param name="str">The message.</param>
        public BufferedDataError(String str)
            : base(str)
        {
        }

        /// <summary>
        /// Pass on an exception.
        /// </summary>
        /// <param name="e">The other exception.</param>
        public BufferedDataError(Exception e)
            : base(e)
        {
        }
    }

    public class BufferedMLDataSet : IMLDataSet
    {
        /// <summary>
        /// Error message for ADD.
        /// </summary>
        public const String ErrorAdd = "Add can only be used after calling beginLoad.";

        /// <summary>
        /// True, if we are in the process of loading.
        /// </summary>
        [NonSerialized]
        private bool _loading;

        /// <summary>
        /// The file being used.
        /// </summary>
        private readonly String _file;

        /// <summary>
        /// The EGB file we are working wtih.
        /// </summary>
        [NonSerialized]
        private SyntEGBFile _egb;

        /// <summary>
        /// Additional sets that were opened.
        /// </summary>
        [NonSerialized]
        private readonly IList<BufferedMLDataSet> _additional = new List<BufferedMLDataSet>();

        /// <summary>
        /// The owner.
        /// </summary>
        [NonSerialized]
        private BufferedMLDataSet _owner;


        /// <summary>
        /// Construct a buffered dataset using the specified file. 
        /// </summary>
        /// <param name="binaryFile">The file to read/write binary data to/from.</param>
        public BufferedMLDataSet(String binaryFile)
        {
            _file = binaryFile;
            _egb = new SyntEGBFile(binaryFile);
            if (File.Exists(_file))
            {
                _egb.Open();
            }
        }


        /// <summary>
        /// Create an enumerator.
        /// </summary>
        /// <returns>The enumerator</returns>
        public IEnumerator<IMLDataPair> GetEnumerator()
        {
            if (_loading)
            {
                throw new IMLDataError(
                    "Can't create enumerator while loading, call EndLoad first.");
            }
            var result = new BufferedNeuralDataSetEnumerator(this);
            return result;
        }


        /// <summary>
        /// Open the binary file for reading.
        /// </summary>
        public void Open()
        {
            _egb.Open();
        }

        /// <summary>
        /// The record count.
        /// </summary>
        public int Count
        {
            get
            {
                return _egb == null ? 0 : _egb.NumberOfRecords;
            }
        }

        /// <summary>
        /// Read an individual record. 
        /// </summary>
        /// <param name="index">The zero-based index. Specify 0 for the first record, 1 for
        /// the second, and so on.</param>
        /// <param name="pair">The data to read.</param>
        public void GetRecord(int index, IMLDataPair pair)
        {
            double[] inputTarget = pair.InputArray;
            double[] idealTarget = pair.IdealArray;

            _egb.SetLocation(index);
            _egb.Read(inputTarget);
            if (idealTarget != null)
            {
                _egb.Read(idealTarget);
            }
            pair.Significance = _egb.Read();
        }

        /// <summary>
        /// Open an additional training set.
        /// </summary>
        /// <returns>An additional training set.</returns>
        public IMLDataSet OpenAdditional()
        {
            var result = new BufferedMLDataSet(_file) { _owner = this };
            _additional.Add(result);
            return result;
        }

        /// <summary>
        /// Add only input data, for an unsupervised dataset. 
        /// </summary>
        /// <param name="data1">The data to be added.</param>
        public void Add(IMLData data1)
        {
            if (!_loading)
            {
                throw new IMLDataError(ErrorAdd);
            }

            _egb.Write(data1.Data);
            _egb.Write(1.0);
        }


        /// <summary>
        /// Add both the input and ideal data. 
        /// </summary>
        /// <param name="inputData">The input data.</param>
        /// <param name="idealData">The ideal data.</param>
        public void Add(IMLData inputData, IMLData idealData)
        {
            if (!_loading)
            {
                throw new IMLDataError(ErrorAdd);
            }

            _egb.Write(inputData.Data);
            _egb.Write(idealData.Data);
            _egb.Write(1.0);
        }

        /// <summary>
        /// Add a data pair of both input and ideal data. 
        /// </summary>
        /// <param name="pair">The pair to add.</param>
        public void Add(IMLDataPair pair)
        {
            if (!_loading)
            {
                throw new IMLDataError(ErrorAdd);
            }

            _egb.Write(pair.Input.Data);
            _egb.Write(pair.Ideal.Data);
            _egb.Write(pair.Significance);
        }

        /// <summary>
        /// Close the dataset.
        /// </summary>
        public void Close()
        {
            Object[] obj = _additional.ToArray();

            foreach (var set in obj.Cast<BufferedMLDataSet>())
            {
                set.Close();
            }

            _additional.Clear();

            if (_owner != null)
            {
                _owner.RemoveAdditional(this);
            }

            _egb.Close();
            _egb = null;
        }

        /// <summary>
        /// The ideal data size.
        /// </summary>
        public int IdealSize
        {
            get
            {
                return _egb == null ? 0 : _egb.IdealCount;
            }
        }

        /// <summary>
        /// The input data size.
        /// </summary>
        public int InputSize
        {
            get
            {
                return _egb == null ? 0 : _egb.InputCount;
            }
        }

        /// <summary>
        /// True if this dataset is supervised.
        /// </summary>
        public bool Supervised
        {
            get
            {
                if (_egb == null)
                {
                    return false;
                }
                return _egb.IdealCount > 0;
            }
        }


        /// <summary>
        /// Remove an additional dataset that was created. 
        /// </summary>
        /// <param name="child">The additional dataset to remove.</param>
        public void RemoveAdditional(BufferedMLDataSet child)
        {
            lock (this)
            {
                _additional.Remove(child);
            }
        }

        /// <summary>
        /// Begin loading to the binary file. After calling this method the add
        /// methods may be called. 
        /// </summary>
        /// <param name="inputSize">The input size.</param>
        /// <param name="idealSize">The ideal size.</param>
        public void BeginLoad(int inputSize, int idealSize)
        {
            _egb.Create(inputSize, idealSize);
            _loading = true;
        }

        /// <summary>
        /// This method should be called once all the data has been loaded. The
        /// underlying file will be closed. The binary fill will then be opened for
        /// reading.
        /// </summary>
        public void EndLoad()
        {
            if (!_loading)
            {
                throw new BufferedDataError("Must call beginLoad, before endLoad.");
            }

            _egb.Close();
            _loading = false;
        }

        /// <summary>
        /// The binary file used.
        /// </summary>
        public String BinaryFile
        {
            get { return _file; }
        }

        /// <summary>
        /// The EGB file to use.
        /// </summary>
        public SyntEGBFile EGB
        {
            get { return _egb; }
        }

        /// <summary>
        /// Load the binary dataset to memory.  Memory access is faster. 
        /// </summary>
        /// <returns>A memory dataset.</returns>
        public IMLDataSet LoadToMemory()
        {
            var result = new BasicMLDataSet();

            foreach (IMLDataPair pair in this)
            {
                result.Add(pair);
            }

            return result;
        }

        /// <summary>
        /// Load the specified training set. 
        /// </summary>
        /// <param name="training">The training set to load.</param>
        public void Load(IMLDataSet training)
        {
            BeginLoad(training.InputSize, training.IdealSize);
            foreach (IMLDataPair pair in training)
            {
                Add(pair);
            }
            EndLoad();
        }

        /// <summary>
        /// The owner.  Set when create additional is used.
        /// </summary>
        public BufferedMLDataSet Owner
        {
            get { return _owner; }
            set { _owner = value; }
        }

        /// <inheritdoc/>
        public IMLDataPair this[int x]
        {
            get
            {
                IMLDataPair result = BasicMLDataPair.CreatePair(InputSize, IdealSize);
                GetRecord(x, result);
                return result;
            }
        }
    }

    public class LinearErrorFunction : IErrorFunction
    {
        /// <inheritdoc/>
        public void CalculateError(double[] ideal, double[] actual, double[] error)
        {
            for (int i = 0; i < actual.Length; i++)
            {
                error[i] = ideal[i] - actual[i];
            }

        }
    }

    public class BufferedNeuralDataSetEnumerator : IEnumerator<IMLDataPair>
    {
        /// <summary>
        /// The dataset being iterated over.
        /// </summary>
        private readonly BufferedMLDataSet _data;

        /// <summary>
        /// The current record.
        /// </summary>
        private int _current;

        /// <summary>
        /// The current record.
        /// </summary>
        private IMLDataPair _currentRecord;

        /// <summary>
        /// Construct the buffered enumerator. This is where the file is actually
        /// opened.
        /// </summary>
        /// <param name="owner">The object that created this enumeration.</param>
        public BufferedNeuralDataSetEnumerator(BufferedMLDataSet owner)
        {
            _data = owner;
            _current = 0;
        }

        #region IEnumerator<MLDataPair> Members

        /// <summary>
        /// Get the current record
        /// </summary>
        public IMLDataPair Current
        {
            get { return _currentRecord; }
        }

        /// <summary>
        /// Dispose of the enumerator.
        /// </summary>
        public void Dispose()
        {
        }


        object IEnumerator.Current
        {
            get
            {
                if (_currentRecord == null)
                {
                    throw new IMLDataError("Can't read current record until MoveNext is called once.");
                }
                return _currentRecord;
            }
        }

        /// <summary>
        /// Move to the next element.
        /// </summary>
        /// <returns>True if there are more elements to read.</returns>
        public bool MoveNext()
        {
            try
            {
                if (_current >= _data.Count)
                    return false;

                _currentRecord = BasicMLDataPair.CreatePair(_data
                                                               .InputSize, _data.IdealSize);
                _data.GetRecord(_current++, _currentRecord);
                return true;
            }
            catch (EndOfStreamException)
            {
                return false;
            }
        }

        /// <summary>
        /// Not implemented.
        /// </summary>
        /// <exception cref="NotImplementedException"></exception>
        public void Reset()
        {
            throw new NotImplementedException();
        }

        #endregion

        /// <summary>
        /// Close the enumerator, and the underlying file.
        /// </summary>
        public void Close()
        {
        }
    }

    public class SyntEGBFile
    {
        /// <summary>
        /// The size of a double.
        /// </summary>
        public const int DoubleSize = sizeof(double);

        /// <summary>
        /// The size of the file header.
        /// </summary>
        public const int HeaderSize = DoubleSize * 3;

        /// <summary>
        /// The file that we are working with.
        /// </summary>
        private readonly String _file;

        /// <summary>
        /// The binary reader.
        /// </summary>
        private BinaryReader _binaryReader;

        /// <summary>
        /// The binary writer.
        /// </summary>
        private BinaryWriter _binaryWriter;

        /// <summary>
        /// The number of ideal values per record.
        /// </summary>
        private int _idealCount;

        /// <summary>
        /// The number of input values per record.
        /// </summary>
        private int _inputCount;

        /// <summary>
        /// The number of records int he file.
        /// </summary>
        private int _numberOfRecords;

        /// <summary>
        /// The number of values in a record, this is the input and ideal combined.
        /// </summary>
        private int _recordCount;

        /// <summary>
        /// The size of a record.
        /// </summary>
        private int _recordSize;

        /// <summary>
        /// The underlying file.
        /// </summary>
        private FileStream _stream;

        /// <summary>
        /// Construct an EGB file. 
        /// </summary>
        /// <param name="file">The file.</param>
        public SyntEGBFile(String file)
        {
            _file = file;
        }

        /// <summary>
        /// The input count.
        /// </summary>
        public int InputCount
        {
            get { return _inputCount; }
        }

        /// <summary>
        /// The ideal count.
        /// </summary>
        public int IdealCount
        {
            get { return _idealCount; }
        }

        /// <summary>
        /// The stream.
        /// </summary>
        public FileStream Stream
        {
            get { return _stream; }
        }

        /// <summary>
        /// The record count.
        /// </summary>
        public int RecordCount
        {
            get { return _recordCount; }
        }

        /// <summary>
        /// The record size.
        /// </summary>
        public int RecordSize
        {
            get { return _recordSize; }
        }

        /// <summary>
        /// The number of records.
        /// </summary>
        public int NumberOfRecords
        {
            get { return _numberOfRecords; }
        }

        /// <summary>
        /// Create a new RGB file. 
        /// </summary>
        /// <param name="inputCount">The input count.</param>
        /// <param name="idealCount">The ideal count.</param>
        public void Create(int inputCount, int idealCount)
        {
            try
            {
                _inputCount = inputCount;
                _idealCount = idealCount;

                var input = new double[inputCount];
                var ideal = new double[idealCount];

                if (_stream != null)
                {
                    _stream.Close();
                    _stream = null;
                }

                _stream = new FileStream(_file, FileMode.Create, FileAccess.ReadWrite);
                _binaryWriter = new BinaryWriter(_stream);
                _binaryReader = null;

                _binaryWriter.Write((byte)'E');
                _binaryWriter.Write((byte)'N');
                _binaryWriter.Write((byte)'C');
                _binaryWriter.Write((byte)'O');
                _binaryWriter.Write((byte)'G');
                _binaryWriter.Write((byte)'-');
                _binaryWriter.Write((byte)'0');
                _binaryWriter.Write((byte)'0');

                _binaryWriter.Write((double)input.Length);
                _binaryWriter.Write((double)ideal.Length);

                _numberOfRecords = 0;
                _recordCount = _inputCount + _idealCount + 1;
                _recordSize = _recordCount * DoubleSize;
            }
            catch (IOException ex)
            {
                throw new BufferedDataError(ex);
            }
        }

        /// <summary>
        /// Open an existing EGB file.
        /// </summary>
        public void Open()
        {
            try
            {
                _stream = new FileStream(_file, FileMode.Open, FileAccess.Read);
                _binaryReader = new BinaryReader(_stream);
                _binaryWriter = null;

                bool isSyntFile = true;

                isSyntFile = isSyntFile ? _binaryReader.ReadByte() == 'E' : false;
                isSyntFile = isSyntFile ? _binaryReader.ReadByte() == 'N' : false;
                isSyntFile = isSyntFile ? _binaryReader.ReadByte() == 'C' : false;
                isSyntFile = isSyntFile ? _binaryReader.ReadByte() == 'O' : false;
                isSyntFile = isSyntFile ? _binaryReader.ReadByte() == 'G' : false;
                isSyntFile = isSyntFile ? _binaryReader.ReadByte() == '-' : false;

                if (!isSyntFile)
                {
                    throw new BufferedDataError(
                        "File is not a valid Synt binary file:"
                        + _file);
                }

                var v1 = (char)_binaryReader.ReadByte();
                var v2 = (char)_binaryReader.ReadByte();
                String versionStr = "" + v1 + v2;

                try
                {
                    int version = int.Parse(versionStr);
                    if (version > 0)
                    {
                        throw new BufferedDataError(
                            "File is from a newer version of Synt than is currently in use.");
                    }
                }
                catch (Exception)
                {
                    throw new BufferedDataError("File has invalid version number.");
                }

                _inputCount = (int)_binaryReader.ReadDouble();
                _idealCount = (int)_binaryReader.ReadDouble();

                _recordCount = _inputCount + _idealCount + 1;
                _recordSize = _recordCount * DoubleSize;
                _numberOfRecords = (int)((_stream.Length - HeaderSize) / _recordSize);
            }
            catch (IOException ex)
            {
                throw new BufferedDataError(ex);
            }
        }

        /// <summary>
        /// Close the file.
        /// </summary>
        public void Close()
        {
            try
            {
                if (_binaryWriter != null)
                {
                    _binaryWriter.Close();
                    _binaryWriter = null;
                }

                if (_binaryReader != null)
                {
                    _binaryReader.Close();
                    _binaryReader = null;
                }

                if (_stream != null)
                {
                    _stream.Close();
                    _stream = null;
                }
            }
            catch (IOException ex)
            {
                throw new BufferedDataError(ex);
            }
        }

        /// <summary>
        /// Calculate the index for the specified row. 
        /// </summary>
        /// <param name="row">The row to calculate for.</param>
        /// <returns>The index.</returns>
        private long CalculateIndex(long row)
        {
            return (long)HeaderSize + (row * (long)_recordSize);
        }

        /// <summary>
        /// Read a row and column. 
        /// </summary>
        /// <param name="row">The row, or record, to read.</param>
        /// <param name="col">The column to read.</param>
        /// <returns>THe value read.</returns>
        private int CalculateIndex(int row, int col)
        {
            return HeaderSize + (row * _recordSize)
                   + (col * DoubleSize);
        }

        /// <summary>
        /// Set the current location to the specified row. 
        /// </summary>
        /// <param name="row">The row.</param>
        public void SetLocation(int row)
        {
            try
            {
                _stream.Position = CalculateIndex(row);
            }
            catch (IOException ex)
            {
                throw new BufferedDataError(ex);
            }
        }

        /// <summary>
        /// Write the specified row and column. 
        /// </summary>
        /// <param name="row">The row.</param>
        /// <param name="col">The column.</param>
        /// <param name="v">The value.</param>
        public void Write(int row, int col, double v)
        {
            try
            {
                _stream.Position = CalculateIndex(row, col);
                _binaryWriter.Write(v);
            }
            catch (IOException ex)
            {
                throw new BufferedDataError(ex);
            }
        }

        /// <summary>
        /// Write an array at the specified record.
        /// </summary>
        /// <param name="row">The record to write.</param>
        /// <param name="v">The array to write.</param>
        public void Write(int row, double[] v)
        {
            try
            {
                _stream.Position = CalculateIndex(row, 0);
                foreach (double t in v)
                {
                    _binaryWriter.Write(t);
                }
            }
            catch (IOException ex)
            {
                throw new BufferedDataError(ex);
            }
        }

        /// <summary>
        /// Write an array. 
        /// </summary>
        /// <param name="v">The array to write.</param>
        public void Write(double[] v)
        {
            try
            {
                foreach (double t in v)
                {
                    _binaryWriter.Write(t);
                }
            }
            catch (IOException ex)
            {
                throw new BufferedDataError(ex);
            }
        }

        /// <summary>
        /// Write a byte. 
        /// </summary>
        /// <param name="b">The byte to write.</param>
        public void Write(byte b)
        {
            try
            {
                _binaryWriter.Write(b);
            }
            catch (IOException ex)
            {
                throw new BufferedDataError(ex);
            }
        }

        /// <summary>
        /// Write a double. 
        /// </summary>
        /// <param name="d">The double to write.</param>
        public void Write(double d)
        {
            try
            {
                _binaryWriter.Write(d);
            }
            catch (IOException ex)
            {
                throw new BufferedDataError(ex);
            }
        }

        /// <summary>
        /// Read a row and column. 
        /// </summary>
        /// <param name="row">The row to read.</param>
        /// <param name="col">The column to read.</param>
        /// <returns>The value read.</returns>
        public double Read(int row, int col)
        {
            try
            {
                _stream.Position = CalculateIndex(row, col);
                return _binaryReader.ReadDouble();
            }
            catch (IOException ex)
            {
                throw new BufferedDataError(ex);
            }
        }

        /// <summary>
        /// Read a double array at the specified record. 
        /// </summary>
        /// <param name="row">The record to read.</param>
        /// <param name="d">The array to read into.</param>
        public void Read(int row, double[] d)
        {
            try
            {
                _stream.Position = CalculateIndex(row, 0);

                for (int i = 0; i < _recordCount; i++)
                {
                    d[i] = _binaryReader.ReadDouble();
                }
            }
            catch (IOException ex)
            {
                throw new BufferedDataError(ex);
            }
        }

        /// <summary>
        /// Read an array of doubles. 
        /// </summary>
        /// <param name="d">The array to read into.</param>
        public void Read(double[] d)
        {
            try
            {
                for (int i = 0; i < d.Length; i++)
                {
                    d[i] = _binaryReader.ReadDouble();
                }
            }
            catch (IOException ex)
            {
                throw new BufferedDataError(ex);
            }
        }

        /// <summary>
        /// Read a single double. 
        /// </summary>
        /// <returns>The double read.</returns>
        public double Read()
        {
            try
            {
                return _binaryReader.ReadDouble();
            }
            catch (IOException ex)
            {
                throw new BufferedDataError(ex);
            }
        }
    }

    public class MemoryDataLoader
    {
        /// <summary>
        /// The CODEC to use.
        /// </summary>
        private readonly IDataSetCODEC _codec;

        /// <summary>
        /// Construct a loader with the specified CODEC. 
        /// </summary>
        /// <param name="codec">The codec to use.</param>
        public MemoryDataLoader(IDataSetCODEC codec)
        {
            _codec = codec;
            Status = new NullStatusReportable();
        }

        /// <summary>
        /// Used to report the status.
        /// </summary>
        private IStatusReportable Status { get; set; }

        /// <summary>
        /// The dataset to load to.
        /// </summary>
        public BasicMLDataSet Result { get; set; }

        /// <summary>
        /// The CODEC that is being used.
        /// </summary>
        public IDataSetCODEC CODEC
        {
            get { return _codec; }
        }

        /// <summary>
        /// Convert an external file format, such as CSV, to an Synt memory training set. 
        /// </summary>
        public IMLDataSet External2Memory()
        {
            Status.Report(0, 0, "Importing to memory");

            if (Result == null)
            {
                Result = new BasicMLDataSet();
            }

            var input = new double[_codec.InputSize];
            var ideal = new double[_codec.IdealSize];

            _codec.PrepareRead();

            int currentRecord = 0;
            int lastUpdate = 0;
            double significance = 1.0;

            while (_codec.Read(input, ideal, ref significance))
            {
                IMLData b = null;

                IMLData a = new BasicMLData(input);

                if (_codec.IdealSize > 0)
                    b = new BasicMLData(ideal);

                IMLDataPair pair = new BasicMLDataPair(a, b);
                pair.Significance = significance;
                Result.Add(pair);

                currentRecord++;
                lastUpdate++;
                if (lastUpdate >= 10000)
                {
                    lastUpdate = 0;
                    Status.Report(0, currentRecord, "Importing...");
                }
            }

            _codec.Close();
            Status.Report(0, 0, "Done importing to memory");
            return Result;
        }
    }
    public class FoldedDataSet : IMLDataSet
    {
        /// <summary>
        /// Error message: adds are not supported.
        /// </summary>
        public const String AddNotSupported = "Direct adds to the folded dataset are not supported.";

        /// <summary>
        /// The underlying dataset.
        /// </summary>
        private readonly IMLDataSet _underlying;

        /// <summary>
        /// The fold that we are currently on.
        /// </summary>
        private int _currentFold;

        /// <summary>
        /// The offset to the current fold.
        /// </summary>
        private int _currentFoldOffset;

        /// <summary>
        /// The size of the current fold.
        /// </summary>
        private int _currentFoldSize;

        /// <summary>
        /// The size of all folds, except the last fold, the last fold may have a
        /// different number.
        /// </summary>
        private int _foldSize;

        /// <summary>
        /// The size of the last fold.
        /// </summary>
        private int _lastFoldSize;

        /// <summary>
        /// The total number of folds. Or 0 if the data has not been folded yet.
        /// </summary>
        private int _numFolds;

        /// <summary>
        /// Create a folded dataset. 
        /// </summary>
        /// <param name="underlying">The underlying folded dataset.</param>
        public FoldedDataSet(IMLDataSet underlying)
        {
            _underlying = underlying;
            Fold(1);
        }

        /// <summary>
        /// The owner object(from openAdditional)
        /// </summary>
        public FoldedDataSet Owner { get; set; }

        /// <summary>
        /// The current fold.
        /// </summary>
        public int CurrentFold
        {
            get
            {
                if (Owner != null)
                {
                    return Owner.CurrentFold;
                }
                return _currentFold;
            }
            set
            {
                if (Owner != null)
                {
                    throw new TrainingError("Can't set the fold on a non-top-level set.");
                }

                if (value >= _numFolds)
                {
                    throw new TrainingError(
                        "Can't set the current fold to be greater than the number of folds.");
                }
                _currentFold = value;
                _currentFoldOffset = _foldSize * _currentFold;

                _currentFoldSize = _currentFold == (_numFolds - 1) ? _lastFoldSize : _foldSize;
            }
        }

        /// <summary>
        /// The current fold offset.
        /// </summary>
        public int CurrentFoldOffset
        {
            get
            {
                if (Owner != null)
                {
                    return Owner.CurrentFoldOffset;
                }
                return _currentFoldOffset;
            }
        }

        /// <summary>
        /// The current fold size.
        /// </summary>
        public int CurrentFoldSize
        {
            get
            {
                if (Owner != null)
                {
                    return Owner.CurrentFoldSize;
                }
                return _currentFoldSize;
            }
        }

        /// <summary>
        /// The number of folds.
        /// </summary>
        public int NumFolds
        {
            get { return _numFolds; }
        }

        /// <summary>
        /// The underlying dataset.
        /// </summary>
        public IMLDataSet Underlying
        {
            get { return _underlying; }
        }

        #region MLDataSet Members

        /// <summary>
        /// Not supported.
        /// </summary>
        /// <param name="data1">Not used.</param>
        public void Add(IMLData data1)
        {
            throw new TrainingError(AddNotSupported);
        }

        /// <summary>
        /// Not supported.
        /// </summary>
        /// <param name="inputData">Not used.</param>
        /// <param name="idealData">Not used.</param>
        public void Add(IMLData inputData, IMLData idealData)
        {
            throw new TrainingError(AddNotSupported);
        }

        /// <summary>
        /// Not supported.
        /// </summary>
        /// <param name="inputData">Not used.</param>
        public void Add(IMLDataPair inputData)
        {
            throw new TrainingError(AddNotSupported);
        }

        /// <summary>
        /// Close the dataset.
        /// </summary>
        public void Close()
        {
            _underlying.Close();
        }


        /// <summary>
        /// The ideal size.
        /// </summary>
        public int IdealSize
        {
            get { return _underlying.IdealSize; }
        }

        /// <summary>
        /// The input size.
        /// </summary>
        public int InputSize
        {
            get { return _underlying.InputSize; }
        }

        /// <summary>
        /// Get a record.
        /// </summary>
        /// <param name="index">The index.</param>
        /// <param name="pair">The record.</param>
        public void GetRecord(int index, IMLDataPair pair)
        {
            _underlying.GetRecord(CurrentFoldOffset + index, pair);
        }

        /// <summary>
        /// The record count.
        /// </summary>
        public int Count
        {
            get { return CurrentFoldSize; }
        }

        /// <summary>
        /// True if this is a supervised set.
        /// </summary>
        public bool Supervised
        {
            get { return _underlying.Supervised; }
        }


        /// <summary>
        /// Open an additional dataset.
        /// </summary>
        /// <returns>The dataset.</returns>
        public IMLDataSet OpenAdditional()
        {
            var folded = new FoldedDataSet(_underlying.OpenAdditional()) { Owner = this };
            return folded;
        }


        /// <summary>
        /// Get an enumberator.
        /// </summary>
        /// <returns>The enumerator.</returns>
        public IEnumerator<IMLDataPair> GetEnumerator()
        {
            return new FoldedEnumerator(this);
        }

        #endregion

        /// <summary>
        /// Fold the dataset. Must be done before the dataset is used. 
        /// </summary>
        /// <param name="numFolds">The number of folds.</param>
        public void Fold(int numFolds)
        {
            _numFolds = Math.Min(numFolds, _underlying
                                               .Count);
            _foldSize = _underlying.Count / _numFolds;
            _lastFoldSize = _underlying.Count - (_foldSize * _numFolds);
            CurrentFold = 0;
        }

        /// <inheritdoc/>
        public IMLDataPair this[int x]
        {
            get
            {
                IMLDataPair result = BasicMLDataPair.CreatePair(InputSize, IdealSize);
                this.GetRecord(x, result);
                return result;
            }
        }
    }

    public class FoldedEnumerator : IEnumerator<IMLDataPair>
    {
        /// <summary>
        /// The owner.
        /// </summary>
        private readonly FoldedDataSet _owner;

        /// <summary>
        /// The current index.
        /// </summary>
        private int _currentIndex;

        /// <summary>
        /// The current data item.
        /// </summary>
        private IMLDataPair _currentPair;

        /// <summary>
        /// Construct an enumerator.
        /// </summary>
        /// <param name="owner">The owner.</param>
        public FoldedEnumerator(FoldedDataSet owner)
        {
            _owner = owner;
            _currentIndex = -1;
        }

        #region IEnumerator<MLDataPair> Members

        /// <summary>
        /// The current object.
        /// </summary>
        public IMLDataPair Current
        {
            get
            {
                if (_currentIndex < 0)
                {
                    throw new InvalidOperationException("Must call MoveNext before reading Current.");
                }
                return _currentPair;
            }
        }

        /// <summary>
        /// Not supported.
        /// </summary>
        /// <exception cref="NotImplementedException"></exception>
        public void Dispose()
        {
            throw new NotImplementedException();
        }

        /// <summary>
        /// Move to the next record.
        /// </summary>
        /// <returns>True, if we were able to move to the next record.</returns>
        public bool MoveNext()
        {
            if (HasNext())
            {
                IMLDataPair pair = BasicMLDataPair.CreatePair(
                    _owner.InputSize, _owner.IdealSize);
                _owner.GetRecord(_currentIndex++, pair);
                _currentPair = pair;
                return true;
            }
            _currentPair = null;
            return false;
        }

        /// <summary>
        /// Not implemented.
        /// </summary>
        public void Reset()
        {
            throw new NotImplementedException();
        }

        /// <summary>
        /// The current object.
        /// </summary>
        object IEnumerator.Current
        {
            get
            {
                if (_currentIndex < 0)
                {
                    throw new InvalidOperationException("Must call MoveNext before reading Current.");
                }
                return _currentPair;
            }
        }

        #endregion

        /// <summary>
        /// Determine if there is a next record.
        /// </summary>
        /// <returns>True, if there is a next record.</returns>
        public bool HasNext()
        {
            return _currentIndex < _owner.CurrentFoldSize;
        }
    }

    public class ImageMLData : BasicMLData
    {
        /// <summary>
        /// Construct an object based on an image.
        /// </summary>
        /// <param name="image">The image to use.</param>
        public ImageMLData(Bitmap image)
            : base(1)
        {
            Image = image;
        }

        /// <summary>
        /// The image associated with this class.
        /// </summary>
        public Bitmap Image { get; set; }


        /// <summary>
        /// Downsample, and copy, the image contents into the data of this object.
        /// Calling this method has no effect on the image, as the same image can be
        /// downsampled multiple times to different resolutions.
        /// </summary>
        /// <param name="downsampler">The downsampler object to use.</param>
        /// <param name="findBounds">Should the bounds be located and cropped.</param>
        /// <param name="height">The height to downsample to.</param>
        /// <param name="width">The width to downsample to.</param>
        /// <param name="hi">The high value to normalize to.</param>
        /// <param name="lo">The low value to normalize to.</param>
        public void Downsample(IDownSample downsampler,
                               bool findBounds, int height, int width,
                               double hi, double lo)
        {
     
        }

        /// <summary>
        /// Return a string representation of this object.
        /// </summary>
        /// <returns>The string form of this object.</returns>
        public override String ToString()
        {
            var builder = new StringBuilder("[ImageNeuralData:");
            for (int i = 0; i < Data.Length; i++)
            {
                if (i != 0)
                {
                    builder.Append(',');
                }
                builder.Append(Data[i]);
            }
            builder.Append("]");
            return builder.ToString();
        }
    }

    public class ImageMLDataSet : BasicMLDataSet
    {
        /// <summary>
        /// Error message to inform the caller that only ImageNeuralData objects can
        /// be used with this collection.
        /// </summary>
        public const String MUST_USE_IMAGE =
            "This data set only supports ImageNeuralData or Image objects.";

        /// <summary>
        /// The downsampler to use.
        /// </summary>
        private readonly IDownSample downsampler;

        /// <summary>
        /// Should the bounds be found and cropped.
        /// </summary>
        private readonly bool findBounds;

        /// <summary>
        /// The high value to normalize to.
        /// </summary>
        private readonly double hi;

        /// <summary>
        /// The low value to normalize to.
        /// </summary>
        private readonly double lo;

        /// <summary>
        /// The height to downsample to.
        /// </summary>
        private int height;

        /// <summary>
        /// The width to downsample to.
        /// </summary>
        private int width;


        /// <summary>
        /// Construct this class with the specified downsampler.
        /// </summary>
        /// <param name="downsampler">The downsampler to use.</param>
        /// <param name="findBounds">Should the bounds be found and clipped.</param>
        /// <param name="hi">The high value to normalize to.</param>
        /// <param name="lo">The low value to normalize to.</param>
        public ImageMLDataSet(IDownSample downsampler,
                              bool findBounds, double hi, double lo)
        {
            this.downsampler = downsampler;
            this.findBounds = findBounds;
            height = -1;
            width = -1;
            this.hi = hi;
            this.lo = lo;
        }

        /// <summary>
        /// The height.
        /// </summary>
        public int Height
        {
            get { return height; }
        }

        /// <summary>
        /// The width.
        /// </summary>
        public int Width
        {
            get { return width; }
        }


        /// <summary>
        /// Add the specified data, must be an ImageNeuralData class.
        /// </summary>
        /// <param name="data">The data The object to add.</param>
        public override void Add(IMLData data)
        {
            if (!(data is ImageMLData))
            {
                throw new NeuralNetworkError(MUST_USE_IMAGE);
            }

            base.Add(data);
        }

        /// <summary>
        /// Add the specified input and ideal object to the collection.
        /// </summary>
        /// <param name="inputData">The image to train with.</param>
        /// <param name="idealData">The expected otuput form this image.</param>
        public override void Add(IMLData inputData, IMLData idealData)
        {
            if (!(inputData is ImageMLData))
            {
                throw new NeuralNetworkError(MUST_USE_IMAGE);
            }

            base.Add(inputData, idealData);
        }

        /// <summary>
        /// Add input and expected output. This is used for supervised training.
        /// </summary>
        /// <param name="inputData">The input data to train on.</param>
        public override void Add(IMLDataPair inputData)
        {
            if (!(inputData.Input is ImageMLData))
            {
                throw new NeuralNetworkError(MUST_USE_IMAGE);
            }

            base.Add(inputData);
        }


        /// <summary>
        /// Downsample all images and generate training data.
        /// </summary>
        /// <param name="height">The height to downsample to.</param>
        /// <param name="width">The width to downsample to.</param>
        public void Downsample(int height, int width)
        {
            this.height = height;
            this.width = width;

            foreach (IMLDataPair pair in this)
            {
                if (!(pair.Input is ImageMLData))
                {
                    throw new NeuralNetworkError(
                        "Invalid class type found in ImageNeuralDataSet, only "
                        + "ImageNeuralData items are allowed.");
                }

                var input = (ImageMLData)pair.Input;
                input.Downsample(downsampler, findBounds, height, width,
                                 hi, lo);
            }
        }
    }

    public class CSVFinal : IMarketLoader
    {

        #region IMarketLoader Members


        string Precision { get; set; }
        public static string LoadedFile { get; set; }


        /// <summary>
        /// Reads the CSV and call loader.
        /// Used internally to load the csv and place data in the marketdataset.
        /// </summary>
        /// <param name="symbol">The symbol.</param>
        /// <param name="neededTypes">The needed types.</param>
        /// <param name="from">From.</param>
        /// <param name="to">To.</param>
        /// <param name="File">The file.</param>
        /// <returns></returns>
        ICollection<LoadedMarketData> ReadAndCallLoader(
            TickerSymbol symbol,
            IEnumerable<MarketDataType> neededTypes,
            DateTime from,
            DateTime to,
            string File)
        {
            //We got a file, lets load it.

            ICollection<LoadedMarketData> result = new List<LoadedMarketData>();
            ReadCSV csv = new ReadCSV(File, true, CSVFormat.English);
            //In case we want to use a different date format...and have used the SetDateFormat method, our DateFormat must then not be null..
            //We will use the ?? operator to check for nullables.
            csv.DateFormat = DateFormat ?? "yyyy-MM-dd HH:mm:ss";
            csv.TimeFormat = "HH:mm:ss";

            DateTime ParsedDate = from;
            bool writeonce = true;

            while (csv.Next())
            {
                DateTime date = csv.GetDate(0);
                ParsedDate = date;

                if (writeonce)
                {
                    Console.WriteLine(@"First parsed date in csv:" + ParsedDate.ToShortDateString());
                    Console.WriteLine(@"Stopping at date:" + to.ToShortDateString());
                    Console.WriteLine(@"Current DateTime:" + ParsedDate.ToShortDateString() + @" Time:" +
                                      ParsedDate.ToShortTimeString() + @"  Asked Start date was " +
                                      from.ToShortDateString());
                    writeonce = false;
                }
                if (ParsedDate >= from && ParsedDate <= to)
                {
                    DateTime datex = csv.GetDate(0);
                    double open = csv.GetDouble(1);
                    double close = csv.GetDouble(2);
                    double high = csv.GetDouble(3);
                    double low = csv.GetDouble(4);
                    double volume = csv.GetDouble(5);
                    double range = Math.Abs(open - close);
                    double HighLowRange = Math.Abs(high - low);
                    double DirectionalRange = close - open;
                    LoadedMarketData data = new LoadedMarketData(datex, symbol);
                    data.SetData(MarketDataType.Open, open);
                    data.SetData(MarketDataType.High, high);
                    data.SetData(MarketDataType.Low, low);
                    data.SetData(MarketDataType.Close, close);
                    data.SetData(MarketDataType.Volume, volume);
                    data.SetData(MarketDataType.RangeHighLow, Math.Round(HighLowRange, 6));
                    data.SetData(MarketDataType.RangeOpenClose, Math.Round(range, 6));
                    data.SetData(MarketDataType.RangeOpenCloseNonAbsolute, Math.Round(DirectionalRange, 6));
                    result.Add(data);


                }

            }

            csv.Close();
            return result;
        }

        /// <summary>
        /// Gets or sets the date format for the whole csv file.
        /// </summary>
        /// <value>
        /// The date format.
        /// </value>
        public string DateFormat { get; set; }
        /// <summary>
        /// Sets the date format for the csv file.
        /// </summary>
        /// <param name="stringFormat">The string format.</param>
        public void SetDateFormat(string stringFormat)
        {
            DateFormat = stringFormat;
            return;
        }

        public ICollection<LoadedMarketData> Load(TickerSymbol ticker, IList<MarketDataType> dataNeeded, DateTime from, DateTime to)
        {


            return File.Exists(LoadedFile) ? (ReadAndCallLoader(ticker, dataNeeded, from, to, LoadedFile)) : null;
        }



        #endregion

        #region IMarketLoader Members




        #endregion

        #region IMarketLoader Members


        /// <summary>
        /// Gets the file we want to parse.
        /// </summary>
        /// <param name="file">The file.</param>
        /// <returns></returns>
        public string GetFile(string file)
        {
            if (File.Exists(file))
                LoadedFile = file;
            return LoadedFile;
        }

        #endregion

    }

    public class CSVLoader : IMarketLoader
    {

        #region IMarketLoader Members  


        string Precision { get; set; }
        string LoadedFile { get; set; }
        public List<MarketDataType> TypesLoaded = new List<MarketDataType>();
        CSVFormat LoadedFormat { get; set; }
        string DateTimeFormat { get; set; }

        public ICollection<LoadedMarketData> ReadAndCallLoader(TickerSymbol symbol, IList<MarketDataType> neededTypes, DateTime from, DateTime to, string File)
        {
            try
            {


                //We got a file, lets load it.



                ICollection<LoadedMarketData> result = new List<LoadedMarketData>();
                ReadCSV csv = new ReadCSV(File, true, LoadedFormat);


                csv.DateFormat = DateTimeFormat.Normalize();
                //  Time,Open,High,Low,Close,Volume
                while (csv.Next())
                {
                    DateTime date = csv.GetDate("Time");
                    double open = csv.GetDouble("Open");
                    double close = csv.GetDouble("High");
                    double high = csv.GetDouble("Low");
                    double low = csv.GetDouble("Close");
                    double volume = csv.GetDouble("Volume");
                    LoadedMarketData data = new LoadedMarketData(date, symbol);
                    data.SetData(MarketDataType.Open, open);
                    data.SetData(MarketDataType.High, high);
                    data.SetData(MarketDataType.Low, low);
                    data.SetData(MarketDataType.Close, close);
                    data.SetData(MarketDataType.Volume, volume);
                    result.Add(data);
                }

                csv.Close();
                return result;
            }

            catch (Exception ex)
            {

                Console.WriteLine("Something went wrong reading the csv");
                Console.WriteLine("Something went wrong reading the csv:" + ex.Message);
            }

            Console.WriteLine("Something went wrong reading the csv");
            return null;
        }

        public CSVFormat fromStringCSVFormattoCSVFormat(string csvformat)
        {
            switch (csvformat)
            {
                case "Decimal Point":
                    LoadedFormat = CSVFormat.DecimalPoint;
                    break;
                case "Decimal Comma":
                    LoadedFormat = CSVFormat.DecimalComma;
                    break;
                case "English Format":
                    LoadedFormat = CSVFormat.English;
                    break;
                case "EG Format":
                    LoadedFormat = CSVFormat.EgFormat;
                    break;

                default:
                    break;
            }

            return LoadedFormat;
        }

        public ICollection<LoadedMarketData> Load(TickerSymbol ticker, IList<MarketDataType> dataNeeded, DateTime from, DateTime to)
        {
            //ICollection<LoadedMarketData> result = new List<LoadedMarketData>();


            //CSVFormLoader formLoader = new CSVFormLoader();
            //if (File.Exists(formLoader.Chosenfile))
            //{
            //    LoadedFormat = formLoader.format;

            //    //Lets add all the marketdatatypes we selected in the form.
            //    foreach (MarketDataType item in formLoader.TypesLoaded)
            //    {
            //        TypesLoaded.Add(item);

            //    }
            //    DateTimeFormat = formLoader.DateTimeFormatTextBox.Text;
            //    result = ReadAndCallLoader(ticker, dataNeeded, from, to, formLoader.Chosenfile);
            //    return result;
            //}


            return null;
        }



        #endregion

        #region IMarketLoader Members


        public string GetFile(string file)
        {
            throw new NotImplementedException();
        }

        #endregion
    }

    public class LoadedMarketData : IComparable<LoadedMarketData>
    {
        /// <summary>
        /// The data that was collection for the sample date.
        /// </summary>
        private readonly IDictionary<MarketDataType, Double> _data;

        /// <summary>
        /// What is the ticker symbol for this data sample.
        /// </summary>
        private readonly TickerSymbol _ticker;

        /// <summary>
        /// Construct one sample of market data.
        /// </summary>
        /// <param name="when">When was this sample taken.</param>
        /// <param name="ticker">What is the ticker symbol for this data.</param>
        public LoadedMarketData(DateTime when, TickerSymbol ticker)
        {
            When = when;
            _ticker = ticker;
            _data = new Dictionary<MarketDataType, Double>();
        }

        /// <summary>
        /// When is this data from.
        /// </summary>
        public DateTime When { get; set; }

        /// <summary>
        /// The ticker symbol that this data was from.
        /// </summary>
        public TickerSymbol Ticker
        {
            get { return _ticker; }
        }

        /// <summary>
        /// The data that was downloaded.
        /// </summary>
        public IDictionary<MarketDataType, Double> Data
        {
            get { return _data; }
        }

        #region IComparable<LoadedMarketData> Members

        /// <summary>
        /// Compare this object with another of the same type.
        /// </summary>
        /// <param name="other">The other object to compare.</param>
        /// <returns>Zero if equal, greater or less than zero to indicate order.</returns>
        public int CompareTo(LoadedMarketData other)
        {
            return When.CompareTo(other.When);
        }

        #endregion

        /// <summary>
        /// Set the specified type of data.
        /// </summary>
        /// <param name="t">The type of data to set.</param>
        /// <param name="d">The value to set.</param>
        public void SetData(MarketDataType t, double d)
        {
            _data[t] = d;
        }

        /// <summary>
        /// Get the specified data type.
        /// </summary>
        /// <param name="t">The type of data to get.</param>
        /// <returns>The value.</returns>
        public double GetData(MarketDataType t)
        {
            return _data[t];
        }
    }

    public class LoaderError : MarketError
    {
        /// <summary>
        /// Construct a message exception.
        /// </summary>
        /// <param name="str">The message.</param>
        public LoaderError(String str)
            : base(str)
        {
        }

        /// <summary>
        /// Pass on an exception.
        /// </summary>
        /// <param name="e">The other exception.</param>
        public LoaderError(Exception e)
            : base(e)
        {
        }
    }

    public class YahooFinanceLoader : IMarketLoader
    {
        #region IMarketLoader Members

        /// <summary>
        /// Load the specified financial data. 
        /// </summary>
        /// <param name="ticker">The ticker symbol to load.</param>
        /// <param name="dataNeeded">The financial data needed.</param>
        /// <param name="from">The beginning date to load data from.</param>
        /// <param name="to">The ending date to load data to.</param>
        /// <returns>A collection of LoadedMarketData objects that represent the data
        /// loaded.</returns>
        public ICollection<LoadedMarketData> Load(TickerSymbol ticker,
                                                  IList<MarketDataType> dataNeeded, DateTime from,
                                                  DateTime to)
        {
            ICollection<LoadedMarketData> result =
                new List<LoadedMarketData>();
            //Uri url = BuildURL(ticker, from, to);
            //WebRequest http = WebRequest.Create(url);
            //var response = (HttpWebResponse)http.GetResponse();

            //using (Stream istream = response.GetResponseStream())
            //{
            //    var csv = new ReadCSV(istream, true, CSVFormat.DecimalPoint);

            //    while (csv.Next())
            //    {
            //        DateTime date = csv.GetDate("date");
            //        double adjClose = csv.GetDouble("adj close");
            //        double open = csv.GetDouble("open");
            //        double close = csv.GetDouble("close");
            //        double high = csv.GetDouble("high");
            //        double low = csv.GetDouble("low");
            //        double volume = csv.GetDouble("volume");

            //        var data =
            //            new LoadedMarketData(date, ticker);
            //        data.SetData(MarketDataType.AdjustedClose, adjClose);
            //        data.SetData(MarketDataType.Open, open);
            //        data.SetData(MarketDataType.Close, close);
            //        data.SetData(MarketDataType.High, high);
            //        data.SetData(MarketDataType.Low, low);
            //        data.SetData(MarketDataType.Open, open);
            //        data.SetData(MarketDataType.Volume, volume);
            //        result.Add(data);
            //    }

            //    csv.Close();
            //    istream.Close();
            //}
            return result;
        }

        #endregion

        /// <summary>
        /// This method builds a URL to load data from Yahoo Finance for a neural
        /// network to train with.
        /// </summary>
        /// <param name="ticker">The ticker symbol to access.</param>
        /// <param name="from">The beginning date.</param>
        /// <param name="to">The ending date.</param>
        /// <returns>The URL to read from</returns>
        private static Uri BuildURL(TickerSymbol ticker, DateTime from,
                             DateTime to)
        {
            // construct the URL
            var mstream = new MemoryStream();
            var form = new FormUtility(mstream, null);

            form.Add("s", ticker.Symbol.ToUpper());
            form.Add("a", "" + (from.Month - 1));
            form.Add("b", "" + from.Day);
            form.Add("c", "" + from.Year);
            form.Add("d", "" + (to.Month - 1));
            form.Add("e", "" + to.Day);
            form.Add("f", "" + to.Year);
            form.Add("g", "d");
            form.Add("ignore", ".csv");
            mstream.Close();
            byte[] b = mstream.GetBuffer();

            String str = "http://ichart.finance.yahoo.com/table.csv?"
                         + StringUtil.FromBytes(b);
            return new Uri(str);
        }

        #region IMarketLoader Members


        public string GetFile(string file)
        {
            throw new NotImplementedException();
        }

        #endregion
    }

    public class MarketDataDescription : TemporalDataDescription
    {
        /// <summary>
        /// The type of data to be loaded from the specified ticker symbol.
        /// </summary>
        private readonly MarketDataType _dataType;

        /// <summary>
        /// The ticker symbol to be loaded.
        /// </summary>
        private readonly TickerSymbol _ticker;

        /// <summary>
        /// Construct a MarketDataDescription item.
        /// </summary>
        /// <param name="ticker">The ticker symbol to use.</param>
        /// <param name="dataType">The data type needed.</param>
        /// <param name="type">The normalization type.</param>
        /// <param name="activationFunction"> The activation function to apply to this data, can be null.</param>
        /// <param name="input">Is this field used for input?</param>
        /// <param name="predict">Is this field used for prediction?</param>
        public MarketDataDescription(TickerSymbol ticker,
                                     MarketDataType dataType, Type type,
                                     IActivationFunction activationFunction, bool input,
                                     bool predict)
            : base(activationFunction, type, input, predict)
        {
            _ticker = ticker;
            _dataType = dataType;
        }


        /// <summary>
        /// Construct a MarketDataDescription item.
        /// </summary>
        /// <param name="ticker">The ticker symbol to use.</param>
        /// <param name="dataType">The data type needed.</param>
        /// <param name="type">The normalization type.</param>
        /// <param name="input">Is this field used for input?</param>
        /// <param name="predict">Is this field used for prediction?</param>
        public MarketDataDescription(TickerSymbol ticker,
                                     MarketDataType dataType, Type type, bool input,
                                     bool predict)
            : this(ticker, dataType, type, null, input, predict)
        {
        }

        /// <summary>
        /// Construct a MarketDataDescription item.
        /// </summary>
        /// <param name="ticker">The ticker symbol to use.</param>
        /// <param name="dataType">The data type needed.</param>
        /// <param name="input">Is this field used for input?</param>
        /// <param name="predict">Is this field used for prediction?</param>
        public MarketDataDescription(TickerSymbol ticker,
                                     MarketDataType dataType, bool input,
                                     bool predict)
            : this(ticker, dataType, Type.PercentChange, null, input, predict)
        {
        }

        /// <summary>
        /// The ticker symbol.
        /// </summary>
        public TickerSymbol Ticker
        {
            get { return _ticker; }
        }

        /// <summary>
        /// The data type that this is.
        /// </summary>
        public MarketDataType DataType
        {
            get { return _dataType; }
        }
    }

    public class MarketError : SyntError
    {
        /// <summary>
        /// Construct a message exception.
        /// </summary>
        /// <param name="str">The message.</param>
        public MarketError(String str)
            : base(str)
        {
        }

        /// <summary>
        /// Pass on an exception.
        /// </summary>
        /// <param name="e">The other exception.</param>
        public MarketError(Exception e)
            : base(e)
        {
        }
    }

    public sealed class MarketMLDataSet : TemporalMLDataSet
    {
        /// <summary>
        /// The loader to use to obtain the data.
        /// </summary>
        private readonly IMarketLoader _loader;

        /// <summary>
        /// A map between the data points and actual data.
        /// </summary>
        private readonly IDictionary<Int64, TemporalPoint> _pointIndex =
            new Dictionary<Int64, TemporalPoint>();

        /// <summary>
        /// Construct a market data set object.
        /// </summary>
        /// <param name="loader">The loader to use to get the financial data.</param>
        /// <param name="inputWindowSize">The input window size, that is how many datapoints do we use to predict.</param>
        /// <param name="predictWindowSize">How many datapoints do we want to predict.</param>
        public MarketMLDataSet(IMarketLoader loader, Int64 inputWindowSize, Int64 predictWindowSize)
            : base((int)inputWindowSize, (int)predictWindowSize)
        {
            _loader = loader;
            SequenceGrandularity = TimeUnit.Days;
        }

        /// <summary>
        /// Initializes a new instance of the <see cref="MarketMLDataSet"/> class.
        /// </summary>
        /// <param name="loader">The loader.</param>
        /// <param name="inputWindowSize">Size of the input window.</param>
        /// <param name="predictWindowSize">Size of the predict window.</param>
        /// <param name="unit">The time unit to use.</param>
        public MarketMLDataSet(IMarketLoader loader, Int64 inputWindowSize, Int64 predictWindowSize, TimeUnit unit)
            : base((int)inputWindowSize, (int)predictWindowSize)
        {

            _loader = loader;
            SequenceGrandularity = unit;
        }

        /// <summary>
        /// The loader that is being used for this set.
        /// </summary>
        public IMarketLoader Loader
        {
            get { return _loader; }
        }

        /// <summary>
        /// Add one description of the type of market data that we are seeking at
        /// each datapoint.
        /// </summary>
        /// <param name="desc"></param>
        public override void AddDescription(TemporalDataDescription desc)
        {
            if (!(desc is MarketDataDescription))
            {
                throw new MarketError(
                    "Only MarketDataDescription objects may be used "
                    + "with the MarketMLDataSet container.");
            }
            base.AddDescription(desc);
        }


        /// <summary>
        /// Create a datapoint at the specified date.
        /// </summary>
        /// <param name="when">The date to create the point at.</param>
        /// <returns>Returns the TemporalPoint created for the specified date.</returns>
        public override TemporalPoint CreatePoint(DateTime when)
        {
            Int64 sequence = (Int64)GetSequenceFromDate(when);
            TemporalPoint result;

            if (_pointIndex.ContainsKey(sequence))
            {
                result = _pointIndex[sequence];
            }
            else
            {
                result = base.CreatePoint(when);
                _pointIndex[(int)result.Sequence] = result;
            }

            return result;
        }


        /// <summary>
        /// Load data from the loader.
        /// </summary>
        /// <param name="begin">The beginning date.</param>
        /// <param name="end">The ending date.</param>
        public void Load(DateTime begin, DateTime end)
        {
            // define the starting point if it is not already defined
            if (StartingPoint == DateTime.MinValue)
            {
                StartingPoint = begin;
            }

            // clear out any loaded points
            Points.Clear();

            // first obtain a collection of symbols that need to be looked up
            IDictionary<TickerSymbol, object> symbolSet = new Dictionary<TickerSymbol, object>();
            foreach (MarketDataDescription desc in Descriptions)
            {
                if (symbolSet.Count == 0)
                {
                    symbolSet[desc.Ticker] = null;
                }
                foreach (TickerSymbol ts in symbolSet.Keys)
                {
                    if (!ts.Equals(desc.Ticker))
                    {
                        symbolSet[desc.Ticker] = null;
                        break;
                    }
                }
            }

            // now loop over each symbol and load the data
            foreach (TickerSymbol symbol in symbolSet.Keys)
            {
                LoadSymbol(symbol, begin, end);
            }

            // resort the points
            SortPoints();
        }


        /// <summary>
        /// Load one point of market data.
        /// </summary>
        /// <param name="ticker">The ticker symbol to load.</param>
        /// <param name="point">The point to load at.</param>
        /// <param name="item">The item being loaded.</param>
        private void LoadPointFromMarketData(TickerSymbol ticker,
                                             TemporalPoint point, LoadedMarketData item)
        {
            foreach (TemporalDataDescription desc in Descriptions)
            {
                var mdesc = (MarketDataDescription)desc;

                if (mdesc.Ticker.Equals(ticker))
                {
                    point.Data[mdesc.Index] = item.Data[mdesc.DataType];
                }
            }
        }

        /// <summary>
        /// Load one ticker symbol.
        /// </summary>
        /// <param name="ticker">The ticker symbol to load.</param>
        /// <param name="from">Load data from this date.</param>
        /// <param name="to">Load data to this date.</param>
        private void LoadSymbol(TickerSymbol ticker, DateTime from,
                                DateTime to)
        {
            IList<MarketDataType> types = new List<MarketDataType>();
            foreach (MarketDataDescription desc in Descriptions)
            {
                if (desc.Ticker.Equals(ticker))
                {
                    types.Add(desc.DataType);
                }
            }
            ICollection<LoadedMarketData> data = Loader.Load(ticker, types, from, to);
            foreach (LoadedMarketData item in data)
            {
                TemporalPoint point = CreatePoint(item.When);

                LoadPointFromMarketData(ticker, point, item);
            }
        }
    }

    public class MarketPoint : TemporalPoint
    {
        /// <summary>
        /// When to hold the data from.
        /// </summary>
        private readonly DateTime _when;


        /// <summary>
        /// Construct a MarketPoint with the specified date and size.
        /// </summary>
        /// <param name="when">When is this data from.</param>
        /// <param name="size">What is the size of the data.</param>
        public MarketPoint(DateTime when, int size)
            : base(size)
        {
            _when = when;
        }

        /// <summary>
        /// When is this point from.
        /// </summary>
        public DateTime When
        {
            get { return _when; }
        }
    }

    public class TickerSymbol
    {
        /// <summary>
        /// The exchange.
        /// </summary>
        private readonly String _exchange;

        /// <summary>
        /// The ticker symbol.
        /// </summary>
        private readonly String _symbol;


        /// <summary>
        /// Construct a ticker symbol with no exchange.
        /// </summary>
        /// <param name="symbol">The ticker symbol</param>
        public TickerSymbol(String symbol)
        {
            _symbol = symbol;
            _exchange = null;
        }

        /// <summary>
        /// Construct a ticker symbol with exchange.
        /// </summary>
        /// <param name="symbol">The ticker symbol.</param>
        /// <param name="exchange">The exchange.</param>
        public TickerSymbol(String symbol, String exchange)
        {
            _symbol = symbol;
            _exchange = exchange;
        }

        /// <summary>
        /// The stock symbol.
        /// </summary>
        public String Symbol
        {
            get { return _symbol; }
        }

        /// <summary>
        /// The exchange that this stock is on.
        /// </summary>
        public String Exchange
        {
            get { return _exchange; }
        }


        /// <summary>
        /// Determine if two ticker symbols equal each other.
        /// </summary>
        /// <param name="other">The other ticker symbol.</param>
        /// <returns>True if the two symbols equal.</returns>
        public bool Equals(TickerSymbol other)
        {
            // if the symbols do not even match then they are not equal
            if (!other.Symbol.Equals(this.Symbol))
            {
                return false;
            }

            // if the symbols match then we need to compare the exchanges
            if (other.Exchange == null && other.Exchange == null)
            {
                return true;
            }

            if (other.Exchange == null || this.Exchange == null)
            {
                return false;
            }

            return other.Exchange.Equals(this.Exchange);
        }
    }

    [Serializable]
    public class BiPolarMLData : IMLData
    {
        /// <summary>
        /// The data held by this object.
        /// </summary>
        private bool[] _data;

        /// <summary>
        /// Construct this object with the specified data. 
        /// </summary>
        /// <param name="d">The data to create this object with.</param>
        public BiPolarMLData(bool[] d)
        {
            _data = new bool[d.Length];
            for (int i = 0; i < d.Length; i++)
            {
                _data[i] = d[i];
            }
        }

        /// <summary>
        /// Construct a data object with the specified size.
        /// </summary>
        /// <param name="size">The size of this data object.</param>
        public BiPolarMLData(int size)
        {
            _data = new bool[size];
        }

        /// <summary>
        /// Allowes indexed access to the data.
        /// </summary>
        /// <param name="x">The index.</param>
        /// <returns>The value at the specified index.</returns>
        public double this[int x]
        {
            get { return BiPolarUtil.Bipolar2double(_data[x]); }
            set { _data[x] = BiPolarUtil.Double2bipolar(value); }
        }

        /// <summary>
        /// Get the data as an array.
        /// </summary>
        public double[] Data
        {
            get { return BiPolarUtil.Bipolar2double(_data); }
            set { _data = BiPolarUtil.Double2bipolar(value); }
        }

        /// <summary>
        /// The size of the array.
        /// </summary>
        public int Count
        {
            get { return _data.Length; }
        }

        /// <summary>
        /// Get the specified data item as a boolean.
        /// </summary>
        /// <param name="i"></param>
        /// <returns></returns>
        public bool GetBoolean(int i)
        {
            return _data[i];
        }

        /// <summary>
        /// Clone this object.
        /// </summary>
        /// <returns>A clone of this object.</returns>
        public virtual object Clone()
        {
            return new BiPolarMLData(_data);
        }

        /// <summary>
        /// Set the value as a boolean.
        /// </summary>
        /// <param name="index">The index.</param>
        /// <param name="b">The boolean value.</param>
        public void SetBoolean(int index, bool b)
        {
            _data[index] = b;
        }

        /// <summary>
        /// Clear to false.
        /// </summary>
        public void Clear()
        {
            for (int i = 0; i < _data.Length; i++)
            {
                _data[i] = false;
            }
        }

        /// <inheritdoc/>
        public String ToString()
        {
            var result = new StringBuilder();
            result.Append('[');
            for (var i = 0; i < Count; i++)
            {
                result.Append(this[i] > 0 ? "T" : "F");
                if (i != Count - 1)
                {
                    result.Append(",");
                }
            }
            result.Append(']');
            return (result.ToString());
        }

        /// <summary>
        /// Not supported.
        /// </summary>
        /// <returns>Nothing.</returns>
        public ICentroid<IMLData> CreateCentroid()
        {
            return null;
        }

    }

    public class CSVMLDataSet : BasicMLDataSet
    {
        /// <summary>
        /// The CSV filename to read from.
        /// </summary>
        private readonly String _filename;

        /// <summary>
        /// The format that separates the columns, defaults to a comma.
        /// </summary>
        private readonly CSVFormat _format;

        /// <summary>
        /// Specifies if headers are present on the first row.
        /// </summary>
        private readonly bool _headers;

        /// <summary>
        /// The number of columns of ideal data.
        /// </summary>
        private readonly int _idealSize;

        /// <summary>
        /// The number of columns of input data.
        /// </summary>
        private readonly int _inputSize;

        /// <summary>
        /// Construct this data set using a comma as a delimiter.
        /// </summary>
        /// <param name="filename">The CSV filename to read.</param>
        /// <param name="inputSize">The number of columns that make up the input set.</param>
        /// <param name="idealSize">The number of columns that make up the ideal set.</param>
        /// <param name="headers">True if headers are present on the first line.</param>
        public CSVMLDataSet(String filename, int inputSize,
                            int idealSize, bool headers)
            : this(filename, inputSize, idealSize, headers, CSVFormat.English, false)
        {
        }

        /// <summary>
        /// Construct this data set using a comma as a delimiter.
        /// </summary>
        /// <param name="filename">The CSV filename to read.</param>
        /// <param name="inputSize">The number of columns that make up the input set.</param>
        /// <param name="idealSize">The number of columns that make up the ideal set.</param>
        /// <param name="headers">True if headers are present on the first line.</param>
        /// <param name="format">The format to use.</param>
        public CSVMLDataSet(String filename, int inputSize,
                            int idealSize, bool headers, CSVFormat format, bool expectSignificance)
        {
            _filename = filename;
            _inputSize = inputSize;
            _idealSize = idealSize;
            _format = format;
            _headers = headers;

            IDataSetCODEC codec = new CSVDataCODEC(filename, format, headers, inputSize, idealSize, expectSignificance);
            var load = new MemoryDataLoader(codec) { Result = this };
            load.External2Memory();
        }

        /// <summary>
        /// Get the filename for the CSV file.
        /// </summary>
        public String Filename
        {
            get { return _filename; }
        }

        /// <summary>
        /// The delimiter.
        /// </summary>
        public CSVFormat Format
        {
            get { return _format; }
        }

        /// <summary>
        /// True if the first row specifies field names.
        /// </summary>
        public bool Headers
        {
            get { return _headers; }
        }

        /// <summary>
        /// The amount of ideal data.
        /// </summary>
        public override int IdealSize
        {
            get { return _idealSize; }
        }

        /// <summary>
        /// The amount of input data.
        /// </summary>
        public override int InputSize
        {
            get { return _inputSize; }
        }
    }

    public class SQLMLDataSet : BasicMLDataSet
    {
        /// <summary>
        /// Create a SQL neural data set.
        /// </summary>
        /// <param name="sql">The SQL to execute.</param>
        /// <param name="inputSize">The size of the input data being read.</param>
        /// <param name="idealSize">The size of the ideal output data being read.</param>
        /// <param name="connectString">The connection string.</param>
        public SQLMLDataSet(String sql, int inputSize,
                            int idealSize, String connectString)
        {
            IDataSetCODEC codec = new SQLCODEC(sql, inputSize, idealSize, connectString);
            var load = new MemoryDataLoader(codec) { Result = this };
            load.External2Memory();
        }
    }

    public class TemporalDataDescription
    {
        #region Type enum

        /// <summary>
        /// The type of data requested.
        /// </summary>
        public enum Type
        {
            /// <summary>
            /// Data in its raw, unmodified form.
            /// </summary>
            Raw,
            /// <summary>
            /// The percent change.
            /// </summary>
            PercentChange,
            /// <summary>
            /// The difference change.
            /// </summary>
            DeltaChange,
        }

        #endregion

        /// <summary>
        /// Should an activation function be used?
        /// </summary>
        private readonly IActivationFunction _activationFunction;

        /// <summary>
        /// What type of data is requested?
        /// </summary>
        private readonly Type _type;

        /// <summary>
        /// Construct a data description item. Set both low and high to zero for
        /// unbounded.
        /// </summary>
        /// <param name="activationFunction">What activation function should be used?</param>
        /// <param name="low">What is the lowest allowed value.</param>
        /// <param name="high">What is the highest allowed value.</param>
        /// <param name="type">What type of data is this.</param>
        /// <param name="input">Used for input?</param>
        /// <param name="predict">Used for prediction?</param>
        public TemporalDataDescription(IActivationFunction activationFunction,
                                       double low, double high, Type type,
                                       bool input, bool predict)
        {
            Low = low;
            _type = type;
            High = high;
            IsInput = input;
            IsPredict = predict;
            _activationFunction = activationFunction;
        }

        /// <summary>
        /// Construct a data description with an activation function, but no range.
        /// </summary>
        /// <param name="activationFunction">The activation function.</param>
        /// <param name="type">The type of data.</param>
        /// <param name="input">Used for input?</param>
        /// <param name="predict">Used for prediction?</param>
        public TemporalDataDescription(IActivationFunction activationFunction,
                                       Type type, bool input, bool predict)
            : this(activationFunction, 0, 0, type, input, predict)
        {
        }

        /// <summary>
        /// Construct a data description with no activation function or range.
        /// </summary>
        /// <param name="type">The type of data.</param>
        /// <param name="input">Used for input?</param>
        /// <param name="predict">Used for prediction?</param>
        public TemporalDataDescription(Type type, bool input,
                                       bool predict)
            : this(null, 0, 0, type, input, predict)
        {
        }

        /// <summary>
        /// The lowest allowed data.
        /// </summary>
        public double Low { get; set; }

        /// <summary>
        /// The highest allowed value.
        /// </summary>
        public double High { get; set; }

        /// <summary>
        /// Is this data input?  Or is it to be predicted.
        /// </summary>
        public bool IsInput { get; set; }

        /// <summary>
        /// Determine if this is a predicted value.
        /// </summary>
        public bool IsPredict { get; set; }

        /// <summary>
        /// Get the index.
        /// </summary>
        public int Index { get; set; }

        /// <summary>
        /// The type of data this is.
        /// </summary>
        public Type DescriptionType
        {
            get { return _type; }
        }

        /// <summary>
        /// The activation function for this layer.
        /// </summary>
        public IActivationFunction ActivationFunction
        {
            get { return _activationFunction; }
        }
    }

    public class TemporalError : SyntError
    {
        /// <summary>
        /// Construct a message exception.
        /// </summary>
        /// <param name="str">The message.</param>
        public TemporalError(String str)
            : base(str)
        {
        }

        /// <summary>
        /// Pass on an exception.
        /// </summary>
        /// <param name="e">The other exception.</param>
        public TemporalError(Exception e)
            : base(e)
        {
        }
    }

    public class TemporalMLDataSet : BasicMLDataSet
    {
        /// <summary>
        /// Error message: adds are not supported.
        /// </summary>
        public const String AddNotSupported = "Direct adds to the temporal dataset are not supported.  "
                                                + "Add TemporalPoint objects and call generate.";

        /// <summary>
        /// Descriptions of the data needed.
        /// </summary>
        private readonly IList<TemporalDataDescription> _descriptions =
            new List<TemporalDataDescription>();

        /// <summary>
        /// The temporal points at which we have data.
        /// </summary>
        private readonly List<TemporalPoint> _points = new List<TemporalPoint>();

        /// <summary>
        /// How big would we like the input size to be.
        /// </summary>
        private int _desiredSetSize;

        /// <summary>
        /// The highest sequence.
        /// </summary>
        private int _highSequence;

        /// <summary>
        /// How many input neurons will be used.
        /// </summary>
        private int _inputNeuronCount;

        /// <summary>
        /// The size of the input window, this is the data being used to predict.
        /// </summary>
        private int _inputWindowSize;

        /// <summary>
        /// The lowest sequence.
        /// </summary>
        private int _lowSequence;

        /// <summary>
        /// How many output neurons will there be.
        /// </summary>
        private int _outputNeuronCount;

        /// <summary>
        /// The size of the prediction window.
        /// </summary>
        private int _predictWindowSize;

        /// <summary>
        /// What is the granularity of the temporal points? Days, months, years,
        /// etc?
        /// </summary>
        private TimeUnit _sequenceGrandularity;

        /// <summary>
        /// What is the date for the first temporal point.
        /// </summary>
        private DateTime _startingPoint = DateTime.MinValue;

        /// <summary>
        /// Construct a dataset.
        /// </summary>
        /// <param name="inputWindowSize">What is the input window size.</param>
        /// <param name="predictWindowSize">What is the prediction window size.</param>
        public TemporalMLDataSet(int inputWindowSize,
                                     int predictWindowSize)
        {
            _inputWindowSize = inputWindowSize;
            _predictWindowSize = predictWindowSize;
            _lowSequence = int.MinValue;
            _highSequence = int.MaxValue;
            _desiredSetSize = int.MaxValue;
            _startingPoint = DateTime.MinValue;
            _sequenceGrandularity = TimeUnit.Days;
        }


        /// <summary>
        /// The data descriptions.
        /// </summary>
        public virtual IList<TemporalDataDescription> Descriptions
        {
            get { return _descriptions; }
        }

        /// <summary>
        /// The points, or time slices to take data from.
        /// </summary>
        public virtual IList<TemporalPoint> Points
        {
            get { return _points; }
        }

        /// <summary>
        /// Get the size of the input window.
        /// </summary>
        public virtual int InputWindowSize
        {
            get { return _inputWindowSize; }
            set { _inputWindowSize = value; }
        }

        /// <summary>
        /// The prediction window size.
        /// </summary>
        public virtual int PredictWindowSize
        {
            get { return _predictWindowSize; }
            set { _predictWindowSize = value; }
        }

        /// <summary>
        /// The low value for the sequence.
        /// </summary>
        public virtual int LowSequence
        {
            get { return _lowSequence; }
            set { _lowSequence = value; }
        }

        /// <summary>
        /// The high value for the sequence.
        /// </summary>
        public virtual int HighSequence
        {
            get { return _highSequence; }
            set { _highSequence = value; }
        }

        /// <summary>
        /// The desired dataset size.
        /// </summary>
        public virtual int DesiredSetSize
        {
            get { return _desiredSetSize; }
            set { _desiredSetSize = value; }
        }

        /// <summary>
        /// The number of input neurons.
        /// </summary>
        public virtual int InputNeuronCount
        {
            get { return _inputNeuronCount; }
            set { _inputNeuronCount = value; }
        }

        /// <summary>
        /// The number of output neurons.
        /// </summary>
        public virtual int OutputNeuronCount
        {
            get { return _outputNeuronCount; }
            set { _outputNeuronCount = value; }
        }

        /// <summary>
        /// The starting point.
        /// </summary>
        public virtual DateTime StartingPoint
        {
            get { return _startingPoint; }
            set { _startingPoint = value; }
        }

        /// <summary>
        /// The size of the timeslices.
        /// </summary>
        public virtual TimeUnit SequenceGrandularity
        {
            get { return _sequenceGrandularity; }
            set { _sequenceGrandularity = value; }
        }


        /// <summary>
        /// Add a data description.
        /// </summary>
        /// <param name="desc">The data description to add.</param>
        public virtual void AddDescription(TemporalDataDescription desc)
        {
            if (_points.Count > 0)
            {
                throw new TemporalError(
                    "Can't add anymore descriptions, there are "
                    + "already temporal points defined.");
            }

            int index = _descriptions.Count;
            desc.Index = index;

            _descriptions.Add(desc);
            CalculateNeuronCounts();
        }

        /// <summary>
        /// Clear the entire dataset.
        /// </summary>
        public virtual void Clear()
        {
            _descriptions.Clear();
            _points.Clear();
            Data.Clear();
        }

        /// <summary>
        /// Adding directly is not supported. Rather, add temporal points and
        /// generate the training data.
        /// </summary>
        /// <param name="inputData">Not used</param>
        /// <param name="idealData">Not used</param>
        public override void Add(IMLData inputData, IMLData idealData)
        {
            throw new TemporalError(AddNotSupported);
        }

        /// <summary>
        /// Adding directly is not supported. Rather, add temporal points and
        /// generate the training data.
        /// </summary>
        /// <param name="inputData">Not used.</param>
        public override void Add(IMLDataPair inputData)
        {
            throw new TemporalError(AddNotSupported);
        }

        /// <summary>
        /// Adding directly is not supported. Rather, add temporal points and
        /// generate the training data.
        /// </summary>
        /// <param name="data">Not used.</param>
        public override void Add(IMLData data)
        {
            throw new TemporalError(AddNotSupported);
        }

        /// <summary>
        /// Create a temporal data point using a sequence number. They can also be
        /// created using time. No two points should have the same sequence number.
        /// </summary>
        /// <param name="sequence">The sequence number.</param>
        /// <returns>A new TemporalPoint object.</returns>
        public virtual TemporalPoint CreatePoint(int sequence)
        {
            var point = new TemporalPoint(_descriptions.Count) { Sequence = sequence };
            _points.Add(point);
            return point;
        }

        /// <summary>
        /// Create a sequence number from a time. The first date will be zero, and
        /// subsequent dates will be increased according to the grandularity
        /// specified. 
        /// </summary>
        /// <param name="when">The date to generate the sequence number for.</param>
        /// <returns>A sequence number.</returns>
        public virtual int GetSequenceFromDate(DateTime when)
        {
            int sequence;

            if (_startingPoint != DateTime.MinValue)
            {
                var span = new TimeSpanUtil(_startingPoint, when);
                sequence = (int)span.GetSpan(_sequenceGrandularity);
            }
            else
            {
                _startingPoint = when;
                sequence = 0;
            }

            return sequence;
        }


        /// <summary>
        /// Create a temporal point from a time. Using the grandularity each date is
        /// given a unique sequence number. No two dates that fall in the same
        /// grandularity should be specified.
        /// </summary>
        /// <param name="when">The time that this point should be created at.</param>
        /// <returns>The point TemporalPoint created.</returns>
        public virtual TemporalPoint CreatePoint(DateTime when)
        {
            int sequence = GetSequenceFromDate(when);
            var point = new TemporalPoint(_descriptions.Count) { Sequence = sequence };
            _points.Add(point);
            return point;
        }

        /// <summary>
        /// Calculate how many points are in the high and low range. These are the
        /// points that the training set will be generated on.
        /// </summary>
        /// <returns>The number of points.</returns>
        public virtual int CalculatePointsInRange()
        {
            return _points.Count(IsPointInRange);
        }

        /// <summary>
        /// Calculate the actual set size, this is the number of training set entries
        /// that will be generated.
        /// </summary>
        /// <returns>The size of the training set.</returns>
        public virtual int CalculateActualSetSize()
        {
            int result = CalculatePointsInRange();
            result = Math.Min(_desiredSetSize, result);
            return result;
        }

        /// <summary>
        /// Calculate how many input and output neurons will be needed for the
        /// current data.
        /// </summary>
        public virtual void CalculateNeuronCounts()
        {
            _inputNeuronCount = 0;
            _outputNeuronCount = 0;

            foreach (TemporalDataDescription desc in _descriptions)
            {
                if (desc.IsInput)
                {
                    _inputNeuronCount += _inputWindowSize;
                }
                if (desc.IsPredict)
                {
                    _outputNeuronCount += _predictWindowSize;
                }
            }
        }

        /// <summary>
        /// Is the specified point within the range. If a point is in the selection
        /// range, then the point will be used to generate the training sets.
        /// </summary>
        /// <param name="point">The point to consider.</param>
        /// <returns>True if the point is within the range.</returns>
        public virtual bool IsPointInRange(TemporalPoint point)
        {
            return ((point.Sequence >= LowSequence) && (point.Sequence <= HighSequence));
        }

        /// <summary>
        /// Generate input neural data for the specified index.
        /// </summary>
        /// <param name="index">The index to generate neural data for.</param>
        /// <returns>The input neural data generated.</returns>
        public virtual BasicNeuralData GenerateInputNeuralData(int index)
        {
            if (index + _inputWindowSize > _points.Count)
            {
                throw new TemporalError("Can't generate input temporal data "
                                        + "beyond the end of provided data.");
            }

            var result = new BasicNeuralData(_inputNeuronCount);
            int resultIndex = 0;

            for (int i = 0; i < _inputWindowSize; i++)
            {
                foreach (TemporalDataDescription desc in _descriptions)
                {
                    if (desc.IsInput)
                    {
                        result[resultIndex++] = FormatData(desc, index
                                                                 + i);
                    }
                }
            }
            return result;
        }

        /// <summary>
        /// Get data between two points in raw form.
        /// </summary>
        /// <param name="desc">The data description.</param>
        /// <param name="index">The index to get data from.</param>
        /// <returns>The requested data.</returns>
        private double GetDataRaw(TemporalDataDescription desc,
                                  int index)
        {
            TemporalPoint point = _points[index - 1];
            return point[desc.Index];
        }

        /// <summary>
        /// Get data between two points in delta form.
        /// </summary>
        /// <param name="desc">The data description.</param>
        /// <param name="index">The index to get data from.</param>
        /// <returns>The requested data.</returns>
        private double GetDataDeltaChange(TemporalDataDescription desc,
                                          int index)
        {
            if (index == 0)
            {
                return 0.0;
            }
            TemporalPoint point = _points[index];
            TemporalPoint previousPoint = _points[index - 1];
            return point[desc.Index]
                   - previousPoint[desc.Index];
        }


        /// <summary>
        /// Get data between two points in percent form.
        /// </summary>
        /// <param name="desc">The data description.</param>
        /// <param name="index">The index to get data from.</param>
        /// <returns>The requested data.</returns>
        private double GetDataPercentChange(TemporalDataDescription desc,
                                            int index)
        {
            if (index == 0)
            {
                return 0.0;
            }
            TemporalPoint point = _points[index];
            TemporalPoint previousPoint = _points[index - 1];
            double currentValue = point[desc.Index];
            double previousValue = previousPoint[desc.Index];
            return (currentValue - previousValue) / previousValue;
        }

        /// <summary>
        /// Format data according to the type specified in the description.
        /// </summary>
        /// <param name="desc">The data description.</param>
        /// <param name="index">The index to format the data at.</param>
        /// <returns>The formatted data.</returns>
        private double FormatData(TemporalDataDescription desc,
                                  int index)
        {
            var result = new double[1];

            switch (desc.DescriptionType)
            {
                case TemporalDataDescription.Type.DeltaChange:
                    result[0] = GetDataDeltaChange(desc, index);
                    break;
                case TemporalDataDescription.Type.PercentChange:
                    result[0] = GetDataPercentChange(desc, index);
                    break;
                case TemporalDataDescription.Type.Raw:
                    result[0] = GetDataRaw(desc, index);
                    break;
                default:
                    throw new TemporalError("Unsupported data type.");
            }

            if (desc.ActivationFunction != null)
            {
                desc.ActivationFunction.ActivationFunction(result, 0, 1);
            }

            return result[0];
        }

        /// <summary>
        /// Generate neural ideal data for the specified index.
        /// </summary>
        /// <param name="index">The index to generate for.</param>
        /// <returns>The neural data generated.</returns>
        public virtual BasicNeuralData GenerateOutputNeuralData(int index)
        {
            if (index + _predictWindowSize > _points.Count)
            {
                throw new TemporalError("Can't generate prediction temporal data "
                                        + "beyond the end of provided data.");
            }

            var result = new BasicNeuralData(_outputNeuronCount);
            int resultIndex = 0;

            for (int i = 0; i < _predictWindowSize; i++)
            {
                foreach (TemporalDataDescription desc in _descriptions)
                {
                    if (desc.IsPredict)
                    {
                        result[resultIndex++] = FormatData(desc, index
                                                                 + i);
                    }
                }
            }
            return result;
        }

        /// <summary>
        /// Calculate the index to start at.
        /// </summary>
        /// <returns>The starting point.</returns>
        public virtual int CalculateStartIndex()
        {
            for (int i = 0; i < _points.Count; i++)
            {
                TemporalPoint point = _points[i];
                if (IsPointInRange(point))
                {
                    return i;
                }
            }

            return -1;
        }

        /// <summary>
        /// Sort the points.
        /// </summary>
        public virtual void SortPoints()
        {
            _points.Sort();
        }

        /// <summary>
        /// Generate the training sets.
        /// </summary>
        public virtual void Generate()
        {
            //SortPoints();
            //int start = CalculateStartIndex() + 1;
            //int setSize = CalculateActualSetSize();
            //int range = start
            //            + (setSize - _predictWindowSize - _inputWindowSize);

            //for (int i = start; i < range; i++)
            //{
            //    BasicNeuralData input = GenerateInputNeuralData(i);
            //    BasicNeuralData ideal = GenerateOutputNeuralData(i
            //                                                     + _inputWindowSize);
            //    var pair = new BasicNeuralDataPair(input, ideal);
            //    base.Add(pair);
            //}
        }
    }

    public class TemporalPoint : IComparable<TemporalPoint>
    {
        /// <summary>
        /// The data for this point.
        /// </summary>
        private double[] _data;

        /// <summary>
        /// The sequence number for this point.
        /// </summary>
        private int _sequence;

        /// <summary>
        /// Construct a temporal point of the specified size.
        /// </summary>
        /// <param name="size">The size to create the temporal point for.</param>
        public TemporalPoint(int size)
        {
            _data = new double[size];
        }

        /// <summary>
        /// Allowes indexed access to the data.
        /// </summary>
        public double[] Data
        {
            get { return _data; }
            set { _data = value; }
        }

        /// <summary>
        /// The sequence number, used to sort.
        /// </summary>
        public int Sequence
        {
            get { return _sequence; }
            set { _sequence = value; }
        }

        /// <summary>
        /// Allowes indexed access to the data.
        /// </summary>
        /// <param name="x">The index.</param>
        /// <returns>The data at the specified index.</returns>
        public double this[int x]
        {
            get { return _data[x]; }
            set { _data[x] = value; }
        }

        #region IComparable<TemporalPoint> Members

        /// <summary>
        /// Compare two temporal points.
        /// </summary>
        /// <param name="that">The other temporal point to compare.</param>
        /// <returns>Returns 0 if they are equal, less than 0 if this point is less,
        /// greater than zero if this point is greater.</returns>
        public int CompareTo(TemporalPoint that)
        {
            if (Sequence == that.Sequence)
            {
                return 0;
            }
            if (Sequence < that.Sequence)
            {
                return -1;
            }
            return 1;
        }

        #endregion

        /**
         * Convert this point to string form.
         * @return This point as a string.
         */

        public override String ToString()
        {
            var builder = new StringBuilder("[TemporalPoint:");
            builder.Append("Seq:");
            builder.Append(_sequence);
            builder.Append(",Data:");
            for (int i = 0; i < _data.Length; i++)
            {
                if (i > 0)
                {
                    builder.Append(',');
                }
                builder.Append(_data[i]);
            }
            builder.Append("]");
            return builder.ToString();
        }
    }

    public class IMLDataError : SyntError
    {
       
        public IMLDataError(String str)
            : base(str)
        {
        }

       
        public IMLDataError(Exception e)
            : base(e)
        {
        }
    }

    public class MLDataError : SyntError
    {
        /// <summary>
        /// Construct a message exception.
        /// </summary>
        /// <param name="str">The message.</param>
        public MLDataError(String str)
            : base(str)
        {
        }

        /// <summary>
        /// Pass on an exception.
        /// </summary>
        /// <param name="e">The other exception.</param>
        public MLDataError(Exception e)
            : base(e)
        {
        }

        /// <summary>
        /// Pass on an exception.
        /// </summary>
        /// <param name="msg">The message.</param>
        /// <param name="e">The exception.</param>
        public MLDataError(String msg, Exception e)
            : base(msg, e)
        {
        }
    }

    public class BayesianFactory
    {
        /// <summary>
        /// Create a bayesian network.
        /// </summary>
        /// <param name="architecture">The architecture to use.</param>
        /// <param name="input">The input neuron count.</param>
        /// <param name="output">The output neuron count.</param>
        /// <returns>The new bayesian network.</returns>
        public IMLMethod Create(String architecture, int input,
                                int output)
        {
            var method = new BayesianNetwork { Contents = architecture };
            return method;
        }
    }

    public class FeedforwardFactory
    {
        /// <summary>
        /// Error.
        /// </summary>
        ///
        public const String CantDefineAct = "Can't define activation function before first layer.";

        /// <summary>
        /// The activation function factory to use.
        /// </summary>
        private MLActivationFactory _factory = new MLActivationFactory();

        /// <summary>
        /// Create a feed forward network.
        /// </summary>
        ///
        /// <param name="architecture">The architecture string to use.</param>
        /// <param name="input">The input count.</param>
        /// <param name="output">The output count.</param>
        /// <returns>The feedforward network.</returns>
        public IMLMethod Create(String architecture, int input,
                               int output)
        {
            var result = new BasicNetwork();
            IList<String> layers = ArchitectureParse.ParseLayers(architecture);
            IActivationFunction af = new ActivationLinear();

            int questionPhase = 0;

            foreach (String layerStr in layers)
            {
                // determine default
                int defaultCount = questionPhase == 0 ? input : output;

                ArchitectureLayer layer = ArchitectureParse.ParseLayer(
                    layerStr, defaultCount);
                bool bias = layer.Bias;

                String part = layer.Name;
                part = part != null ? part.Trim() : "";

                IActivationFunction lookup = _factory.Create(part);

                if (lookup != null)
                {
                    af = lookup;
                }
                else
                {
                    if (layer.UsedDefault)
                    {
                        questionPhase++;
                        if (questionPhase > 2)
                        {
                            throw new SyntError("Only two ?'s may be used.");
                        }
                    }

                    if (layer.Count == 0)
                    {
                        throw new SyntError("Unknown architecture element: "
                                             + architecture + ", can't parse: " + part);
                    }

                    result.AddLayer(new BasicLayer(af, bias, layer.Count));
                }
            }

            result.Structure.FinalizeStructure();
            result.Reset();

            return result;
        }
    }

    public class PNNFactory
    {
        /// <summary>
        /// The max layer count.
        /// </summary>
        ///
        public const int MaxLayers = 3;

        /// <summary>
        /// Create a PNN network.
        /// </summary>
        ///
        /// <param name="architecture">THe architecture string to use.</param>
        /// <param name="input">The input count.</param>
        /// <param name="output">The output count.</param>
        /// <returns>The RBF network.</returns>
        public IMLMethod Create(String architecture, int input,
                               int output)
        {
            IList<String> layers = ArchitectureParse.ParseLayers(architecture);
            if (layers.Count != MaxLayers)
            {
                throw new SyntError(
                    "PNN Networks must have exactly three elements, "
                    + "separated by ->.");
            }

            ArchitectureLayer inputLayer = ArchitectureParse.ParseLayer(
                layers[0], input);
            ArchitectureLayer pnnLayer = ArchitectureParse.ParseLayer(
                layers[1], -1);
            ArchitectureLayer outputLayer = ArchitectureParse.ParseLayer(
                layers[2], output);

            int inputCount = inputLayer.Count;
            int outputCount = outputLayer.Count;

            PNNKernelType kernel;
            PNNOutputMode outmodel;

            if (pnnLayer.Name.Equals("c", StringComparison.InvariantCultureIgnoreCase))
            {
                outmodel = PNNOutputMode.Classification;
            }
            else if (pnnLayer.Name.Equals("r", StringComparison.InvariantCultureIgnoreCase))
            {
                outmodel = PNNOutputMode.Regression;
            }
            else if (pnnLayer.Name.Equals("u", StringComparison.InvariantCultureIgnoreCase))
            {
                outmodel = PNNOutputMode.Unsupervised;
            }
            else
            {
                throw new NeuralNetworkError("Unknown model: " + pnnLayer.Name);
            }

            var holder = new ParamsHolder(pnnLayer.Params);

            String kernelStr = holder.GetString("KERNEL", false, "gaussian");

            if (kernelStr.Equals("gaussian", StringComparison.InvariantCultureIgnoreCase))
            {
                kernel = PNNKernelType.Gaussian;
            }
            else if (kernelStr.Equals("reciprocal", StringComparison.InvariantCultureIgnoreCase))
            {
                kernel = PNNKernelType.Reciprocal;
            }
            else
            {
                throw new NeuralNetworkError("Unknown kernel: " + kernelStr);
            }

            var result = new BasicPNN(kernel, outmodel, inputCount,
                                      outputCount);

            return result;
        }
    }

    public class RBFNetworkFactory
    {
        /// <summary>
        /// The max layer count.
        /// </summary>
        ///
        public const int MaxLayers = 3;

        /// <summary>
        /// Create a RBF network.
        /// </summary>
        ///
        /// <param name="architecture">THe architecture string to use.</param>
        /// <param name="input">The input count.</param>
        /// <param name="output">The output count.</param>
        /// <returns>The RBF network.</returns>
        public IMLMethod Create(String architecture, int input,
                               int output)
        {
            IList<String> layers = ArchitectureParse.ParseLayers(architecture);
            if (layers.Count != MaxLayers)
            {
                throw new SyntError(
                    "RBF Networks must have exactly three elements, "
                    + "separated by ->.");
            }

            ArchitectureLayer inputLayer = ArchitectureParse.ParseLayer(
                layers[0], input);
            ArchitectureLayer rbfLayer = ArchitectureParse.ParseLayer(
                layers[1], -1);
            ArchitectureLayer outputLayer = ArchitectureParse.ParseLayer(
                layers[2], output);

            int inputCount = inputLayer.Count;
            int outputCount = outputLayer.Count;

            RBFEnum t;

            if (rbfLayer.Name.Equals("Gaussian", StringComparison.InvariantCultureIgnoreCase))
            {
                t = RBFEnum.Gaussian;
            }
            else if (rbfLayer.Name.Equals("Multiquadric", StringComparison.InvariantCultureIgnoreCase))
            {
                t = RBFEnum.Multiquadric;
            }
            else if (rbfLayer.Name.Equals("InverseMultiquadric", StringComparison.InvariantCultureIgnoreCase))
            {
                t = RBFEnum.InverseMultiquadric;
            }
            else if (rbfLayer.Name.Equals("MexicanHat", StringComparison.InvariantCultureIgnoreCase))
            {
                t = RBFEnum.MexicanHat;
            }
            else
            {
                throw new NeuralNetworkError("Unknown RBF: " + rbfLayer.Name);
            }

            var holder = new ParamsHolder(rbfLayer.Params);

            int rbfCount = holder.GetInt("C", true, 0);

            var result = new RBFNetwork(inputCount, rbfCount,
                                        outputCount, t);

            return result;
        }
    }

    public class SOMFactory
    {
        /// <summary>
        /// Create a SOM.
        /// </summary>
        ///
        /// <param name="architecture">The architecture string.</param>
        /// <param name="input">The input count.</param>
        /// <param name="output">The output count.</param>
        /// <returns>The newly created SOM.</returns>
        public IMLMethod Create(String architecture, int input,
                               int output)
        {
            IList<String> layers = ArchitectureParse.ParseLayers(architecture);
            if (layers.Count != 2)
            {
                throw new SyntError(
                    "SOM's must have exactly two elements, separated by ->.");
            }

            ArchitectureLayer inputLayer = ArchitectureParse.ParseLayer(
                layers[0], input);
            ArchitectureLayer outputLayer = ArchitectureParse.ParseLayer(
                layers[1], output);

            int inputCount = inputLayer.Count;
            int outputCount = outputLayer.Count;

            var pattern = new SOMPattern { InputNeurons = inputCount, OutputNeurons = outputCount };
            return pattern.Generate();
        }
    }

    public class SRNFactory
    {
        /// <summary>
        /// The max layer count.
        /// </summary>
        ///
        public const int MaxLayers = 3;

        /// <summary>
        /// Create the SRN.
        /// </summary>
        ///
        /// <param name="architecture">The architecture string.</param>
        /// <param name="input">The input count.</param>
        /// <param name="output">The output count.</param>
        /// <returns>The newly created SRN.</returns>
        public IMLMethod Create(String architecture, int input,
                               int output)
        {
            IList<String> layers = ArchitectureParse.ParseLayers(architecture);
            if (layers.Count != MaxLayers)
            {
                throw new SyntError(
                    "SRN Networks must have exactly three elements, "
                    + "separated by ->.");
            }

            ArchitectureLayer inputLayer = ArchitectureParse.ParseLayer(
                layers[0], input);
            ArchitectureLayer rbfLayer = ArchitectureParse.ParseLayer(
                layers[1], -1);
            ArchitectureLayer outputLayer = ArchitectureParse.ParseLayer(
                layers[2], output);

            int inputCount = inputLayer.Count;
            int outputCount = outputLayer.Count;

            RBFEnum t;

            if (rbfLayer.Name.Equals("Gaussian", StringComparison.InvariantCultureIgnoreCase))
            {
                t = RBFEnum.Gaussian;
            }
            else if (rbfLayer.Name.Equals("Multiquadric", StringComparison.InvariantCultureIgnoreCase))
            {
                t = RBFEnum.Multiquadric;
            }
            else if (rbfLayer.Name.Equals("InverseMultiquadric", StringComparison.InvariantCultureIgnoreCase))
            {
                t = RBFEnum.InverseMultiquadric;
            }
            else if (rbfLayer.Name.Equals("MexicanHat", StringComparison.InvariantCultureIgnoreCase))
            {
                t = RBFEnum.MexicanHat;
            }
            else
            {
                t = RBFEnum.Gaussian;
            }

            var result = new RBFNetwork(inputCount,
                                        rbfLayer.Count, outputCount, t);

            return result;
        }
    }

    public class SVMFactory
    {
        /// <summary>
        /// The max layer count.
        /// </summary>
        ///
        public const int MAX_LAYERS = 3;

        /// <summary>
        /// Create the SVM.
        /// </summary>
        ///
        /// <param name="architecture">The architecture string.</param>
        /// <param name="input">The input count.</param>
        /// <param name="output">The output count.</param>
        /// <returns>The newly created SVM.</returns>
        public IMLMethod Create(String architecture, int input,
                               int output)
        {
            IList<String> layers = ArchitectureParse.ParseLayers(architecture);
            if (layers.Count != MAX_LAYERS)
            {
                throw new SyntError(
                    "SVM's must have exactly three elements, separated by ->.");
            }

            ArchitectureLayer inputLayer = ArchitectureParse.ParseLayer(
                layers[0], input);
            ArchitectureLayer paramsLayer = ArchitectureParse.ParseLayer(
                layers[1], input);
            ArchitectureLayer outputLayer = ArchitectureParse.ParseLayer(
                layers[2], output);

            String name = paramsLayer.Name;
            String kernelStr = paramsLayer.Params.ContainsKey("KERNEL") ? paramsLayer.Params["KERNEL"] : null;
            String svmTypeStr = paramsLayer.Params.ContainsKey("TYPE") ? paramsLayer.Params["TYPE"] : null;

            SVMType svmType = SVMType.NewSupportVectorClassification;
            KernelType kernelType = KernelType.RadialBasisFunction;

            bool useNew = true;

            if (svmTypeStr == null)
            {
                useNew = true;
            }
            else if (svmTypeStr.Equals("NEW", StringComparison.InvariantCultureIgnoreCase))
            {
                useNew = true;
            }
            else if (svmTypeStr.Equals("OLD", StringComparison.InvariantCultureIgnoreCase))
            {
                useNew = false;
            }
            else
            {
                throw new SyntError("Unsupported type: " + svmTypeStr
                                     + ", must be NEW or OLD.");
            }

            if (name.Equals("C", StringComparison.InvariantCultureIgnoreCase))
            {
                if (useNew)
                {
                    svmType = SVMType.NewSupportVectorClassification;
                }
                else
                {
                    svmType = SVMType.SupportVectorClassification;
                }
            }
            else if (name.Equals("R", StringComparison.InvariantCultureIgnoreCase))
            {
                if (useNew)
                {
                    svmType = SVMType.NewSupportVectorRegression;
                }
                else
                {
                    svmType = SVMType.EpsilonSupportVectorRegression;
                }
            }
            else
            {
                throw new SyntError("Unsupported mode: " + name
                                     + ", must be C for classify or R for regression.");
            }

            if (kernelStr == null)
            {
                kernelType = KernelType.RadialBasisFunction;
            }
            else if ("linear".Equals(kernelStr, StringComparison.InvariantCultureIgnoreCase))
            {
                kernelType = KernelType.Linear;
            }
            else if ("poly".Equals(kernelStr, StringComparison.InvariantCultureIgnoreCase))
            {
                kernelType = KernelType.Poly;
            }
            else if ("precomputed".Equals(kernelStr, StringComparison.InvariantCultureIgnoreCase))
            {
                kernelType = KernelType.Precomputed;
            }
            else if ("rbf".Equals(kernelStr, StringComparison.InvariantCultureIgnoreCase))
            {
                kernelType = KernelType.RadialBasisFunction;
            }
            else if ("sigmoid".Equals(kernelStr, StringComparison.InvariantCultureIgnoreCase))
            {
                kernelType = KernelType.Sigmoid;
            }
            else
            {
                throw new SyntError("Unsupported kernel: " + kernelStr
                                     + ", must be linear,poly,precomputed,rbf or sigmoid.");
            }

            int inputCount = inputLayer.Count;
            int outputCount = outputLayer.Count;

            if (outputCount != 1)
            {
                throw new SyntError("SVM can only have an output size of 1.");
            }

            var result = new SupportVectorMachine(inputCount, svmType, kernelType);

            return result;
        }
    }

    public class ArchitectureLayer
    {
        /// <summary>
        /// Holds any paramaters that were specified for the layer.
        /// </summary>
        ///
        private readonly IDictionary<String, String> _paras;

        /// <summary>
        /// Construct the object.
        /// </summary>
        public ArchitectureLayer()
        {
            _paras = new Dictionary<String, String>();
        }


        /// <value>the count to set</value>
        public int Count { get; set; }


        /// <value>the name to set</value>
        public String Name { get; set; }


        /// <value>the params</value>
        public IDictionary<String, String> Params
        {
            get { return _paras; }
        }


        /// <value>the bias to set</value>
        public bool Bias { get; set; }


        /// <value>the usedDefault to set</value>
        public bool UsedDefault { get; set; }
    }

    public static class ArchitectureParse
    {
        /// <summary>
        /// parse a layer.
        /// </summary>
        ///
        /// <param name="line">The line to parse.</param>
        /// <param name="defaultValue">The default value.</param>
        /// <returns>The parsed ArchitectureLayer.</returns>
        public static ArchitectureLayer ParseLayer(String line,
                                                   int defaultValue)
        {
            var layer = new ArchitectureLayer();

            String check = line.Trim().ToUpper();

            // first check for bias
            if (check.EndsWith(":B"))
            {
                check = check.Substring(0, (check.Length - 2) - (0));
                layer.Bias = true;
            }

            // see if simple number
            try
            {
                layer.Count = Int32.Parse(check);
                if (layer.Count < 0)
                {
                    throw new SyntError("Count cannot be less than zero.");
                }
            }
            catch (FormatException f)
            {
                SyntLogging.Log(f);
            }

            // see if it is a default
            if ("?".Equals(check))
            {
                if (defaultValue < 0)
                {
                    throw new SyntError("Default (?) in an invalid location.");
                }
                layer.Count = defaultValue;
                layer.UsedDefault = true;
                return layer;
            }

            // single item, no function
            int startIndex = check.IndexOf('(');
            int endIndex = check.LastIndexOf(')');
            if (startIndex == -1)
            {
                layer.Name = check;
                return layer;
            }

            // function
            if (endIndex == -1)
            {
                throw new SyntError("Illegal parentheses.");
            }

            layer.Name = check.Substring(0, (startIndex) - (0)).Trim();

            String paramStr = check.Substring(startIndex + 1, (endIndex) - (startIndex + 1));
            IDictionary<String, String> paras = ParseParams(paramStr);
            EngineArray.PutAll(paras, layer.Params);
            return layer;
        }

        /// <summary>
        /// Parse all layers from a line of text.
        /// </summary>
        ///
        /// <param name="line">The line of text.</param>
        /// <returns>A list of the parsed layers.</returns>
        public static IList<String> ParseLayers(String line)
        {
            IList<String> result = new List<String>();

            int bs = 0;
            bool done = false;

            do
            {
                String part;
                int index = line.IndexOf("->", bs);
                if (index != -1)
                {
                    part = line.Substring(bs, (index) - (bs)).Trim();
                    bs = index + 2;
                }
                else
                {
                    part = line.Substring(bs).Trim();
                    done = true;
                }

                bool bias = part.EndsWith("b");
                if (bias)
                {
                    part = part.Substring(0, (part.Length - 1) - (0));
                }

                result.Add(part);
            } while (!done);

            return result;
        }

        /// <summary>
        /// Parse a name.
        /// </summary>
        ///
        /// <param name="parser">The parser to use.</param>
        /// <returns>The name.</returns>
        private static String ParseName(SimpleParser parser)
        {
            var result = new StringBuilder();
            parser.EatWhiteSpace();
            while (parser.IsIdentifier())
            {
                result.Append(parser.ReadChar());
            }
            return result.ToString();
        }

        /// <summary>
        /// Parse parameters.
        /// </summary>
        ///
        /// <param name="line">The line to parse.</param>
        /// <returns>The parsed values.</returns>
        public static IDictionary<String, String> ParseParams(String line)
        {
            IDictionary<String, String> result = new Dictionary<String, String>();

            var parser = new SimpleParser(line);

            while (!parser.EOL())
            {
                String name = ParseName(parser)
                    .ToUpper();

                parser.EatWhiteSpace();
                if (!parser.LookAhead("=", false))
                {
                    throw new SyntError("Missing equals(=) operator.");
                }
                parser.Advance();

                String v = ParseValue(parser);

                result[name.ToUpper()] = v;

                if (!parser.ParseThroughComma())
                {
                    break;
                }
            }

            return result;
        }

        /// <summary>
        /// Parse a value.
        /// </summary>
        ///
        /// <param name="parser">The parser to use.</param>
        /// <returns>The newly parsed value.</returns>
        private static String ParseValue(SimpleParser parser)
        {
            bool quoted = false;
            var str = new StringBuilder();

            parser.EatWhiteSpace();

            if (parser.Peek() == '\"')
            {
                quoted = true;
                parser.Advance();
            }

            while (!parser.EOL())
            {
                if (parser.Peek() == '\"')
                {
                    if (quoted)
                    {
                        parser.Advance();
                        if (parser.Peek() == '\"')
                        {
                            str.Append(parser.ReadChar());
                        }
                        else
                        {
                            break;
                        }
                    }
                    else
                    {
                        str.Append(parser.ReadChar());
                    }
                }
                else if (!quoted
                         && (parser.IsWhiteSpace() || (parser.Peek() == ',')))
                {
                    break;
                }
                else
                {
                    str.Append(parser.ReadChar());
                }
            }
            return str.ToString();
        }
    }

    public class AnnealFactory
    {
        /// <summary>
        /// Create an annealing trainer.
        /// </summary>
        ///
        /// <param name="method">The method to use.</param>
        /// <param name="training">The training data to use.</param>
        /// <param name="argsStr">The arguments to use.</param>
        /// <returns>The newly created trainer.</returns>
        public IMLTrain Create(IMLMethod method,
                              IMLDataSet training, String argsStr)
        {
            if (!(method is BasicNetwork))
            {
                throw new TrainingError(
                    "Invalid method type, requires BasicNetwork");
            }

            ICalculateScore score = new TrainingSetScore(training);

            IDictionary<String, String> args = ArchitectureParse.ParseParams(argsStr);
            var holder = new ParamsHolder(args);
            double startTemp = holder.GetDouble(
                MLTrainFactory.PropertyTemperatureStart, false, 10);
            double stopTemp = holder.GetDouble(
                MLTrainFactory.PropertyTemperatureStop, false, 2);

            int cycles = holder.GetInt(MLTrainFactory.Cycles, false, 100);

            IMLTrain train = new NeuralSimulatedAnnealing(
                (BasicNetwork)method, score, startTemp, stopTemp, cycles);

            return train;
        }
    }

    public class BackPropFactory
    {
        /// <summary>
        /// Create a backProp trainer.
        /// </summary>
        ///
        /// <param name="method">The method to use.</param>
        /// <param name="training">The training data to use.</param>
        /// <param name="argsStr">The arguments to use.</param>
        /// <returns>The newly created trainer.</returns>
        public IMLTrain Create(IMLMethod method,
                              IMLDataSet training, String argsStr)
        {
            IDictionary<String, String> args = ArchitectureParse.ParseParams(argsStr);
            var holder = new ParamsHolder(args);

            double learningRate = holder.GetDouble(
                MLTrainFactory.PropertyLearningRate, false, 0.7d);
            double momentum = holder.GetDouble(
                MLTrainFactory.PropertyLearningMomentum, false, 0.3d);

            return new BackProp((BasicNetwork)method, training,
                                       learningRate, momentum);
        }
    }

    public class ClusterSOMFactory
    {
        /// <summary>
        /// Create a cluster SOM trainer.
        /// </summary>
        ///
        /// <param name="method">The method to use.</param>
        /// <param name="training">The training data to use.</param>
        /// <param name="argsStr">The arguments to use.</param>
        /// <returns>The newly created trainer.</returns>
        public IMLTrain Create(IMLMethod method,
                              IMLDataSet training, String argsStr)
        {
            if (!(method is SOMNetwork))
            {
                throw new SyntError(
                    "Cluster SOM training cannot be used on a method of type: "
                    + method.GetType().FullName);
            }

            return new SOMClusterCopyTraining((SOMNetwork)method, training);
        }
    }

    public class GFactory
    {
        /// <summary>
        /// Create an annealing trainer.
        /// </summary>
        ///
        /// <param name="method">The method to use.</param>
        /// <param name="training">The training data to use.</param>
        /// <param name="argsStr">The arguments to use.</param>
        /// <returns>The newly created trainer.</returns>
        public IMLTrain Create(IMLMethod method,
                              IMLDataSet training, String argsStr)
        {
            if (!(method is BasicNetwork))
            {
                throw new TrainingError(
                    "Invalid method type, requires BasicNetwork");
            }

            ICalculateScore score = new TrainingSetScore(training);

            IDictionary<String, String> args = ArchitectureParse.ParseParams(argsStr);
            var holder = new ParamsHolder(args);
            int populationSize = holder.GetInt(
                MLTrainFactory.PropertyPopulationSize, false, 5000);
            double mutation = holder.GetDouble(
                MLTrainFactory.PropertyMutation, false, 0.1d);
            double mate = holder.GetDouble(MLTrainFactory.PropertyMate,
                                           false, 0.25d);

            IMLTrain train = new NeuralGAlgo((BasicNetwork)method,
                                                       (IRandomizer)(new RangeRandomizer(-1, 1)), score, populationSize, mutation,
                                                       mate);

            return train;
        }
    }

    public class LMAFactory
    {
        /// <summary>
        /// Create a LMA trainer.
        /// </summary>
        ///
        /// <param name="method">The method to use.</param>
        /// <param name="training">The training data to use.</param>
        /// <param name="argsStr">The arguments to use.</param>
        /// <returns>The newly created trainer.</returns>
        public IMLTrain Create(IMLMethod method,
                              IMLDataSet training, String argsStr)
        {
            if (!(method is BasicNetwork))
            {
                throw new SyntError(
                    "LMA training cannot be used on a method of type: "
                    + method.GetType().FullName);
            }

            IDictionary<String, String> args = ArchitectureParse.ParseParams(argsStr);
            var holder = new ParamsHolder(args);

            var result = new LevenbergMarquardtTraining(
                (BasicNetwork)method, training);
            return result;
        }
    }

    public class ManhattanFactory
    {
        /// <summary>
        /// Create a Manhattan trainer.
        /// </summary>
        ///
        /// <param name="method">The method to use.</param>
        /// <param name="training">The training data to use.</param>
        /// <param name="argsStr">The arguments to use.</param>
        /// <returns>The newly created trainer.</returns>
        public IMLTrain Create(IMLMethod method,
                              IMLDataSet training, String argsStr)
        {
            IDictionary<String, String> args = ArchitectureParse.ParseParams(argsStr);
            var holder = new ParamsHolder(args);

            double learningRate = holder.GetDouble(
                MLTrainFactory.PropertyLearningRate, false, 0.1d);

            return new ManhattanProp((BasicNetwork)method, training,
                                            learningRate);
        }
    }

    public class NeighborhoodSOMFactory
    {
        /// <summary>
        /// Create a LMA trainer.
        /// </summary>
        ///
        /// <param name="method">The method to use.</param>
        /// <param name="training">The training data to use.</param>
        /// <param name="argsStr">The arguments to use.</param>
        /// <returns>The newly created trainer.</returns>
        public IMLTrain Create(IMLMethod method,
                              IMLDataSet training, String argsStr)
        {
            if (!(method is SOMNetwork))
            {
                throw new SyntError(
                    "Neighborhood training cannot be used on a method of type: "
                    + method.GetType().FullName);
            }

            IDictionary<String, String> args = ArchitectureParse.ParseParams(argsStr);
            var holder = new ParamsHolder(args);

            double learningRate = holder.GetDouble(
                MLTrainFactory.PropertyLearningRate, false, 0.7d);
            String neighborhoodStr = holder.GetString(
                MLTrainFactory.PropertyNeighborhood, false, "rbf");
            String rbfTypeStr = holder.GetString(
                MLTrainFactory.PropertyRBFType, false, "gaussian");

            RBFEnum t;

            if (rbfTypeStr.Equals("Gaussian", StringComparison.InvariantCultureIgnoreCase))
            {
                t = RBFEnum.Gaussian;
            }
            else if (rbfTypeStr.Equals("Multiquadric", StringComparison.InvariantCultureIgnoreCase))
            {
                t = RBFEnum.Multiquadric;
            }
            else if (rbfTypeStr.Equals("InverseMultiquadric", StringComparison.InvariantCultureIgnoreCase))
            {
                t = RBFEnum.InverseMultiquadric;
            }
            else if (rbfTypeStr.Equals("MexicanHat", StringComparison.InvariantCultureIgnoreCase))
            {
                t = RBFEnum.MexicanHat;
            }
            else
            {
                t = RBFEnum.Gaussian;
            }

            INeighborhoodFunction nf = null;

            if (neighborhoodStr.Equals("bubble", StringComparison.InvariantCultureIgnoreCase))
            {
                nf = new NeighborhoodBubble(1);
            }
            else if (neighborhoodStr.Equals("rbf", StringComparison.InvariantCultureIgnoreCase))
            {
                String str = holder.GetString(
                    MLTrainFactory.PropertyDimensions, true, null);
                int[] size = NumberList.FromListInt(CSVFormat.EgFormat, str);
                nf = new NeighborhoodRBF(size, t);
            }
            else if (neighborhoodStr.Equals("rbf1d", StringComparison.InvariantCultureIgnoreCase))
            {
                nf = new NeighborhoodRBF1D(t);
            }
            if (neighborhoodStr.Equals("single", StringComparison.InvariantCultureIgnoreCase))
            {
                nf = new NeighborhoodSingle();
            }

            var result = new BasicTrainSOM((SOMNetwork)method,
                                           learningRate, training, nf);

            if (args.ContainsKey(MLTrainFactory.PropertyIterations))
            {
                int plannedIterations = holder.GetInt(
                    MLTrainFactory.PropertyIterations, false, 1000);
                double startRate = holder.GetDouble(
                    MLTrainFactory.PropertyStartLearningRate, false, 0.05d);
                double endRate = holder.GetDouble(
                    MLTrainFactory.PropertyEndLearningRate, false, 0.05d);
                double startRadius = holder.GetDouble(
                    MLTrainFactory.PropertyStartRadius, false, 10);
                double endRadius = holder.GetDouble(
                    MLTrainFactory.PropertyEndRadius, false, 1);
                result.SetAutoDecay(plannedIterations, startRate, endRate,
                                    startRadius, endRadius);
            }

            return result;
        }
    }

    public class NelderMeadFactory
    {
        ///// <summary>
        ///// Create a Nelder Mead trainer.
        ///// </summary>
        ///// <param name="method">The method to use.</param>
        ///// <param name="training">The training data to use.</param>
        ///// <param name="argsStr">The arguments to use.</param>
        ///// <returns>The newly created trainer.</returns>
        public IMLTrain Create(IMLMethod method,
                IMLDataSet training, String argsStr)
        {

            IDictionary<String, String> args = ArchitectureParse.ParseParams(argsStr);
            var holder = new ParamsHolder(args);

            //final double learningRate = holder.getDouble(
            //		MLTrainFactory.PROPERTY_LEARNING_RATE, false, 0.1);

            return new NelderMeadTraining((BasicNetwork)method, training);
        }
    }

    public class PNNTrainFactory
    {
        /// <summary>
        /// Create a PNN trainer.
        /// </summary>
        ///
        /// <param name="method">The method to use.</param>
        /// <param name="training">The training data to use.</param>
        /// <param name="args">The arguments to use.</param>
        /// <returns>The newly created trainer.</returns>
        public IMLTrain Create(IMLMethod method,
                              IMLDataSet training, String args)
        {
            if (!(method is BasicPNN))
            {
                throw new SyntError(
                    "PNN training cannot be used on a method of type: "
                    + method.GetType().FullName);
            }

            return new TrainBasicPNN((BasicPNN)method, training);
        }
    }

    public class YTraining : GAlgo, IMLTrain
    {
        /// <summary>
        /// The number of inputs.
        /// </summary>
        private readonly int inputCount;

        /// <summary>
        /// The number of output neurons.
        /// </summary>
        private readonly int outputCount;

        /// <summary>
        /// The average fit adjustment.
        /// </summary>
        private double averageFitAdjustment;

        /// <summary>
        /// The best ever network.
        /// </summary>
        private YNetwork bestEverNetwork;

        /// <summary>
        /// The best ever score.
        /// </summary>
        private double bestEverScore;

        /// <summary>
        /// The iteration number.
        /// </summary>
        private int iteration;

        /// <summary>
        /// The activation mutation rate.
        /// </summary>
        private double paramActivationMutationRate = 0.1;

        /// <summary>
        /// The likelyhood of adding a link.
        /// </summary>
        private double paramChanceAddLink = 0.07;

        /// <summary>
        /// The likelyhood of adding a node.
        /// </summary>
        private double paramChanceAddNode = 0.04;

        /// <summary>
        /// The likelyhood of adding a recurrent link.
        /// </summary>
        private double paramChanceAddRecurrentLink = 0.05;

        /// <summary>
        /// The compatibility threshold for a species.
        /// </summary>
        private double paramCompatibilityThreshold = 0.26;

        /// <summary>
        /// The crossover rate.
        /// </summary>
        private double paramCrossoverRate = 0.7;

        /// <summary>
        /// The max activation perturbation.
        /// </summary>
        private double paramMaxActivationPerturbation = 0.1;

        /// <summary>
        /// The maximum number of species.
        /// </summary>
        private int paramMaxNumberOfSpecies;

        /// <summary>
        /// The maximum number of neurons.
        /// </summary>
        private double paramMaxPermittedNeurons = 100;

        /// <summary>
        /// The maximum weight perturbation.
        /// </summary>
        private double paramMaxWeightPerturbation = 0.5;

        /// <summary>
        /// The mutation rate.
        /// </summary>
        private double paramMutationRate = 0.2;

        /// <summary>
        /// The number of link add attempts.
        /// </summary>
        private int paramNumAddLinkAttempts = 5;

        /// <summary>
        /// The number of generations allowed with no improvement.
        /// </summary>
        private int paramNumGensAllowedNoImprovement = 15;

        /// <summary>
        /// The number of tries to find a looped link.
        /// </summary>
        private int paramNumTrysToFindLoopedLink = 5;

        /// <summary>
        /// The number of tries to find an old link.
        /// </summary>
        private int paramNumTrysToFindOldLink = 5;

        /// <summary>
        /// The probability that the weight will be totally replaced.
        /// </summary>
        private double paramProbabilityWeightReplaced = 0.1;

        /// <summary>
        /// Determines if we are using snapshot mode.
        /// </summary>
        private bool snapshot;

        /// <summary>
        /// The total fit adjustment.
        /// </summary>
        private double totalFitAdjustment;

        /// <summary>
        /// Construct a Y trainer with a new population. The new population is
        /// created from the specified parameters.
        /// </summary>
        /// <param name="calculateScore">The score calculation object.</param>
        /// <param name="inputCount">The input neuron count.</param>
        /// <param name="outputCount">The output neuron count.</param>
        /// <param name="populationSize">The population size.</param>
        public YTraining(ICalculateScore calculateScore,
                            int inputCount, int outputCount,
                            int populationSize)
        {
            this.inputCount = inputCount;
            this.outputCount = outputCount;

            CalculateScore = new GScoreAdapter(calculateScore);
            Comparator = new TComparator(CalculateScore);
            Population = new YPopulation(inputCount, outputCount,
                                            populationSize);

            Init();
        }

        /// <summary>
        /// Construct Y training with an existing population.
        /// </summary>
        /// <param name="calculateScore">The score object to use.</param>
        /// <param name="population">The population to use.</param>
        public YTraining(ICalculateScore calculateScore,
                            IPopulation population)
        {
            if (population.Size() < 1)
            {
                throw new TrainingError("Population can not be empty.");
            }

            var T = (YT)population.Ts[0];
            CalculateScore = new GScoreAdapter(calculateScore);
            Comparator = new TComparator(CalculateScore);
            Population = (population);
            inputCount = T.InputCount;
            outputCount = T.OutputCount;

            Init();
        }

        /// <summary>
        /// The innovations.
        /// </summary>
        public YInnovationList Innovations
        {
            get { return (YInnovationList)Population.Innovations; }
        }

        /// <summary>
        /// The input count.
        /// </summary>
        public int InputCount
        {
            get { return inputCount; }
        }

        /// <summary>
        /// The number of output neurons.
        /// </summary>
        public int OutputCount
        {
            get { return outputCount; }
        }

        /// <summary>
        /// Set the activation mutation rate.
        /// </summary>
        public double ParamActivationMutationRate
        {
            get { return paramActivationMutationRate; }
            set { paramActivationMutationRate = value; }
        }


        /// <summary>
        /// Set the chance to add a link.
        /// </summary>
        public double ParamChanceAddLink
        {
            get { return paramChanceAddLink; }
            set { paramChanceAddLink = value; }
        }


        /// <summary>
        /// Set the chance to add a node.
        /// </summary>
        public double ParamChanceAddNode
        {
            get { return paramChanceAddNode; }
            set { paramChanceAddNode = value; }
        }

        /// <summary>
        /// Set the chance to add a recurrent link.
        /// </summary>
        public double ParamChanceAddRecurrentLink
        {
            get { return paramChanceAddRecurrentLink; }
            set { paramChanceAddRecurrentLink = value; }
        }


        /// <summary>
        /// Set the compatibility threshold for species.
        /// </summary>
        public double ParamCompatibilityThreshold
        {
            get { return paramCompatibilityThreshold; }
            set { paramCompatibilityThreshold = value; }
        }


        /// <summary>
        /// Set the cross over rate.
        /// </summary>
        public double ParamCrossoverRate
        {
            get { return paramCrossoverRate; }
            set { paramCrossoverRate = value; }
        }


        /// <summary>
        /// Set the max activation perturbation.
        /// </summary>
        public double ParamMaxActivationPerturbation
        {
            get { return paramMaxActivationPerturbation; }
            set { paramMaxActivationPerturbation = value; }
        }

        /// <summary>
        /// Set the maximum number of species.
        /// </summary>
        public int ParamMaxNumberOfSpecies
        {
            get { return paramMaxNumberOfSpecies; }
            set { paramMaxNumberOfSpecies = value; }
        }

        /// <summary>
        /// Set the max permitted neurons.
        /// </summary>
        public double ParamMaxPermittedNeurons
        {
            get { return paramMaxPermittedNeurons; }
            set { paramMaxPermittedNeurons = value; }
        }

        /// <summary>
        /// Set the max weight perturbation.
        /// </summary>
        public double ParamMaxWeightPerturbation
        {
            get { return paramMaxWeightPerturbation; }
            set { paramMaxWeightPerturbation = value; }
        }

        /// <summary>
        /// Set the mutation rate.
        /// </summary>
        public double ParamMutationRate
        {
            get { return paramMutationRate; }
            set { paramMutationRate = value; }
        }

        /// <summary>
        /// Set the number of attempts to add a link.
        /// </summary>
        public int ParamNumAddLinkAttempts
        {
            get { return paramNumAddLinkAttempts; }
            set { paramNumAddLinkAttempts = value; }
        }

        /// <summary>
        /// Set the number of no-improvement generations allowed.
        /// </summary>
        public int ParamNumGensAllowedNoImprovement
        {
            get { return paramNumGensAllowedNoImprovement; }
            set { paramNumGensAllowedNoImprovement = value; }
        }

        /// <summary>
        /// Set the number of tries to create a looped link.
        /// </summary>
        public int ParamNumTrysToFindLoopedLink
        {
            get { return paramNumTrysToFindLoopedLink; }
            set { paramNumTrysToFindLoopedLink = value; }
        }


        /// <summary>
        /// Set the number of tries to try an old link.
        /// </summary>
        public int ParamNumTrysToFindOldLink
        {
            get { return paramNumTrysToFindOldLink; }
            set { paramNumTrysToFindOldLink = value; }
        }


        /// <summary>
        /// Set the probability to replace a weight.
        /// </summary>
        public double ParamProbabilityWeightReplaced
        {
            get { return paramProbabilityWeightReplaced; }
            set { paramProbabilityWeightReplaced = value; }
        }

        /// <summary>
        /// Set if we are using snapshot mode.
        /// </summary>
        public bool Snapshot
        {
            get { return snapshot; }
            set { snapshot = value; }
        }

        #region MLTrain Members

        /// <inheritdoc/>
        public void AddStrategy(IStrategy strategy)
        {
            throw new TrainingError(
                "Strategies are not supported by this training method.");
        }

        /// <inheritdoc/>
        public bool CanContinue
        {
            get { return false; }
        }

        /// <inheritdoc/>
        public void FinishTraining()
        {
        }

        /// <summary>
        /// The error for the best T.
        /// </summary>
        public double Error
        {
            get { return bestEverScore; }
            set { bestEverScore = value; }
        }

        /// <inheritdoc/>
        public TrainingImplementationType ImplementationType
        {
            get { return TrainingImplementationType.Iterative; }
        }

        /// <inheritdoc/>
        public int IterationNumber
        {
            get { return iteration; }
            set { iteration = value; }
        }

        /// <summary>
        /// A network created for the best T.
        /// </summary>
        public IMLMethod Method
        {
            get { return bestEverNetwork; }
        }

        /// <inheritdoc/>
        public IList<IStrategy> Strategies
        {
            get { return new List<IStrategy>(); }
        }

        /// <summary>
        /// Returns null, does not use a training set, rather uses a score function.
        /// </summary>
        public IMLDataSet Training
        {
            get { return null; }
        }

        /// <inheritdoc/>
        public bool TrainingDone
        {
            get { return false; }
        }

        /// <summary>
        /// Perform one training iteration.
        /// </summary>
        public override void Iteration()
        {
            iteration++;
            IList<YT> newPop = new List<YT>();

            int numSpawnedSoFar = 0;

            foreach (ISpecies s in Population.Species)
            {
                if (numSpawnedSoFar < Population.Size())
                {
                    var numToSpawn = (int)Math.Round(s.NumToSpawn);

                    bool bChosenBestYet = false;

                    while ((numToSpawn--) > 0)
                    {
                        YT baby = null;

                        if (!bChosenBestYet)
                        {
                            baby = (YT)s.Leader;

                            bChosenBestYet = true;
                        }

                        else
                        {
                            // if the number of individuals in this species is only
                            // one
                            // then we can only perform mutation
                            if (s.Members.Count == 1)
                            {
                                // spawn a child
                                baby = new YT((YT)s.ChooseParent());
                            }
                            else
                            {
                                var g1 = (YT)s.ChooseParent();

                                if (ThreadSafeRandom.NextDouble() < paramCrossoverRate)
                                {
                                    var g2 = (YT)s.ChooseParent();

                                    int numAttempts = 5;

                                    while ((g1.TID == g2.TID)
                                           && ((numAttempts--) > 0))
                                    {
                                        g2 = (YT)s.ChooseParent();
                                    }

                                    if (g1.TID != g2.TID)
                                    {
                                        baby = Crossover(g1, g2);
                                    }
                                }

                                else
                                {
                                    baby = new YT(g1);
                                }
                            }

                            if (baby != null)
                            {
                                baby.TID = Population.AssignTID();

                                if (baby.Neurons.Size() < paramMaxPermittedNeurons)
                                {
                                    baby.AddNeuron(paramChanceAddNode,
                                                   paramNumTrysToFindOldLink);
                                }

                                // now there's the chance a link may be added
                                baby.AddLink(paramChanceAddLink,
                                             paramChanceAddRecurrentLink,
                                             paramNumTrysToFindLoopedLink,
                                             paramNumAddLinkAttempts);

                                // mutate the weights
                                baby.MutateWeights(paramMutationRate,
                                                   paramProbabilityWeightReplaced,
                                                   paramMaxWeightPerturbation);

                                baby.MutateActivationResponse(
                                    paramActivationMutationRate,
                                    paramMaxActivationPerturbation);
                            }
                        }

                        if (baby != null)
                        {
                            // sort the baby's genes by their innovation numbers
                            baby.SortGenes();

                            // add to new pop
                            // if (newPop.contains(baby)) {
                            // throw new SyntError("readd");
                            // }
                            newPop.Add(baby);

                            ++numSpawnedSoFar;

                            if (numSpawnedSoFar == Population.Size())
                            {
                                numToSpawn = 0;
                            }
                        }
                    }
                }
            }

            while (newPop.Count < Population.Size())
            {
                newPop.Add(TournamentSelection(Population.Size() / 5));
            }

            Population.Clear();
            foreach (YT T in newPop)
            {
                Population.Add(T);
            }

            ResetAndKill();
            SortAndRecord();
            SpeciateAndCalculateSpawnLevels();
        }

        /// <inheritdoc/>
        public void Iteration(int count)
        {
            for (int i = 0; i < count; i++)
            {
                Iteration();
            }
        }

        /// <inheritdoc/>
        public TrainingContinuation Pause()
        {
            return null;
        }

        /// <inheritdoc/>
        public void Resume(TrainingContinuation state)
        {
        }

        #endregion

        /// <summary>
        /// Add the specified neuron id.
        /// </summary>
        /// <param name="nodeID">The neuron to add.</param>
        /// <param name="vec">The list to add to.</param>
        public void AddNeuronID(long nodeID, IList<long> vec)
        {
            for (int i = 0; i < vec.Count; i++)
            {
                if (vec[i] == nodeID)
                {
                    return;
                }
            }

            vec.Add(nodeID);

            return;
        }

        /// <summary>
        /// Adjust the compatibility threshold.
        /// </summary>
        public void AdjustCompatibilityThreshold()
        {
            // has this been disabled (unlimited species)
            if (paramMaxNumberOfSpecies < 1)
            {
                return;
            }

            double thresholdIncrement = 0.01;

            if (Population.Species.Count > paramMaxNumberOfSpecies)
            {
                paramCompatibilityThreshold += thresholdIncrement;
            }

            else if (Population.Species.Count < 2)
            {
                paramCompatibilityThreshold -= thresholdIncrement;
            }
        }

        /// <summary>
        /// Adjust each species score.
        /// </summary>
        public void AdjustSpeciesScore()
        {
            foreach (ISpecies s in Population.Species)
            {
                // loop over all Ts and adjust scores as needed
                foreach (IT member in s.Members)
                {
                    double score = member.Score;

                    // apply a youth bonus
                    if (s.Age < Population.YoungBonusAgeThreshold)
                    {
                        score = Comparator.ApplyBonus(score,
                                                      Population.YoungScoreBonus);
                    }

                    // apply an old age penalty
                    if (s.Age > Population.OldAgeThreshold)
                    {
                        score = Comparator.ApplyPenalty(score,
                                                        Population.OldAgePenalty);
                    }

                    double adjustedScore = score / s.Members.Count;

                    member.AdjustedScore = adjustedScore;
                }
            }
        }

        /// <summary>
        /// Perform a cross over.  
        /// </summary>
        /// <param name="mom">The mother T.</param>
        /// <param name="dad">The father T.</param>
        /// <returns></returns>
        public new YT Crossover(YT mom, YT dad)
        {
            YParent best;

            // first determine who is more fit, the mother or the father?
            if (mom.Score == dad.Score)
            {
                if (mom.NumGenes == dad.NumGenes)
                {
                    if (ThreadSafeRandom.NextDouble() > 0)
                    {
                        best = YParent.Mom;
                    }
                    else
                    {
                        best = YParent.Dad;
                    }
                }

                else
                {
                    if (mom.NumGenes < dad.NumGenes)
                    {
                        best = YParent.Mom;
                    }
                    else
                    {
                        best = YParent.Dad;
                    }
                }
            }
            else
            {
                if (Comparator.IsBetterThan(mom.Score, dad.Score))
                {
                    best = YParent.Mom;
                }

                else
                {
                    best = YParent.Dad;
                }
            }

            var babyNeurons = new Q();
            var babyGenes = new Q();

            var vecNeurons = new List<long>();

            int curMom = 0;
            int curDad = 0;

            YLinkGene momGene;
            YLinkGene dadGene;

            YLinkGene selectedGene = null;

            while ((curMom < mom.NumGenes) || (curDad < dad.NumGenes))
            {
                if (curMom < mom.NumGenes)
                {
                    momGene = (YLinkGene)mom.Links.Get(curMom);
                }
                else
                {
                    momGene = null;
                }

                if (curDad < dad.NumGenes)
                {
                    dadGene = (YLinkGene)dad.Links.Get(curDad);
                }
                else
                {
                    dadGene = null;
                }

                if ((momGene == null) && (dadGene != null))
                {
                    if (best == YParent.Dad)
                    {
                        selectedGene = dadGene;
                    }
                    curDad++;
                }
                else if ((dadGene == null) && (momGene != null))
                {
                    if (best == YParent.Mom)
                    {
                        selectedGene = momGene;
                    }
                    curMom++;
                }
                else if (momGene.InnovationId < dadGene.InnovationId)
                {
                    if (best == YParent.Mom)
                    {
                        selectedGene = momGene;
                    }
                    curMom++;
                }
                else if (dadGene.InnovationId < momGene.InnovationId)
                {
                    if (best == YParent.Dad)
                    {
                        selectedGene = dadGene;
                    }
                    curDad++;
                }
                else if (dadGene.InnovationId == momGene.InnovationId)
                {
                    if (ThreadSafeRandom.NextDouble() < 0.5f)
                    {
                        selectedGene = momGene;
                    }

                    else
                    {
                        selectedGene = dadGene;
                    }
                    curMom++;
                    curDad++;
                }

                if (babyGenes.Size() == 0)
                {
                    babyGenes.Add(selectedGene);
                }

                else
                {
                    if (((YLinkGene)babyGenes.Get(babyGenes.Size() - 1))
                            .InnovationId != selectedGene.InnovationId)
                    {
                        babyGenes.Add(selectedGene);
                    }
                }

                // Check if we already have the nodes referred to in SelectedGene.
                // If not, they need to be added.
                AddNeuronID(selectedGene.FromNeuronID, vecNeurons);
                AddNeuronID(selectedGene.ToNeuronID, vecNeurons);
            } // end while

            // now create the required nodes. First sort them into order
            vecNeurons.Sort();

            for (int i = 0; i < vecNeurons.Count; i++)
            {
                babyNeurons.Add(Innovations.CreateNeuronFromID(
                    vecNeurons[i]));
            }

            // finally, create the T
            var babyT = new YT(Population
                                                .AssignTID(), babyNeurons, babyGenes, mom.InputCount,
                                            mom.OutputCount);
            babyT.GA = this;
            babyT.Population = Population;

            return babyT;
        }

        /// <summary>
        /// Init the training.
        /// </summary>
        private void Init()
        {
            if (CalculateScore.ShouldMinimize)
            {
                bestEverScore = Double.MaxValue;
            }
            else
            {
                bestEverScore = Double.MinValue;
            }

            // check the population
            foreach (IT obj in Population.Ts)
            {
                if (!(obj is YT))
                {
                    throw new TrainingError(
                        "Population can only contain objects of YT.");
                }

                var Y = (YT)obj;

                if ((Y.InputCount != inputCount)
                    || (Y.OutputCount != outputCount))
                {
                    throw new TrainingError(
                        "All YT's must have the same input and output sizes as the base network.");
                }
                Y.GA = this;
            }

            Population.Claim(this);

            ResetAndKill();
            SortAndRecord();
            SpeciateAndCalculateSpawnLevels();
        }

        /// <summary>
        /// Reset counts and kill Ts with worse scores.
        /// </summary>
        public void ResetAndKill()
        {
            totalFitAdjustment = 0;
            averageFitAdjustment = 0;

            var speciesArray = new ISpecies[Population.Species.Count];

            for (int i = 0; i < Population.Species.Count; i++)
            {
                speciesArray[i] = Population.Species[i];
            }

            foreach (Object element in speciesArray)
            {
                var s = (ISpecies)element;
                s.Purge();

                if ((s.GensNoImprovement > paramNumGensAllowedNoImprovement)
                    && Comparator.IsBetterThan(bestEverScore,
                                               s.BestScore))
                {
                    Population.Species.Remove(s);
                }
            }
        }

        /// <summary>
        /// Sort the Ts.
        /// </summary>
        public void SortAndRecord()
        {
            foreach (IT g in Population.Ts)
            {
                g.Decode();
                PerformCalculateScore(g);
            }

            Population.Sort();

            IT T = Population.Best;
            double currentBest = T.Score;

            if (Comparator.IsBetterThan(currentBest, bestEverScore))
            {
                bestEverScore = currentBest;
                bestEverNetwork = ((YNetwork)T.Organism);
            }

            bestEverScore = Comparator.BestScore(Error,
                                                 bestEverScore);
        }

        /// <summary>
        /// Determine the species.
        /// </summary>
        public void SpeciateAndCalculateSpawnLevels()
        {
            // calculate compatibility between Ts and species
            AdjustCompatibilityThreshold();

            // assign Ts to species (if any exist)
            foreach (IT g in Population.Ts)
            {
                var T = (YT)g;
                bool added = false;

                foreach (ISpecies s in Population.Species)
                {
                    double compatibility = T.GetCompatibilityScore((YT)s.Leader);

                    if (compatibility <= paramCompatibilityThreshold)
                    {
                        AddSpeciesMember(s, T);
                        T.SpeciesID = s.SpeciesID;
                        added = true;
                        break;
                    }
                }

                // if this T did not fall into any existing species, create a
                // new species
                if (!added)
                {
                    Population.Species.Add(
                        new BasicSpecies(Population, T,
                                         Population.AssignSpeciesID()));
                }
            }

            AdjustSpeciesScore();

            foreach (IT g in Population.Ts)
            {
                var T = (YT)g;
                totalFitAdjustment += T.AdjustedScore;
            }

            averageFitAdjustment = totalFitAdjustment
                                   / Population.Size();

            foreach (IT g in Population.Ts)
            {
                var T = (YT)g;
                double toSpawn = T.AdjustedScore
                                 / averageFitAdjustment;
                T.AmountToSpawn = toSpawn;
            }

            foreach (ISpecies species in Population.Species)
            {
                species.CalculateSpawnAmount();
            }
        }

        /// <summary>
        /// Select a gene using a tournament.
        /// </summary>
        /// <param name="numComparisons">The number of compares to do.</param>
        /// <returns>The chosen T.</returns>
        public YT TournamentSelection(int numComparisons)
        {
            double bestScoreSoFar = 0;

            int chosenOne = 0;

            for (int i = 0; i < numComparisons; ++i)
            {
                var thisTry = (int)RangeRandomizer.Randomize(0, Population.Size() - 1);

                if (Population.Get(thisTry).Score > bestScoreSoFar)
                {
                    chosenOne = thisTry;

                    bestScoreSoFar = Population.Get(thisTry).Score;
                }
            }

            return (YT)Population.Get(chosenOne);
        }
    }

    public class PSOFactory
    {
        /// <summary>
        /// Create a PSO trainer.
        /// </summary>
        /// <param name="method">The method to use.</param>
        /// <param name="training">The training data to use.</param>
        /// <param name="argsStr">The arguments to use.</param>
        /// <returns>The newly created trainer.</returns>
        public IMLTrain Create(IMLMethod method,
                IMLDataSet training, String argsStr)
        {

            IDictionary<String, String> args = ArchitectureParse.ParseParams(argsStr);
            ParamsHolder holder = new ParamsHolder(args);

            int particles = holder.GetInt(
                    MLTrainFactory.PropertyParticles, false, 20);

            ICalculateScore score = new TrainingSetScore(training);
            IRandomizer randomizer =(IRandomizer)( new NguyenWidrowRandomizer());

            IMLTrain train = new NeuralPSO((BasicNetwork)method, randomizer, score, particles);

            return train;
        }
    }

    public class QuickPropFactory
    {
        /// <summary>
        /// Create a quick Prop trainer.
        /// </summary>
        /// <param name="method">The method to use.</param>
        /// <param name="training">The training data to use.</param>
        /// <param name="argsStr">The arguments to use.</param>
        /// <returns>The newly created trainer.</returns>
        public IMLTrain Create(IMLMethod method,
                               IMLDataSet training, String argsStr)
        {
            IDictionary<String, String> args = ArchitectureParse.ParseParams(argsStr);
            var holder = new ParamsHolder(args);

            double learningRate = holder.GetDouble(
                MLTrainFactory.PropertyLearningRate, false, 2.0);

            return new QuickProp((BasicNetwork)method, training, learningRate);
        }
    }

    public class RBFSVDFactory
    {
        /// <summary>
        /// Create a RBF-SVD trainer.
        /// </summary>
        ///
        /// <param name="method">The method to use.</param>
        /// <param name="training">The training data to use.</param>
        /// <param name="args">The arguments to use.</param>
        /// <returns>The newly created trainer.</returns>
        public IMLTrain Create(IMLMethod method,
                              IMLDataSet training, String args)
        {
            if (!(method is RBFNetwork))
            {
                throw new SyntError(
                    "RBF-SVD training cannot be used on a method of type: "
                    + method.GetType().FullName);
            }

            return new SVDTraining((RBFNetwork)method, training);
        }
    }

    public class RPROPFactory
    {
        /// <summary>
        /// Create a RPROP trainer.
        /// </summary>
        ///
        /// <param name="method">The method to use.</param>
        /// <param name="training">The training data to use.</param>
        /// <param name="argsStr">The arguments to use.</param>
        /// <returns>The newly created trainer.</returns>
        public IMLTrain Create(IMLMethod method,
                              IMLDataSet training, String argsStr)
        {
            if (!(method is IContainsFlat))
            {
                throw new SyntError(
                    "RPROP training cannot be used on a method of type: "
                    + method.GetType().FullName);
            }

            IDictionary<String, String> args = ArchitectureParse.ParseParams(argsStr);
            var holder = new ParamsHolder(args);
            double initialUpdate = holder.GetDouble(
                MLTrainFactory.PropertyInitialUpdate, false,
                RPROPConst.DefaultInitialUpdate);
            double maxStep = holder.GetDouble(
                MLTrainFactory.PropertyMaxStep, false,
                RPROPConst.DefaultMaxStep);

            return new ResilientProp((IContainsFlat)method, training,
                                            initialUpdate, maxStep);
        }
    }

    public class SVMSearchFactory
    {
        /// <summary>
        /// Property for gamma.
        /// </summary>
        ///
        public const String PropertyGamma1 = "GAMMA1";

        /// <summary>
        /// Property for constant.
        /// </summary>
        ///
        public const String PropertyC1 = "C1";

        /// <summary>
        /// Property for gamma.
        /// </summary>
        ///
        public const String PropertyGamma2 = "GAMMA2";

        /// <summary>
        /// Property for constant.
        /// </summary>
        ///
        public const String PropertyC2 = "C2";

        /// <summary>
        /// Property for gamma.
        /// </summary>
        ///
        public const String PropertyGammaStep = "GAMMASTEP";

        /// <summary>
        /// Property for constant.
        /// </summary>
        ///
        public const String PropertyCStep = "CSTEP";

        /// <summary>
        /// Create a SVM trainer.
        /// </summary>
        ///
        /// <param name="method">The method to use.</param>
        /// <param name="training">The training data to use.</param>
        /// <param name="argsStr">The arguments to use.</param>
        /// <returns>The newly created trainer.</returns>
        public IMLTrain Create(IMLMethod method,
                              IMLDataSet training, String argsStr)
        {
            if (!(method is SupportVectorMachine))
            {
                throw new SyntError(
                    "SVM Train training cannot be used on a method of type: "
                    + method.GetType().FullName);
            }

            IDictionary<String, String> args = ArchitectureParse.ParseParams(argsStr);
            new ParamsHolder(args);

            var holder = new ParamsHolder(args);
            double gammaStart = holder.GetDouble(
                PropertyGamma1, false,
                SVMSearchTrain.DefaultGammaBegin);
            double cStart = holder.GetDouble(PropertyC1,
                                             false, SVMSearchTrain.DefaultConstBegin);
            double gammaStop = holder.GetDouble(
                PropertyGamma2, false,
                SVMSearchTrain.DefaultGammaEnd);
            double cStop = holder.GetDouble(PropertyC2,
                                            false, SVMSearchTrain.DefaultConstEnd);
            double gammaStep = holder.GetDouble(
                PropertyGammaStep, false,
                SVMSearchTrain.DefaultGammaStep);
            double cStep = holder.GetDouble(PropertyCStep,
                                            false, SVMSearchTrain.DefaultConstStep);

            var result = new SVMSearchTrain((SupportVectorMachine)method, training)
            {
                GammaBegin = gammaStart,
                GammaEnd = gammaStop,
                GammaStep = gammaStep,
                ConstBegin = cStart,
                ConstEnd = cStop,
                ConstStep = cStep
            };

            return result;
        }
    }

    public class SVMTrain : BasicTraining
    {
        /// <summary>
        /// The default starting number for C.
        /// </summary>
        ///
        public const double DefaultConstBegin = -5;

        /// <summary>
        /// The default ending number for C.
        /// </summary>
        ///
        public const double DefaultConstEnd = 15;

        /// <summary>
        /// The default step for C.
        /// </summary>
        ///
        public const double DefaultConstStep = 2;

        /// <summary>
        /// The default gamma begin.
        /// </summary>
        ///
        public const double DefaultGammaBegin = -10;

        /// <summary>
        /// The default gamma end.
        /// </summary>
        ///
        public const double DefaultGammaEnd = 10;

        /// <summary>
        /// The default gamma step.
        /// </summary>
        ///
        public const double DefaultGammaStep = 1;

        /// <summary>
        /// The network that is to be trained.
        /// </summary>
        ///
        private readonly SupportVectorMachine _network;

        /// <summary>
        /// The problem to train for.
        /// </summary>
        ///
        private readonly svm_problem _problem;

        /// <summary>
        /// The const c value.
        /// </summary>
        ///
        private double _c;

        /// <summary>
        /// The number of folds.
        /// </summary>
        ///
        private int _fold;

        /// <summary>
        /// The gamma value.
        /// </summary>
        ///
        private double _gamma;

        /// <summary>
        /// Is the training done.
        /// </summary>
        ///
        private bool _trainingDone;

        /// <summary>
        /// Construct a trainer for an SVM network.
        /// </summary>
        ///
        /// <param name="method">The network to train.</param>
        /// <param name="dataSet">The training data for this network.</param>
        public SVMTrain(SupportVectorMachine method, IMLDataSet dataSet) : base(TrainingImplementationType.OnePass)
        {
            _fold = 0;
            _network = method;
            Training = dataSet;
            _trainingDone = false;

            _problem = SyntesisSVMProblem.Syntesis(dataSet, 0);
            _gamma = 1.0d / _network.InputCount;
            _c = 1.0d;
        }

        /// <inheritdoc/>
        public override sealed bool CanContinue
        {
            get { return false; }
        }

        /// <summary>
        /// Set the constant C.
        /// </summary>
        public double C
        {
            get { return _c; }
            set
            {
                if (value <= 0 || value < SyntFramework.DefaultDoubleEqual)
                {
                    throw new SyntError("SVM training cannot use a c value less than zero.");
                }

                _c = value;
            }
        }


        /// <summary>
        /// Set the number of folds.
        /// </summary>
        public int Fold
        {
            get { return _fold; }
            set { _fold = value; }
        }


        /// <summary>
        /// Set the gamma.
        /// </summary>
        public double Gamma
        {
            get { return _gamma; }
            set
            {
                if (value <= 0 || value < SyntFramework.DefaultDoubleEqual)
                {
                    throw new SyntError("SVM training cannot use a gamma value less than zero.");
                }
                _gamma = value;
            }
        }


        /// <inheritdoc/>
        public override IMLMethod Method
        {
            get { return _network; }
        }


        /// <value>The problem being trained.</value>
        public svm_problem Problem
        {
            get { return _problem; }
        }


        /// <value>True if the training is done.</value>
        public override bool TrainingDone
        {
            get { return _trainingDone; }
        }

        /// <summary>
        /// Evaluate the error for the specified model.
        /// </summary>
        ///
        /// <param name="param">The params for the SVN.</param>
        /// <param name="prob">The problem to evaluate.</param>
        /// <param name="target">The output values from the SVN.</param>
        /// <returns>The calculated error.</returns>
        private static double Evaluate(svm_parameter param, svm_problem prob,
                                double[] target)
        {
            int totalCorrect = 0;

            var error = new ErrorCalculation();

            if ((param.svm_type == svm_parameter.EPSILON_SVR)
                || (param.svm_type == svm_parameter.NU_SVR))
            {
                for (int i = 0; i < prob.l; i++)
                {
                    double ideal = prob.y[i];
                    double actual = target[i];
                    error.UpdateError(actual, ideal);
                }
                return error.Calculate();
            }
            for (int i = 0; i < prob.l; i++)
            {
                if (target[i] == prob.y[i])
                {
                    ++totalCorrect;
                }
            }

            return Format.HundredPercent * totalCorrect / prob.l;
        }


        /// <summary>
        /// Perform either a train or a cross validation.  If the folds property is 
        /// greater than 1 then cross validation will be done.  Cross validation does 
        /// not produce a usable model, but it does set the error. 
        /// If you are cross validating try C and Gamma values until you have a good 
        /// error rate.  Then use those values to train, producing the final model.
        /// </summary>
        ///
        public override sealed void Iteration()
        {
            _network.Params.C = _c;
            _network.Params.gamma = _gamma;

            SyntLogging.Log(SyntLogging.LevelInfo, "Training with parameters C = " + _c + ", gamma = " + _gamma);

            if (_fold > 1)
            {
                // cross validate
                var target = new double[_problem.l];

                svm.svm_cross_validation(_problem, _network.Params,
                                         _fold, target);
                _network.Model = null;

                Error = Evaluate(_network.Params, _problem, target);
            }
            else
            {
                // train
                _network.Model = svm.svm_train(_problem,
                                              _network.Params);

                Error = _network.CalculateError(Training);
            }

            _trainingDone = true;
        }

        /// <inheritdoc/>
        public override sealed TrainingContinuation Pause()
        {
            return null;
        }

        /// <inheritdoc/>
        public override void Resume(TrainingContinuation state)
        {
        }
    }

    public class SVMSearchTrain : BasicTraining
    {
        /// <summary>
        /// The default starting number for C.
        /// </summary>
        ///
        public const double DefaultConstBegin = 1;

        /// <summary>
        /// The default ending number for C.
        /// </summary>
        ///
        public const double DefaultConstEnd = 15;

        /// <summary>
        /// The default step for C.
        /// </summary>
        ///
        public const double DefaultConstStep = 2;

        /// <summary>
        /// The default gamma begin.
        /// </summary>
        ///
        public const double DefaultGammaBegin = 1;

        /// <summary>
        /// The default gamma end.
        /// </summary>
        ///
        public const double DefaultGammaEnd = 10;

        /// <summary>
        /// The default gamma step.
        /// </summary>
        ///
        public const double DefaultGammaStep = 1;

        /// <summary>
        /// The internal training object, used for the search.
        /// </summary>
        ///
        private readonly SVMTrain _internalTrain;

        /// <summary>
        /// The network that is to be trained.
        /// </summary>
        ///
        private readonly SupportVectorMachine _network;

        /// <summary>
        /// The best values found for C.
        /// </summary>
        ///
        private double _bestConst;

        /// <summary>
        /// The best error.
        /// </summary>
        ///
        private double _bestError;

        /// <summary>
        /// The best values found for gamma.
        /// </summary>
        ///
        private double _bestGamma;

        /// <summary>
        /// The beginning value for C.
        /// </summary>
        ///
        private double _constBegin;

        /// <summary>
        /// The ending value for C.
        /// </summary>
        ///
        private double _constEnd;

        /// <summary>
        /// The step value for C.
        /// </summary>
        ///
        private double _constStep;

        /// <summary>
        /// The current C.
        /// </summary>
        ///
        private double _currentConst;

        /// <summary>
        /// The current gamma.
        /// </summary>
        ///
        private double _currentGamma;

        /// <summary>
        /// The number of folds.
        /// </summary>
        ///
        private int _fold;

        /// <summary>
        /// The beginning value for gamma.
        /// </summary>
        ///
        private double _gammaBegin;

        /// <summary>
        /// The ending value for gamma.
        /// </summary>
        ///
        private double _gammaEnd;

        /// <summary>
        /// The step value for gamma.
        /// </summary>
        ///
        private double _gammaStep;

        /// <summary>
        /// Is the network setup.
        /// </summary>
        ///
        private bool _isSetup;

        /// <summary>
        /// Is the training done.
        /// </summary>
        ///
        private bool _trainingDone;

        /// <summary>
        /// Construct a trainer for an SVM network.
        /// </summary>
        ///
        /// <param name="method">The method to train.</param>
        /// <param name="training">The training data for this network.</param>
        public SVMSearchTrain(SupportVectorMachine method, IMLDataSet training)
            : base(TrainingImplementationType.Iterative)
        {
            _fold = 0;
            _constBegin = DefaultConstBegin;
            _constStep = DefaultConstStep;
            _constEnd = DefaultConstEnd;
            _gammaBegin = DefaultGammaBegin;
            _gammaEnd = DefaultGammaEnd;
            _gammaStep = DefaultGammaStep;
            _network = method;
            Training = training;
            _isSetup = false;
            _trainingDone = false;

            _internalTrain = new SVMTrain(_network, training);
        }

        /// <inheritdoc/>
        public override sealed bool CanContinue
        {
            get { return false; }
        }


        /// <value>the constBegin to set</value>
        public double ConstBegin
        {
            get { return _constBegin; }
            set { _constBegin = value; }
        }


        /// <value>the constEnd to set</value>
        public double ConstEnd
        {
            get { return _constEnd; }
            set { _constEnd = value; }
        }


        /// <value>the constStep to set</value>
        public double ConstStep
        {
            get { return _constStep; }
            set { _constStep = value; }
        }


        /// <value>the fold to set</value>
        public int Fold
        {
            get { return _fold; }
            set { _fold = value; }
        }


        /// <value>the gammaBegin to set</value>
        public double GammaBegin
        {
            get { return _gammaBegin; }
            set { _gammaBegin = value; }
        }


        /// <value>the gammaEnd to set.</value>
        public double GammaEnd
        {
            get { return _gammaEnd; }
            set { _gammaEnd = value; }
        }


        /// <value>the gammaStep to set</value>
        public double GammaStep
        {
            get { return _gammaStep; }
            set { _gammaStep = value; }
        }


        /// <inheritdoc/>
        public override IMLMethod Method
        {
            get { return _network; }
        }


        /// <value>True if the training is done.</value>
        public override bool TrainingDone
        {
            get { return _trainingDone; }
        }

        /// <inheritdoc/>
        public override sealed void FinishTraining()
        {
            _internalTrain.Gamma = _bestGamma;
            _internalTrain.C = _bestConst;
            _internalTrain.Iteration();
        }


        /// <summary>
        /// Perform one training iteration.
        /// </summary>
        public override sealed void Iteration()
        {
            if (!_trainingDone)
            {
                if (!_isSetup)
                {
                    Setup();
                }

                PreIteration();

                _internalTrain.Fold = _fold;

                if (_network.KernelType == KernelType.RadialBasisFunction)
                {
                    _internalTrain.Gamma = _currentGamma;
                    _internalTrain.C = _currentConst;
                    _internalTrain.Iteration();
                    double e = _internalTrain.Error;

                    //System.out.println(this.currentGamma + "," + this.currentConst
                    //		+ "," + e);

                    // new best error?
                    if (!Double.IsNaN(e))
                    {
                        if (e < _bestError)
                        {
                            _bestConst = _currentConst;
                            _bestGamma = _currentGamma;
                            _bestError = e;
                        }
                    }

                    // advance
                    _currentConst += _constStep;
                    if (_currentConst > _constEnd)
                    {
                        _currentConst = _constBegin;
                        _currentGamma += _gammaStep;
                        if (_currentGamma > _gammaEnd)
                        {
                            _trainingDone = true;
                        }
                    }

                    Error = _bestError;
                }
                else
                {
                    _internalTrain.Gamma = _currentGamma;
                    _internalTrain.C = _currentConst;
                    _internalTrain.Iteration();
                }

                PostIteration();
            }
        }

        /// <inheritdoc/>
        public override sealed TrainingContinuation Pause()
        {
            return null;
        }

        /// <inheritdoc/>
        public override void Resume(TrainingContinuation state)
        {
        }

        /// <summary>
        /// Setup to train the SVM.
        /// </summary>
        ///
        private void Setup()
        {
            _currentConst = _constBegin;
            _currentGamma = _gammaBegin;
            _bestError = Double.PositiveInfinity;
            _isSetup = true;

            if (_currentGamma <= 0 || _currentGamma < SyntFramework.DefaultDoubleEqual)
            {
                throw new SyntError("SVM search training cannot use a gamma value less than zero.");
            }

            if (_currentConst <= 0 || _currentConst < SyntFramework.DefaultDoubleEqual)
            {
                throw new SyntError("SVM search training cannot use a const value less than zero.");
            }

            if (_gammaStep < 0)
            {
                throw new SyntError("SVM search gamma step cannot use a const value less than zero.");
            }

            if (_constStep < 0)
            {
                throw new SyntError("SVM search const step cannot use a const value less than zero.");
            }
        }
    }
    
    public class TrainBayesianFactory
    {
        /**
 * Create a K2 trainer.
 * 
 * @param method
 *            The method to use.
 * @param training
 *            The training data to use.
 * @param argsStr
 *            The arguments to use.
 * @return The newly created trainer.
 */
        public IMLTrain Create(IMLMethod method,
                IMLDataSet training, String argsStr)
        {
            IDictionary<String, String> args = ArchitectureParse.ParseParams(argsStr);
            ParamsHolder holder = new ParamsHolder(args);

            int maxParents = holder.GetInt(
                    MLTrainFactory.PropertyMaxParents, false, 1);
            String searchStr = holder.GetString("SEARCH", false, "k2");
            String estimatorStr = holder.GetString("ESTIMATOR", false, "simple");
            String initStr = holder.GetString("INIT", false, "naive");

            IBayesSearch search;
            IBayesEstimator estimator;
            BayesianInit init;

            if (string.Compare(searchStr, "k2", true) == 0)
            {
                search = new SearchK2();
            }
            else if (string.Compare(searchStr, "none", true) == 0)
            {
                search = new SearchNone();
            }
            else
            {
                throw new BayesianError("Invalid search type: " + searchStr);
            }

            if (string.Compare(estimatorStr, "simple", true) == 0)
            {
                estimator = new SimpleEstimator();
            }
            else if (string.Compare(estimatorStr, "none", true) == 0)
            {
                estimator = new EstimatorNone();
            }
            else
            {
                throw new BayesianError("Invalid estimator type: " + estimatorStr);
            }

            if (string.Compare(initStr, "simple") == 0)
            {
                init = BayesianInit.InitEmpty;
            }
            else if (string.Compare(initStr, "naive") == 0)
            {
                init = BayesianInit.InitNaiveBayes;
            }
            else if (string.Compare(initStr, "none") == 0)
            {
                init = BayesianInit.InitNoChange;
            }
            else
            {
                throw new BayesianError("Invalid init type: " + initStr);
            }

            return new TrainBayesian((BayesianNetwork)method, training, maxParents, init, search, estimator);
        }
    }

    public class MLActivationFactory
    {
        public const String AF_BIPOLAR = "bipolar";
        public const String AF_COMPETITIVE = "comp";
        public const String AF_GAUSSIAN = "gauss";
        public const String AF_LINEAR = "linear";
        public const String AF_LOG = "log";
        public const String AF_RAMP = "ramp";
        public const String AF_SIGMOID = "sigmoid";
        public const String AF_SIN = "sin";
        public const String AF_SOFTMAX = "softmax";
        public const String AF_STEP = "step";
        public const String AF_TANH = "tanh";

        public IActivationFunction Create(String fn)
        {

            foreach (SyntPluginBase plugin in SyntFramework.Instance.Plugins)
            {
                if (plugin is ISyntPluginService1)
                {
                    IActivationFunction result = ((ISyntPluginService1)plugin).CreateActivationFunction(fn);
                    if (result != null)
                    {
                        return result;
                    }
                }
            }
            return null;
        }
    }

    public class MLMethodFactory
    {
        /// <summary>
        /// String constant for a bayesian neural network.
        /// </summary>
	    public const String TypeBayesian = "bayesian";

        /// <summary>
        /// String constant for feedforward neural networks.
        /// </summary>
        ///
        public const String TypeFeedforward = "feedforward";

        /// <summary>
        /// String constant for RBF neural networks.
        /// </summary>
        ///
        public const String TypeRbfnetwork = "rbfnetwork";

        /// <summary>
        /// String constant for support vector machines.
        /// </summary>
        ///
        public const String TypeSVM = "svm";

        /// <summary>
        /// String constant for SOMs.
        /// </summary>
        ///
        public const String TypeSOM = "som";

        /// <summary>
        /// A probabilistic neural network. Supports both PNN and GRNN.
        /// </summary>
        ///
        public const String TypePNN = "pnn";

        /// <summary>
        /// Create a new machine learning method.
        /// </summary>
        ///
        /// <param name="methodType">The method to create.</param>
        /// <param name="architecture">The architecture string.</param>
        /// <param name="input">The input count.</param>
        /// <param name="output">The output count.</param>
        /// <returns>The newly created machine learning method.</returns>
        public IMLMethod Create(String methodType,
                               String architecture, int input, int output)
        {
            foreach (SyntPluginBase plugin in SyntFramework.Instance.Plugins)
            {
                if (plugin is ISyntPluginService1)
                {
                    IMLMethod result = ((ISyntPluginService1)plugin).CreateMethod(
                            methodType, architecture, input, output);
                    if (result != null)
                    {
                        return result;
                    }
                }
            }

            throw new SyntError("Unknown method type: " + methodType);
        }
    }

    public class MLTrainFactory
    {
        /// <summary>
        /// The maximum number of parents for K2.
        /// </summary>
        public const string PropertyMaxParents = "MAXPARENTS";


        ///<summary>
        /// The number of particles.
        ///</summary>
        public const String PropertyParticles = "PARTICLES";

        /// <summary>
        /// Nelder Mead training for Bayesian.
        /// </summary>
        public const String TypeNelderMead = "nm";

        /// <summary>
        /// K2 training for Bayesian.
        /// </summary>
        public const String TypeBayesian = "bayesian";

        /// <summary>
        /// PSO training.
        /// </summary>
        public const String TypePSO = "pso";

        /// <summary>
        /// String constant for RPROP training.
        /// </summary>
        ///
        public const String TypeRPROP = "rprop";

        /// <summary>
        /// String constant for RPROP training.
        /// </summary>
        ///
        public const String TypeQPROP = "qprop";

        /// <summary>
        /// String constant for backprop training.
        /// </summary>
        ///
        public const String TypeBackprop = "backprop";

        /// <summary>
        /// String constant for SCG training.
        /// </summary>
        ///
        public const String TypeSCG = "scg";

        /// <summary>
        /// String constant for LMA training.
        /// </summary>
        ///
        public const String TypeLma = "lma";

        /// <summary>
        /// String constant for SVM training.
        /// </summary>
        ///
        public const String TypeSVM = "svm-train";

        /// <summary>
        /// String constant for SVM-Search training.
        /// </summary>
        ///
        public const String TypeSVMSearch = "svm-search";

        /// <summary>
        /// String constant for SOM-Neighborhood training.
        /// </summary>
        ///
        public const String TypeSOMNeighborhood = "som-neighborhood";

        /// <summary>
        /// String constant for SOM-Cluster training.
        /// </summary>
        ///
        public const String TypeSOMCluster = "som-cluster";

        /// <summary>
        /// Property for learning rate.
        /// </summary>
        ///
        public const String PropertyLearningRate = "LR";

        /// <summary>
        /// Property for momentum.
        /// </summary>
        ///
        public const String PropertyLearningMomentum = "MOM";

        /// <summary>
        /// Property for init update.
        /// </summary>
        ///
        public const String PropertyInitialUpdate = "INIT_UPDATE";

        /// <summary>
        /// Property for max step.
        /// </summary>
        ///
        public const String PropertyMaxStep = "MAX_STEP";

        /// <summary>
        /// Property for bayes reg.
        /// </summary>
        ///
        public const String PropertyBayesianRegularization = "BAYES_REG";

        /// <summary>
        /// Property for gamma.
        /// </summary>
        ///
        public const String PropertyGamma = "GAMMA";

        /// <summary>
        /// Property for constant.
        /// </summary>
        ///
        public const String PropertyC = "C";

        /// <summary>
        /// Property for neighborhood.
        /// </summary>
        ///
        public const String PropertyPropertyNeighborhood = "NEIGHBORHOOD";

        /// <summary>
        /// Property for iterations.
        /// </summary>
        ///
        public const String PropertyIterations = "ITERATIONS";

        /// <summary>
        /// Property for starting learning rate.
        /// </summary>
        ///
        public const String PropertyStartLearningRate = "START_LR";

        /// <summary>
        /// Property for ending learning rate.
        /// </summary>
        ///
        public const String PropertyEndLearningRate = "END_LR";

        /// <summary>
        /// Property for starting radius.
        /// </summary>
        ///
        public const String PropertyStartRadius = "START_RADIUS";

        /// <summary>
        /// Property for ending radius.
        /// </summary>
        ///
        public const String PropertyEndRadius = "END_RADIUS";

        /// <summary>
        /// Property for neighborhood.
        /// </summary>
        ///
        public const String PropertyNeighborhood = "NEIGHBORHOOD";

        /// <summary>
        /// Property for rbf type.
        /// </summary>
        ///
        public const String PropertyRBFType = "RBF_TYPE";

        /// <summary>
        /// Property for dimensions.
        /// </summary>
        ///
        public const String PropertyDimensions = "DIM";

        /// <summary>
        /// The number of cycles.
        /// </summary>
        ///
        public const String Cycles = "cycles";

        /// <summary>
        /// The starting temperature.
        /// </summary>
        ///
        public const String PropertyTemperatureStart = "startTemp";

        /// <summary>
        /// The ending temperature.
        /// </summary>
        ///
        public const String PropertyTemperatureStop = "stopTemp";

        /// <summary>
        /// Use simulated annealing.
        /// </summary>
        ///
        public const String TypeAnneal = "anneal";

        /// <summary>
        /// Population size.
        /// </summary>
        ///
        public const String PropertyPopulationSize = "population";

        /// <summary>
        /// Percent to mutate.
        /// </summary>
        ///
        public const String PropertyMutation = "mutate";

        /// <summary>
        /// Percent to mate.
        /// </summary>
        ///
        public const String PropertyMate = "mate";

        /// <summary>
        /// G training.
        /// </summary>
        ///
        public const String TypeG = "G";

        /// <summary>
        /// Manhattan training.
        /// </summary>
        ///
        public const String TypeManhattan = "manhattan";

        /// <summary>
        /// RBF-SVD training.
        /// </summary>
        ///
        public const String TypeSvd = "rbf-svd";

        /// <summary>
        /// PNN training.
        /// </summary>
        ///
        public const String TypePNN = "pnn";


        /// <summary>
        /// Construct the boject.
        /// </summary>
        public MLTrainFactory()
        {
        }

        /// <summary>
        /// Create a trainer.
        /// </summary>
        ///
        /// <param name="method">The method to train.</param>
        /// <param name="training">The training data.</param>
        /// <param name="type">Type type of trainer.</param>
        /// <param name="args">The training args.</param>
        /// <returns>The new training method.</returns>
        public IMLTrain Create(IMLMethod method,
                              IMLDataSet training, String type, String args)
        {
            foreach (SyntPluginBase plugin in SyntFramework.Instance.Plugins)
            {
                if (plugin is ISyntPluginService1)
                {
                    IMLTrain result = ((ISyntPluginService1)plugin).CreateTraining(
                            method, training, type, args);
                    if (result != null)
                    {
                        return result;
                    }
                }
            }
            throw new SyntError("Unknown training type: " + type);
        }
    }

    [Serializable]
    public class Q
    {
        /// <summary>
        /// The individual elements of this Q.
        /// </summary>
        ///
        private readonly List<IGene> _genes;

        /// <summary>
        /// Construct the object.
        /// </summary>
        public Q()
        {
            _genes = new List<IGene>();
        }

        /// <summary>
        /// Used the get the entire gene list.
        /// </summary>
        ///
        /// <value>the genes</value>
        public List<IGene> Genes
        {
            get { return _genes; }
        }

        /// <summary>
        /// Add a gene.
        /// </summary>
        ///
        /// <param name="gene">The gene to add.</param>
        public void Add(IGene gene)
        {
            _genes.Add(gene);
        }

        /// <summary>
        /// Get an individual gene.
        /// </summary>
        ///
        /// <param name="i">The index of the gene.</param>
        /// <returns>The gene.</returns>
        public IGene Get(int i)
        {
            return _genes[i];
        }

        /// <summary>
        /// Get the specified gene.
        /// </summary>
        ///
        /// <param name="gene">The specified gene.</param>
        /// <returns>The gene specified.</returns>
        public IGene GetGene(int gene)
        {
            return _genes[gene];
        }


        /// <returns>The number of genes in this Q.</returns>
        public int Size()
        {
            return _genes.Count;
        }
    }

    public class FlatLayer
    {
        /// <summary>
        /// The neuron count.
        /// </summary>
        ///
        private readonly int _count;

        /// <summary>
        /// The bias activation, usually 1 for bias or 0 for no bias.
        /// </summary>
        ///
        private double _biasActivation;

        /// <summary>
        /// The layer that feeds this layer's context.
        /// </summary>
        ///
        private FlatLayer _contextFedBy;

        /// <summary>
        /// Construct a flat layer.
        /// </summary>
        ///
        /// <param name="activation">The activation function.</param>
        /// <param name="count">The neuron count.</param>
        /// <param name="biasActivation">The bias activation.</param>
        public FlatLayer(IActivationFunction activation, int count,
                         double biasActivation)
        {
            Activation = activation;
            _count = count;
            _biasActivation = biasActivation;
            _contextFedBy = null;
        }


        /// <value>the activation to set</value>
        public IActivationFunction Activation { get; set; }


        /// <summary>
        /// Set the bias activation.
        /// </summary>
        public double BiasActivation
        {
            get
            {
                if (HasBias())
                {
                    return _biasActivation;
                }
                return 0;
            }
            set { _biasActivation = value; }
        }


        /// <value>The number of neurons our context is fed by.</value>
        public int ContextCount
        {
            get
            {
                if (_contextFedBy == null)
                {
                    return 0;
                }
                return _contextFedBy.Count;
            }
        }


        /// <summary>
        /// Set the layer that this layer's context is fed by.
        /// </summary>
        public FlatLayer ContextFedBy
        {
            get { return _contextFedBy; }
            set { _contextFedBy = value; }
        }


        /// <value>the count</value>
        public int Count
        {
            get { return _count; }
        }


        /// <value>The total number of neurons on this layer, includes context, bias
        /// and regular.</value>
        public int TotalCount
        {
            get
            {
                if (_contextFedBy == null)
                {
                    return Count + ((HasBias()) ? 1 : 0);
                }
                return Count + ((HasBias()) ? 1 : 0)
                       + _contextFedBy.Count;
            }
        }


        /// <returns>the bias</returns>
        public bool HasBias()
        {
            return Math.Abs(_biasActivation) > SyntFramework.DefaultDoubleEqual;
        }

        /// <inheritdoc/>
        public override sealed String ToString()
        {
            var result = new StringBuilder();
            result.Append("[");
            result.Append(GetType().Name);
            result.Append(": count=");
            result.Append(_count);
            result.Append(",bias=");

            if (HasBias())
            {
                result.Append(_biasActivation);
            }
            else
            {
                result.Append("false");
            }
            if (_contextFedBy != null)
            {
                result.Append(",contextFed=");
                if (_contextFedBy == this)
                {
                    result.Append("itself");
                }
                else
                {
                    result.Append(_contextFedBy);
                }
            }
            result.Append("]");
            return result.ToString();
        }
    }

    public class BasicGAlgo : GAlgo
    {
        /// <summary>
        /// Is this the first iteration.
        /// </summary>
        ///
        private bool _first;

        /// <summary>
        /// Construct the object.
        /// </summary>
        public BasicGAlgo()
        {
            _first = true;
        }

        /// <summary>
        /// Modify the weight matrix and bias values based on the last call to
        /// calcError.
        /// </summary>
        public override sealed void Iteration()
        {
            if (_first)
            {
                Population.Claim(this);
                _first = false;
            }

            var countToMate = (int)(Population.PopulationSize * PercentToMate);
            int offspringCount = countToMate * 2;
            int offspringIndex = Population.PopulationSize
                                 - offspringCount;
            var matingPopulationSize = (int)(Population.PopulationSize * MatingPopulation);

            // mate and form the next generation
            Parallel.For(0, countToMate, i =>
            {
                //IT mother = Population.Ts[i];
                //var fatherInt = (int)(ThreadSafeRandom.NextDouble() * matingPopulationSize);
                //IT father = Population.Ts[fatherInt];
                //IT child1 = Population.Ts[offspringIndex];
                //IT child2 = Population.Ts[offspringIndex + 1];

                //var worker = new MateWorker(mother, father, child1,
                //                            child2);

                //worker.Run();

                //offspringIndex += 2;
            });

            // sort the next generation
            Population.Sort();
        }
    }

    public class ErrorCalculation
    {
        /// <summary>
        /// The current error calculation mode.
        /// </summary>
        private static ErrorCalculationMode _mode = ErrorCalculationMode.MSE;

        /// <summary>
        /// The overall error.
        /// </summary>
        private double _globalError;

        /// <summary>
        /// The size of a set.
        /// </summary>
        private int _setSize;

        /// <summary>
        /// The error calculation mode, this is static and therefore global to
        /// all Synt training. If a particular training method only supports a
        /// particular error calculation method, it may override this value. It will
        /// not change the value set here, rather the training will occur with its
        /// preferred training method. Currently the only training method that does
        /// this is Levenberg Marquardt (LMA).
        /// 
        /// The default error mode for Synt is RMS.
        /// </summary>
        public static ErrorCalculationMode Mode
        {
            get { return _mode; }
            set { _mode = value; }
        }

        /// <summary>
        /// Returns the root mean square error for a complete training set. 
        /// </summary>
        /// <returns>The current error for the neural network.</returns>
        public double Calculate()
        {
            if (_setSize == 0)
            {
                return 0;
            }

            switch (Mode)
            {
                case ErrorCalculationMode.RMS:
                    return CalculateRMS();
                case ErrorCalculationMode.MSE:
                    return CalculateMSE();
                default:
                    return CalculateMSE();
            }
        }


        /// <summary>
        /// Calculate the error with MSE. 
        /// </summary>
        /// <returns>The current error for the neural network.</returns>
        public double CalculateMSE()
        {
            if (_setSize == 0)
            {
                return 0;
            }
            double err = _globalError / _setSize;
            return err;
        }


        /// <summary>
        /// Calculate the error with RMS. 
        /// </summary>
        /// <returns>The current error for the neural network.</returns>
        public double CalculateRMS()
        {
            if (_setSize == 0)
            {
                return 0;
            }
            double err = Math.Sqrt(_globalError / _setSize);
            return err;
        }



        /// <summary>
        /// Reset the error accumulation to zero.
        /// </summary>
        public void Reset()
        {
            _globalError = 0;
            _setSize = 0;
        }

        /// <summary>
        /// Called to update for each number that should be checked.
        /// </summary>
        /// <param name="actual">The actual number.</param>
        /// <param name="ideal">The ideal number.</param>
        /// <param name="significance">The significance of this error, 1.0 is the baseline.</param>
        public void UpdateError(double[] actual, double[] ideal, double significance)
        {
            for (int i = 0; i < actual.Length; i++)
            {
                double delta = ideal[i] - actual[i];

                _globalError += delta * delta;
            }

            _setSize += ideal.Length;
        }

        /// <summary>
        /// Update the error with single values.
        /// </summary>
        /// <param name="actual">The actual value.</param>
        /// <param name="ideal">The ideal value.</param>
        public void UpdateError(double actual, double ideal)
        {
            double delta = ideal - actual;

            _globalError += delta * delta;

            _setSize++;
        }

        /// <summary>
        /// Calculate the error as sum of squares.
        /// </summary>
        /// <returns>The error.</returns>
        public double CalculateSSE()
        {
            return _globalError / 2;
        }
    }

    public class TComparator : IComparer<IT>
    {
        /// <summary>
        /// The method to calculate the score.
        /// </summary>
        ///
        private readonly ICalculateTScore _calculateScore;

        /// <summary>
        /// Construct the T comparator.
        /// </summary>
        ///
        /// <param name="theCalculateScore">The score calculation object to use.</param>
        public TComparator(ICalculateTScore theCalculateScore)
        {
            _calculateScore = theCalculateScore;
        }

        /// <value>The score calculation object.</value>
        public ICalculateTScore CalculateScore
        {
            get { return _calculateScore; }
        }

        #region IComparer<IT> Members

        /// <summary>
        /// Compare two Ts.
        /// </summary>
        ///
        /// <param name="T1">The first T.</param>
        /// <param name="T2">The second T.</param>
        /// <returns>Zero if equal, or less than or greater than zero to indicate
        /// order.</returns>
        public int Compare(IT T1, IT T2)
        {
            return T1.Score.CompareTo(T2.Score);
        }

        #endregion

        /// <summary>
        /// Apply a bonus, this is a simple percent that is applied in the direction
        /// specified by the "should minimize" property of the score function.
        /// </summary>
        ///
        /// <param name="v">The current value.</param>
        /// <param name="bonus">The bonus.</param>
        /// <returns>The resulting value.</returns>
        public double ApplyBonus(double v, double bonus)
        {
            double amount = v * bonus;
            if (_calculateScore.ShouldMinimize)
            {
                return v - amount;
            }
            return v + amount;
        }

        /// <summary>
        /// Apply a penalty, this is a simple percent that is applied in the
        /// direction specified by the "should minimize" property of the score
        /// function.
        /// </summary>
        ///
        /// <param name="v">The current value.</param>
        /// <param name="bonus">The penalty.</param>
        /// <returns>The resulting value.</returns>
        public double ApplyPenalty(double v, double bonus)
        {
            double amount = v * bonus;
            return _calculateScore.ShouldMinimize ? v - amount : v + amount;
        }

        /// <summary>
        /// Determine the best score from two scores, uses the "should minimize"
        /// property of the score function.
        /// </summary>
        ///
        /// <param name="d1">The first score.</param>
        /// <param name="d2">The second score.</param>
        /// <returns>The best score.</returns>
        public double BestScore(double d1, double d2)
        {
            return _calculateScore.ShouldMinimize ? Math.Min(d1, d2) : Math.Max(d1, d2);
        }


        /// <summary>
        /// Determine if one score is better than the other.
        /// </summary>
        ///
        /// <param name="d1">The first score to compare.</param>
        /// <param name="d2">The second score to compare.</param>
        /// <returns>True if d1 is better than d2.</returns>
        public bool IsBetterThan(double d1, double d2)
        {
            return _calculateScore.ShouldMinimize ? d1 < d2 : d1 > d2;
        }
    }

    public class SCGFactory
    {
        /// <summary>
        /// Create a SCG trainer.
        /// </summary>
        ///
        /// <param name="method">The method to use.</param>
        /// <param name="training">The training data to use.</param>
        /// <param name="args">The arguments to use.</param>
        /// <returns>The newly created trainer.</returns>
        public IMLTrain Create(IMLMethod method,
                              IMLDataSet training, String args)
        {
            if (!(method is BasicNetwork))
            {
                throw new SyntError(
                    "SCG training cannot be used on a method of type: "
                    + method.GetType().FullName);
            }

            return new ScaledConjugateGradient((BasicNetwork)method, training);
        }
    }

    public class BasicNeuralData : BasicMLData, INeuralData
    {
        /// <summary>
        /// Construct the object from an array.
        /// </summary>
        /// <param name="d">The array to base on.</param>
        public BasicNeuralData(double[] d) : base(d)
        {
        }

        /// <summary>
        /// Construct an empty array of the specified size.
        /// </summary>
        /// <param name="size">The size.</param>
        public BasicNeuralData(int size) : base(size)
        {
        }
    }

    public class CrossValidationKFold : CrossTraining
    {
        /// <summary>
        /// The flat network to train.
        /// </summary>
        ///
        private readonly FlatNetwork _flatNetwork;

        /// <summary>
        /// The network folds.
        /// </summary>
        ///
        private readonly NetworkFold[] _networks;

        /// <summary>
        /// The underlying trainer to use. This trainer does the actual training.
        /// </summary>
        ///
        private readonly IMLTrain _train;

        /// <summary>
        /// Construct a cross validation trainer.
        /// </summary>
        ///
        /// <param name="train">The training</param>
        /// <param name="k">The number of folds.</param>
        public CrossValidationKFold(IMLTrain train, int k) : base(train.Method, (FoldedDataSet)train.Training)
        {
            _train = train;
            Folded.Fold(k);

            _flatNetwork = ((BasicNetwork)train.Method).Structure.Flat;

            _networks = new NetworkFold[k];
            for (int i = 0; i < _networks.Length; i++)
            {
                _networks[i] = new NetworkFold(_flatNetwork);
            }
        }

        /// <inheritdoc />
        public override sealed bool CanContinue
        {
            get { return false; }
        }

        /// <summary>
        /// Perform one iteration.
        /// </summary>
        ///
        public override void Iteration()
        {
            double error = 0;

            for (int valFold = 0; valFold < Folded.NumFolds; valFold++)
            {
                //// restore the correct network
                //_networks[valFold].CopyToNetwork(_flatNetwork);

                //// train with non-validation folds
                //for (int curFold = 0; curFold < Folded.NumFolds; curFold++)
                //{
                //    if (curFold != valFold)
                //    {
                //        Folded.CurrentFold = curFold;
                //        _train.Iteration();
                //    }
                //}

                //// evaluate with the validation fold			
                //Folded.CurrentFold = valFold;
                //double e = _flatNetwork.CalculateError(Folded);
                ////System.out.println("Fold " + valFold + ", " + e);
                //error += e;
                //_networks[valFold].CopyFromNetwork(_flatNetwork);
            }

            Error = error / Folded.NumFolds;
        }

        /// <summary>
        /// 
        /// </summary>
        ///
        public override sealed TrainingContinuation Pause()
        {
            return null;
        }

        /// <summary>
        /// 
        /// </summary>
        ///
        public override sealed void Resume(TrainingContinuation state)
        {
        }
    }


    public class StopTrainingStrategy : IEndTrainingStrategy
    {
        /// <summary>
        /// The default minimum improvement before training stops.
        /// </summary>
        ///
        public const double DefaultMinImprovement = 0.0000001d;

        /// <summary>
        /// The default number of cycles to tolerate.
        /// </summary>
        ///
        public const int DefaultTolerateCycles = 100;

        /// <summary>
        /// The minimum improvement before training stops.
        /// </summary>
        ///
        private readonly double _minImprovement;

        /// <summary>
        /// The number of cycles to tolerate the minimum improvement.
        /// </summary>
        ///
        private readonly int _toleratedCycles;

        /// <summary>
        /// The number of bad training cycles.
        /// </summary>
        ///
        private int _badCycles;

        /// <summary>
        /// The error rate from the previous iteration.
        /// </summary>
        ///
        private double _bestError;

        /// <summary>
        /// The error rate from the previous iteration.
        /// </summary>
        ///
        private double _lastError;

        /// <summary>
        /// Has one iteration passed, and we are now ready to start evaluation.
        /// </summary>
        ///
        private bool _ready;

        /// <summary>
        /// Flag to indicate if training should stop.
        /// </summary>
        ///
        private bool _shouldStop;

        /// <summary>
        /// The training Algo that is using this strategy.
        /// </summary>
        ///
        private IMLTrain _train;

        /// <summary>
        /// Construct the strategy with default options.
        /// </summary>
        ///
        public StopTrainingStrategy() : this(DefaultMinImprovement, DefaultTolerateCycles)
        {
        }

        /// <summary>
        /// Construct the strategy with the specified parameters.
        /// </summary>
        ///
        /// <param name="minImprovement">The minimum accepted improvement.</param>
        /// <param name="toleratedCycles">The number of cycles to tolerate before stopping.</param>
        public StopTrainingStrategy(double minImprovement,
                                    int toleratedCycles)
        {
            _minImprovement = minImprovement;
            _toleratedCycles = toleratedCycles;
            _badCycles = 0;
            _bestError = Double.MaxValue;
        }

        #region EndTrainingStrategy Members

        /// <summary>
        /// 
        /// </summary>
        ///
        public virtual void Init(IMLTrain train)
        {
            _train = train;
            _shouldStop = false;
            _ready = false;
        }

        /// <summary>
        /// 
        /// </summary>
        ///
        public virtual void PostIteration()
        {
            if (_ready)
            {
                if (Math.Abs(_bestError - _train.Error) < _minImprovement)
                {
                    _badCycles++;
                    if (_badCycles > _toleratedCycles)
                    {
                        _shouldStop = true;
                    }
                }
                else
                {
                    _badCycles = 0;
                }
            }
            else
            {
                _ready = true;
            }

            _lastError = _train.Error;
            _bestError = Math.Min(_lastError, _bestError);
        }

        /// <summary>
        /// 
        /// </summary>
        ///
        public virtual void PreIteration()
        {
        }

        /// <summary>
        /// 
        /// </summary>
        ///
        public virtual bool ShouldStop()
        {
            return _shouldStop;
        }

        #endregion
    }
    [Serializable]
    public class PersistYPopulation : ISyntPersistor
    {
        #region SyntPersistor Members

        /// <summary>
        /// The persistence class string.
        /// </summary>
        public virtual String PersistClassString
        {
            get { return typeof(YPopulation).Name; }
        }


        /// <summary>
        /// Read the object.
        /// </summary>
        /// <param name="mask0">The stream to read the object from.</param>
        /// <returns>The object that was loaded.</returns>
        public virtual Object Read(Stream mask0)
        {
            var result = new YPopulation();
            var innovationList = new YInnovationList { Population = result };
            result.Innovations = innovationList;
            var ins0 = new SyntReadHelper(mask0);
            IDictionary<Int32, ISpecies> speciesMap = new Dictionary<Int32, ISpecies>();
            IDictionary<ISpecies, Int32> leaderMap = new Dictionary<ISpecies, Int32>();
            IDictionary<Int32, IT> TMap = new Dictionary<Int32, IT>();
            SyntFileSection section;

            while ((section = ins0.ReadNextSection()) != null)
            {
                if (section.SectionName.Equals("Y-POPULATION")
                    && section.SubSectionName.Equals("INNOVATIONS"))
                {
                    foreach (String line in section.Lines)
                    {
                        IList<String> cols = SyntFileSection.SplitColumns(line);
                        var innovation = new YInnovation
                        {
                            InnovationID = Int32.Parse(cols[0]),
                            InnovationType = StringToInnovationType(cols[1]),
                            NeuronType = StringToNeuronType(cols[2]),
                            SplitX = CSVFormat.EgFormat.Parse(cols[3]),
                            SplitY = CSVFormat.EgFormat.Parse(cols[4]),
                            NeuronID = Int32.Parse(cols[5]),
                            FromNeuronID = Int32.Parse(cols[6]),
                            ToNeuronID = Int32.Parse(cols[7])
                        };
                        result.Innovations.Add(innovation);
                    }
                }
                else if (section.SectionName.Equals("Y-POPULATION")
                         && section.SubSectionName.Equals("SPECIES"))
                {
                    foreach (String line in section.Lines)
                    {
                        String[] cols = line.Split(',');
                        var species = new BasicSpecies
                        {
                            SpeciesID = Int32.Parse(cols[0]),
                            Age = Int32.Parse(cols[1]),
                            BestScore = CSVFormat.EgFormat.Parse(cols[2]),
                            GensNoImprovement = Int32.Parse(cols[3]),
                            SpawnsRequired = CSVFormat.EgFormat
                                                  .Parse(cols[4])
                        };

                        species.SpawnsRequired = CSVFormat.EgFormat
                            .Parse(cols[5]);
                        leaderMap[(species)] = (Int32.Parse(cols[6]));
                        result.Species.Add(species);
                        speciesMap[((int)species.SpeciesID)] = (species);
                    }
                }
                else if (section.SectionName.Equals("Y-POPULATION")
                         && section.SubSectionName.Equals("TS"))
                {
                    YT lastT = null;

                    foreach (String line in section.Lines)
                    {
                        IList<String> cols = SyntFileSection.SplitColumns(line);
                        if (cols[0].Equals("g", StringComparison.InvariantCultureIgnoreCase))
                        {
                            lastT = new YT
                            {
                                NeuronsQ = new Q(),
                                LinksQ = new Q()
                            };
                            lastT.Qs.Add(lastT.NeuronsQ);
                            lastT.Qs.Add(lastT.LinksQ);
                            lastT.TID = Int32.Parse(cols[1]);
                            lastT.SpeciesID = Int32.Parse(cols[2]);
                            lastT.AdjustedScore = CSVFormat.EgFormat
                                .Parse(cols[3]);
                            lastT.AmountToSpawn = CSVFormat.EgFormat
                                .Parse(cols[4]);
                            lastT.NetworkDepth = Int32.Parse(cols[5]);
                            lastT.Score = CSVFormat.EgFormat.Parse(cols[6]);
                            result.Add(lastT);
                            TMap[(int)lastT.TID] = lastT;
                        }
                        else if (cols[0].Equals("n", StringComparison.InvariantCultureIgnoreCase))
                        {
                            var neuronGene = new YNeuronGene
                            {
                                Id = Int32.Parse(cols[1]),
                                NeuronType = StringToNeuronType(cols[2]),
                                Enabled = Int32.Parse(cols[3]) > 0,
                                InnovationId = Int32.Parse(cols[4]),
                                ActivationResponse = CSVFormat.EgFormat
                                                         .Parse(cols[5]),
                                SplitX = CSVFormat.EgFormat.Parse(cols[6]),
                                SplitY = CSVFormat.EgFormat.Parse(cols[7])
                            };
                            lastT.Neurons.Add(neuronGene);
                        }
                        else if (cols[0].Equals("l", StringComparison.InvariantCultureIgnoreCase))
                        {
                            var linkGene = new YLinkGene();
                            linkGene.Id = Int32.Parse(cols[1]);
                            linkGene.Enabled = Int32.Parse(cols[2]) > 0;
                            linkGene.Recurrent = Int32.Parse(cols[3]) > 0;
                            linkGene.FromNeuronID = Int32.Parse(cols[4]);
                            linkGene.ToNeuronID = Int32.Parse(cols[5]);
                            linkGene.Weight = CSVFormat.EgFormat.Parse(cols[6]);
                            linkGene.InnovationId = Int32.Parse(cols[7]);
                            lastT.Links.Add(linkGene);
                        }
                    }
                }
                else if (section.SectionName.Equals("Y-POPULATION")
                         && section.SubSectionName.Equals("CONFIG"))
                {
                    IDictionary<String, String> paras = section.ParseParams();

                    result.YActivationFunction = SyntFileSection
                        .ParseActivationFunction(paras,
                                                 YPopulation.PropertyYActivation);
                    result.OutputActivationFunction = SyntFileSection
                        .ParseActivationFunction(paras,
                                                 YPopulation.PropertyOutputActivation);
                    result.Snapshot = SyntFileSection.ParseBoolean(paras,
                                                                    PersistConst.Snapshot);
                    result.InputCount = SyntFileSection.ParseInt(paras,
                                                                  PersistConst.InputCount);
                    result.OutputCount = SyntFileSection.ParseInt(paras,
                                                                   PersistConst.OutputCount);
                    result.OldAgePenalty = SyntFileSection.ParseDouble(paras,
                                                                        PopulationConst.PropertyOldAgePenalty);
                    result.OldAgeThreshold = SyntFileSection.ParseInt(paras,
                                                                       PopulationConst.PropertyOldAgeThreshold);
                    result.PopulationSize = SyntFileSection.ParseInt(paras,
                                                                      PopulationConst.PropertyPopulationSize);
                    result.SurvivalRate = SyntFileSection.ParseDouble(paras,
                                                                       PopulationConst.PropertySurvivalRate);
                    result.YoungBonusAgeThreshhold = SyntFileSection.ParseInt(
                        paras, PopulationConst.PropertyYoungAgeThreshold);
                    result.YoungScoreBonus = SyntFileSection.ParseDouble(paras,
                                                                          PopulationConst.PropertyYoungAgeBonus);
                    result.TIDGenerate.CurrentID = SyntFileSection.ParseInt(paras,
                                                                                  PopulationConst.
                                                                                      PropertyNextTID);
                    result.InnovationIDGenerate.CurrentID = SyntFileSection.ParseInt(paras,
                                                                                      PopulationConst.
                                                                                          PropertyNextInnovationID);
                    result.GeneIDGenerate.CurrentID = SyntFileSection.ParseInt(paras,
                                                                                PopulationConst.
                                                                                    PropertyNextGeneID);
                    result.SpeciesIDGenerate.CurrentID = SyntFileSection.ParseInt(paras,
                                                                                   PopulationConst.
                                                                                       PropertyNextSpeciesID);
                }
            }

            // now link everything up


            // first put all the Ts into correct species
            foreach (IT T in result.Ts)
            {
                var YT = (YT)T;
                var speciesId = (int)YT.SpeciesID;
                if (speciesMap.ContainsKey(speciesId))
                {
                    ISpecies s = speciesMap[speciesId];
                    s.Members.Add(YT);
                }

                YT.InputCount = result.InputCount;
                YT.OutputCount = result.OutputCount;
            }


            // set the species leader links
            foreach (ISpecies species in leaderMap.Keys)
            {
                int leaderID = leaderMap[species];
                IT leader = TMap[leaderID];
                species.Leader = leader;
                ((BasicSpecies)species).Population = result;
            }

            return result;
        }

        /// <summary>
        /// Save the object.
        /// </summary>
        /// <param name="os">The stream to write to.</param>
        /// <param name="obj">The object to save.</param>
        public virtual void Save(Stream os, Object obj)
        {
            var xout = new SyntWriteHelper(os);
            var pop = (YPopulation)obj;
            xout.AddSection("Y-POPULATION");
            xout.AddSubSection("CONFIG");
            xout.WriteProperty(PersistConst.Snapshot, pop.Snapshot);
            xout.WriteProperty(YPopulation.PropertyOutputActivation,
                               pop.OutputActivationFunction);
            xout.WriteProperty(YPopulation.PropertyYActivation,
                               pop.YActivationFunction);
            xout.WriteProperty(PersistConst.InputCount, pop.InputCount);
            xout.WriteProperty(PersistConst.OutputCount, pop.OutputCount);
            xout.WriteProperty(PopulationConst.PropertyOldAgePenalty,
                               pop.OldAgePenalty);
            xout.WriteProperty(PopulationConst.PropertyOldAgeThreshold,
                               pop.OldAgeThreshold);
            xout.WriteProperty(PopulationConst.PropertyPopulationSize,
                               pop.PopulationSize);
            xout.WriteProperty(PopulationConst.PropertySurvivalRate,
                               pop.SurvivalRate);
            xout.WriteProperty(PopulationConst.PropertyYoungAgeThreshold,
                               pop.YoungBonusAgeThreshold);
            xout.WriteProperty(PopulationConst.PropertyYoungAgeBonus,
                               pop.YoungScoreBonus);
            xout.WriteProperty(PopulationConst.PropertyNextTID, pop.TIDGenerate.CurrentID);
            xout.WriteProperty(PopulationConst.PropertyNextInnovationID, pop.InnovationIDGenerate.CurrentID);
            xout.WriteProperty(PopulationConst.PropertyNextGeneID, pop.GeneIDGenerate.CurrentID);
            xout.WriteProperty(PopulationConst.PropertyNextSpeciesID, pop.SpeciesIDGenerate.CurrentID);
            xout.AddSubSection("INNOVATIONS");
            if (pop.Innovations != null)
            {
                foreach (IInnovation innovation in pop.Innovations.Innovations)
                {
                    var YInnovation = (YInnovation)innovation;
                    xout.AddColumn(YInnovation.InnovationID);
                    xout.AddColumn(InnovationTypeToString(YInnovation.InnovationType));
                    xout.AddColumn(NeuronTypeToString(YInnovation.NeuronType));
                    xout.AddColumn(YInnovation.SplitX);
                    xout.AddColumn(YInnovation.SplitY);
                    xout.AddColumn(YInnovation.NeuronID);
                    xout.AddColumn(YInnovation.FromNeuronID);
                    xout.AddColumn(YInnovation.ToNeuronID);
                    xout.WriteLine();
                }
            }
            xout.AddSubSection("TS");

            foreach (IT T in pop.Ts)
            {
                var YT = (YT)T;
                xout.AddColumn("g");
                xout.AddColumn(YT.TID);
                xout.AddColumn(YT.SpeciesID);
                xout.AddColumn(YT.AdjustedScore);
                xout.AddColumn(YT.AmountToSpawn);
                xout.AddColumn(YT.NetworkDepth);
                xout.AddColumn(YT.Score);
                xout.WriteLine();


                foreach (IGene neuronGene in YT.Neurons.Genes)
                {
                    var YNeuronGene = (YNeuronGene)neuronGene;
                    xout.AddColumn("n");
                    xout.AddColumn(YNeuronGene.Id);
                    xout.AddColumn(NeuronTypeToString(YNeuronGene.NeuronType));
                    xout.AddColumn(YNeuronGene.Enabled);
                    xout.AddColumn(YNeuronGene.InnovationId);
                    xout.AddColumn(YNeuronGene.ActivationResponse);
                    xout.AddColumn(YNeuronGene.SplitX);
                    xout.AddColumn(YNeuronGene.SplitY);
                    xout.WriteLine();
                }

                foreach (IGene linkGene in YT.Links.Genes)
                {
                    var YLinkGene = (YLinkGene)linkGene;
                    xout.AddColumn("l");
                    xout.AddColumn(YLinkGene.Id);
                    xout.AddColumn(YLinkGene.Enabled);
                    xout.AddColumn(YLinkGene.Recurrent);
                    xout.AddColumn(YLinkGene.FromNeuronID);
                    xout.AddColumn(YLinkGene.ToNeuronID);
                    xout.AddColumn(YLinkGene.Weight);
                    xout.AddColumn(YLinkGene.InnovationId);
                    xout.WriteLine();
                }
            }
            xout.AddSubSection("SPECIES");

            foreach (ISpecies species in pop.Species)
            {
                xout.AddColumn(species.SpeciesID);
                xout.AddColumn(species.Age);
                xout.AddColumn(species.BestScore);
                xout.AddColumn(species.GensNoImprovement);
                xout.AddColumn(species.NumToSpawn);
                xout.AddColumn(species.SpawnsRequired);
                xout.AddColumn(species.Leader.TID);
                xout.WriteLine();
            }
            xout.Flush();
        }

        /// <summary>
        /// The file version.
        /// </summary>
        public virtual int FileVersion
        {
            get { return 1; }
        }

        #endregion

        /// <summary>
        /// Convert the neuron type to a string.
        /// </summary>
        /// <param name="t">The neuron type.</param>
        /// <returns>The string.</returns>
        public static String NeuronTypeToString(YNeuronType t)
        {
            switch (t)
            {
                case YNeuronType.Bias:
                    return ("b");
                case YNeuronType.Hidden:
                    return ("h");
                case YNeuronType.Input:
                    return ("i");
                case YNeuronType.None:
                    return ("n");
                case YNeuronType.Output:
                    return ("o");
                default:
                    return null;
            }
        }

        /// <summary>
        /// Convert the innovation type to a string.
        /// </summary>
        /// <param name="t">The innovation type.</param>
        /// <returns>The string.</returns>
        public static String InnovationTypeToString(YInnovationType t)
        {
            switch (t)
            {
                case YInnovationType.NewLink:
                    return "l";
                case YInnovationType.NewNeuron:
                    return "n";
                default:
                    return null;
            }
        }

        /// <summary>
        /// Convert a string to an innovation type.
        /// </summary>
        /// <param name="t">The string to convert.</param>
        /// <returns>The innovation type.</returns>
        public static YInnovationType StringToInnovationType(String t)
        {
            if (t.Equals("l", StringComparison.InvariantCultureIgnoreCase))
            {
                return YInnovationType.NewLink;
            }
            if (t.Equals("n", StringComparison.InvariantCultureIgnoreCase))
            {
                return YInnovationType.NewNeuron;
            }
            return default(YInnovationType) /* was: null */;
        }

        /// <summary>
        /// Convert a string to a neuron type.
        /// </summary>
        /// <param name="t">The string.</param>
        /// <returns>The resulting neuron type.</returns>
        public static YNeuronType StringToNeuronType(String t)
        {
            if (t.Equals("b"))
            {
                return YNeuronType.Bias;
            }
            if (t.Equals("h"))
            {
                return YNeuronType.Hidden;
            }
            if (t.Equals("i"))
            {
                return YNeuronType.Input;
            }
            if (t.Equals("n"))
            {
                return YNeuronType.None;
            }
            if (t.Equals("o"))
            {
                return YNeuronType.Output;
            }
            throw new SyntError("Unknonw neuron type: " + t);
        }

        /// <inheritdoc/>
        public Type NativeType
        {
            get { return typeof(YPopulation); }
        }
    }

    public class PersistYNetwork : ISyntPersistor
    {
        #region SyntPersistor Members

        /// <summary>
        /// The file version.
        /// </summary>
        public virtual int FileVersion
        {
            get { return 1; }
        }

        /// <summary>
        /// The persist class string.
        /// </summary>
        public virtual String PersistClassString
        {
            get { return "YNetwork"; }
        }

        /// <summary>
        /// Read the object.
        /// </summary>
        /// <param name="mask0">The stream to read from.</param>
        /// <returns>The loaded object.</returns>
        public virtual Object Read(Stream mask0)
        {
            var result = new YNetwork();
            var ins0 = new SyntReadHelper(mask0);
            SyntFileSection section;
            IDictionary<Int32, YNeuron> neuronMap = new Dictionary<Int32, YNeuron>();

            while ((section = ins0.ReadNextSection()) != null)
            {
                if (section.SectionName.Equals("Y")
                    && section.SubSectionName.Equals("PARAMS"))
                {
                    IDictionary<String, String> paras = section.ParseParams();

                    foreach (String key in paras.Keys)
                    {
                        result.Properties.Add(key, paras[key]);
                    }
                }
                if (section.SectionName.Equals("Y")
                    && section.SubSectionName.Equals("NETWORK"))
                {
                    IDictionary<String, String> p = section.ParseParams();

                    result.InputCount = SyntFileSection.ParseInt(p,
                                                                  PersistConst.InputCount);
                    result.OutputCount = SyntFileSection.ParseInt(p,
                                                                   PersistConst.OutputCount);
                    result.ActivationFunction = SyntFileSection
                        .ParseActivationFunction(p,
                                                 PersistConst.ActivationFunction);
                    result.OutputActivationFunction = SyntFileSection
                        .ParseActivationFunction(p,
                                                 YPopulation.PropertyOutputActivation);
                    result.NetworkDepth = SyntFileSection.ParseInt(p,
                                                                    PersistConst.Depth);
                    result.Snapshot = SyntFileSection.ParseBoolean(p,
                                                                    PersistConst.Snapshot);
                }
                else if (section.SectionName.Equals("Y")
                         && section.SubSectionName.Equals("NEURONS"))
                {
                    foreach (String line in section.Lines)
                    {
                        IList<String> cols = SyntFileSection.SplitColumns(line);

                        long neuronID = Int32.Parse(cols[0]);
                        YNeuronType neuronType = PersistYPopulation
                            .StringToNeuronType(cols[1]);
                        double activationResponse = CSVFormat.EgFormat
                            .Parse(cols[2]);
                        double splitY = CSVFormat.EgFormat
                            .Parse(cols[3]);
                        double splitX = CSVFormat.EgFormat
                            .Parse(cols[4]);

                        var YNeuron = new YNeuron(neuronType,
                                                        neuronID, splitY, splitX, activationResponse);
                        result.Neurons.Add(YNeuron);
                        neuronMap[((int)neuronID)] = (YNeuron);
                    }
                }
                else if (section.SectionName.Equals("Y")
                         && section.SubSectionName.Equals("LINKS"))
                {
                    foreach (String line in section.Lines)
                    {
                        IList<String> cols = SyntFileSection.SplitColumns(line);
                        int fromID = Int32.Parse(cols[0]);
                        int toID = Int32.Parse(cols[1]);
                        bool recurrent = Int32.Parse(cols[2]) > 0;
                        double weight = CSVFormat.EgFormat.Parse(cols[3]);
                        YNeuron fromNeuron = (neuronMap[fromID]);
                        YNeuron toNeuron = (neuronMap[toID]);
                        var YLink = new YLink(weight, fromNeuron,
                                                    toNeuron, recurrent);
                        fromNeuron.OutputboundLinks.Add(YLink);
                        toNeuron.InboundLinks.Add(YLink);
                    }
                }
            }

            return result;
        }

        /// <summary>
        /// Save the object.
        /// </summary>
        /// <param name="os">The output stream.</param>
        /// <param name="obj">The object to save.</param>
        public virtual void Save(Stream os, Object obj)
        {
            var xout = new SyntWriteHelper(os);
            var Y = (YNetwork)obj;
            xout.AddSection("Y");
            xout.AddSubSection("PARAMS");
            xout.AddProperties(Y.Properties);
            xout.AddSubSection("NETWORK");

            xout.WriteProperty(PersistConst.InputCount, Y.InputCount);
            xout.WriteProperty(PersistConst.OutputCount, Y.OutputCount);
            xout.WriteProperty(PersistConst.ActivationFunction,
                               Y.ActivationFunction);
            xout.WriteProperty(YPopulation.PropertyOutputActivation,
                               Y.OutputActivationFunction);
            xout.WriteProperty(PersistConst.Depth, Y.NetworkDepth);
            xout.WriteProperty(PersistConst.Snapshot, Y.Snapshot);

            xout.AddSubSection("NEURONS");

            foreach (YNeuron YNeuron in Y.Neurons)
            {
                xout.AddColumn((int)YNeuron.NeuronID);
                xout.AddColumn(PersistYPopulation.NeuronTypeToString(YNeuron.NeuronType));
                xout.AddColumn(YNeuron.ActivationResponse);
                xout.AddColumn(YNeuron.SplitX);
                xout.AddColumn(YNeuron.SplitY);
                xout.WriteLine();
            }

            xout.AddSubSection("LINKS");

            foreach (YNeuron YNeuron in Y.Neurons)
            {
                foreach (YLink link in YNeuron.OutputboundLinks)
                {
                    WriteLink(xout, link);
                }
            }

            xout.Flush();
        }

        #endregion

        /// <summary>
        /// Write a link.
        /// </summary>
        /// <param name="xout">The output file.</param>
        /// <param name="link">The link.</param>
        private static void WriteLink(SyntWriteHelper xout, YLink link)
        {
            xout.AddColumn((int)link.FromNeuron.NeuronID);
            xout.AddColumn((int)link.ToNeuron.NeuronID);
            xout.AddColumn(link.Recurrent);
            xout.AddColumn(link.Weight);
            xout.WriteLine();
        }

        /// <inheritdoc/>
        public Type NativeType
        {
            get { return typeof(YNetwork); }
        }
    }


    public class PersistCPN : ISyntPersistor
    {
        /// <summary>
        /// The input to instar property.
        /// </summary>
        ///
        internal const String PropertyInputToInstar = "inputToInstar";

        /// <summary>
        /// The instar to input property.
        /// </summary>
        ///
        internal const String PropertyInstarToInput = "instarToInput";

        /// <summary>
        /// The winner count property.
        /// </summary>
        ///
        internal const String PropertyWinnerCount = "winnerCount";

        /// <inheritdoc/>
        public Type NativeType
        {
            get { return typeof(CPNNetwork); }
        }

        #region SyntPersistor Members

        /// <inheritdoc/>
        public int FileVersion
        {
            get { return 1; }
        }


        /// <inheritdoc/>
        public String PersistClassString
        {
            get { return "CPN"; }
        }


        /// <inheritdoc/>
        public Object Read(Stream mask0)
        {
            IDictionary<String, String> networkParams = null;
            var ins0 = new SyntReadHelper(mask0);
            SyntFileSection section;
            int inputCount = 0;
            int instarCount = 0;
            int outputCount = 0;
            int winnerCount = 0;
            Matrix m1 = null;
            Matrix m2 = null;

            while ((section = ins0.ReadNextSection()) != null)
            {
                if (section.SectionName.Equals("CPN")
                    && section.SubSectionName.Equals("PARAMS"))
                {
                    networkParams = section.ParseParams();
                }
                if (section.SectionName.Equals("CPN")
                    && section.SubSectionName.Equals("NETWORK"))
                {
                    IDictionary<String, String> paras = section.ParseParams();

                    inputCount = SyntFileSection.ParseInt(paras,
                                                           PersistConst.InputCount);
                    instarCount = SyntFileSection.ParseInt(paras,
                                                            PersistConst.Instar);
                    outputCount = SyntFileSection.ParseInt(paras,
                                                            PersistConst.OutputCount);
                    winnerCount = SyntFileSection.ParseInt(paras,
                                                            PropertyWinnerCount);
                    m1 = SyntFileSection.ParseMatrix(paras,
                                                      PropertyInputToInstar);
                    m2 = SyntFileSection.ParseMatrix(paras,
                                                      PropertyInstarToInput);
                }
            }

            var result = new CPNNetwork(inputCount, instarCount, outputCount,
                                        winnerCount);
            EngineArray.PutAll(networkParams, result.Properties);
            result.WeightsInputToInstar.Set(m1);
            result.WeightsInstarToOutstar.Set(m2);
            return result;
        }

        /// <inheritdoc/>
        public void Save(Stream os, Object obj)
        {
            var xout = new SyntWriteHelper(os);
            var cpn = (CPNNetwork)obj;
            xout.AddSection("CPN");
            xout.AddSubSection("PARAMS");
            xout.AddProperties(cpn.Properties);
            xout.AddSubSection("NETWORK");

            xout.WriteProperty(PersistConst.InputCount, cpn.InputCount);
            xout.WriteProperty(PersistConst.Instar, cpn.InstarCount);
            xout.WriteProperty(PersistConst.OutputCount, cpn.OutputCount);
            xout.WriteProperty(PropertyInputToInstar,
                               cpn.WeightsInputToInstar);
            xout.WriteProperty(PropertyInstarToInput,
                               cpn.WeightsInstarToOutstar);
            xout.WriteProperty(PropertyWinnerCount, cpn.WinnerCount);

            xout.Flush();
        }

        #endregion
    }

    public class PopulationConst
    {
        /// <summary>
        /// Property tag for the next gene id.
        /// </summary>
        ///
        public const String PropertyNextGeneID = "nextGeneID";

        /// <summary>
        /// Property tag for the next T id.
        /// </summary>
        ///
        public const String PropertyNextTID = "nextTID";

        /// <summary>
        /// Property tag for the next innovation id.
        /// </summary>
        ///
        public const String PropertyNextInnovationID = "nextInnovationID";

        /// <summary>
        /// Property tag for the next species id.
        /// </summary>
        ///
        public const String PropertyNextSpeciesID = "nextSpeciesID";

        /// <summary>
        /// Property tag for the old age penalty.
        /// </summary>
        ///
        public const String PropertyOldAgePenalty = "oldAgePenalty";

        /// <summary>
        /// Property tag for the old age threshold.
        /// </summary>
        ///
        public const String PropertyOldAgeThreshold = "oldAgeThreshold";

        /// <summary>
        /// Property tag for the population size.
        /// </summary>
        ///
        public const String PropertyPopulationSize = "populationSize";

        /// <summary>
        /// Property tag for the survival rate.
        /// </summary>
        ///
        public const String PropertySurvivalRate = "survivalRate";

        /// <summary>
        /// Property tag for the young age bonus.
        /// </summary>
        ///
        public const String PropertyYoungAgeBonus = "youngAgeBonus";

        /// <summary>
        /// Property tag for the young age threshold.
        /// </summary>
        ///
        public const String PropertyYoungAgeThreshold = "youngAgeThreshold";

        /// <summary>
        /// Property tag for the Ts collection.
        /// </summary>
        ///
        public const String PropertyTs = "Ts";

        /// <summary>
        /// Property tag for the innovations collection.
        /// </summary>
        ///
        public const String PropertyInnovations = "innovations";

        /// <summary>
        /// Property tag for the species collection.
        /// </summary>
        ///
        public const String PropertySpecies = "species";
    }

    [Serializable]
    public class BasicSpecies : ISpecies
    {
        /// <summary>
        /// The list of Ts.
        /// </summary>
        ///
        private readonly IList<IT> _members;

        /// <summary>
        /// The age of this species.
        /// </summary>
        ///
        private int _age;

        /// <summary>
        /// The best score.
        /// </summary>
        ///
        private double _bestScore;

        /// <summary>
        /// The number of generations with no improvement.
        /// </summary>
        ///
        private int _gensNoImprovement;

        /// <summary>
        /// The leader.
        /// </summary>
        ///
        private IT _leader;

        /// <summary>
        /// The id of the leader.
        /// </summary>
        [NonSerialized]
        private long _leaderID;

        /// <summary>
        /// The owner class.
        /// </summary>
        ///
        private IPopulation _population;

        /// <summary>
        /// The number of spawns required.
        /// </summary>
        ///
        private double _spawnsRequired;

        /// <summary>
        /// The species id.
        /// </summary>
        ///
        private long _speciesID;

        /// <summary>
        /// Default constructor, used mainly for persistence.
        /// </summary>
        ///
        public BasicSpecies()
        {
            _members = new List<IT>();
        }

        /// <summary>
        /// Construct a species.
        /// </summary>
        ///
        /// <param name="thePopulation">The population the species belongs to.</param>
        /// <param name="theFirst">The first T in the species.</param>
        /// <param name="theSpeciesID">The species id.</param>
        public BasicSpecies(IPopulation thePopulation, IT theFirst,
                            long theSpeciesID)
        {
            _members = new List<IT>();
            _population = thePopulation;
            _speciesID = theSpeciesID;
            _bestScore = theFirst.Score;
            _gensNoImprovement = 0;
            _age = 0;
            _leader = theFirst;
            _spawnsRequired = 0;
            _members.Add(theFirst);
        }

        /// <value>the population to set</value>
        public IPopulation Population
        {
            get { return _population; }
            set { _population = value; }
        }

        /// <summary>
        /// Set the leader id. This value is not persisted, it is used only for
        /// loading.
        /// </summary>
        ///
        /// <value>the leaderID to set</value>
        public long TempLeaderID
        {
            get { return _leaderID; }
            set { _leaderID = value; }
        }

        #region ISpecies Members

        /// <summary>
        /// Calculate the amount to spawn.
        /// </summary>
        ///
        public void CalculateSpawnAmount()
        {
            _spawnsRequired = 0;

            foreach (IT T in _members)
            {
                _spawnsRequired += T.AmountToSpawn;
            }
        }

        /// <summary>
        /// Choose a parent to mate. Choose from the population, determined by the
        /// survival rate. From this pool, a random parent is chosen.
        /// </summary>
        ///
        /// <returns>The parent.</returns>
        public IT ChooseParent()
        {
            IT baby;

            // If there is a single member, then choose that one.
            if (_members.Count == 1)
            {
                baby = _members[0];
            }
            else
            {
                // If there are many, then choose the population based on survival
                // rate
                // and select a random T.
                int maxIndexSize = (int)(_population.SurvivalRate * _members.Count) + 1;
                var theOne = (int)RangeRandomizer.Randomize(0, maxIndexSize);
                baby = _members[theOne];
            }

            return baby;
        }

        /// <summary>
        /// Set the age of this species.
        /// </summary>
        ///
        /// <value>The age of this species.</value>
        public int Age
        {
            get { return _age; }
            set { _age = value; }
        }


        /// <summary>
        /// Set the best score.
        /// </summary>
        ///
        /// <value>The best score.</value>
        public double BestScore
        {
            get { return _bestScore; }
            set { _bestScore = value; }
        }


        /// <summary>
        /// Set the number of generations with no improvement.
        /// </summary>
        ///
        /// <value>The number of generations.</value>
        public int GensNoImprovement
        {
            get { return _gensNoImprovement; }
            set { _gensNoImprovement = value; }
        }


        /// <summary>
        /// Set the leader.
        /// </summary>
        ///
        /// <value>The new leader.</value>
        public IT Leader
        {
            get { return _leader; }
            set { _leader = value; }
        }


        /// <value>The members of this species.</value>
        public IList<IT> Members
        {
            get { return _members; }
        }


        /// <value>The number to spawn.</value>
        public double NumToSpawn
        {
            get { return _spawnsRequired; }
        }


        /// <summary>
        /// Set the number of spawns required.
        /// </summary>
        public double SpawnsRequired
        {
            get { return _spawnsRequired; }
            set { _spawnsRequired = value; }
        }


        /// <summary>
        /// Purge all members, increase age by one and count the number of
        /// generations with no improvement.
        /// </summary>
        ///
        public void Purge()
        {
            _members.Clear();
            _age++;
            _gensNoImprovement++;
            _spawnsRequired = 0;
        }

        /// <summary>
        /// Set the species id.
        /// </summary>
        public long SpeciesID
        {
            get { return _speciesID; }
            set { _speciesID = value; }
        }

        #endregion
    }

    public static class SyntesisSVMProblem
    {
        /// <summary>
        /// Syntesis the Synt dataset.
        /// </summary>
        ///
        /// <param name="training">The training data.</param>
        /// <param name="outputIndex"></param>
        /// <returns>The SVM problem.</returns>
        public static svm_problem Syntesis(IMLDataSet training,
                                         int outputIndex)
        {
            try
            {
                var result = new svm_problem { l = (int)training.Count };

                result.y = new double[result.l];
                result.x = new svm_node[result.l][];
                for (int i = 0; i < result.l; i++)
                {
                    result.x[i] = new svm_node[training.InputSize];
                }

                int elementIndex = 0;


                foreach (IMLDataPair pair in training)
                {
                    IMLData input = pair.Input;
                    IMLData output = pair.Ideal;
                    result.x[elementIndex] = new svm_node[input.Count];

                    for (int i = 0; i < input.Count; i++)
                    {
                        result.x[elementIndex][i] = new svm_node { index = i + 1, value_Renamed = input[i] };
                    }

                    result.y[elementIndex] = output[outputIndex];

                    elementIndex++;
                }

                return result;
            }
            catch (OutOfMemoryException)
            {
                throw new SyntError("SVM Model - Out of Memory");
            }
        }
    }

    public class BasicNeuralDataSet : BasicMLDataSet, INeuralDataSet
    {
        /// <summary>
        /// Construct a data set from input and ideal.
        /// </summary>
        /// <param name="input">The input data.</param>
        /// <param name="ideal">The ideal data.</param>
        public BasicNeuralDataSet(double[][] input, double[][] ideal)
            : base(input, ideal)
        {
        }
    }
}